Microsoft chief executive Steve Ballmer is expecting 2013 to be one of the company's busiest years, but he's not yet ready to start talking about Windows 8 and Surface sales.In an interview with The Wall Street Journal, Ballmer said that in terms of Windows 8 and Surface sales for the first few days, "there's not really much that's interesting to report."On any ordinary day, that probably would've plunged stock price by a good few percent. So, whether or not Ballmer is playing his cards close to his chest, preparing for some big reveal later, or sales haven't been all that interesting, it remains to be seen.Ballmer went on to say: "If you were to call the retailers, they would say, 'Hey, off to a very good start'." and that, "we're out of stock [in] a lot of places on touch-[screen] machines".Reading between the lines, and putting this together with what I've been hearing from the supply chain and the OEMs, I think that Microsoft has decided to play to safe with Surface and keep the initial order modest. It's better to sell out of tablets, and keep the customers wanting more, than it is to end up will millions gathering dust and have to have a frantic fire sale down the line -- such as the one that HP ended up having with the TouchPad.As for Windows 8, I have to say that this is the most subdued Windows launch that I can recall. The buzz doesn't seem to be there, and instead it's been replaced by confusion over pricing, hardware requirements, and the whole issue of touch. There also seems to be a great deal of confusion over the differences between Windows 8 and Windows RT, specifically nobody quite knows what the latter is even for.This much consumer confusion at the point of release seems to suggest that the industry -- specifically Microsoft and its hardware partners -- have not done a good enough job of educating the masses about Windows 8.We'll have to wait until Microsoft unveils financial details for this quarter to see if this had a negative effect on sales.San Francisco - The Electronic Frontier Foundation (EFF) won renewal of critical exemptions to the Digital Millennium Copyright Act (DMCA) in a ruling published today, including the upholding of jailbreaking rights for smartphones as well as new and expanded legal protections for video remixing."The DMCA creates a cloud of legal uncertainty over American consumers â€“ whether they are tinkerers, artists, or just looking to make their gadgets work better," said EFF Intellectual Property Director Corynne McSherry. "The ruling from the Copyright Office today goes a long way towards mitigating some of the DMCA's most grievous harms."Crucial support for the successful request on behalf of video remix artists â€“ carving out new legal protection for this important art form â€“ was provided by the Organization for Transformative Works (OTW). The OTW gathered evidence and presented testimony about the DMCA's adverse impact on several communities of remix creators, who use short clips from movies to build new creative works. The Copyright Office's decision broadens EFF's previously successful exemption request, which allows for taking short excerpts from DVDs in creating noncommercial works, by also protecting the use of clips from online streaming or downloading services."Remix videos are thriving on YouTube and other sites, offering dynamic criticism and commentary on popular movies as well as popular culture. It's a great example of how new technologies foster free expression, yet the anti-circumvention provisions of the DMCA endanger these important works," said McSherry. "We're thrilled that the Copyright Office broke new ground in protecting remix artists. We can't let misguided federal law block a new form of art and expression."The Copyright Office also renewed EFF's exemption request that protects smartphone jailbreaking, liberating phone owners to run operating systems and applications from any source, not just those approved by the manufacturer. However, the Copyright Office declined to expand that exemption to tablets and video game consoles, arguing that the category of "tablets" is not well defined and that jailbreaking video game consoles might lead to more copyright infringement."If you bought your gadget, you own it, and you should be able to install whatever software you please without facing potential legal threats," said EFF Senior Staff Attorney Marcia Hofmann. "We're pleased the Copyright Office renewed our smartphone jailbreaking exemption request, but we're disappointed that it couldn't see that consumers deserve the same rights for all the gadgets they own. We'll be back with more exemption requests in the next rulemaking, and we're hopeful the Copyright Office will keep moving in the right direction."The Copyright Office's rulemaking process is conducted every three years in order to mitigate the danger the DMCA poses to legitimate, non-infringing uses of copyrighted materials. The DMCA prohibits "circumventing" digital rights management (DRM) and "other technical protection measures" used to control access to copyrighted works. While the DMCA still chills competition, free speech, and fair use, today's exemptions help give consumers and artists protection from the law's extensive reach.EFF would like to acknowledge the invaluable assistance of the Samuelson Law, Technology & Public Policy Clinic at the University of California, Berkeley, in drafting the jailbreaking exemption requests.For the full ruling from the copyright office:https://www.eff.org/node/72131For more on our exemption requests:https://www.eff.org/cases/2012-dmca-rulemakingThe Advanced Research Projects Agency Network (ARPANET) was the world's first operational packet switching network and the progenitor of what was to become the global Internet. The network was initially funded by the Advanced Research Projects Agency (ARPA, later DARPA) within the U.S. Department of Defense for use by its projects at universities and research laboratories in the US. The packet switching of the ARPANET was based on designs by British scientist Donald Davies and Lawrence Roberts of the Lincoln Laboratory.Packet switching, today the dominant basis for data communications worldwide, was a new concept at the time of the conception of the ARPANET. Prior to the advent of packet switching, both voice and data communications had been based on the idea of circuit switching, as in the traditional telephone circuit, wherein each telephone call is allocated a dedicated, end to end, electronic connection between the two communicating stations. Such stations might be telephones or computers. The (temporarily) dedicated line is typically composed of many intermediary lines which are assembled into a chain that stretches all the way from the originating station to the destination station. With packet switching, a data system could use a single communications link to communicate with more than one machine by collecting data into datagrams and transmitting these as packets onto the attached network link, as soon as the link becomes idle. Thus, not only can the link be shared, much as a single post box can be used to post letters to different destinations, but each packet can be routed independently of other packets.The earliest ideas for a computer network intended to allow general communications among computer users were formulated by computer scientist J. C. R. Licklider, of Bolt, Beranek and Newman (BBN), in August 1962, in memoranda discussing his concept for an "Intergalactic Computer Network". Those ideas contained almost everything that composes the contemporary Internet. In October 1963, Licklider was appointed head of the Behavioral Sciences and Command and Control programs at the Defense Department's Advanced Research Projects Agency â€” ARPA (the initial ARPANET acronym). He then convinced Ivan Sutherland and Bob Taylor that this computer network concept was very important and merited development, although Licklider left ARPA before any contracts were let that worked on this concept.Ivan Sutherland and Bob Taylor continued their interest in creating such a computer communications network, in part, to allow ARPA-sponsored researchers at various corporate and academic locales to put to use the computers ARPA was providing them, and, in part, to make new software and other computer science results quickly and widely available. In his office, Taylor had three computer terminals, each connected to separate computers, which ARPA was funding: the first, for the System Development Corporation (SDC) Q-32, in Santa Monica; the second, for Project Genie, at the University of California, Berkeley; and the third, for Multics, at MIT. Taylor recalls the circumstance: "For each of these three terminals, I had three different sets of user commands. So, if I was talking online with someone at S.D.C., and I wanted to talk to someone I knew at Berkeley, or M.I.T., about this, I had to get up from the S.D.C. terminal, go over and log into the other terminal and get in touch with them. I said, "Oh Man!", it's obvious what to do: If you have these three terminals, there ought to be one terminal that goes anywhere you want to go. That idea is the ARPANET". Somewhat contemporaneously, several other people had (mostly independently) worked out the aspects of "packet switching", with the first public demonstration presented by the National Physical Laboratory (NPL), on 5 August 1968, in the United Kingdom.By mid-1968, Taylor had prepared a complete plan for a computer network, and, after ARPA's approval, a Request for Quotation (RFQ) was sent to 140 potential bidders. Most computer science companies regarded the ARPAâ€“Taylor proposal as outlandish, and only twelve submitted bids to build the network; of the twelve, ARPA regarded only four as top-rank contractors. At year's end, ARPA considered only two contractors, and awarded the contract to build the network to BBN Technologies on 7 April 1969. The initial, seven-man BBN team were much aided by the technical specificity of their response to the ARPA RFQ â€“ and thus quickly produced the first working computers. This team was led by Frank Heart. The BBN-proposed network closely followed Taylor's ARPA plan: a network composed of small computers called Interface Message Processors (IMPs), that functioned as gateways (today called routers) interconnecting local resources. At each site, the IMPs performed store-and-forward packet switching functions, and were interconnected with modems that were connected to leased lines, initially running at 50kbit/second. The host computers were connected to the IMPs via custom serial communication interfaces. The system, including the hardware and the packet switching software, was designed and installed in nine months.The first-generation IMPs were initially built by BBN Technologies using a rugged computer version of the Honeywell DDP-516 computer configured with 24kB of expandable core memory, and a 16-channel Direct Multiplex Control (DMC) direct memory access unit. The DMC established custom interfaces with each of the host computers and modems. In addition to the front-panel lamps, the DDP-516 computer also features a special set of 24 indicator-lamps showing the status of the IMP communication channels. Each IMP could support up to four local hosts, and could communicate with up to six remote IMPs via leased lines.Common ARPANET lore posits that the computer network was designed to survive a nuclear attack. In A Brief History of the Internet, the Internet Society describes the coalescing of the technical ideas that produced the ARPANET:Although the ARPANET was designed to survive subordinate-network losses, the principal reason was that the switching nodes and network links were unreliable, even without any nuclear attacks. About the resource scarcity that spurred the creation of the ARPANET, Charles Herzfeld, ARPA Director (1965â€“1967), said:Packet switching pioneer Paul Baran affirms this, explaining: "Bob Taylor had a couple of computer terminals speaking to different machines, and his idea was to have some way of having a terminal speak to any of them and have a network. That's really the origin of the ARPANET. The method used to connect things together was an open issue for a time."The initial ARPANET consisted of four IMPs:The first message on the ARPANET was sent by UCLA student programmer Charley Kline, at 10:30Â pm on 29 October 1969, from Boelter Hall 3420. Kline transmitted from the university's SDS Sigma 7 Host computer to the Stanford Research Institute's SDS 940 Host computer. The message text was the word login; the l and the o letters were transmitted, but the system then crashed. Hence, the literal first message over the ARPANET was lo. About an hour later, having recovered from the crash, the SDS Sigma 7 computer effected a full login. The first permanent ARPANET link was established on 21 November 1969, between the IMP at UCLA and the IMP at the Stanford Research Institute. By 5 December 1969, the entire four-node network was established.In March 1970, the ARPANET reached the East Coast of the United States, when an IMP at BBN in Cambridge, Massachusetts was connected to the network. Thereafter, the ARPANET grew: 9 IMPs by June 1970 and 13 IMPs by December 1970, then 18 by September 1971 (when the network included 23 university and government hosts); 29 IMPs by August 1972, and 40 by September 1973. By June 1974, there were 46 IMPs, and in July 1975, the network numbered 57 IMPs. By 1981, the number was 213 host computers, with another host connecting approximately every twenty days.In 1973 a transatlantic satellite link connected the Norwegian Seismic Array (NORSAR) to the ARPANET, making Norway the first country outside the US to be connected to the network. At about the same time a terrestrial circuit added a London IMP.In 1975, the ARPANET was declared "operational". The Defense Communications Agency took control since ARPA was intended to fund advanced research.In 1983, the ARPANET was split with U.S. military sites on their own Military Network (MILNET) for unclassified defense department communications. The combination was called the Defense Data Network (DDN). Separating the civil and military networks reduced the 113-node ARPANET by 68 nodes. Gateways relayed electronic mail between the two networks. MILNET later became the NIPRNet.Because of its government ties, certain forms of traffic were discouraged or prohibited. A 1982 handbook on computing at MIT's AI Lab stated regarding network etiquette:Support for inter-IMP circuits of up to 230.4 kbit/s was added in 1970, although considerations of cost and IMP processing power meant this capability was not actively used.1971 saw the start of the use of the non-ruggedized (and therefore significantly lighter) Honeywell 316 as an IMP. It could also be configured as a Terminal Interface Processor (TIP), which provided terminal server support for up to 63 ASCII serial terminals through a multi-line controller in place of one of the hosts. The 316 featured a greater degree of integration than the 516, which made it less expensive and easier to maintain. The 316 was configured with 40 kB of core memory for a TIP. The size of core memory was later increased, to 32 kB for the IMPs, and 56 kB for TIPs, in 1973.In 1975, BBN introduced IMP software running on the Pluribus multi-processor. These appeared in a small number of sites. In 1981, BBN introduced IMP software running on its own C/30 processor product.In 1983, TCP/IP protocols replaced NCP as the ARPANET's principal protocol, and the ARPANET then became one subnet of the early Internet.The original IMPs and TIPs were phased out as the ARPANET was shut down after the introduction of the NSFNet, but some IMPs remained in service as late as 1989.The ARPANET Completion Report, jointly published by BBN and ARPA, concludes that:In the wake of ARPANET being formally decommissioned on 28 February 1990, Vinton Cerf wrote the following lamentation, entitled "Requiem of the ARPANET":Senator Albert Gore, Jr. began to craft the High Performance Computing and Communication Act of 1991 (commonly referred to as "The Gore Bill") after hearing the 1988 report toward a National Research Network submitted to Congress by a group chaired by Leonard Kleinrock, professor of computer science at UCLA. The bill was passed on 9 December 1991 and led to the National Information Infrastructure (NII) which Al Gore called the "information superhighway". ARPANET was the subject of two IEEE Milestones, both dedicated in 2009.The starting point for host-to-host communication on the ARPANET in 1969 was the 1822 protocol, which defined the transmission of messages to an IMP. The message format was designed to work unambiguously with a broad range of computer architectures. An 1822 message essentially consisted of a message type, a numeric host address, and a data field. To send a data message to another host, the transmitting host formatted a data message containing the destination host's address and the data message being sent, and then transmitted the message through the 1822 hardware interface. The IMP then delivered the message to its destination address, either by delivering it to a locally connected host, or by delivering it to another IMP. When the message was ultimately delivered to the destination host, the receiving IMP would transmit a Ready for Next Message (RFNM) acknowledgement to the sending, host IMP.Unlike modern Internet datagrams, the ARPANET was designed to reliably transmit 1822 messages, and to inform the host computer when it loses a message; the contemporary IP is unreliable, whereas the TCP is reliable. Nonetheless, the 1822 protocol proved inadequate for handling multiple connections among different applications residing in a host computer. This problem was addressed with the Network Control Program (NCP), which provided a standard method to establish reliable, flow-controlled, bidirectional communications links among different processes in different host computers. The NCP interface allowed application software to connect across the ARPANET by implementing higher-level communication protocols, an early example of the protocol layering concept incorporated to the OSI model.In 1983, TCP/IP protocols replaced NCP as the ARPANET's principal protocol, and the ARPANET then became one component of the early Internet.NCP provided a standard set of network services that could be shared by several applications running on a single host computer. This led to the evolution of application protocols that operated, more or less, independently of the underlying network service. When the ARPANET migrated to the Internet protocols in 1983, the major application protocols migrated with it.Â­The Supreme Court is scheduled to hear arguments today in a case called Kirtsaeng v. Wiley, and their final decision could help shape the future of "first sale," a legal doctrine that underpins the right to sell, lend, or give away the things you buy, even if those things contain copyrighted elements.First sale provides the legal framework for marketplaces like used bookstores, flea markets, garage sales, and eBay. Itâ€™s crucial to making sure U.S. copyright holders canâ€™t dictate, for decades, what you do with the books, CDs, DVDs, games, etc., that you buy. But book publisher Wiley says it doesnâ€™t apply if the copyright holder is clever enough to ensure the product in question is manufactured outside of the United States.The Kirtsaeng case specifically deals with textbooks, but the Courtâ€™s decision is likely to affect a range of markets and consumers. First, many of the goods that people purchase every day are manufactured overseas and have some components or logos on the packaging that are subject to copyright law. In fact, the Swiss watchmaker Omega successfully sued Costco for copyright infringement because the retailer was reselling genuine Omega watches, purchased abroad, that happened to have the Omega logo on them. Second, if the Supreme Court rules in Wileyâ€™s favor, U.S. copyright holders will likely ensure that as many of their works as possible are manufactured outside the United States, so that they, too, can escape that pesky first sale doctrine.This dispute, however, is still just a skirmish in a larger battle to protect your right to actually own the things you buy. The first sale doctrine has long been a thorn in the side of many copyright holders, because it limits their ability to profit from and control secondary markets. In fact, attempts to lock down works after you purchase them extend back at least 100 years, when some publishers tried to set a minimum price at which you could resell their books. In more recent times, the problem has only gotten worse, with record labels attempting to restrict people's rights with "promotional" CDs to movie studios going after automated DVD rental services. Thankfully, Congress, the courts, and the market have repeatedly rejected those efforts.So big media has embraced an alternative approach: bypass the first sale doctrine by recasting every sale as a mere license agreement. That ebook you bought? Licensed. That MP3? Licensed. And these end-user license agreements, or EULAs, donâ€™t just prevent resale â€” they impose a variety of onerous terms of use as a condition of clicking the "buy" button for digital works sold online. It's an attempt to chip away at the rights consumers have long enjoyed in order to protect a legacy business model. That means the fight for first sale is also a fight against the proliferation of EULAs.It's good that the Supreme Court is hearing Kirtsaeng this term â€” in fact, we joined a brief encouraging them to â€” but the story isn't necessarily over once the decision comes down. The next step might be for Congress to respond with legislation. If so, they need to know what consumers think: if it looks like a sale and feels like a sale, it's a sale, with all the accompanying rights and privileges. We're joining our friends at Demand Progress in giving you tools to ask your Congressmembers to defend your rights in your digital goods.We know how vigorous the copyright industry lobby is about pushing for laws in their favor, even when they're against the public interest. It's important we let Congress know now that we want to see first sale alive and well and protecting our rights in the things we buy, even if they are digital goods and the sale is labeled a license.If the copyright industry has its way, you may have to seek permission or face penalties when you resell or tinker with the things you've bought. And if that comes to pass, then we've all been owned.EFF is teaming up with Demand Progress and Free Software Foundation to raise awareness about this issue and fight back. Please show your support by embedding this graphic into your website or replacing your social media avatar:It's easy! Just copy and paste this code into the HTML of your site:<a href="https://eff.org/r.a7pC"><img src="https://eff.org/files/owned.jpg" alt="You've Been Owned: Stand Up For Digital First Sale" /></a><br/>And visit our action center to tell Congress to defend your rights to do what you want with the digital goods you paid for.Doctors use different standards to judge scientific research depending on who funded it. They judge research funded by industry as less rigorous, have less confidence in the results, and are less likely to prescribe new drugs than when the funding source is either the NIH or unknown â€“ even when the apparent quality of the research is the same.Those were the results of a study published by Harvard researchers Dr. Aaron Kesselheim and colleagues in the New England Journal of Medicine last month. The story has received a fair amount of coverage since then, including being analyzed by theÂ Scientific AmericanGuest Blog, the Los Angeles Times, and the New York Times.Thereâ€™s a question of ethical and practical relevance embedded in this: is it justifiable to judge a paper by its author or funding source â€“ even when you cannot discern a difference in quality?The perspective from much of the medical side seems to be a definite yes. The divide between doctors and so-called â€œBig Pharmaâ€? is nothing new. Pharma has a bad reputation in the medical community, and there is history to back it. One of the most well-known scandals involved Vioxx being taken off the market in 2004 after Merck admitted it withheld information about known adverse risk of heart disease, resulting in tens of thousands of deaths. In 2008, physician and former Editor in Chief of the New England Journal of Medicine Marcia Angell wrote, â€œBias in the way industry-sponsored research is conducted and reported is not unusual and by no means limited to Merck.â€? In 2011, Harriet Washington published a piece inÂ The American Scholar highlighting some of the ways industry has misled and manipulated data, which include: comparing a new drug against a placebo rather than against another treatment option, comparing drugs to competitors in wrong dosages, pairing a drug with one known to work well, ending a trial prematurely when they see â€œclues that the trial is going south,â€? and cherry-picking only positive findings to report. This type of behavior can and should be called out as scientific misconduct, and those who commit it must be held accountable.But if thereâ€™s something just a bit unsavory about judging a paper solely by who wrote it, thereâ€™s good reason for it. The scientific world prides itself on judging content of ideas, not presumed integrity of authors. Itâ€™s the rationale behind the widespread practice of research journals blinding reviewers of authorsâ€™ names. Using any criteria other than quality in scientific evaluation is admittedly a kind of bias â€“ something we are usually quite wary of in science. As the authors of the study succinctly put it, â€œThe methodologic rigor of a trial, not its funding disclosure, should be a primary determinant of its credibility.â€? Moreover, if weâ€™re comfortable using authorship as a proxy for quality, itâ€™s not an absurd leap to start extending that approach to authors outside of industry. Itâ€™s not uncommon to hear accusations of industry bias because of self-interest in financial gain; but imagine if we started hearing sweeping accusations that young researchers, for example, should be trusted less because of their self-interest in trying to advance their careers. Industry is not alone in being capable of bias. The problem of publishing only positive results, for instance, is a recognized problem that has been discussed in the scientific community at large for years.There are also practical concerns of being overly dismissive of industry. Amidst the history of manipulation and fraud, there are medical contributions too. In the New York Times, surgeon and author Pauline Chen cited data showing thatÂ industry was responsible for nearly 60 percent of the more than $100 billion spent on research in 2007. Using authorship ties as a proxy for quality means possibly overlooking research of potential value for patients.So why not just use quality, removing the need to probe into researchersâ€™ background, affiliations, and motivations? Unfortunately, letting the data speak for themselves is not always possible. The low quality parts could be found in what does not make it to print. In the list of misconduct Washingtonâ€™s article described, ending a trial prematurely and failing to report negative results are forms of misconduct that would not be transparent from a paper alone. Similarly, failing to report side effects, as in the Vioxx scandal, is another way relevant data can be hidden. Thatâ€™s conscious and explicit manipulation, but thereâ€™s evidence for unconscious manipulation too. Numerous studies have found that the â€œfunding bias,â€? in which conclusions of research are more likely to agree with the sponsorâ€™s aims, is a real phenomenon. While unconscious bias is again not unique to industry, thereâ€™s something to be said for awareness of the trend where it has been clearly tracked.At the end of all this, we are left with two competing facts: 1) Industry sometimes produces valuable research that contributes to patient care. 2) There is also a significant history of manipulation. Is it possible to reconcile these two facts, in a way that is both vigilant against misconduct but also doesnâ€™t pass over potentially valuable findings?I think the last point about quality not always being transparent is the critical fact. Given that itâ€™s entirely scientifically feasible for a study that appears to be of good quality to actually be flawed, holding research conducted by authors with a dubious history seems justifiable. Should you dismiss industry across the board? Probably not. I think the authorsâ€™ caution against the dangers of excessive skepticism is sensible. I also agree that more â€œfundamental strategiesâ€? such as increased protocol and data transparency will make the whole process of determining quality easier. But as it stands, those doctors in the study voicing skepticism about the conclusions of industry sponsored research is understandable. As it goes, a critical eye and looking to others to replicate findings before you embrace new conclusions is probably a good approach to research in general, no matter who the initial authors are.With 100 million first-grade-aged children worldwide having no access to schooling, the One Laptop Per Child organization is trying something new in two remote Ethiopian villagesâ€”simply dropping off tablet computers with preloaded programs and seeing what happens.The goal: to see if illiterate kids with no previous exposure to written words can learn how to read all by themselves, by experimenting with the tablet and its preloaded alphabet-training games, e-books, movies, cartoons, paintings, and other programs.Early observations are encouraging, said Nicholas Negroponte, OLPCâ€™s founder, at MIT Technology Reviewâ€™s EmTech conference last week.The devices involved are Motorola Xoom tabletsâ€”used together with a solar charging system, which OLPC workers had taught adults in the village to use. Once a week, an OLPC worker visits the villages and swaps out memory cards so that researchers can study how the machines were actually used.After several months, the kids in both villages were still heavily engaged in using and recharging the machines, and had been observed reciting the â€œalphabet song,â€? and even spelling words. One boy, exposed to literacy games with animal pictures, opened up a paint program and wrote the word â€œLion.â€?The experiment is being done in two isolated rural villages with about 20 first-grade-aged children each, about 50 miles from Addis Ababa. One village is called Wonchi, on the rim of a volcanic crater at 11,000 feet; the other is called Wolonchete, in the Rift Valley. Children there had never previously seen printed materials, road signs, or even packaging that had words on them, Negroponte said.Earlier this year, OLPC workers dropped off closed boxes containing the tablets, taped shut, with no instruction. â€œI thought the kids would play with the boxes. Within four minutes, one kid not only opened the box, found the on-off switch â€¦ powered it up. Within five days, they were using 47 apps per child, per day. Within two weeks, they were singing ABC songs in the village, and within five months, they had hacked Android,â€? Negroponte said. â€œSome idiot in our organization or in the Media Lab had disabled the camera, and they figured out the camera, and had hacked Android.â€?Elaborating later on Negroponteâ€™s hacking comment, Ed McNierney, OLPCâ€™s chief technology officer, said that the kids had gotten around OLPCâ€™s effort to freeze desktop settings. â€œThe kids had completely customized the desktopâ€”so every kidsâ€™ tablet looked different. We had installed software to prevent them from doing that,â€? McNierney said. â€œAnd the fact they worked around it was clearly the kind of creativity, the kind of inquiry, the kind of discovery that we think is essential to learning.â€?â€œIf they can learn to read, then they can read to learn.â€?In an interview after his talk, Negroponte said that while the early results are promising, reaching conclusions about whether children could learn to read this way would require more time. â€œIf it gets funded, it would need to continue for another a year and a half to two years to come to a conclusion that the scientific community would accept,â€? Negroponte said. â€œWeâ€™d have to start with a new village and make a clean start.â€?The idea of dropping off tablets outside of the context of schools is a new paradigm for OLPC. Through the late 2000s, the company was focused on delivering a custom miniaturized and ruggedized laptop, the XO, of which about 3 million have been distributed to kids in 40 countries. Deployments went to schools including ones in Peru.Giving computers directly to poor kids without any instruction is even more ambitious than OLPCâ€™s earlier pushes. â€œWhat can we do for these 100 million kids around the world who donâ€™t go to school?â€? McNierney said. â€œCan we give them tool to read and learnâ€”without having to provide schools and teachers and textbooks and all that?â€?Vince "k|ngp|n" Lucido is one of the world's most well known Overclockers today. So in October 2012, EVGA put his skills to the test and challenged him to crush the competition and sweep the board for 3DMark 11 scores. Armed with an assortment of EVGA GeForce GTX 680 Classified, EVGA X79 Classified Motherboard, EVGA SuperNOVA NEX1500 Classified power supplies, and enough Liquid Nitrogen to turn Taipei into a deep freeze; Vince was able to smash three brand new 3DMark 11 World Records*. In fact, EVGA along with k|ngp|n were the first to reach over 17,000 points on a single graphics card!Also! Don't forget to sign up for the EVGA 3D Eclipse giveaway, download the exclusive EVGA Precision X skin, and maybe a chance to win some incredible OC prizes! http://www.evga.com/articles/00712/To learn more about extreme overclocking and stay up to date on the latest news, make sure to follow EVGA, Kingpin Cooling and GSkill on Facebook!https://www.facebook.com/TEAMEVGAhttps://www.facebook.com/kingpincoolinghttps://www.facebook.com/gskillofficial*World Records verified on October 23, 2012Back when Firefox 2 was released (six years ago this week!), the Internet Explorer team started a friendly tradition of sending Mozilla a cake as congratulations. This continued for Firefox 3 and Firefox 4. After Firefox switched from major releases once or twice a year to incremental updates every six weeks, they sent us a cupcake for the next few updates instead.I thought it would be fun to revive the tradition by ordering a cake for the IE team for the IE10 release today. Here it is right after I picked it up from Baked Custom Cakes, with a Firefox logo in painted fondant:Fellow Mozilla developer Eitan Isaacson drove with my wife Sarah and me to Microsoft Building 50 in Redmond, where program manager Jacob Rossi helped us deliver the cake to a group of IE team members:The IE team posted their thanks through their official Twitter account. (As you can see from their picture, the bottom border of the cake was slightly restyled in transit.) Just 30 minutes later, Michael Bolan tweeted that the cake was gone. I hear the sugary Firefox logo was eaten soon after.So congratulations to the Internet Explorer team on your latest release, and we hope you enjoyed the cake!Vince "k|ngp|n" Lucido is one of the world's most well known Overclockers today. So in October 2012, EVGA put his skills to the test and challenged him to crush the competition and sweep the board for 3DMark 11 scores. Armed with an assortment of EVGA GeForce GTX 680 Classified, EVGA X79 Classified Motherboard, EVGA SuperNOVA NEX1500 Classified power supplies, and enough Liquid Nitrogen to turn Taipei into a deep freeze; Vince was able to smash three brand new 3DMark 11 World Records*. In fact, EVGA along with k|ngp|n were the first to reach over 17,000 points on a single graphics card!Also! Don't forget to sign up for the EVGA 3D Eclipse giveaway, download the exclusive EVGA Precision X skin, and maybe a chance to win some incredible OC prizes! http://www.evga.com/articles/00712/To learn more about extreme overclocking and stay up to date on the latest news, make sure to follow EVGA, Kingpin Cooling and GSkill on Facebook!https://www.facebook.com/TEAMEVGAhttps://www.facebook.com/kingpincoolinghttps://www.facebook.com/gskillofficial*World Records verified on October 23, 2012Following the furor over the company's mapping service, the iOS software chief refused to sign a letter apologizing for its shortcomings and got the boot as a result, the Wall Street Journal reported.The exit of Apple iOS software chief Scott Forstall was apparently anything but quiet. Forstall was forced out after he refused to sign a letter apologizing for problems with Apple Maps, according to the Wall Street Journal.The New York Times confirmed the firing, along with the unrelated ouster of Apple's new retail chief, John Browett.The Journal reported that some within Apple considered Forstall a divisive figure who "never fit into the culture at Apple," and who had long rankled other company execs but enjoyed the confidence of Steve Jobs. As WSJ reporter Jessica Lessin wrote:In fact, Forstall recently sent an email to some of the folks on Apple's iOS software team saying that the group "wasn't working on enough big ideas in mobile software," according to the WSJ. That's effectively saying that Forstall thought the company was struggling to compete, so it's no surprise that tensions were mounting.Apple has said that Forstall will be replaced by Craig Federighi in 2013. Federighi will oversee both the iOS and OS X groups under one umbrella.A walkthrough and review of the just released Xbox SmartGlass app for Android, running on a Asus Google Nexus 7 through side-loading the app.While it's available - here's the APK you can sideload onto your device.https://www.dropbox.com/s/go8ufab7pd9emxs/com.microsoft.smartglass.apkThe company tells CNET that sales of its flagship Galaxy S III actually rose following the unveiling of the iPhone 5, the latest illustration of its run to the top.The Korean conglomerate's flagship Galaxy S III had four of its five best-selling weeks in the U.S. after the iPhone 5 was unveiled, Samsung told CNET.The spike after the iPhone 5 launch suggests that consumers hung around to see what Apple had to show off, weren't impressed, and went with a Galaxy S III instead."I was shocked by the numbers," Kevin Packingham, chief product officer of Samsung's U.S. mobile arm, said in an interview. "I thought: 'What the heck is going on here?'"It's just the latest bit of good news for a company that has enjoyed a remarkable run to the top of the smartphone business, allowing it to surpass Apple and dominate with a flagship brand that has virtually the same appeal as the iPhone.Samsung is poised to continue its run into the holidays as it drums up attention for its latest product, the extra-large Galaxy Note 2. In typical Samsung fashion, the company on Wednesday threw a splashy party for media, d-list celebrities, and select Samsung fans in Manhattan's old Post Office headquarters, capping off the night with a performance by Kanye West."It's the holiday season and they needed something to generate buzz around its products," said Avi Greengart, who covers consumer products for Current Analysis.Keep in mind that the event was being held for a product that has already been announced globally and in the U.S., with reviews of the Galaxy Note 2 already widely available.But that didn't stop Samsung from going big with the event, and partly illustrates why the company has been so successful in battling Apple and establishing its leadership in the mobile world. Few companies have the resources, recognition, and heft to compete with Apple; Samsung just happens to be one of them.The investment in mobile has clearly paid off. Samsung earlier today posted a record quarterly profit of $7.4 billion, thanks largely to its Galaxy line of smartphones. In this industry, only Apple can boast of better results, having posted an $8.2 billion profit yesterday.Given the strength and resources of both companies, Apple and Samsung are likely to continue dominating the handset industry, applying even more pressure to its smaller rivals and potentially forcing some out of the business altogether.Winning 'Phablet' fans Credit Samsung's persistence in creating a new segment for the success of the original Galaxy Note. The device, bigger than a phone, but smaller than a tablet, was initially mocked by critics who thought it looked silly. But Samsung said the company has slowly won over people despite the large size, and pressed the category even further with the larger Galaxy Note 2.Samsung said that it had sold 10 million units of the Galaxy Note in the first nine months of availability around the world, but it's unclear how well it actually did in the U.S. The first Galaxy Note debuted earlier this year with AT&T before later getting picked up by T-Mobile USA as well. But given that a majority of smartphone sales at AT&T are made up of iPhones, there's a question mark for how much share the Galaxy Note actually got.Packingham insisted that the Galaxy Note was "tremendously successful," and that its performance convinced other carriers to add it to their lineup. This time around, the Galaxy Note 2 will be sold by all four national carriers, as well as a few regional ones."It's impressive that they have all the carriers lined up," Greengart said.J.K. Shin, head of Samsung's mobile business, has high expectations for the Galaxy Note 2, and told reporters at a briefing that he expects it to sell three times more quickly than the previous version, hitting 3 million units in the first 90 days.Samsung's more bullish because the Galaxy Note 2 has the benefit of wider availability and higher awareness from consumers, Packingham said. He added that carriers like the device because it targets the kind of customers they want to go after: power users looking for more from their mobile devices and well-off enough to buy the product.Galaxy Note 2 vs. iPad Mini? At $299.99 with a two-year contract, the Galaxy Note 2 isn't for bargain seekers.In fact, it's only $30 less expensive than the recently released iPad Mini from Apple. (A cellular version starts at $459.) There are, of course, fundamental differences between the two devices, with the Galaxy Note 2 sold more as a phone with a smartphone plan and seen as more of a primary device, while the iPad Mini is more a complementary device. Still, they also aren't that far apart when it comes to size.Packingham doesn't believe that the Galaxy Note 2 will compete with the iPad Mini. Samsung has a lot of experience with 7-inch tablets, with its Galaxy Tab being one of the first such Android devices, and Packingham said that the customers who buy them are different than ones who would buy the Galaxy Note 2.While Samsung isn't the first to sell a 5-inch device, the company does take credit for creating this new category of tweener devices. (Internally, executives don't refer to them as "phablets.") The Galaxy Note has spawned follow-up attempts, including the Optimus Vu from LG, known as the Intuition at Verizon Wireless. Packingham, however, was fairly dismissive of other attempts."Clearly in this segment, the Note stands alone," he said.A walkthrough and review of the just released Xbox SmartGlass app for Android, running on a Asus Google Nexus 7 through side-loading the app.While it's available - here's the APK you can sideload onto your device.https://www.dropbox.com/s/go8ufab7pd9emxs/com.microsoft.smartglass.apkPeople increasingly have more than one device, and they switch between them many times a day. Nexusâ€”Googleâ€™s hardware line for Android devicesâ€”gets rid of the hassle. Just sign in with your Google Account and everything is there ready to go, whatever device youâ€™re using: photos, emails, contacts, bookmarks, even your entertainment on Google Play.Today, weâ€™re excited to announce three great new Nexus devices â€¦ in small, medium and large. And they all run Android 4.2, a new flavor of Jelly Beanâ€”which includes the latest version of Google Now and other great new features.Nexus 4 with Google Now and Photo Sphere Nexus 4 is our latest smartphone, developed together with LG. It has a quad-core processor which means it's super fast, a crisp 4.7" (320 ppi) display that's perfect for looking at photos and watching YouTube, and with wireless charging you just set the phone down on a charging surface to power it up, no wires needed. While Nexus 4 is incredibly powerful under the hood, it also features the latest version of Jelly Bean, Android 4.2â€”the simplest and smartest version of Android yet. Starting with the camera, we've reinvented the photo experience with Photo Sphere, which lets you capture images that are literally larger than life. Snap shots up, down and in every direction to create stunning 360-degree immersive experiences that you can share on Google+ with friends and familyâ€”or you can add your Photo Sphere to Google Maps for the world to see.Android 4.2 brings other great goodies like Gesture Typing, which lets you glide your finger over the letters you want to type on the keyboardâ€”it makes typing fast, fun and a whole lot simpler. Android 4.2 also adds support for wireless display so you can wirelessly watch movies, YouTube videos and play games right on your Miracast-compatible HDTV.Learn more about all of the new features of Android 4.2, Jelly Bean, here.Google Nowâ€”even more useful We designed Google Now to make life simpler by giving you the right information at just the right time in easy to read cards, before you even ask. And the feedback has been awesome. So today weâ€™re adding more cards that we hope youâ€™ll find useful. Flight information, restaurant reservations, hotel confirmations and shipping detailsâ€”how often have you found yourself wading through your email to get this information at the last moment? So next time you book a table for dinner, youâ€™ll get a reminder with all the details without ever having to lift a finger. Youâ€™ll also get cards for nearby attractions, interesting photo spots, movies times at nearby theaters or concerts by your favorite artists.Nexus 7: Thin, light and now even more portableNexus 7 brings you the best of Googleâ€“YouTube, Chrome, Gmail, Mapsâ€“and all the great content from Google Play in a slim, portable package that fits perfectly in your hand. To give you more room for all that great content you can now get Nexus 7 with 16GB ($199) or 32GB ($249) of storage. But we also wanted to make this highly portable tablet even more mobile. So we added HSPA+ mobile data. Nexus 7 is now also available with 32GB and HSPA+ mobile ($299), which can operate on more than 200 GSM providers worldwide, including AT&T and T-Mobile in the U.S. Nexus 10: Powerful and shareable Nexus 10 is the ultimate tablet for watching movies or reading magazines. We wanted to build a premium entertainment device, so we partnered with Samsung to do just that. Nexus 10 is the highest resolution tablet on the planet with a 10.055" display at 2560-by-1600 (300ppi), that's over 4 million pixels right in your hands. It comes with a powerful battery that will get you up to nine hours of video playback and more than 500 hours of standby time. With a set of front-facing stereo speakers, you can watch movies right from your Nexus 10 and they simply sound awesome. But what makes Nexus 10 unique is that it's the first truly shareable tablet. With Android 4.2, you can add multiple users and switch between them instantly right from the lockscreen. We believe that everyone should have quick and easy access to their own stuff -- email, apps, bookmarks, and more. That way, everyone can have their own home screens, their own music, and even their own high scores.Google Play: More entertainment, more countriesWeâ€™ve recently added a ton of great new entertainment to Google Play, such as movies and TV shows from Twentieth Century Fox. Earlier this year we expanded our service beyond movie rentals and now you can purchase movies and build a library of your favorites in Google Play. Today weâ€™re bringing movie purchasing to more countries - Canada, the U.K., France, Spain and Australia.Weâ€™re also excited to announce two new partnerships. Weâ€™re now working with Time, Inc. to bring you even more magazines like InStyle, PEOPLE, TIME and others. And weâ€™ve partnered with Warner Music Group who will be adding their full music catalog with new songs coming each day. Weâ€™re now working with all of the major record labels globally, and all the major U.S. magazine publishers, as well as many independent labels, artists and publishers.On November 13, we're bringing music on Google Play to Europe.  Those of you in the U.K, France, Germany, Italy and Spain will be able to purchase music from the Google Play store and add up to 20,000 songsâ€”for freeâ€”from your existing collection to the cloud for streaming to your Android devices or web browser. Weâ€™re also launching our new matching feature to streamline the process of uploading your personal music to Google Play. Weâ€™ll scan your music collection and any song we match against the Google Play catalog will be automatically added to your online library without needing to upload it, saving you time. This will be available in Europe at launch on November 13 and is coming to the U.S. soon after. This will all be for freeâ€”free storage of your music, free matching, free syncing across your devices and free listening.Great valueWeâ€™ve always focused on building great devices at great value.  And we think todayâ€™s devices offer the very best that money can buy. Here are more details on when and where you can pick up your next Nexus device:Nexus 4: 8GB for $299; 16GB for $349; available unlocked and without a contract on 11/13 on the Google Play store in the U.S., U.K., Australia, France, Germany, Spain and Canada. The 16GB version will also be available through T-Mobile for $199, with a 2-year contract (check here for more details).Nexus 7: 16GB for $199 and 32GB for $249; available in the U.S., U.K., Australia, France, Germany, Spain, Canada and Japan, and also through our retail partners Gamestop, Office Depot, Office Max, Staples and Walmart.Nexus 7 with 32GB and mobile data: $299 and unlocked, on sale 11/13 in the Google Play store in the U.S., U.K., Australia, France, Germany, Spain and  Canada.Nexus 10: 16GB for $399; 32GB for $499; available on 11/13 in the Google Play Store in the U.S., U.K., Australia, France, Germany, Spain, Canada and Japan. You'll also be able to purchase the 32GB version in more than 2,000 Walmart stores in the U.S.A Nexus device is much more than simply a phone or tablet. Itâ€™s your connection to the best of Googleâ€”all of your stuff and entertainment, everywhere you go with no hassle.  Now you have three new Nexus devices, a new improved version of Jelly Bean and more entertainment than ever beforeâ€”all available on Google Play. The playground is open.On the way to the Apple Store today to buy AppleCare+ for my wifeâ€™s new iPhone 5, we passed the new Microsoft Store, coincidentally in the middle of their Surface with Windows RT launch. (That is actually the productâ€™s name. â€œSurface with Windows RTâ€?.)They had set up a table and an Xbox demo in the hallway and were giving away â€œMicrosoft Surfaceâ€?-branded disposable rain ponchos (this entire mall is indoors, including the parking, and it didnâ€™t rain today) and muffin fragments (much like when you order a soda on a plane, they pour a third of it into a little plastic cup full of hollow ice cylinders, and they donâ€™t let you keep the rest of the can). An employee with a microphone in front of the Xbox kiosk was talking to the audience of nobody as if it were a dance party.The store is creepy: so many elements are embarrassingly similar to the Apple Store on the next floor. Microsoft even ripped off trivial elements that easily could have been different, such as the employee uniform. Thereâ€™s a huge elephant in the room, and we can all see it, but Microsoft still implicitly denies it.There were far more employees than customers, and I was curious, so I thought Iâ€™d stop in to take a look at Microsoftâ€™s new tablet. The employees in the store were overly enthusiastic, especially for 3:47 PM, and practically mobbed anyone who entered. â€œHEY! WELCOME TO THE MICROSOFT STORE! WOULD YOU LIKE TO TRY THE NEW SURFACE?â€?The salesman launched into an elaborate pitch. He wasnâ€™t a confident speaker, so the rote was obvious. I wanted to jump right in and start playing with the software, but the salesman kept butting in and driving â€œmyâ€? demo.The first thing he had me do was detach and reattach the keyboard cover. Click. He sold the keyboard cover hard. â€œNobody else has a cover like this.â€?The staff loved Adam so much that he later vomited in the Apple Store.The salesman then showed off the kickstand and started flipping through the applications himself. I wondered if this was how the press got to â€œuseâ€? the Surface before today.When we finally broke the salesmanâ€™s concentration so we could pick it up and start playing with it, Tiff and I both had the same first impression: itâ€™s heavy. On paper, itâ€™s 1.5 pounds (without the half-pound keyboard), like the iPad 1 and a bit heavier than the iPad 3. But itâ€™s not just heavy: it feels dense, like the iPhone 4 and 4S (and notably not like the iPhone 5).Like the Zune, the Surface might always be competing with the previous-generation iPad. Microsoft has approximately matched the weight of the already-too-heavy iPad 3 right as Apple is releasing the far lighter iPad Mini. (And Microsoft just launched this tablet at $500 as everyone else is moving to much lower pricing.)I tried rotating the Surface. There was a long enough delay that I thought rotation just wasnâ€™t supported, then it kicked in and the newly laid out screen just popped in. No transition, no animation. I switched to a different app and tried the same thing with the same results. Rotation was always slow and sloppy.My demo was interrupted as another employee walked through the store, shouting enthusiastically, â€œWE HAVE WORKSHOPS IN THE BACK!â€? Nobody followed him there.The diagonally-oriented camera is strange. In the one orientation itâ€™s optimized for, itâ€™s slightly annoying. In any other orientation, itâ€™s almost intolerable. If I brought home a Surface and didnâ€™t know this was a design decision, I might assume the camera was broken and return it.The maps app is very sluggish and doesnâ€™t use vector graphics, making it feel old.iOS is so responsive and so liberal with animations that it has a very tactile feel, and rather than thinking â€œtap this button to openâ€? or â€œswipe across this box to shareâ€?, conceptually, you just move the things on the screen with your fingers.The distinction seems subtle, but itâ€™s important. Every action on the Surface feels deliberate. It feels like youâ€™re using a computer.The standard gestures donâ€™t help, requiring many in-from-the-edge swipes that not only arenâ€™t discoverable but also frequently conflict with scrolling. My gestures often didnâ€™t work, and it wasnâ€™t clear whether there just wasnâ€™t a hidden context menu at that moment or I just screwed up the swipe.Most of the animations also arenâ€™t helpful, with minimal spatial consistency. Many animations seem arbitrary, not hinting at anything behaviorally useful. Microsoft has applied animations and gestures in Windows 8 about as effectively as they applied color in Windows XP and transparency in Windows Vista: they knew that Apple had been successful with these features, so they made a checklist and just applied them haphazardly. â€œApple does animations, so now we do animations! Apple does gestures, so now we have gestures!â€?An employee was stationed by these big letters on the floor to instruct people to exit to the left, rather than stepping over them. Iâ€™ve never been given instructions on how to exit â€œother storesâ€?.The keyboards are both decent but unmemorable. Every Surface had its own Touch Cover (no physical key movement), and the employees were frantically passing around a single Type Cover (traditional slim keys). Since everyone wanted to try the Type Cover, I only got a few seconds with it, but it was comparable to good iPad keyboards like Logitechâ€™s.The Touch Cover is one of the Surfaceâ€™s biggest innovations. I thought I would hate it, but I didnâ€™t. Itâ€™s not like typing on a completely flat surface: each â€œkeyâ€? is raised slightly, so while there isnâ€™t any mechanical feedback, it does feel a bit like a keyboard.But since it responds to touches rather than mechanical pressure, you canâ€™t rest your fingers on it without triggering key presses. Your fingers must hover over it, which makes it easy to get misaligned from your expected positions and type a bunch of wrong characters. I had a hard time keeping alignment when I needed to stretch for the boundary keys, including Shift. Every time I typed a capital letter, I mistyped the next few letters.I couldnâ€™t type on the Touch Cover significantly faster than with the on-screen keyboard, so I question its purpose. Moreover, since the Touch Cover and Type Cover are so close in price and nearly indistinguishable in size and weight, Iâ€™m not sure why the Touch Cover exists at all other than to be different from â€œother tabletsâ€?. I donâ€™t know why someone would get it instead of the Type Cover.I went to another Surface and was greeted by another salesman. He also aggressively demoed the tablet for me, not letting me take over for more than three seconds at a time. It was obvious that they had all had the same training and were instructed to hard-sell the same talking points. The pitches were aggressive, fast-paced, and competitively defensive: they often mentioned â€œother tabletsâ€? and didnâ€™t let me forget which features were â€œnot available on any other tabletâ€?.He kept showing me the home screen and how to rearrange my icons, even though I kept wanting to explore the apps.He showed me Office, which was almost unusable: it was extremely sluggish, and touch targets were tiny and difficult to hit. He said this was the only tablet that could run Office, and if you used Office at work, this was therefore the only tablet that you could use at work. I played dumb.He asked what kind of computer I had at home. I told him the truth: that I used to have PCs, but now I had an old Mac and wanted to see the newer options out there.He showed me the L-shaped magnetic power connector, which can be plugged in either way, and showed how the magnet safely disconnects when the cable is pulled. It was vaguely familiar, but I continued to play dumb.I asked about 3G options, which the Surface doesnâ€™t have. He said it would restrict me from being able to use it anywhere (?), so I pushed a little further, and he said nobody wants two bills and you can just use tethering and why mess with the pesky 3G connection?He started selling me on the screen quality, saying it had a better screen than any other tablet. I asked, â€œWhat do you mean? Which other tablets?â€?I couldnâ€™t get him to say â€œiPadâ€?, but he did say it was better than â€œRetina screensâ€?.I broke character slightly. â€œI donâ€™t know, I saw the Retina iPad upstairs and I canâ€™t see the pixels at all on it. On here, I can see the pixels clearly.â€?â€œNo you canâ€™t. Where can you see the individual pixels?â€?â€œRight there. See, the left stroke on that capital â€˜Dâ€™ has one solid pixel on the left and a half-shaded pixel on the right.â€?He scaled the icon up to â€œzoom inâ€?, which, of course, changes what the physical pixels display. â€œI canâ€™t see any pixels!â€?I gave up. It was like arguing with a Tea Partier. But I figured, now that I had broken character a little, Iâ€™d risk a bit more.An Apple Store employee had stopped by after his shift, with the original blue shirt over his shoulder, to check out the Surface across from us. We smiled at him. I asked my salesman, â€œDid you apply to work at the Apple Store upstairs first, or did you always want to work here?â€?â€œNo, I went right here. Always been a PC guy. I like being able to customize things, like upgrading my sound cardâ€”â€?I couldnâ€™t resist. â€œOh, can you upgrade the sound card in the Surface?â€?â€œNo, butâ€¦ I started working here before the Surface came out.â€? (This Microsoft Store opened 28 days ago.) â€œBut you can add more RAM to this, right over here, this is an SDXC slot, which means Extra Capacity.â€?Like John Moltz, Iâ€™m left to ask the question: why buy a Surface instead of an iPad? For the price, you can almost buy two baseline iPad Minis. Or you can buy a 32 GB iPad Mini with LTE and a Smart Cover.But I donâ€™t think many Surface buyers are going to comparison-shop with the iPad, or vice versa. Itâ€™s very clear who the Surface is for, and itâ€™s not us.The Surface is partially for Microsoftâ€™s world of denial: the world in which this store contains no elephants and Microsoft invented the silver store with the glass front and the glowing logo and blue shirts and white lanyards and these table layouts and the modern tablet and its magnetic power cable. In that world, this is a groundbreaking new tablet that you can finally use at work and leave your big creaky plastic Dell laptop behind when you go to the conference room to have a conference call on the starfish phone with all of the wires and dysfunctional communication.But itâ€™s also for people like that salesman who donâ€™t agree with Appleâ€™s choices: people who want to have more hardware options, more customization, more hackability, and fewer people saying â€œnoâ€? to what they can do on their devices.Appleâ€™s products say, â€œYou canâ€™t do that because we think it would suck.â€? Microsoftâ€™s products say, â€œWeâ€™ll let you try to do anything on anything if you really want to, even if it sucks.â€?People who dislike Appleâ€™s approach or whose requirements are incompatible with it will always exist in great numbers, and the Surface is for them. Itâ€™ll probably sell well, especially if Microsoft can expand their retail presence quickly.But itâ€™s not for me at all. Not even for testing, experimenting, or curiosity. It feels too much like using a Windows PC, which was exactly Microsoftâ€™s intention, and it will appeal to people who want that. But thatâ€™s a world I fled 8 years ago with no intention of returning.Apple's co-founder fears that freedom of information is under attack, with the internet controlled and regulated in unnecessary and harmful ways. RT talked to Steve Wozniak on a range of topics, from Wikileaks to Megaupload founder Kim Dotcom.RT LIVE http://rt.com/on-airSubscribe to RT! http://www.youtube.com/subscription_center?add_user=RussiaTodayLike us on Facebook http://www.facebook.com/RTnewsFollow us on Twitter http://twitter.com/RT_comFollow us on Google+ http://plus.google.com/b/102728491539958529040RT (Russia Today) is a global news network broadcasting from Moscow and Washington studios. RT is the first news channel to break the 500 million YouTube views benchmark.Hello from Advertising Week! You may remember a couple months ago at another industry event across the pond I shared how we were bringing in creative agency partners earlier than ever before to co-ideate on potential advertising opportunities with Windows 8 Ads in Apps. Bringing partners on board from the beginning is vital to the long-term success of the Windows 8 ecosystem. Working together in the co-ideation process demonstrates what can be gained from great collaboration when you involve creativity and technology. Itâ€™s exciting to see how weâ€™re driving innovation in this opportunity to create new industry standards.Weâ€™ve enjoyed digging in and getting creative with folks from the IAB creative board including Big Spaceship, Razorfish, Team Detroit, Universal McCann and Y&R Group on blue sky thinking for in-app ad concepts, as we are considering Windows 8 a brand new advertising canvas that offers endless opportunities. The connected user interface and unique, fluid design of Windows 8 will encourage people to explore and discover ads without disrupting their experience. Based on that, we set out not to just create new ad formats â€“ our goal was to rethink the entire experience.The results of our co-ideation sessions and work are the first five unique, custom advertising scenarios that feature major brand campaign concepts within marquee publisher apps â€“ including Delta Airlines in an NBC News app, Finish Line in an LA Times app, Ford Fusion in a Chicago Tribune app, Jeep in an AccuWeather app and Goldfish Crackers in a Slacker Radio app. Below is snapshot of each, which you can also see in a quick video with our partners here.Delta is launching a new advertising campaign called â€œUpâ€? that is all about upping the ante in travel with the airline. The Razorfish creative team leveraged the unique, creative campaign and content of â€œUpâ€? to conceptualize a Windows 8 Ads in Apps concept for Delta in the NBC News app that is an intuitive, contextually relevant and immersive experience, which is ideal for a tablet. When in the NBC News app, a user can initiate the ad by touching on the Delta tile so that it expands up the screen. The user can swipe â€˜upâ€™ to continue a visual journey of a travel experienceâ€”from checking in at the airport, to bags going up the ramp, until the plane is up in the skyâ€”that is simple and aspirational. Once the experience is closed, users are returned to the NBC News app content.Big Spaceship came up with a simple, yet compelling concept for Finish Line called, "Elements Change, Running's Eternal." The Big Spaceship team was excited about how Windows 8 encourages advertisers to create ads that deserve attention, rather than simply shouting messages, blinking repeatedly or interrupting people. As a result, the Windows 8 Ads in Apps concept for Finish Line is beautiful and fun to explore. In the sports section of the LA Times app, the Finish Line ad opens into a panoramic format that show a day in the life of a female athlete who loves to run. The concepts encourages people to follow her journey while showcasing Finish Line products through strategically placed â€œhot spotsâ€? on the runner that allows people to touch to learn more.Team Detroit created a Windows 8 Ads in Apps concept for Ford Fusionâ€™s new ad campaign that leveraged the consumer-first architecture of Windows 8 to tell a story and present content in a way that is non-intrusive and within the context of what the consumer wants and when. The team created an advertising concept with a dynamic background that is subtle and contextual, and empowers the user to control their brand experience. Shown within the Chicago Tribune app, as consumers scroll left to right, they see environmental changes in the background that are brought to life through dynamic layering of elements and timeline based animation with three advertisement spots highlighting various components of the Ford Fusion story.Universal McCann/Sapient created a dynamic Windows 8 Ads in Apps concept for Jeep within the AccuWeather app that speaks to how its new vehicle is ready for all weather. Once inside the AccuWeather app, the user scrolls through the content to the right until they come to the end and â€˜bumpâ€™ into the Jeep ad, which features engaging animation and a beautiful experience that encourages users to click. Once a user engages, the Jeep ad expands to a full-screen experience where the user can thumb through informative text, graphics and video elements.Pepperidge Farm is looking to expand beyond its typical moms audience to reach teens â€“ which is known as challenging to connect with in general. Y&R identified Slacker Radio as an ideal publishing partner to reach teens in their environment, and developed a Windows 8 Ads in Apps concept featuring a branded experience without having to leave the app. Y&R had to make it more than just awareness â€“ with teens itâ€™s all about selling indirectly to them to get them engaged. The team created the â€œMusic Visualizerâ€? with Goldfish Crackers that can play or work with any kind of music within the Slacker Radio app. The Goldfish crackers jump and literally dance to the music based on the beat/sound wave experience.The pairings were determined through ongoing conversations between the agencies, brands and publishers with the goal of matching like-minded audiences and creating organic, contextually relevant experiences. For instance, Jeep partnered with AccuWeather because weather is inherent to the driving experience and it mapped perfectly to their new all-weather, all-terrain Jeep vehicle.These concepts showcase how digital advertising can be more interactive and revolve around customer-initiated experiences that can be beautiful, relevant and useful. Our agency partners already agree that the potential for creative innovation is great â€“ just see what they had to say.â€œMicrosoft has over 1.3 billion customersâ€¦ if youâ€™re a global brand, Microsoft is the most relevant player in that ecosystem. Theyâ€™re ones that you really have to partner with. I think Windows 8 is going to be that next evolution.â€? Eric Baumgartner, Chief Innovation Officer, Y&R Groupâ€œWindows 8 allows us to tell stories â€¦over a long period of time. It doesn't have to be a single or a one-hit wonder. â€¦The ad formats are innovative, breakthrough, not too overt. Itâ€™s about connecting, and the ability to make an impact.â€? David Cohen, SVP, Universal McCann Interactiveâ€œThe way that Windows works is changing the very definition of an [agency] team today.â€? Margaret Cziesler, National Lead, Strategic Alliances, RazorfishHope everyone enjoys the rest of Advertising Week!Stephen Kim, General Manager of Yarn (formerly Global Creative Solutions) for Microsoft AdvertisingApple's co-founder fears that freedom of information is under attack, with the internet controlled and regulated in unnecessary and harmful ways. RT talked to Steve Wozniak on a range of topics, from Wikileaks to Megaupload founder Kim Dotcom.RT LIVE http://rt.com/on-airSubscribe to RT! http://www.youtube.com/subscription_center?add_user=RussiaTodayLike us on Facebook http://www.facebook.com/RTnewsFollow us on Twitter http://twitter.com/RT_comFollow us on Google+ http://plus.google.com/b/102728491539958529040RT (Russia Today) is a global news network broadcasting from Moscow and Washington studios. RT is the first news channel to break the 500 million YouTube views benchmark.Following the Amazon Web Services outage earlier this week, major sites and platforms are experiencing outages today, including at least Dropbox and Google App Engine. At the time of writing itâ€™s unclear how the two downtimes are related, but Tumblrâ€™s performance issues earlier today point to a clue.The blogging company told us in a statement: â€œTumblr is experiencing network problems following an issue with one of our uplink providers. Recovery is moving quickly and we will return to full service shortly.â€? Internet Traffic Report is reporting major packet loss in North America as well as issues in Asia (the problem is large enough that itâ€™s spilling into the rest of the world):At the time of writing, Dropbox is giving the following error (although it does seem to go back and forth every once in a while):Google App Engine is meanwhile timing out, and actually the Google Developers domain as a whole is having trouble loading. This is affecting Googleâ€™s own properties, such as Android Developers, as well as many other third-party Web sites that rely on App Engine. They are showing errors like this one (ironically, this is for BreakingNews.com):Even YouTube is experiencing issues; Downrightnow is calling it a â€œLikely Service Disruption,â€? although itâ€™s working fine for us:We have contacted both Dropbox and Google about these issues. We will update this article when we hear back.Update at 12:05PM EST: Dropbox appears to be coming back. Google App Engine is still down and out, and the search giant has classified the issue as an â€œAnomalyâ€? (talk about understatement) over at Google App Engineâ€™s System Status page. â€œApp Engine is currently experiencing serving issues. The team is actively working on restoring the service to full strength.â€? We are told to keep an eye on this Google Groups thread for more information.Update at 12:35PM EST: Cedexis has posted Google App Engine traffic details for today, which show things may be starting to return to normal:Update at 1:15PM EST: Google has posted an explanation.At approximately 7:30am Pacific time this morning, Google began experiencing slow performance and dropped connections from one of the components of App Engine. The symptoms that service users would experience include slow response and an inability to connect to services. We currently show that a majority of App Engine users and services are affected. Google engineering teams are investigating a number of options for restoring service as quickly as possible, and we will provide another update as information changes, or within 60 minutes.Update at 1:50PM EST: Google App Engine is starting to come back.Update at 2:10PM EST: Itâ€™s down again. Google has more.We are continuing work to correct the ongoing issues with App Engine. Operation has been restored for some services, while others continue to see slow response times and elevated error rates. The malfunction appears to be limited to a single component which routes requests from users to the application instance they are using, and does not affect the application instances themselves. Weâ€™ll post another status update as more information becomes available, and/or no later than one hour from now.Update at 3:45PM EST: All systems are go.At this point, we have stabilized service to App Engine applications. App Engine is now successfully serving at our normal daily traffic level, and we are closely monitoring the situation and working to prevent recurrence of this incident. This morning around 7:30AM US/Pacific time, a large percentage of App Engineâ€™s load balancing infrastructure began failing. As the system recovered, individual jobs became overloaded with backed-up traffic, resulting in cascading failures. Affected applications experienced increased latencies and error rates. Once we confirmed this cycle, we temporarily shut down all traffic and then slowly ramped it back up to avoid overloading the load balancing infrastructure as it recovered. This restored normal serving behavior for all applications. Weâ€™ll be posting a more detailed analysis of this incident once we have fully investigated and analyzed the root cause.Google has sent over an apologetic statement.Update at 4:15PM EST: Now itâ€™s Facebookâ€™s turn.Update at 9:00PM EST: Google has more information on the outage today over on its App Engine blog.Categories abpwatcher adblock adblock plus adblock plus chrome adblock plus kmeleon customizations development builds easylist elemhidehelper gecko jsdeobfuscator mozilla newsletter off-topic private progress releases security songbird textpattern tomtom weavesync website xulCommenting is closed for this article.Gauntlet is a one handed glove that serves as a wireless keyboard. Type by easily tapping your thumb on each segment of your fingers. Erase letters with just a swipe. Compatible today with iPhone, Android, and Bluetooth enabled tablets, laptops, and desktop computers.Four years after discovering that militants were tapping into drone video feeds, the U.S. military still hasnâ€™t secured the transmissions of more than half of its fleet of Predator and Reaper drones, Danger Room has learned.Â The majority of the aircraft still broadcast their classified video streams â€œin the clearâ€? â€” without encryption. With a minimal amount of equipment and know-how, militants can see what Americaâ€™s drones see.Unmanned aerial vehicles, or UAVs, have become the single most important weapon in Americaâ€™s far-flung pursuit of violent extremists. Hundreds of American Predators and Reapers fly above Libya, Yemen, Somalia, Pakistan, and Afghanistan â€” watching suspected enemies, and striking them when necessary.Â Nearly 3,000 people have been killedÂ in the decade-long drone campaign.â€œIf somebody could obtain reliable access to real-time Predator or Reaper video â€” without attribution or alerting U.S. military â€” that would Â a tremendous intel coup,â€? says Micah Zenko, a fellow at the Council on Foreign Relations. â€œThere is an insatiable demand from Predator and Reaper imagery in Afghanistan and elsewhere. Any reluctance to use those for spying or missile strikes places operations in Afghanistan, Pakistan, Yemen, and Somalia at some risk.â€?Military officials have known about â€” and mostly shrugged off â€” the vulnerability since the development of the Predator in the 1990s. But the problem drew increased attentionÂ in 2008, when drone video footage was found on the laptops of Shiâ€™ite militants in Iraq, who were able to intercept the feed using a piece of $26 software. The Pentagon and the defense industry assured the public that theyâ€™d close the hole by retrofitting the robotic aircraft with new communications protocols and encrypted transceivers that would keep the video from being intercepted again.Four years into the effort, however, only â€œ30 to 50 percentâ€? of Americaâ€™s Predators and Reapers are using fully encrypted transmissions, a source familiar with the retrofitting effort tells Danger Room. The total fleet wonâ€™t see its communications secured until 2014. This source and others who work closely with drone operations say that drones flying overseas are among the first to get the newly secured equipment. They also noted that they are unaware of any incidents of militants using Americaâ€™s unmanned eyes in the sky to their advantage. â€œBut Iâ€™m surprised I havenâ€™t,â€? the source adds. â€œAnd that doesnâ€™t mean itâ€™s not happening.â€?This isnâ€™t the only vulnerability in the drone fleet. In March of 2011, an unknown software glitch caused a PredatorÂ stationed at a U.S. base inÂ Africa toÂ start its engine without human direction.Â Last October, as Danger Room first reported, Air Force technicians discovered aÂ virus infecting the dronesâ€™ remote cockpitsÂ in Las Vegas. It tookÂ weeks of sustained effortÂ to clean up the machines. The aircraft, which rely on GPS to guide them through the air, can run into problems if GPS signals are jammed in a particular area â€” something that can be done with cheap, commercially available hardware.Â Iranian officials claimed they hacked the GPS control signal of an advanced drone, though itâ€™sÂ impossible to verify that lofty claim.No one who works with UAVs is questioning the fundamental integrity of the drone fleet at the moment; it would take an incredibly sophisticated hacker toÂ commandeerÂ a Predator, for example. Nor is anyone pretending that this premiere tool of the U.S.global Â counterterror campaign is flawless.Predators and the larger, better-armed Reapers transmit video and accept instructions in one of two ways. The first is via satellite, to remote pilots and sensor operators who are often on the other side of the planet; these satellite communications are encrypted, and are generally considered secure.The second is through a radio frequency signal called the Common Data Link, which is used to share the droneâ€™s video feed with troops on the ground. The CDLâ€™s carrier signal â€” its specific pattern of frequencies, in a given order and for a given length of time â€” tells both transmitter and receiver on how to function. The problem is that the Predatorsâ€™ version of the CDL carrier signal (also known as a â€œwaveformâ€?) didnâ€™t include an order to encrypt the signal. So neither the transmitter on the drone nor the receivers that troops used on the ground employed encryption, either.There were reasons for this.Â The original Predator, just 27 feet long, was little more than a scaled-up model plane with an 85-horsepower engine. It had a payload of just half a ton for all its fuel, cameras and radios. And encryption systems can be heavy. (Big crypto boxesÂ are a major reasonÂ the Armyâ€™s futuristic universal radio ended up being too bulky for combat, for example.) With the early Predator models, the Air Force made the conscious decision to leave off the crypto.The flying branch was well aware of the risk. â€œDepending on the theater of operation and hostile electronic combat systems present, the threat to the UAVs could range from negligible with only a potential of signal intercept for detection purpose, to an active jamming effort made against an operating, unencrypted UAV,â€?Â the Air Force reported in 1996.Â â€?The link characteristics of the baseline Predator system could be vulnerable to corruption of down links data or hostile data insertions.â€?The Predator models steadily grew in power and payload, and took a big leap in dimensions and capability with the 36-foot-long Reaper version introduced in 2007. The Reaper has a 950-horsepower engine and a nearly 4,000-pound payload â€” more than enough capacity for crypto-enabled systems which, like all electronics, had shrunk in size and weight.The problem was that, by then, the military had rushed to the battlefield hundreds ofÂ Remotely Operated Video Enhanced Receivers, orÂ RoversÂ â€“ rugged, laptop-sized receivers with screens for watching drone footage. And those early version of the Rovers were developed and distributed so fast, the military once again left the crypto off. â€œIt could be both intercepted (e.g., hacked into) and jammed,â€? e-mails an Air Force officer with knowledge of the program.Which mean the Pentagon was stuck, for a time. The military couldnâ€™t replace the old CDL waveform with something encryptable until the Rovers â€” and the radio transmitters aboard the Predators â€” could handle such a signal.Eventually, the Rovers began to be swapped out for newer models. The latest version, the â€œTactical Rover,â€? (.pdf) is about the size of an old-school mobile phone. It can use both the Advanced Encryption Standard an the triple-Data Encryption Standard to secure video feeds. There are now about a thousand of the units in the militaryâ€™s hands.And now, the Predators and Reapers are starting to get enhanced radios, too. â€œThe fleet-wide upgrade begins later this year and carries on for several years,â€? says Maj. Mary Danner-Jones, an Air Force spokesperson. The service is spending $12 million on crypto-enabled Vortex transceivers (.pdf).Thatâ€™s allowing a new, hardened waveform to be introduced throughout the Predator and Reaper fleet. The Air Force recently gave Predator-maker General Atomics Aeronautical SystemsÂ a $26 million contract to retrofit its drone cockpits to accept the carrier signal, among other enhancements.The question is why hasnâ€™t this happened sooner. After all,Â the Navy installed multiple layers of encryption inÂ theirÂ â€™bots some time ago. Navy spokesman Jamie Cosgrove tells Danger Room that â€œthe vast majorityâ€? of naval drones are encrypted â€“Â  â€œand have been since development.â€?One source who works on developing Navy UAVs, but is not authorized the speak on the record, explains why:Â â€?Standard unencrypted video is basically a broadcast to whoever can figure out the right carrier frequency, so essentially, we are simulcasting to battlefield commanders and the opposing force. If that opposing force knows we can see them and from where, they can take better evasive maneuvers.â€?Itâ€™s possible that none of the militants America is trying today are as sophisticated as the ones who intercepted that drone video in 2008. Itâ€™s possible that the value of such footage-from-above is so fleeting that extremists have never again bothered to grab it. But itâ€™s worth noting that Predator and Reaper video is considered by the U.S. military to be classified information. And when U.S. commanders on the ground get into a firefight, the first call they usually make is for a drone, so they can take a look at the battlefield through the eyes of a drone.Amsterdam, the Netherlands, â€“ Building on its innovation capabilities, today Philips unveils hue, the worldâ€™s smartest web-enabled LED home lighting system. Philips hue signals a new era in home lighting both in the way we think about and experience light in our homes. It allows you to create and control the light using your smartphone or tablet. Bringing endless possibilities to help you get creative and help you personalize your lighting to suit yours and your familyâ€™s lifestyle, Philips hue is available exclusively from Apple stores from 30th October. A starter pack includes three bulbs[1] that simply screw into your existing lamps, and a bridge that you plug into your home Wi-Fi router. Simply download the hue app to start experiencing light in a completely new way.Philips hue can be setup in minutes. The intuitive app allows you to remotely control your home lighting to help secure your home, personalize your home lighting experience with custom settings and program timers to help manage your daily schedules, all through the convenience of a smart device. An intuitive and seamless system, Philips hue is upgradeable and future-proof, with the potential for more features to be downloaded and enjoyed in the future.With its high quality energy-saving LED light, Philips hue allows you to tune shades of white light or create any color. In addition, Philips hue can:The app for Philipsâ€™ hue also features expert LightRecipes:Â  four pre-programmed lighting settings based on Philipsâ€™ research around the biological effects that lighting has on the body.Â  These scenarios adjust bulbs to the optimum shade and brightness of white light to help you relax, read, concentrate or energize.Jeroen de Waal, Head of Marketing & Strategy at Philips Lighting commented:Â  â€œPhilips hue is a game-changer in lighting â€“ a completely new way to experience and interact with light. In the way phones, media and entertainment have been revolutionized by digital technology, now we can also personalize light and enjoy limitless applications.Â  Philips continues to redefine the possibilities of LED technology, and hue pushes the boundaries even more, not only in offering great light quality, but in how lighting can be digitized and integrated with our world to further simplify and enhance our lives.â€?Â Â In home tests conducted in New York, Berlin and Shanghai, users highlighted hueâ€™s great quality light, programmable timers and the fact they could control their lighting from outside the home as features they most appreciated.Â  Moreover, consumers liked the ability to save personal light settings and recreate them at the touch of a button as well as the convenience of managing their lighting from their mobile device.Philips is opening up the hue app to the developer community and has created an open source platform at www.meethue.comÂ  inviting developers to explore the app and unleash even more possibilities to show what light can do to enhance your life. You can share light scenes or get inspired on the meethue.com community site. Philips hue uses the open ZigBee Light Link standard so that it can be integrated with other ZigBee certified systems.Building on the success of its AmbiLight experience, Philips is developing future product features, such as allowing hue to integrate with other media including sound and video.Â  Philips is also working on features such as geo-location services, allowing hue to sense when you are close to home and automatically turn on the lights, or turn them off when you leave.Â Â Â Philips hue is available only from Apple stores and Apple.com for $ 199 / â‚¬ 199 / Â£179. To find out more, visit www.meethue.com.Â For further information, please contact:Jeannet HarpePhilips LightingTel +31 6 53 722221Email: jeannet.harpe@philips.comAbout Royal Philips ElectronicsRoyal Philips Electronics of the Netherlands (NYSE: PHG, AEX: PHI) is a diversified health and well-being company, focused on improving peopleâ€™s lives through timely innovations. As a world leader in healthcare, lifestyle and lighting, Philips integrates technologies and design into people-centric solutions, based on fundamental customer insights and the brand promise of â€œsense and simplicity.â€? Headquartered in the Netherlands, Philips employs approximately 122,000 employees with sales and services in more than 100 countries worldwide. With sales of EUR 22.6 billion in 2011, the company is a market leader in cardiac care, acute care and home healthcare, energy efficient lighting solutions and new lighting applications, as well as lifestyle products for personal well-being and pleasure with strong leadership positions in male shaving and grooming, portable entertainment and oral healthcare. News from Philips is located at www.philips.com/newscenter.Â About ZigBee Light LinkZigBee Light Link gives the lighting industry a global standard for interoperable and very easy-to-use consumer lighting and control products. It allows consumers to gain wireless control over all their LED fixtures, light bulbs, timers, remotes and switches. Products using this standard will let consumers change lighting remotely to reflect ambiance, task or season, all while managing energy use and making their homes greener.Products built using this standard are as easy-to-use as a common dimmer switch. The standard does not require any special devices to coordinate with the lighting network, making it both easy and intuitive for consumers to use every day. Plus, it makes adding or even removing products to the lighting network a quick and easy. ZigBee Light Link products earning the ZigBee Certified seal are the industry's only networked consumer lighting products offering simplicity and interoperability.Since ZigBee Light Link is a ZigBee standard, lighting products will interoperate effortlessly with products using other ZigBee standards already in consumers' homes, including ZigBee Home Automation, ZigBee Input Device, ZigBee Remote Control and ZigBee Health Care.Leading home lighting solution manufacturers who contributed their expertise to the development of ZigBee Light Link, including GE, Greenwave, OSRAM Sylvania and Philips.Of all the images that have ever been made, would you be able to select just 100 to represent our species and human achievement? Trevor Paglenâ€™s Last Pictures is a project to do not only that, but also launch those images intoÂ geosynchronousÂ orbit around Earth â€“ all so that long after humans are gone, any space-wanderer will be able to fathom what humanity was all about.The project is based on the idea that after billions of years, all signs of human civilization will have eroded away on Earth, but its satellites will still spin around the planet, making them the best bet for an indefinite time capsule.â€œAny group of people would come up with 100 totally different images, but that is part of the fun. Itâ€™s an impossible project. Part of it was to engage peoplesâ€™ imaginations,â€?Â says artist Trevor Paglen, who conceived of the concept and collaborated with scientists, anthropologists, curators and corporations to get the images into space.Writer and artistÂ Anya VenturaÂ coordinated the work of five researchers who whittled down the image selection fromÂ 10,000 to 500 to 100. With every choice open to debate, it was a mindful experience.â€œWeâ€™re inundated with images, but we donâ€™t stop to look at them,â€? says Ventura.Â â€?The Last Pictures necessitates the act of looking. Itâ€™s a project that sticks with me because of our discussions about what makes a good photograph.Â We were tackling issues of representation and decoding images.â€?But choosing the images was only the beginning â€“ two more giant problems loomed. Firstly, how does one fabricate those 100 images to survive billions of years in space? Secondly, how does one get them into orbit?Brian Wardle, associate professor at MITâ€™s Department of Aeronautics and Astronautics and director of theÂ Nano-Engineered Composite aerospace StructuresÂ (NECST) Consortium, consulted on design and fabricated the vessel for the images. He andÂ Professor Karl Berggren, a quantumÂ nano-structuresÂ expert, were mostly concerned with preventing diffusion â€“ the incredibly slow movement of molecules which over millions of years could potentially degrade the sharpness of the image.â€œBy using a single material, Silicon, and etching physical features in that material, the Artifact will maximally resist diffusion. Usually the â€˜sands of timeâ€™ erase writings through erosion, but in this case we used sand/Silicon against time to resist its effect,â€? says Wardle with a poetic flourish.To that end, theÂ Last PicturesÂ are nano-etched onto a silicon disc â€“ referred to within the project as â€œthe Artifactâ€? â€“ and secured within a gold-plated aluminum clamshell.Paglen now knew the images could survive, but how to get them up there?Creative Time, a stalwart New York arts organization andÂ Last Pictures partner, was on board to help with the logistics, but even when the project mangerÂ telephoned every company that put hardware into space they drew a blank.Short on options,Â Anne Pasternak, Executive Director ofÂ Creative Time, began making pleas to audience members at her numerous public speaking events for contacts within theÂ satelliteÂ industry. Two connections and a few phone calls later,Â Last PicturesÂ had an agreement withÂ EchoStar Corporation, a Colorado-basedÂ telecommunicationsÂ company responsible for maintaining Dish Networkâ€™s satellite fleet. (EchoStar also owns SlingBox.)Once the deal was done, Paglen waited for a window. It came in December 2011 when Palo Alto-basedÂ Space Systems Loral were in the final stages of manufacturing the next EchoStar satellite.â€œEchostar gave us a month to get the disc tested and flight ready,â€? says Paglen.Â â€?Many engineers stepped up over the Christmas holidays.â€?After two delayed launch attempts, the 6,600 kilograms EchoStar XVI is set for launchÂ on November 20th from the Baikonur CosmodromeÂ inÂ Kazakhstan, on the back of an ILS Proton Breeze M Rocket. EchoStarâ€™s main cargo is 32 Ku-band transponders which will deliver direct-broadcast satellite (DBS) signals back to earth for suped-up local HD channels among other things.Last Picturesâ€˜ efforts have reminded many of Â Carl Saganâ€™sÂ Voyager Golden RecordÂ which includedÂ 116 images of animals, food, architecture, portraits and daily human life, as well as sounds.Â Ventura says the Last Pictures team were a bit sniffy about the appropriateness of Saganâ€™s images to farily represent unified humanity but when they took on a similar selection process, â€œweÂ realizedÂ how difficult it was,â€? says Ventura.â€œAt the beginning we imagined the images as an archive, but later we started to think of them as a silent film, like poetry. We made aesthetic decisions,â€? says Paglen who in the book arranges many images in pairs based on formal relationships.Â â€?I guess thatâ€™s where my artistic influence came in.â€?Paglen and his team deliberately included images to challenge viewers.â€œWeâ€™re making cave paintings for the future,â€? he says. â€œA lot of images are enigmatic.Â Thereâ€™s stories outside of the images. Enough to keep the aliens on their toes!â€?One curve ball is an installation shot of Malevichâ€™s work at the Last Futurist Exhibition in St Petersburg, 1915.Â It is Paglenâ€™s nod to the convergence of art, philosophy and science and to the definitive differences between the American and the Russian space programs.â€œThe U.S. space program has mythologies attached to pioneering and conquering, but the Russian tradition is very different,â€? says Paglen. â€œIn the Russian tradition, the ultimate goal of humanity was to resurrect all humans. In the late 19th centuryÂ Russian CosmistsÂ such asÂ Nikolai FyodorovÂ believed we need to go to space to collect all the particles of all the people who had ever lived.Â Cosmism says going into space is going into the past.â€?The majority of the images, which are published in the Last Pictures book, carry layers of narrative. Percival Lowellâ€™s 19th century maps of â€œcanalsâ€? on Mars surface are typical of the tension between reality and perception. Lowell wasnâ€™t out to fool anyone but the conflagration of tiny aperture and a eye condition he wasnâ€™t aware of had him seeing things.â€œHe thought he was mapping canals on Mars, but he was really seeing blemishes in his own eye,â€? says Anya Ventura.No one on the team is pompous about the selection. Rather Last Pictures is an interstellar version of the question, â€œIf your house was burning down, which photos would you save?â€? Itâ€™s about questions, not necessarily answers.â€œItâ€™s a paradoxical project. It is about time and space, but also ambivalent,â€? says Paglen. â€œLast Pictures questions material circumstances. What does it mean that we make machines that exist as long as the sun?â€?For those who are uncurious about the answers to these questions, fear not. Ultimately the project taxed only a relatively small amount of resources.â€œThe Artifact hitched a ride on a satellite that was going up anyway, and the delta in payload was absolutely negligible relative to typical mass budgets and this one specifically,â€? saysÂ BrianÂ Wardle of MIT.The hostÂ satellite will onlyÂ broadcast signal andÂ orbit Earth for 15 years. Scheduled for 2027, the mission profile of Echostar XVI includes an end-of-life maneuver into a spacecraft junkyard just beyond the Clarke Belt.â€œCreative projects are rarely the result of a single personâ€™s efforts,â€? says Paglen.Â â€?Technologically, it is not hard to launch anÂ objectÂ into space. Emotionally, it has been difficult.â€?Last Pictures, the book, is published by University of California Press. The project is to be presented as an travelling exhibition in 2013.Nexus 7 comes with all of Googleâ€™s best in class Apps - like Maps, Gmail, Chrome, Google+ and YouTube - all in the palm of your hand. With tons of free cloud storage, easy to use apps stay in sync automatically across your tablet, phone and PC. Google Now brings you just the right information, at just the right time. It shows you how much traffic to expect on your way to work, lets you know if your flight is delayed, and brings you live scores from your favorite sports teams. All automatically.On Thursday, 25 October, hundreds of Internet Archive supporters, volunteers, and staff celebrated addition of the 10,000,000,000,000,000th byte to the Archiveâ€™s massive collections.The only thing missing was electricity; the building lost all power just as the presentation was to begin. Thanks to the creativity of the Archiveâ€™s engineers and a couple of ridiculously long extension cords that reached a nearby house, the show went on.Vid The big launch of Microsoftâ€™s Surface slab got off to an inauspicious start in Beijing after an elderly couple invaded the stage in an attempt to halt proceedings.Redmond launched the Windows RT tablet-cum-laptop device at a series of events starting at midnight across the country in partnership with retail giant Suning.However, the Thursday night outdoor launch in the capital attracted two rather irascible Chinese attendees among the hundreds of Microsoft fans keen to be the first in the world to get their hands on the tablet.The inevitable YouTube clip - see below - shows an old dear mount the stage in an attempt to kill the noise because it was apparently stopping her grandchildren from getting to sleep before school the next day.Her brave attempt ends in failure, though, as sheâ€™s unceremoniously bundled off the stage by two guards, followed by her husband, while the glamorous sparkly dancers try to complete their routine.Not quite the impression Microsoft wanted to make in China.Things went from bad to worse for the software giant in Asia after reports emerged that a high-profile live public demonstration of Windows 8 in downtown Taipei fell flat when the OS cocked up on some devices. Microsoft staff apparently had trouble closing apps on several all-in-one PCs and instead were forced to demo the new OS on tablets.â€œIt was pretty rushed to the launch date, and the user experience will improve,â€? marketing manager Yi-Fang Chu told the Wall Street Journal.â€œIt is a hardware issue, rather than a software one. Itâ€™s partly because of the large screen size of the all-in-ones.â€? Â®Google has officially announced the Nexus 4, the latest phone in its Nexus line of flagship Android devices. Built by LG, the phone features a 4.7-inch 1280 x 768 IPS display, a 1.5GHz quad-core Snapdragon S4 Pro processor â€” which Google claims is the fastest on the market â€” an 8 megapixel camera and a 1.3 megapixel front-facing camera, and up to 16GB of storage. Oh, and the back is made of glass â€” etched, layered glass that sparkles with a strange, almost holographic depth.The executive vibe is balanced nicely by the playfulness of the backNot much of that should be surprising, as the phone had been thoroughly leaked around the web in the past few weeks. What is surprising is how much better it all looks in person. Compared to the LG Optimus G, which shares many of the same components, it's no contest â€” the Nexus 4 is a far nicer piece of hardware. It feels weighty and high-end, and the tight construction combined with the soft-touch plastic on the sides and chrome edging give it a solidly executive vibe â€” a vibe that's balanced nicely by the playfulness of Disco City on the back.The device will sell for $299 with 8GB of storage, or $349 with 16GB. A T-Mobile version will sell unlocked for $199 on a two-year contract. Alongside the improved screen and faster CPU, the Nexus 4 has 2GB of RAM, Wi-Fi 802.11b/g/n, NFC, Bluetooth, and built-in compatibility with Google's latest accessory, the Wireless Charging Orb â€” an inductive charging dock. The phone also houses a sizable 2100 mAh battery, which the company claims will get you about 10 hours of talk time.There's no LTE hereAll that battery life would be great if the device was sporting LTE radios â€” but it is not. Google has decided to forgo stricter carrier partnerships in the US, which for now means that the company will only offer the device as an unlocked HSPA+ phone. That's a bit of a crushing blow to many, who expected Google's next flagship phone to go toe-to-toe with the iPhone 5 and the latest crop of Windows Phone devices.On the bright side, the 320 ppi IPS+ LCD screen is terrific â€” a massive upgrade over the so-so Galaxy Nexus display and competitive with the iPhone's 326 ppi Retina Display. And it's not just competitive in pixel density; the screen looks stunning. It's also laminated and uses LG's new "G2" technology which integrates the touch sensor into the Gorilla Glass 2 outer layer, making everything thinner as well as bringing the actual pixels closer to the surface of the display. (Apple uses a similar technique called "in-cell touch" on the iPhone 5, which integrates the touch sensor into the display panel.) The screen is also curved slightly at the edges, like it's been melted over the phone; Google says it's meant to improve swiping in from the sides of the device.Performance on the phone was snappy. Google execs we spoke with pointed out just how fast the new Snapdragon CPU is, and in our short time testing the phone, it seemed to rip through just about anything we threw at it with little or no hesitation.The screen is curved slightly at the edges, like it's been melted over the phoneFor those disappointed with the camera performance of the Galaxy Nexus, there's also a bright spot here. Literally. Photos taken with the Nexus 4 seem greatly improved over the last generation, and Google reps say that a lot of attention has been paid to the low-light performance of the camera. We won't know for sure just how much better it is than previous phones until we put the device through its full paces, but first impressions suggest a big improvement.On the software front, Google is launching Android 4.2 along with the Nexus 4 (and the Nexus 10 tablet), and it's got some killer new features. We have a full look at the software here, not to mention an exclusive feature on the inside story of the Android team here, but there are a few standout components of the OS update that are worth mentioning.For starters, Google has added widget functionality to the lock screen, meaning you can quickly glance at information without having to get into the phone. The camera has also been improved with a completely redesigned UI focused on single-handed input, and Google has added a Street View-like mode called Photo Sphere which makes panorama shots seem tiny by comparison. The company has also improved Google Now significantly (we have a big feature story on that too).Android now has a typing mode called Gesture Typing, which mimics the functionality of Swype in conjunction with standard tap typing. The company has also added a new quick settings menu to the notifications window, tweaked Gmail with much-needed features like swipe to archive and scale-to-fit messages (like the iPhone), and added new accessibility options that make Android easier than ever â€” for all users.We'll have a full review of the Nexus 4 soon; until then, be sure to check into all of the in-depth news on Google's announcements today.You can also watch this video on YouTube.The system is powered by Nvidia GPUs and thought to be one of the two fastest supercomputers in the world. It's capable of making 20,000 trillion calculations each second.Forecasting for weather like this week's "Frankenstorm" may become a lot more accurate with the help of the Department of Energy's Titan supercomputer, a system that launched this month for open research development.The computer, an update to the Jaguar system, is operated in Tennessee by Oak Ridge National Laboratory, part of the DOE's network of research labs. Researchers from academia, government labs, and various industries will be able to use Titan -- believed to be one of the two most powerful machines in the world -- to research things such as climate change and alternative fuels."Why care about these big computers? It's really because society's got big problems," Steve Scott, chief technology officer of Nvidia's GPU accelerated computing business, said in a recent interview. "There are healthcare issues, lots of diseases across the board, an aging population. Energy is a huge problem facing the world and our country. ... Increasingly computers are used to solve these problems."As part of this month's launch of Titan, the DOE has awarded 4.7 billion supercomputing hours at Oak Ridge and another facility to 61 science and engineering projects with "high potential for accelerating discovery and innovation" through its Innovative and Novel Computational Impact on Theory and Experiment (INCITE) program.While the areas of research vary, there are six main areas targeted for Titan, according to Nvidia's Scott:Â• Material science code. This is basically looking at material at the atom level, to understand its properties. It also involves figuring out how to construct new materials to have superior properties of strength, weight, and other characteristics.Â• Climate change. Researchers want to answer questions about what's going on, how to change it, how to adapt to it, etc.Â• Biofuels. This involves looking at certain plants -- like switchgrass -- and converting them into ethanol using an enzymatic process.Â• Nuclear energy. The technology can be used to simulate neutron flux in fusion and fission. It includes looking at a new form of fusion energy that would be safer and cleaner, as well as new fuels that would burn longer and cleaner.Â• Combustion. Titan can allow the simulation of combustion for researchers trying to optimize the fuel, process, and engine design to get a cleaner burning fuel."All of these areas have tremendous real world societal benefits," Scott said. "And they need high performance computing to drive them forward."None of the research would be possible without the massive computing abilities provided by Titan. The system is believed to be more powerful than the world's current top supercomputers from Japan and China, and it rivals the Top500's No. 1 machine from June, the DOE's Sequoia machine at Lawrence Livermore National Laboratory.Titan is one of the new types of systems that combine discrete graphics chips, or GPUs, commonly used for videogames, along with standard microprocessors. In this case, Nvidia is providing the GPUs while the CPUs come from Advanced Micro Devices. Graphics chips are used to accelerate the number-crunching functions of supercomputers by allowing many tasks to be completed at once, and they require less power than CPUs alone.Titan is 10-times more powerful and five-times more energy efficient than Oak Ridge's last system, dubbed Jaguar. Oak Ridge says the use of GPUs combined with CPUs allows Titan to take up the same physical space as Jaguar while using only "marginally" more electricity (9 megawatts for Titan versus 7 megawatts for Jaguar).If Oak Ridge upgraded Jaguar by simply expanding the CPUs, the system would be more than four-times its current size and would consume more than 30 megawatts of power.Jaguar became the world's most powerful supercomputer in late 2009, and it held onto that title for a year before being passed by a Chinese system. The DOE's Sequoia system, meanwhile, nabbed the top spot in June with a performance of 16.32 petaflops. That system is powered by IBM chips and is used for classified national defense research.Titan may prove to be the most powerful system when the list is again released early next month, Scott said.It's almost mindboggling how fast Titan operates. The system is capable of churning through more than 20,000 trillion calculations each second -- or 20 petaflops -- by using GPUs.The system, developed by Cray, contains 18,688 nodes, with each containing a 16-core AMD Opteron processor and an Nvidia Tesla GPU based on the graphics chipmaker's Kepler architecture. Titan also has more than 700 terabytes of memory.Bill Blake, chief technology officer at Cray, said the industry is at an inflection point where GPUs become necessary to reach higher performance in supercomputers."For the foreseeable future, for sure the next 10 years plus, the industry will be on this inflection point of change because of accelerated computing," he said in a recent interview.A smart road design that features glow in the dark tarmac and illuminated weather indicators will be installed in the Netherlands from mid-2013."One day I was sitting in my car in the Netherlands, and I was amazed by these roads we spend millions on but no one seems to care what they look like and how they behave," the designer behind the concept, Daan Roosegaarde, told Wired.co.uk. "I started imagining this Route 66 of the future where technology jumps out of the computer screen and becomes part of us."The Smart Highway by Studio Roosegaarde and infrastructure management group Heijmans won Best Future Concept at the Dutch Design Awards, and has already gone beyond pure concept. The studio has developed a photo-luminising powder that will replace road markings -- it charges up in sunlight, giving it up to ten hours of glow-in-the-dark time come nightfall. "It's like the glow in the dark paint you and I had when we were children," designer Roosegaarde explained, "but we teamed up with a paint manufacture and pushed the development. Now, it's almost radioactive".Special paint will also be used to paint markers like snowflakes across the road's surface -- when temperatures fall to a certain point, these images will become visible, indicating that the surface will likely be slippery. Roosegaarde says this technology has been around for years, on things like baby food -- the studio has just upscaled it.The first few hundred metres of glow in the dark, weather-indicating road will be installed in the province of Brabant in mid-2013, followed by priority induction lanes for electric vehicles, interactive lights that switch on as cars pass and wind-powered lights within the next five years.The idea is to not only use more sustainable methods of illuminating major roads, thus making them safer and more efficient, but to rethink the design of highways at the same time as we continue to rethink vehicle design. As Studio Roosegaarde sees it, connected cars and internal navigation systems linked up to the traffic news represent just one half of our future road management systems -- roads need to fill their end of the bargain and become intelligent, useful drivers of information too."Research on smart transportation systems and smart roads has existed for over 30 years -- call any transportation and infrastructure specialist and you'll find out yourself," Studio Roosegaarde comunications partner Emina Sendijarevic told Wired.co.uk. "What's lacking is the implementation of those innovations and making those innovations intuitive and valuable to the end-consumers -- drivers. For this, a mentality change needs to take place within a country and its people, but also within a company such as Heijmans."This is a story that goes beyond the 'Smart Highway' as such -- it's about the fact that Heijmans and Roosegaarde are not going to wait any longer for innovations to find their way through the political system, but will start building this highway now."All together, the studio has around 20 ideas that will eventually be rolled out and it has had inquiries from countries across the globe -- "India is really keen on it; they have a lot of blackouts there, it would be hallelujah to them".Roosegaarde also hopes to take his designs to the US west coast, where companies like Google already have autonomous vehicles driving round their campuses: "It amazes me that most innovation in the west coast is screen based -- I always imagined that technology jumping out of our screens and becoming part of our environment. It's incredibly important we keep imagining what our reality is going to look. A lot of people have told me along the way that what I wanted could not be done, and it's my job to prove them wrong."The Roosegaarde design promise comes as UK authorities announce that lights on motorways, residential streets and footpaths will be turned off or dimmed from as early as 9pm to save money (hundreds of thousands of pounds, in some cases) and to meet green targets.Some councils are, however, taking on the burden of installing new lights with dimmers, the cost of which will mean they will need to wait four to five years before they recoup the money -- by which time, they could have conserved cash for more efficient and safer ways to save on lighting costs. A Sunday Telegraph report has also revealed that nearly 5,000km of motorways and trunk roads in England are already unlit, 75km have their lights switched off between midnight and 5am and 73 percent of 134 councils surveyed switch off or dim lights, or plan to. Fully switching the lights off on major roads saved the Highways Agency just Â£400,000 in 2011.Paul Watters, head of roads policy at the AA, told the Telegraph: "We do know that most accidents happen in the dark. It's also comforting for people, especially if they arrive back from somewhere in the night, when they have got a late train. There are also suggestions that it increases crime. So it may save money in terms of energy but then you have to look at the cost in terms of security, safety and accidents, it may actually be more."According to a report by car insurance company Zurich Connect, there is an 11 percent increase in claims immediately following the winter clock change in the UK, when nights get darker earlier.A slide taken from an online slideshow by a political targeting firm.Connect with Facebook to share articles you read on ProPublica. Learn more Â»If you're a registered voter and surf the web, one of the sites you visit has almost certainly placed a tiny piece of data on your computer flagging your political preferences. That piece of data, called a cookie, marks you as a Democrat or Republican, when you last voted, and what contributions you've made. It also can include factors like your estimated income, what you do for a living, and what you've bought at the local mall.Across the country, companies are using cookies to tailor the political ads you see online. One of the firms is CampaignGrid, which boasted in a recent slideshow, "Internet Users are No Longer Anonymous."Â The slideshow includes an image of the famous New Yorker cartoon from 1993: "On the Internet, nobody knows you're a dog." Next to it, CampaignGrid lists what it can now know about an Internet user: "Lives in Pennsylvania's 13th Congressional District, 19002 zip code, Registered primary voting Republican, High net worth household, Age 50-54, Teenagers in the home, Technology professional, Interested in politics, Shopping for a car, Planning a vacation in Puerto Rico."The slideshow was online until last week, when the company removed it after we asked for comment. (Here is the full slideshow.) Rich Masterson, CampaignGrid's chairman, wrote in an email that the slideshow was posted in error: "It was an unapproved version of a sales deck that was posted by an intern who no longer works for the company."CampaignGrid does indeed collect 18 different "attributes" for every voter, Masterson told ProPublica, including age, gender, political donations, and more. Campaigns use this data to tailor the online ads you see.Online targeting has taken off this campaign season. ProPublica has identified seven companies that advertise the ability to help campaigns target specific voters online. Among them is Experian, the credit reporting company. Datalogix, a company that works with Facebook to track users' buying patterns, is also involved. (Here are marketing materials and comment from the seven companies). CampaignGrid and a few, similar firms have been profiled for their innovative approaches. Yet the scale of the targeting and the number of companies involved has received little notice.Few of the companies involved in the targeting talk about it publicly. But CampaignGrid, which works with Republicans, and a similar, Democratic firm, Precision Network, told ProPublica they have political information on 150 million American Internet users, or roughly 80 percent of the nation's registered voters.The information â€” stripped of your name or address â€” is connected to your computer via a cookie. Targeting firms say replacing your name with an ID number keeps the process anonymous and protects users' privacy.But privacy experts say that assembling information about Internet users' political behavior can be problematic even if voters' names aren't attached."A lot of people would consider their political identity more private than lots of information," said William McGeveran, a data privacy expert at the University of Minnesota Law School. "We make more rules about medical privacy. We make more rules about financial privacy. So if you think private political beliefs are in that category, maybe you're concerned about having them treated like your favorite brand of toothpaste."Google has stayed away from this kind of targeting. It classifies political beliefs as "sensitive personal information," in the same category as medical information and religious beliefs.But other big players have embraced the "political cookie," as one company branded it.As we reported in June, Yahoo and Microsoft sell access to your registration information for political targeting. That's one way CampaignGrid and other companies find you online. Political targeting firms say they also work with other websites, but would not name them.While campaigns and the firms working with them can buy reams of data about voters, voters have been left mostly in the dark.Many online ad companies mark targeted ads with a small blue triangle symbol, or the phrase "Ad Choices," and offer surfers a chance to opt out. But even if web users know what the triangle means, they get no information about how or why they were targeted."Consumers don't really understand what's going on and haven't given their permission," says Joseph Turow, a digital marketing and privacy expert at the University of Pennsylvania's Annenberg School for Communication.There are few legal regulations governing how online targeting works, or what notification consumers must receive.Online advertising experts point out that individual voting records are public information and have long been used to target voters through direct mail. And targeting companies say they are offering a valuable service. Instead of seeing random ads, users get to see ads from candidates they might actually want to support."We empower voters," Jeff Dittus, co-founder of Campaign Grid and now head of Audience Partners, wrote in an email. "We give voters information that is meaningful to them and helps them make choices."Stuart Ingis, a lawyer for the Digital Advertising Alliance, an industry group, said that voter file targeting is a First Amendment issue, and that targeting should be protected as part of political speech."These technologies provide a method for politicians inexpensively to improve our democracy," he said. "I would say that the founding fathers firmly believed in the ability â€” I think our society very much values the ability â€” to efficiently reach a desired audience with a political message."Not everyone seems to agree. A recent study from the University of Pennsylvania's Annenberg School found that 86 percent of surveyed adults did not want "political advertising tailored to your interests," and that 77 percent would not return to a website if they knew it "was sharing information about me with political advertisers."While targeting firms promise a wealth of individual detail, it's hard to know how much information most campaigns are actually using."The more third-party data providers you use, the smaller the universe of people who you can reach becomes," CampaignGrid's Masterson said. "Republican women 25-34 who drive SUVs and have American Express cards, and go to the theater once a month â€” that might be four people."One place online voter targeting has been used successfully is in the state senate primary race of Morgan McGarvey, a Kentucky Democrat who faced off against three other Democratic candidates this May.With four liberal candidates competing for a liberal district, McGarvey told ProPublica, he needed to convince the small number of voters who would turn out in the primary that they should vote for him.His campaign worked with Precision Network to show online McGarvey ads to local voters under 35, and to female Democrats who had voted in at least three of the past five primary elections. (Two of his challengers were women.)"When every dollar counts, when literally every vote counts, you have to be more targeted," he said."I do think it helped us win."McGarvey is now running unopposed in the November election.Have you seen a targeted political ad?Help us find out how politicians are targeting you online.1. If you spot a small blue triangle icon on any online political ad, or the words "Ad Choices," take a screenshot of the ad.2. Then click on the blue triangle or the words "Ad Choices" to find out which company showed you the ad. Take a screenshot of that, too.3. Email the screenshots to us at targeting2012@propublica.org. Please include the full URL of the page where you saw the ad.If the ad asks you to "learn more," visit a website, donate, or sign a petition, please send us a screenshot of that site or petition, as well. (The page where the ad sends you may also be targeted to what advertisers know about you.)Not sure how to take a screenshot? Here are the instructions if you're using a PC, using a Mac, or using a smartphone.On 9th July 2012 the High Court of Justice of England and Wales ruled that Samsung Electronic (UK) Limited's Galaxy Tablet Computer, namely the Galaxy Tab 10.1, Tab 8.9 and Tab 7.7 do not infringe Apple's registered design No. 0000181607-0001. A copy of the full judgment of the High court is available on the following link www.bailii.org/ew/cases/EWHC/Patents/2012/1882.html.In the ruling, the judge made several important points comparing the designs of the Apple and Samsung products:"The extreme simplicity of the Apple design is striking. Overall it has undecorated flat surfaces with a plate of glass on the front all the way out to a very thin rim and a blank back. There is a crisp edge around the rim and a combination of curves, both at the corners and the sides. The design looks like an object the informed user would want to pick up and hold. It is an understated, smooth and simple product. It is a cool design.""The informed user's overall impression of each of the Samsung Galaxy Tablets is the following. From the front they belong to the family which includes the Apple design; but the Samsung products are very thin, almost insubstantial members of that family with unusual details on the back. They do not have the same understated and extreme simplicity which is possessed by the Apple design. They are not as cool."That Judgment has effect throughout the European Union and was upheld by the Court of Appeal on 18 October 2012. A copy of the Court of Appeal's judgment is available on the following link www.bailii.org/ew/cases/EWCA/Civ/2012/1339.html. There is no injunction in respect of the registered design in force anywhere in Europe.However, in a case tried in Germany regarding the same patent, the court found that Samsung engaged in unfair competition by copying the iPad design. A U.S. jury also found Samsung guilty of infringing on Apple's design and utility patents, awarding over one billion U.S. dollars in damages to Apple Inc. So while the U.K. court did not find Samsung guilty of infringement, other courts have recognized that in the course of creating its Galaxy tablet, Samsung willfully copied Apple's far more popular iPad.The land in West Oakland where Eric Maundu is trying to farm is covered with freeways, roads, light rail and parking lots so there's not much arable land and the soil is contaminated. So Maundu doesn't use soil. Instead he's growing plants using fish and circulating water.It's called aquaponics- a gardening system that combines hydroponics (water-based planting) and aquaculture (fish farming). It's been hailed as the future of farming: it uses less water (up to 90% less than traditional gardening), doesn't attract soil-based bugs and produces two types of produce (both plants and fish).Aquaponics has become popular in recent years among urban gardeners and DIY tinkerers, but Maundu- who is trained in industrial robotics- has taken the agricultural craft one step further and made his gardens smart. Using sensors (to detect water level, pH and temperature), microprocessors (mostly the open-source Arduino microcontroller), relay cards, clouds and social media networks (Twitter and Facebook), Maundu has programmed his gardens to tweet when there's a problem (e.g. not enough water) or when there's news (e.g. an over-abundance of food to share).Maundu himself ran from agriculture in his native Kenya- where he saw it as a struggle for land, water and resources. This changed when he realized he could farm without soil and with little water via aquaponics and that he could apply his robotics background to farming. Today he runs Kijani Grows ("Kijani" is Swahili for green), a small startup that designs and sells custom aquaponics systems for growing food and attempts to explore new frontiers of computer-controlled gardening. Maundu believes that by putting gardens online, especially in places like West Oakland (where his solar-powered gardens are totally off the grid), it's the only way to make sure that farming remains viable to the next generation of urban youth.More info on original story: http://faircompanies.com/videos/view/internet-food-arduino-based-urban-aquapo...TorrentFreak broke an unsurprising, but amazing, story this week in uncovering that Stroz Friedberg, the supposedly "independent and impartial tech expert" that was brought on to assist the Center for Copyright Information (CCI) in making sure that the new "six strikes" program BitTorrent monitoring is accurate, used to lobby for the RIAA. Apparently this bit of news took folks at CCI completely by surprise, since the RIAA failed to mention that tidbit of info. Now, CCI is apparently scrambling to make things right -- either by finding someone new, or by "opening up" the review that Stroz Friedberg does for the public to review. Either way, it's pretty incredible that the RIAA thought that no one would notice that the "impartial and independent" expert just happened to be a biased party that lobbied directly for them in the past.The land in West Oakland where Eric Maundu is trying to farm is covered with freeways, roads, light rail and parking lots so there's not much arable land and the soil is contaminated. So Maundu doesn't use soil. Instead he's growing plants using fish and circulating water.It's called aquaponics- a gardening system that combines hydroponics (water-based planting) and aquaculture (fish farming). It's been hailed as the future of farming: it uses less water (up to 90% less than traditional gardening), doesn't attract soil-based bugs and produces two types of produce (both plants and fish).Aquaponics has become popular in recent years among urban gardeners and DIY tinkerers, but Maundu- who is trained in industrial robotics- has taken the agricultural craft one step further and made his gardens smart. Using sensors (to detect water level, pH and temperature), microprocessors (mostly the open-source Arduino microcontroller), relay cards, clouds and social media networks (Twitter and Facebook), Maundu has programmed his gardens to tweet when there's a problem (e.g. not enough water) or when there's news (e.g. an over-abundance of food to share).Maundu himself ran from agriculture in his native Kenya- where he saw it as a struggle for land, water and resources. This changed when he realized he could farm without soil and with little water via aquaponics and that he could apply his robotics background to farming. Today he runs Kijani Grows ("Kijani" is Swahili for green), a small startup that designs and sells custom aquaponics systems for growing food and attempts to explore new frontiers of computer-controlled gardening. Maundu believes that by putting gardens online, especially in places like West Oakland (where his solar-powered gardens are totally off the grid), it's the only way to make sure that farming remains viable to the next generation of urban youth.More info on original story: http://faircompanies.com/videos/view/internet-food-arduino-based-urban-aquapo...The search and software giant says it has hit the new milestone for programs available for Android. By comparison, Microsoft has 120,000.Google has hit another milestone for Android apps, and this one is pretty big news for Apple too.The number of apps available for Android now totals about 700,000, a Google spokesman confirmed to CNET. That's up from the 675,000the company said it had a month ago.And it equals the figure Apple most recently touted. The Cupertino, Calif., company first revealed it had about 700,000 apps available in its store last month, and Apple reiterated that amount during the iPad Mini launch last week.The number of apps offered for an operating system is an important factor for driving user adoption. Apple had long led the rest of the market, but Google had been quickly catch up. By comparison, Microsoft said yesterday that it now has 120,000 apps for it Windows Phone OS. That's a pretty big figure for the company but it significantly lags Android and iOS.There may be an app for almost everything, but there still isnâ€™t one for controlling Mother Nature.Google this morning officially canceled the Android event that was scheduled to occur on Monday, October 29 in New York City due to Hurricane Sandy, which is expected to hit the city on Sunday evening.In an email sent to reporters signed up to attend the event first picked up by Marketing Landâ€™s Danny Sullivan, Google issued a terse explanation:â€œWe are canceling our Monday morning event in New York due to Hurricane Sandy. We will let you know our plans as soon as we know more.â€?Weâ€™ve reached out to Google PR for more detail on when the event may be rescheduled, and will be sure to update this with anything we hear.The Android event was expected to compete for press attention with Microsoftâ€™s Windows Phone 8 launch also planned for Monday October 29th. That event is still on, though, as itâ€™s taking place in sunny San Francisco.Over 170,000 people are part of the Sophos community on Facebook. Why not join us on Facebook to find out about the latest security threats. Don't show me this againHi fellow Twitter user! Follow our team of security experts on Twitter for the latest news about internet security threats. Don't show me this againDon't forget you can subscribe to the SophosLabs YouTube channel to find all our latest videos. Don't show me this againHi there! If you're new here, you might want to subscribe to our RSS feed for updates. Don't show me this againAlready using Google+? Find us on Google+ for the latest security news. Don't show me this againOn LinkedIn? Join the Naked Security discussion group and connect with your peers in the security industry. Don't show me this againSorry, something happened and we couldn't sign you up. Please come back later and try again.Congratulations, you've successfully signed up for our daily news! Check your inbox soon, we've sent you an email.Sorry, that email doesn't look right to us so we haven't added it to our list.Join thousands of others, and sign up for Naked Security's newsletterA little more than a month ago Apache went head to head with Microsoft over the choice of do not track (DNT) in Internet Explorer 10. Apache has now backed down and provides the code to ignore DNT as a commented option in its config files.On Friday Yahoo! decided it was time to take over the resistance to DNT by announcing it would now ignore Internet Explorer 10 users' choices to not be tracked on grounds that it believes its users' experience is "better when it is personalized."There are several problems with their argument.The crux of the matter is whether Internet Explorer 10 is requiring users to choose a tracking preference. Considering the options presented during installation, this should be obvious.Yahoo! and other organizations that depend upon advertising revenue need to find a balance between targeted ads and respect for user privacy. If I log into their services I expect personalized weather, sports, stock and targeted advertising.If I simply click a link that leads to a Yahoo! asset, they should respect my choice, do not track, and present ads that may not be tailored, but still support Yahoo's valuable services.Every day I receive non-targeted ads in my physical mailbox. Pizzas, manicures and concerts from the latest bands. Clearly this generates revenue and costs significantly more than delivering a banner ad.I am not a piece of meat to be sent to market. Respect my choices and adapt your business model. I am happy to buy products and happy to pay for the services I receive.Proof? Follow me on App.Net. If you care about your privacy, insist that companies honor your preferences and don't patronize those who don't.And to Yahoo!: If you want to talk big about privacy, put your money where your mouth is. I don't begrudge you your methods, but respect my choices. Microsoft fairly presents a choice and you need to honor it or become irrelevant.What theyâ€™re doing on Marsden Farm isnâ€™t organic. Itâ€™s not industrial, either. Itâ€™s a hybrid of the two, an alternative version of agriculture for the 21st century: smart, green and powerful.On this farm in Boone County, Iowa, in the heart of corn country, researchers have borrowed from both approaches, using traditional techniques and modern chemicals to get industrial yields â€” but without industrial consequences.If the approach works at commercial scales, and thereâ€™s good reason to think it will, it might just be an answer to modern farmingâ€™s considerable problems.â€œWe wanted to show that small amounts of synthetic inputs are very powerful tools, but theyâ€™re tools with which you tune the system, not drive it,â€? said Adam Davis, a researcher with the United States Department of Agriculture.The Marsden Farm experiment, which is described in a study published Oct. 10 in Public Library of Science One, started in 2003, when Davis was a graduate student under agronomist Matt Liebman of Iowa State University. Liebmanâ€™s specialty is integrated pest management, or strategies that use nature to accomplish whatâ€™s typically done with pesticides, herbicides and synthetic fertilizer.Itâ€™s not a new idea, but itâ€™s one thatâ€™s been generally neglected for the last several decades, as large-scale farming came to rely on simplified, chemically intensive and ultimately unsustainable approaches. For a while, these worked, but with high yields came big problems: the threat of catastrophic disease outbreaks in monocultures, an insatiable demand for nitrogen fertilizer, pesticide-resistant bugs and herbicide-resistant superweeds, and a new generation of crops designed to be drenched in toxic chemicals.â€œWe have two choices now,â€? said Liebman. â€œWe can double down, load more chemicals into the system, and get another decade of increasingly ineffective control â€” or we can choose the path towards integrated management.â€?Liebman, inspired in part by a pioneering Iowa farmer named Dick Thompson, wanted to bring integrated pest management back, but augmented with technologyâ€™s new tools. On 22 acres at Marsden Farm, his team planted three plots with different rotations of crops. The first followed a two-year rotation, alternating between corn and soybeans, as is customary in the region. It was managed the usual way, with lots of chemicals.For the second plot, the researchers rotated over three years between corn, soy and oats, with red clover planted in winter. The clover, which absorbs atmospheric nitrogen, was planted between crop rows and plowed under as soil-replenishing â€œgreen manureâ€? in spring. On another plot, instead of red clover the researchers planted a fourth-year crop of alfalfa, which can be used to feed livestock. The animalsâ€™ manure came back as fertilizer.On these fields, the researchers still used herbicides and pesticides, but not the usual way. Rather than spraying them routinely over large areas, Liebmanâ€™s team applied them only when necessary. â€œWe use low-dose products in the smallest quantities possible,â€? he said. â€œWeâ€™re not against their use. What weâ€™re arguing for is using them as carefully deployed tactical options.â€?Liebman called these applications â€œtherapeutic measures.â€? Therapy wasnâ€™t often needed. Having different crops with different life cycles made it harder for weeds to grow. What might flourish among corn and soy, for example, was disrupted by oats. When red clover and alfalfa were mowed, weeds were chewed up before they flowered. As for insect problems, low pesticide use, along with habitat provided by cover crops, allowed pest-eating bugs and birds to flourish.After eight years, Liebman and Davis used eight times less herbicide in the three- and four-year rotations than in the conventional plot, they report in the new study. Ecotoxicity in surrounding water was two orders of magnitude lower. Thanks to clover and alfalfa, the experimental plots also used 86 percent less synthetic fertilizer.Most important of all, the experimental plots were as productive as the conventional. They produced just as much total crop biomass. When the researchers calculated the value of their environmentally friendly harvest, it was every bit as profitable.â€œWe exceeded those goals â€” not by pumping chemicals in, but by maximizing ecosystem services,â€? Davis said. â€œWeâ€™re not throwing away those tools. Theyâ€™re very important. But you use a strong cropping system as the foundation for your agriculture. Then, when you need it, you tweak it a little bit with the inputs.â€?Liebman and Davis said the system can be scaled up and applied to other crops. While the new studyâ€™s details were local, the essential underlying principle, of building a crop system around the ecological services it provides, is universal.â€œThis is a great study,â€? said John Reganold, a soil scientist at Washington State University who was not involved in the research. â€œWeâ€™ve been pushing the envelope on yields, and not paying as much attention to the environmental and social and economic consequences. This shows that these integrated systems can be profitable, produce high yields, and offer more environmental benefit.â€?In a paper published last year in Science, Reganold called for a transformation of U.S. agriculture along the lines seen at Marsden Farm. â€œTheyâ€™re almost like a blend of conventional and organic, using the best of both worlds,â€? he said. â€œItâ€™s these kinds of systems we need.â€?â€œTheir ideas point to the way that agriculture has to be in the future,â€? said agronomist Nicholas Jordan of the University of Minnesota. â€œThereâ€™s wide consensus that we have to figure out this fusion of â€˜organicâ€™ and â€˜industrial.â€™ Theyâ€™ve illustrated what that fusion looks like. Itâ€™s power and efficiency.â€?Jordan stressed that the Marsden Farm data was sound: No fudged numbers, no apples-and-oranges comparisons or subtle statistical slip-ups. Asked if the methods could scale commercially, Jordan said â€œthe answer is a resounding yes.â€?His enthusiasm was, however, tempered with caveats about challenges. Integrated pest management is much more complicated than industrial farming, requiring more day-to-day decisions and local knowledge. â€œWeâ€™ve become very, very used to a system thatâ€™s straightforward,â€? said crop scientist GermÃ¡n Bollero of the University of Illinois. â€œImplementing this at a large scale is not going to be easy.â€?Integrated pest management also requires more work. In the new study, the conventional method demanded one-third less labor than Liebman and Davisâ€™s fusion. â€œIt takes an energetic farmer, someone whoâ€™s investing a lot more of their own time, or potentially hiring added labor,â€? said agricultural economist Greg Graff of Colorado State University.These challenges should not be insurmountable. Locale-specific research will help with complexity. As for the additional labor, money that would have gone to chemicals can be used to hire workers. â€œI would argue that needing more labor in these systems means more jobs,â€? Reganold said. â€œIt will be good for the well-being of rural communities.â€?There are other advantages to the Marsden Farm method. As corn and soy production intensified in the midwest, field farmers often stopped raising livestock. These are now grown in concentrated animal feeding operations, which both incubate new disease and generate immense amounts of waste. If livestock again became part of local farming, as was required to consume the Marsden Farmâ€™s alfalfa, that waste would be fertilizer.Diverse, year-round crop rotations are also more resilient to climate stress. Weather patterns in the the midwestern United States are becoming more extreme, veering between the catastrophic floods of 2008 and 2010 and this summerâ€™s epic drought. Complex root systems prevent soil from washing away during spring rains, and store extra water against dry spells.â€œThese more diversified systems, the three- and four-year systems in the study, are less vulnerable to resource scarcities, climate change and market volatility,â€? said Reganold. â€œThese systems use less fertilizer and pesticides than the typical conventional system. Yes, this is environmentally beneficial, but it also has economic benefits because the price of fertilizers and pesticides will likely increase in the future.â€?If transforming agriculture seems an imposing task, Liebman said it can start small, with something as simple as weaving conservation strips into fields. It also doesnâ€™t need to happen immediately, in one radical step.â€œThe concept could be introduced by encouraging farmers to continue farming in the traditional way, but little by little introduce diversity. There could be tax benefit or subsidy for introducing things like cover crops,â€? Bollero said. â€œIf those signals are there, youâ€™ll see a lot of farmers adopting this.â€?Graff noted that farm subsidies currently favor intensive soy and corn production, and that industry lobbying groups have actively resisted subsidy reform that rewards other types of crop production. Ultimately, however, this is an issue that citizens can decide.â€œA very large amount of taxpayer money is channeled through the federal government into the farming sector. In Iowa, itâ€™s something like $1 billion of your money,â€? Liebman said. â€œIf you can get cleaner water, less exposure to pesticide, and more wildlife habitat, if farmers can maintain their revenue streams and work in a healthier world â€” why wouldnâ€™t you do that?â€?NEW YORK (CNNMoney) -- It's gadget season, and Google wants in on all the fun that Microsoft and Apple have been having.Google (GOOG, Fortune 500) unveiled a new "Nexus" phone, tablet and Android operating system on Monday. Its goal is wrest back some of the attention that Windows 8, Surface, the iPad, iPad miniand iPhone 5 have gotten over the past several weeks.The Nexus 4 is the fourth annual "Google phone," designed by the search giant and manufactured by one of its Android partners -- this time, LG. Google didn't say much about the device, other than that it has the latest quad-core mobile processor (that's fast), and a 4.7-inch screen (really big).Google's Nexus phones have never sold particularly well, but this time around Google is trying something bold. For $299, customers can buy a Nexus 4 without a two-year contract. That's quite cheap for an "unlocked" high-end smartphone. An unlocked iPhone 5, by comparison, costs $650.The base model Nexus 4 comes with 8 gigabytes of storage, half the typical amount for a smartphone. A 16 GB phone is available for $349. Both will go on sale on Nov. 13 online at the Google Play store. T-Mobile customers can also get a 16 GB version with a two-year contract for $199.The Nexus also works on AT&T (T, Fortune 500), which uses a similar network technology, but it isn't compatible with Verizon's network or Sprint's, according to a Google spokesman.The search leader also announced a new 10-inch tablet, dubbed the Nexus 10. With 300 pixels per inch, the Samsung device has the highest-resolution screen for any tablet, Google claims, including the iPad with Apple's Retina display. Apple (AAPL, Fortune 500) says the iPad sports a 264-pixels-per-inch screen.The Nexus 10 allows for multiple user accounts, so that a family can share the device and keep separate apps and settings for each user. It also has stereo speakers and a standard tablet battery that lasts for nine hours.The price tag is competitive: The 16 GB version will go on sale on the Google Play store Nov. 13 for $399, and a 32 GB version will be available for $499. Comparable iPads are each $100 more expensive.Google also unveiled an update to its Nexus 7 tablet, which the company unveiled in June. A new 32 GB version of the seven-inch Asus device is now available with AT&T's 3G-HSPA+ service -- which AT&T brands as "4G" -- for $299."We think today's devices offer the very best that money can buy," Android chief Andy Rubin said in a blog post.The Android software that runs Google's devices also got a minor update on Monday. New features include Photo Sphere, a 360-degree photo-taking app and wireless streaming support for Qualcomm's (QCOM, Fortune 500) Miracast wireless displays. It also offers a keyboard that doesn't require typing: "Gesture Typing" lets users glide their fingers over the letters they want to type.Google Now, an app that surfaces important information from e-mail, calendars and social networks, added support for flight information notifications, restaurant reservations, hotel confirmations and shipping details, in addition to nearby attractions like movies times at local theaters.A launch event had been planned in New York, but it was canceled due to Hurricane Sandy. Google announced the devices in a blog post instead.Microsoft (MSFT, Fortune 500) will be holding a Windows Phone 8 launch event in San Francisco on Monday.The European Union will spend approximately $900 million on a project to build the world's most intense, powerful laser beam in order to eviscerate nuclear waste and possibly provide new cancer treatments as well.TheÂ EXTREME LIGHT INFRASTRUCTURE project (ELI)Â involves nearly 40 research and academic institutions from 13 different states within the European Unioin.ELI's coordinator at its Romanian facility, Nicolae-Victor Zamfir, told Bloomberg that the lasers are "10 times more powerful than any yet built and will be strong enough to create subatomic particles in a vacuum, similar to conditions that may have followed the start of the universe."Â "Eventually," according to Zamfir, "the power of the light beams could be used to deteriorate the radioactivity of nuclear waste in just a few seconds and target cancerous tumors."The cancer treatment would be similar to a current experiential process known as hadron therapy.Â The therapy is particularlyÂ effective in targeting cancers located in areas "which are inaccessible to the surgeon's instruments or which are hard to treat by radiotherapy," like brain tumors, those in areas close to the spinal cord, or inside the eye.There will be four separate sites throughout Europe that make up the facility when it is completed: the one in Romania, another in Hungary, a third in the Czech Republic, and a fourth in a location that has yet to be named (but will be by the end of 2012).The laser is expected to become operational in 2017.See the most energetic laser beam ever created >MENLO PARK, Calif. â€” Many people cite Albert Einsteinâ€™s aphorism â€œEverything should be made as simple as possible, but no simpler.â€? Only a handful, however, have had the opportunity to discuss the concept with the physicist over breakfast.One of those is Peter G. Neumann, now an 80-year-old computer scientist at SRI International, a pioneering engineering research laboratory here.As an applied-mathematics student at Harvard, Dr. Neumann had a two-hour breakfast with Einstein on Nov. 8, 1952. What the young math student took away was a deeply held philosophy of design that has remained with him for six decades and has been his governing principle of computing and computer security.For many of those years, Dr. Neumann (pronounced NOY-man) has remained a voice in the wilderness, tirelessly pointing out that the computer industry has a penchant for repeating the mistakes of the past. He has long been one of the nationâ€™s leading specialists in computer security, and early on he predicted that the security flaws that have accompanied the pell-mell explosion of the computer and Internet industries would have disastrous consequences.â€œHis biggest contribution is to stress the â€˜systemsâ€™ nature of the security and reliability problems,â€? said Steven M. Bellovin, chief technology officer of the Federal Trade Commission. â€œThat is, trouble occurs not because of one failure, but because of the way many different pieces interact.â€?Dr. Bellovin said that it was Dr. Neumann who originally gave him the insight that â€œcomplex systems break in complex waysâ€? â€” that the increasing complexity of modern hardware and software has made it virtually impossible to identify the flaws and vulnerabilities in computer systems and ensure that they are secure and trustworthy.The consequence has come to pass in the form of an epidemic of computer malware and rising concerns about cyberwarfare as a threat to global security, voiced alarmingly this month by the defense secretary, Leon E. Panetta, who warned of a possible â€œcyber-Pearl Harborâ€? attack on the United States.It is remarkable, then, that years after most of his contemporaries have retired, Dr. Neumann is still at it and has seized the opportunity to start over and redesign computers and software from a â€œclean slate.â€?He is leading a team of researchers in an effort to completely rethink how to make computers and networks secure, in a five-year project financed by the Pentagonâ€™s Defense Advanced Research Projects Agency, or Darpa, with Robert N. Watson, a computer security researcher at Cambridge Universityâ€™s Computer Laboratory.â€œIâ€™ve been tilting at the same windmills for basically 40 years,â€? said Dr. Neumann recently during a lunchtime interview at a Chinese restaurant near his art-filled home in Palo Alto, Calif. â€œAnd I get the impression that most of the folks who are responsible donâ€™t want to hear about complexity. They are interested in quick and dirty solutions.â€?Dr. Neumann, who left Bell Labs and moved to California as a single father with three young children in 1970, has occupied the same office at SRI for four decades. Until the building was recently modified to make it earthquake-resistant, the office had attained notoriety for the towering stacks of computer science literature that filled every cranny. Legend has it that colleagues who visited the office after the 1989 earthquake were stunned to discover that while other offices were in disarray from the 7.1-magnitude quake, nothing in Dr. Neumannâ€™s office appeared to have been disturbed.A trim and agile man, with piercing eyes and a salt-and-pepper beard, Dr. Neumann has practiced tai chi for decades. But his passion, besides computer security, is music. He plays a variety of instruments, including bassoon, French horn, trombone and piano, and is active in a variety of musical groups. At computer security conferences it has become a tradition for Dr. Neumann to lead his colleagues in song, playing tunes from Gilbert and Sullivan and Tom Lehrer.Until recently, security was a backwater in the world of computing. Today it is a multibillion-dollar industry, though one of dubious competence, and safeguarding the nationâ€™s computerized critical infrastructure has taken on added urgency. President Obama cited it in the third debate of the presidential campaign, focusing on foreign policy, as something â€œwe need to be thinking aboutâ€? as part of the nationâ€™s military strategy.Dan joins the BGR team as the Android Editor, covering all things relating to GoogleÃ¢â‚¬â„¢s premiere operating system. When he isnÃ¢â‚¬â„¢t testing the latest devices or apps, he can be found enjoying the New York City nightlife.The iPad mini has been rumored for nearly as long as the original iPad has existed, but it wasn't clear early on how many of those rumors were based on fact and how many were based on hope. Hope, that was, for a smaller, more portable tablet that would bring access to all the Apple ecosystem had to offer, in a package you could easily hold in one hand. Specifically, a package more affordable than the 10-incher.That's this, the 7.9-inch, $329 iPad mini that sports a screen with the same resolution as the iPad 2 -- only smaller. As we put this one through its paces it quickly became clear that this is far more than a cheaper, smaller iPad. This is a thinner, lighter device that deserves independent consideration. In many ways, it's actually better than the 10-inch slate from which it was born. But is it better for you? Join us after the break as we find out.Apple wanted to be very clear at its product-packed iPad mini launch event that this isn't just a shrunken-down iPad. And, indeed, that starts with a very different case design. While the second, third and fourth generations of iPads have all been more or less indistinguishable, the iPad mini's anodized aluminum back looks entirely different. In fact, the whole thing looks a lot more like a blown-up fifth-generation iPod touch than a shrunken-down fourth-generation iPad.The profile itself is more rounded than the full-size iPad, lacking the sharp taper at the edges. This, we presume, gives a little more room for the battery inside, but it also makes this a more comfortable slate to carry around. The edges on the 10-inch iPad can cut into your hand if you're the sort who carries yours wherever you go. Not so with the mini.Of course, that's helped greatly by the decrease in weight here. The WiFi-only iPad mini weighs just 0.68 pounds (308 grams), which is less than half the weight of the fourth-generation iPad. It's far thinner, too, at 7.2mm (vs. 9.4) and measures 7.87 x 5.3 inches (200 x 135mm) on the other dimensions. Inside that plane is a 7.9-inch, 1,024 x 768 IPS LCD which has significantly smaller bezels than those found in other iPads. It's thanks to those bezels that a display this size can be housed in a slate this size, but still that 5.3-inch horizontal span may be a bit of a problem for some.To us, the joy of a 7-inch tablet is walking across the office or the airport, holding the slate in one hand while tapping away at it with the other. The Nexus 7, with its 16:9 aspect ratio, is relatively narrow and easy to carry securely one-handed -- even by those whose mittens are size S. With the iPad mini, holding the slate in the same way can be a bit of a reach. This editor, who wears XL gloves, had no problem palming the littler iPad, but when we handed it to other, dainty-fingered people they sometimes struggled to hold it securely.The scrawny bezels on either side actually exacerbate this issue to some degree, as those who must loop a thumb around the front of the device when holding it are forced to put that thumb right on the display. Thankfully, every app we tried handled this situation without issue, Kindle and iBooks turning pages and acting normally even with that stray opposable member making square contact on the digitizer.Overall, the tablet is very comfortable to hold; its thinness and lightness are both attributes that must be perceived first-hand. That 7.2mm depth is exactly the same as the fourth-generation iPod touch, which even today is an impressively svelte device. We reviewed the black model, which features a dark bezel and anodized back to match. It's cool and matte to the touch, which we find very appealing, but time will tell just how durable this black version will prove. Those who are scratch-averse may want to think about the white and silver variety, which will likely hide those markings a bit better.The layout of the buttons is familiar, but different. The volume rocker and orientation lock switches are on the upper portion of the right side, but here up and down are distinct buttons, not like the integrated rocker on the full-size iPad. It's also not like the three-way rocker found on the latest iPod nano, which features an integrated play/pause button. That's a bit unfortunate, as we'd like to see that find its way across the product line, but perhaps it will in future revisions. (Yes, we're expecting more.)The power button is up top, looking and feeling very much like those on older iPads. There's a small slit for a microphone up there as well, and on the other side, the 3.5mm headphone jack, which bucks the trend of bottom-placement found on nearly every other Apple mobile device. On the left side of the device nothing, and on the bottom is where the Lightning connector lives. Like the iPhone 5, that connector is flanked by two sets of two rows of holes, drilled to let the device's sound out. It's reasonably loud and, since it's on the bottom not the back, the sound is closer to traveling in the right direction to meet your ears, but it's still a less than ideal listening experience. You'll want a set of headphones -- which, as with other iPads, are not included.The only other button is on the front, a smaller version of the same Home button found on the iPad. Curiously, it's even smaller than the button on the iPhone, making it very petite indeed. Around back, there's just one detail to concern yourself with: the lens assembly for the 5-megapixel iSight camera stuffed in the upper-left. That's paired with a 1.2-megapixel FaceTime HD center-cut in the bezel atop the LCD.No, this isn't Retina, but maintaining the same resolution as a 10-inch display shrunken down to 7.9 means a necessary boost in pixel density: 163ppi. That's a nice increase over the iPad 2's 132ppi, but it still falls short of the 264ppi of the fourth-generation iPad -- not to mention, the iPhone 5's 326dpi. Naturally, this means that text isn't anywhere near as sharp as on the newer iPads, but this is still a very nice-looking display.In fact we found the brightness and color reproduction to be improved over the iPad 2, comparable to the latest Retina displays. Colors are very pleasing to the eye and viewing angles, as ever with an Apple display, do not disappoint. You can line up as many friends as you like and sit them shoulder-to-shoulder, they'll all have a bright, clear picture. Yes, mini owners may have to make do with some resolution envy, but they at least won't be lacking in any other regard.The iPad mini is running a dual-core 1GHz CPU with 512MB of RAM, same as in the iPad 2 and as such it throws down the same benchmark scores and overall performance figures. Geekbench averages out at 751 and GLBench shows 24fps on the 2.5 Egypt HD benchmark. The SunSpider JavaScript benchmark completes in 1,426ms.These numbers pale in comparison to the new, fourth-gen iPad but we think that in day-to-day usage the relative lack of performance won't be as noticeable. Apps do load more slowly but most are still up and running within a second or two and when it comes to general web surfing tasks the iPad mini easily kept up with our taps and swipes. So, perhaps not the greatest performance in the Apple lineup, but there is one place where it bests the rest: battery life.In our standard battery run-down test, which entails looping a video with WiFi enabled and a fixed display brightness, the iPad mini managed an astounding 12 hours and 43 minutes. This gives it the longest battery life of any tablet we've ever tested, besting even the Samsung Galaxy Tab 7.7 by 42 minutes. Indeed during the course of our testing the battery on the iPad mini exceeded our expectations, expectations that were already high thanks to the consistently great battery life offered by the iPad family.The iPad 2 never saw HDR nor the Panorama mode that wowed us so on the iPhone 5, and neither does the iPad mini. It does, however, have a better camera than the iPad 2, a 5-megapixel shooter with an f/2.4 lens, and a 1.2-megapixel Facetime HD camera up front. The one 'round back appears to be the same camera module used on the iPhone 4 and as such, it takes good quality images. No, they don't quite pop like the 8-megapixel shooter on the iPhone 5, nor does this tablet manage low-light shooting as well as Apple's latest round of CPUs, but in our opinion tablets should only be used to take pictures in a pinch, and as such the iPad mini does just fine.It also takes reasonably good video, shooting at 1080p like all the latest Apple devices. But again, the combination of a lower-res sensor and the lack of a newer image processing chip means image stabilization isn't nearly as good here as on the iPhone 5. So, you'll want to hold steady while shooting, but remember to do so in a place with enough ambient light; do that and you'll get yourself some quality footage.You can't tally up any iPad's chances in the market without comparing it against all the other iPads in the market, and so we'll start by comparing the mini to its siblings, of which there are two at present. First is the iPad 2, available only in 16GB sizes either WiFi-only or a 3G model, each priced $70 more than the same-sized mini. For that $70 more you get a bigger screen and lower-resolution cameras front and back. For us, this is a no-brainer. Get the mini. Unless you suffer from ailing eyesight and need a larger portal into the iOS world, the smaller device is far and away the better one.The choice between this and the new fourth-generation iPad is a bit more challenging. It's a considerably more expensive device, starting at $499, and of course a bigger and heavier one, too. Still, battery life on that guy is impressively good (over 11 hours) and the performance is stellar -- living up to and exceeding Apple's "2x faster" claims. Still, speed isn't everything and while we love that big, Retina display we're not entirely sure that we prefer it to the tiny, lightweight form factor of the mini. In fact, we found ourselves enjoying the portability of the mini so much that we'd probably give that one the nod, but this decision will almost certainly come down to personal preference. So, if you can, head to an Apple Store and try out both.Moving outside of the ecosystem, most people are comparing the iPad mini to the Nexus 7. To some degree that's a natural comparison, as this is Apple's cheapest tablet compared to Google's low-cost device. In practice, these are very different devices, starting with the cost: $199 for a 16GB Nexus 7 vs. $329 for the iPad. The designs are strikingly different, too, with the Nexus having a high-quality but somewhat discount feel versus the overwhelmingly high-end iPad mini. In no way does Apple's latest feel like a tablet that was made to a budget. It simply feels like an Apple device.And, of course, it gives access to Apple's ecosystem of hundreds of thousands of tablet-friendly apps -- plus all the media iTunes has to offer. We can't help you decide which ecosystem, Apple or Google's, is better-suited to your interests, but we do imagine that will be the deciding factor for most. When it comes down to hardware, it's almost no contest between the two, with the iPad mini clearly winning out -- except in one area. That's the display. The Nexus 7 has a higher-resolution panel that's also 16:9, making it better for movie watching. It's also narrower, and thus easier to hold in your hand.We'd also be remiss if we didn't at least mention the $199 Kindle Fire HD. Amazon's latest also offers a higher-resolution, IPS LCD and has the extra selling point of stereo speakers. It also has a strong suite of content, courtesy of Amazon's many partnerships, but overall we have a hard time comparing these two. Amazon's device is clearly a cut-rate slate designed to push as much digital buying power into the hands of consumers as possible, while Apple's is simply a legitimately nice tablet. It's a legitimately nice tablet that Apple certainly would love for you to fill with premium content downloaded through iTunes, but it never feels like a shopping portal. The Kindle does.Surely, the most popular accessory for the iPad mini will be the new Smart Cover that, despite being both smaller and of considerably simpler construction, still costs the same $39 as the bigger, 10-inch version. That's a little unfortunate, especially because we don't think this version works as well. There is one positive change: the smaller Smart Cover moves away from the aluminum hinge on the bigger version, a good thing because we've seen plenty of scratches caused by that metal-on-metal contact.It's still attached magnetically, but where the 10-inch model will immediately snap into the perfect placement every time, we found the mini cover just as eager to attach either too high or too low. It requires a little more precision. Hardly a deal-breaker (how often are you removing your Smart Cover?) but a bit of an annoyance.The other accessories, and there are plenty of them, all make use of the device's Lightning connector, many existing only to add a little more life to your various iPod docks and chargers. The stubby 30-pin to Lightning adapter is $29, the same cost as the two camera adapters: one USB and one SD. (This is a change from the 30-pin Camera Connection Kit, which included both for $29.) The Lightning to 30-pin adapter (which includes a 0.2 meter cable in the middle) costs $39 and, finally, both the VGA and digital AV adapters are $49. Like the previous Digital AV adapter (which was $39), this one includes HDMI output and has an input so that you can still charge the tablet while it's in use. Handy for those digital signage applications -- or getting in one final, epic Lord of the Rings marathon before December.This isn't just an Apple tablet made to a budget. This isn't just a shrunken-down iPad. This is, in many ways, Apple's best tablet yet, an incredibly thin, remarkably light, obviously well-constructed device that offers phenomenal battery life. No, the performance doesn't match Apple's latest and yes, that display is a little lacking in resolution, but nothing else here will leave you wanting. At $329, this has a lot to offer over even Apple's more expensive tablets.Those comparing this to the Kindle Fire HD will have a hard time, as that's a tablet manufactured to a fixed cost and designed to sell you content. This is very much more. Similarly, the hardware here -- the materials, the lightness, the build quality, the overall package as it sits in your hand -- is much nicer than the Nexus 7 and it offers access to the comprehensively more tablet-friendly App Store, but whether that's worth the extra cost depends entirely on the size of your budget -- and your proclivity toward Android.Regardless, the iPad mini is well worth considering for anybody currently in the market for a tablet. Its cost is compelling, its design superb and it of course gives access to the best selection of tablet-optimized apps on the market. To consider it just a cheap, tiny iPad is a disservice. This is, simply, a great tablet.Update: This review originally stated (as does Apple's spec page) that the iPad mini has a mono speaker. It is, in fact, a stereo device.[Last photo by Will Lipman]When you buy a USB charger, how do you know if you're getting a safe, high-quality charger for your money? You can't tell from the outside if a charger provides silky-smooth power or if it is a dangerous charger that emits noisy power that cause touchscreen malfunctions[1] and could self-destruct. In this article, I carefully measure the performance of a dozen different chargers, rate their performance in multiple categories, and determine the winners and losers.Inside a chargerThese chargers cram a lot of complex circuitry into a small package, as you can see from the iPhone charger below. (See my iPhone charger teardown for more details.) The small size makes it challenging to make an efficient, high-quality charger, while the commoditization of chargers and the demand for low prices pressure manufacturers to make the circuit as simple as possible and exclude expensive components, even if the power quality is worse. The result is a wide variation in the quality of the chargers, most of which is invisible to the user, who may believe "a charger is a charger".Internally a charger is an amazingly compact switching power supply that efficiently converts line AC into 5 volt DC output. The input AC is first converted to high-voltage DC. The DC is chopped up tens of thousands of times a second and fed into a tiny flyback transformer. The output of the transformer is converted to low-voltage DC, filtered, and provided as the 5 volt output through the USB port. A feedback mechanism regulates the chopping frequency to keep the output voltage stable. Name-brand chargers use a specialized control IC to run the charger, while cheap chargers cut corners by replacing the IC with a cheap, low-quality feedback circuit.[4]A poor design can suffer several problems. If the output voltage is not filtered well, there will be noise and spikes due to the high-frequency switching. At extreme levels this could damage your phone, but the most common symptom is the touchscreen doesn't work while the charger is plugged in.[1] A second problem is the output voltage can be affected by the AC input, causing 120 Hz "ripple".[5] Third, the charger is supposed to provide a constant voltage. A poor design can cause the voltage to sag as the load increases. Your phone will take longer to charge if the charger doesn't provide enough power. Finally, USB chargers are not all interchangeable; the wrong type of charger may not work with your device.[6]CounterfeitsCounterfeit chargers pose a safety hazard as well as a hazard to your phone. You can buy a charger that looks just like an Apple charger for about $2, but the charger is nothing like an Apple charger internally. The power is extremely bad quality (as I will show below). But more importantly, these chargers ignore safety standards. Since chargers have hundreds of volts internally, there's a big risk if a charger doesn't have proper insulation. You're putting your phone, and more importantly yourself, at risk if you use one of these chargers. I did a teardown of a counterfeit charger, which shows the differences in detail.I've taken apart several counterfeit chargers and readers have sent me photos of others. Surprisingly, the counterfeit chargers I've examined all use different circuitry internally. If you get a counterfeit, it could be worse or better than what I've seen.How do you tell if a charger is counterfeit? The fakes are very similar; it's hard for me to tell, even after studying many chargers. There's a video on how to distinguish real and fake chargers through subtle differences. You can also weigh the charger (if you have an accurate scale), and compare with the weights I give above. The easiest way to get a genuine Apple charger is fork over $29 to an Apple store. If you buy a $2 "Original Genuine Apple" charger on eBay shipped from China, I can guarantee it's counterfeit. On the other hand, I've succeeded in buying genuine used chargers from US resellers for a moderate price on eBay, but you're taking a chance.The following picture shows a counterfeit charger that burned up. The safety issues with counterfeits are not just theoretical; when hundreds of volts short out, the results can be spectacular.A device being charged can detect what type of charger is being used through specific voltages on the USB data pins.[6] Because of this, some devices only work with their own special chargers. For instance, an "incorrect" charger may be rejected by an iPhone 3GS or later with the message "Charging is not supported with this accessory".[7]There are many different charger types, but only a few are used in the chargers I examined. A USB charger that follows the standard is known as a "dedicated USB charger". However, some manufacturers (such as Apple, Sony, and HP) don't follow the USB standard but implement their own proprietary charger types. Apple has separate charger types for 1 amp (iPhone) and 2 amp (iPad) chargers. HP has a special type for the HP TouchPad.The point is that USB chargers are not interchangeable, and devices may not work if the charger type doesn't match what the device expects. The table below shows the type of charger, the current that the label claims the charger provides, the current it actually provides, and the charger type it indicates to the device.The types of the counterfeit chargers are a mess, as they advertise one power level, actually supply a different power level, and have the charger type for a third level. For example, the counterfeit iPhone charger is advertised as supplying 1 amp, but has the 2A charger type, so an iPad will expect 2 amps but not obtain enough power. On the other hand, the counterfeit iPad charger claims to supply 2 amps, but really only supplies 1 amp and has a 1A type.People often wonder how much power their charger is wasting while it's idle, and if they should unplug their charger when not in use. I measured this "vampire" power usage and found the chargers varied by more than a factor of 20 in their idle power usage. The Samsung oblong charger came in best, using just 19 mW; this was so low compared to the other chargers that I measured it again a different way to make sure I hadn't made an error. On the other extreme, the fake iPhone charger used 375 mW. The Apple iPhone charger performed surprisingly badly at 195 mW. If plugged in for a year, this would cost you about 21 cents in electricity, so it's probably not worth worrying about.[8] In the following table, I use the official charger Star Rating System (yes, there actually is such a thing).[9][10]I also measured efficiency of the chargers under load.[11] One of the benefits of switching power supplies over simpler linear supplies is they are much more efficient at converting the input power to output. The chargers I measured all did pretty well, with 63% to 80% efficiency. The HP charger was the winner here.I'm proud to announce an upcoming private beta of sex.ly! sex.ly is a new web and mobile app aimed at bringing Social to Sex. It's based around the idea that sexual intercourse itself should be more social, more open, and more fun.To that end, sex.ly will feature the following:â€” Check-in to sexual encounters. You'll now never forget a night. Describe positions, durations, sounds.â€” If (and only if) your partner(s) agrees, you can rate and review them. If they don't, you still can review them as anonymous partners.â€” Give a heads-up (pun intended) warning to other potential mates. Make sure dysfunction is kept out of your life.â€” Earn sex-cred for number of check-ins, which can be used at sex stores and other selected merchants.â€” Geo-tag sexual encounters! Support for in-airplane geo-tags is coming soon.sex.ly is of course not real. And yet, each day, I become more and more convinced that we really are not that far from it.You were repulsed by the above description of this imaginary site. But not because of some prudish reasons, not even because it had to do with sex. No. You were repulsed because sex.ly violates something very deep and fundamental about humanity. But what, in particular?I doubt that it's some old-fashioned 'don't kiss and tell' shit. After all, we have plenty of sex writers in the world, all describing their sex lives in detail, and we don't hate that. Nor do I think it is even the egoism of the whole thing.No. What is truly horrifying about sex.ly is that it so utterly and absolutely cheapens the experience of something very important. It bundles it all up into some packaged product of check-ins and ratings and de-humanizing rankings. It turns us into commercial broadcasters of the meaningful parts of our lives.And yet one can almost already hear it: "It's not really sex until it's on sex.ly."Now my description of sex.ly is obviously an intuition pump. I want you to hate it â€” because, with only slight exaggeration, this is how I feel about almost all life-casting.We have begun to pollute and desecrate and cheapen all of our experiences. We are creating neat little life-boxes for everything, all tied up with a geo-tag, a photo, a check-in; our daily existence transformed into database entries in some NoSQL database on some spinning disk in some rack in suburban Virginia.The end-game is this. Slowly, gradually, without realizing: we stop participating in our own lives. We become spectators, checking off life achievements for reasons we do not know. At some point, everything we do is done soley to broadcast these things to casual friends, stalkers, and sycophants.Philip Larkin, writing about the destruction of the English countryside, once said that most things are never meant. That may be true here too. Maybe things won't get so bad.But as I watch us fall further and further into packaged lives, I can't escape hearing Larkin's conclusion to that poem: I just think it will happen, soon.New York - The Electronic Frontier Foundation (EFF) urged a federal appeals court Friday not to shut down Aereo, a startup that lets customers send local broadcast television to Internet-connected devices, arguing that consumers have the right to watch free broadcast TV with the technology of their choice.Broadcasters and TV networks â€“ including ABC, Fox, Univision, Disney, CBS, NBC, and PBS â€“ sued Aereo for copyright infringement in March, claiming that Aereo should be paying them license fees. The trial court declined to shut Aereo down during the lawsuit, and the broadcasters appealed. Now, the appeals court will decide whether Aereo can stay open while the case goes forward. EFF, along with Public Knowledge and the Consumer Electronics Association (CEA), filed a friend of the court brief Friday, asking the appeals court to reject the networks' bogus copyright claims and protect the rights of consumers."Just because Aereo's system sends TV signals to customers doesn't mean that Aereo needs permission from the broadcasters," said EFF Staff Attorney Mitch Stoltz. "Personal TV transmissions don't violate copyright â€“ it's a private use that copyright law doesn't reach. This is just a craven attempt by TV executives to profit from technology that they didn't think of first."Aereo's system works with thousands of dime-sized antennas installed on a Brooklyn rooftop. Each customer is assigned a single antenna that he or she can control, and the signal from that antenna travels over the Internet to the customer's devices. Aereo has explained in court that it simply takes the place of "rabbit ears" or a rooftop antenna, but the networks argued that Aereo should be treated like a cable system that must get permission from and pay fees to broadcasters.In deciding not to shut Aereo down pending trial, Judge Alison Nathan of the Southern District of New York said that Aereo's system was similar to another technology that survived a court challenge: Cablevision's "remote DVR" system, which in 2008 was found not to infringe copyright law. Like Aereo, Cablevision took equipment that customers traditionally put in their homes â€“ in that case, digital video recorders â€“ and moved them to the company's offices. Judge Nathan ruled that the appeals court's decision in the Cablevision case also applied to Aereo."Broadcasters have exclusive use of a scarce public resource â€“ the airwaves â€“ and that privilege carries with it a responsibility to serve the public. Obviously, the public benefits by having alternative ways to enjoy TV content," said EFF Intellectual Property Director Corynne McSherry. "Judge Nathan reached the right result and we hope the appeals court does too."EFF co-wrote its brief with John Bergmayer and Sherwin Siy of Public Knowledge.We've written before about Google's investments in a wide range of green energy companies, including wind, solar, and geothermal plants. At this week's annual shareholder's meeting, CEO Larry Page announced a new R&D team charged with capitalizing on those investments and Google's own cleantech intellectual property. These moves suggest the search and software giant is ramping up its efforts to develop its own clean technology in conjunction with its partners to bring that energy to market at efficiency and scale.Google's energy investments have always been complicated, spread between philanthropy and business, trying to be responsible to both shareholders and the planet. On one hand, Google wants to take the long view, identifying genuinely transformative possibilities in energy generation and transmission and securing its own high-energy-needs future. On the other hand, the company is looking for places where it can make an immediate technological impact and generate a solid return on its investment."We spend most of our time on search and advertising," Page said, but "to people outside the company, what's more interesting is 'what is the latest crazy thing that Google did?'""For us, those things are interesting, too, but it tends to be three people somewhere in the company," he noted. "We're not betting the farm on any of those things." In the case of renewable energy, Google's new hires seem to indicate it will be five people somewhere in the company, but their work is more serious than just engineers fiddling in a lab looking for "the latest crazy thing." In other words, it isn't like a driverless car that may or may not appear in the indefinite future, but a serious industry that Google's approaching with urgency.The ultimate goal is eminently practical: "RE < C," Google's long-established project to make renewable energy cheaper than coal. The urgency comes in the addendum to that formula: "Within a few years."To that end, Google has advertised five new positions in its Renewable Energy Engineering wing in Mountain View. One will be charged with managing Google's own energy usage to help keep the company cost-efficient and carbon-neutral. The other four spots are much more mechanical-engineering heavy than the typical Google hires. These are more interesting.The three-person renewable energy engineering team will be responsible for both evaluating and recommending investments for the company and in developing new technologies. There's a head of renewable energy engineering to lead the team, an engineer specializing in early-stage technology and prototyping, and a mechanical engineer who heads up design and manufacturing.The key phrase throughout the advertised positions is "utility-scale." The language of the mechanical engineer advertisement is especially revealing: "You will not be designing laboratory experiments; you will be designing useful systems that must deliver cost-effective results in the real world." This isn't pie-in-the-sky R&D. This is about products.I asked Google spokesperson Parag Chokshi if it would be fair to say that Google may soon be playing a more active role with its clean energy partners than just capital support. "We haven't changed our strategy," Chokshi said, while noting that Google doesn't typically comment on the specifics of its hiring strategy. "In fact, we have and continue to work closely with our partners... [both] the renewable energy projects in which we have invested, and with the co-investors who have joined us in investing in those projects."In April, Rick Needham, Google's Director of Green Business Operations and Strategy, toldFast Companythat Google's energy approach was both investment- and technology-driven: "We want to have an impact on the scale of the project, and an impact because of the technology being deployed." Large-scale projects are "the proof point of technology on a scale that allows those technologies to be financed and deployed at other locations."As new CEO, Larry Page is under pressure to deliver something big. Recently, Malcolm Gladwell argued (in his typically contrarian fashion) that the Internet "search solves problems that aren't really problems":Can we make a better Google or Bing? Yeah; sure we can. But it solves a problem that isn't really a problem. You cannot point to any area of intellectual activity or innovation that is today being compromised or hamstrung by their lack of access to search technology. Can we honestly go to some scientist to say that the reason you haven't cured cancer is because you don't have access to some information about cancer research? No!There isn't a problem that's any bigger or more real than generating renewable energy and bringing it to market. If Google can find big ways in just the next few years to solve only a part of that puzzle, turning Google's energy wing into a business remotely as robust as its search and software core, then Page will have delivered something big indeed.Go ahead, jailbreak your cellphone. But just know that tablet computer of yours is off limits.The U.S. Copyright Office published a document on Oct. 26, specifying that while jailbreaking a smartphone is deemed legal, the same rules do not apply to gaming consoles or tablets like Apple's iPad or the Microsoft Surface.According to CNET, the Copyright Office accepts requests every three years from "digital rights proponents and opponents" to alter laws under the Digital Millennium Copyright Act. This legislation was passed in 1998 and, fittingly, was put into effect in 2000. The American Library Associationdefines the act as a way for "U.S. copyright law to meet the demands of the Digital Age." In short, amendments to this act change the legality of practices like jailbreaking, or unlocking, your gadgets.The updated document (seen here) states the following:So which organizations wanted consumers to legally be allowed to jailbreak their devices? The legal papers show that the Electronic Frontier Foundation (EFF), New America Foundationâ€™s Open Technology Initiative, New Media Rights, Mozilla Corporation and the Free Software Foundation (FSF) were all proponents.The Copyright Office cites several reasons as to why cellphones can legally undergo the process of jailbreaking, while other devices are excluded from this freedom. Explanations are provided below:Still, how long will many of these laws be applicable? For example, the idea that smartphones are more widely adapted than tablets could be an outdated concept by 2015. Either way, the updated copyright laws will be implemented on Oct. 28, 2012 and remain in effect for three years.What are your thoughts on the Copyright Office's amendments? What makes sense and what seems completely ridiculous? Tell us your opinions in the comments section, or tweet us your response to this article at [@HuffPostTech]. Then read more about the latest anti-piracy rules (here), or flip through the slideshow below of the top nine countries downloading the most illegal music.Apple (AAPL) customers are famed for their loyalty, but it looks as though some of them may not be as fanatical as theyâ€™ve been in the past. New data from Strategy Analytics shows that 75% of iPhone owners in Western Europe said they would buy an Apple device for their next smartphone, versus 88% who said theyâ€™d buy an iPhone for their next device last year. iPhone user loyalty also dipped slightly in the United States, with 88% of iPhone owners saying theyâ€™d buy an Apple smartphone in the future, down from 93% last year. Paul Brown, the director at Strategy Analyticsâ€™ User Experience Practice, said that Appleâ€™s loyalty numbers may have taken a hit because of â€œnegative press prompted by a perceived lack of recent innovation.â€? Strategy Analyticsâ€™ press release is posted below.Boston, MA â€“ October 30, 2012 â€“ For the first time since the Apple iPhone was released in 2007, the number of iPhone owners who say they definitely will or probably will purchase their next phone from the same brand has declined.The recent Strategy Analytics Wireless Device Lab Report, iPhone Owner Loyalty Declines: Is Apple Losing its Innovation Edge?, found that only 75 percent of iPhone owners in Western Europe say they are likely to buy their next phone from Apple, down from 88 percent in 2011. US repeat purchase intentions have also seen a slight decline, down from 93 percent in 2011 to 88 percent in 2012.â€œThere is no doubt that Apple is continuing its success in retaining existing user base while attracting new customers,â€? commented Paul Brown, Director at Strategy Analyticsâ€™ User Experience Practice. â€œHowever, negative press prompted by a perceived lack of recent innovation by Apple has meant we are starting to see some growth in the number of previously highly loyal consumers who are now reconsidering whether or not they will purchase a new iPhone for their next device.â€?Taryn Tulay, Analyst at Strategy Analyticsâ€™ Wireless Device Lab added, â€œRespondents who say they probably will or definitely will not buy their next phone from Apple is low. However, it is the shift in the number of those who are unsure whether they will remain with the same brand for their next phone that Apple should be concerned about.â€?Microsoft CEO Steve Ballmer cites the strong debut as a selling point to convince developers to create more apps for the company's platforms, primarily Windows 8 and Windows Phone 8.REDMOND, Wash. -- Microsoft CEO Steve Ballmer said the company has sold 4 million copies of Windows 8 to consumers since the operating system debuted on Friday.Ballmer made the announcement today at the start of the Build conference, a show Microsoft is hosting on its campus for more than 2,000 developers. Microsoft is hoping to convince developers to create applications for its new operating system and the Windows Phone 8 operating system that debuted yesterday."In a sense, what these launches really do is the kick off the golden age of opportunity for you as developers," Ballmer said.Right now, the Windows Store, the application marketplace on Windows 8, has about 5,000 apps in stock for U.S. customers. ESPN said it will have an app for the store by the end of the year. Dropbox as well as enterprise software maker SAP are also working on apps that will be available soon. And Ballmer said that Twitter is working on a Windows 8 app that will be available "in the months ahead.""It will be the most important in terms of highlighting and showcasing some of these capabilities we're talking about today," Ballmer said.Toward the end of his speech, Ballmer became animated, raising his voice to exhort developers to build new applications for the various Microsoft platforms."Windows 8 is the best opportunity for software development today," Ballmer said. "Hundreds of millions of people are aching to use your apps, just dying to use your application."The centerpiece of Ballmer's pitch to developers: Microsoft's huge footprint. Ballmer said that there are currently 670 million PCs running Windows 7, all of which can be upgraded to Windows 8. What's more, analysts expect computer makers to sell 400 million PCs next year, most of which will run Windows."I think we're going to see a lot of growth and vitality and explosion in the PC market," Ballmer said. "This is a market in which you can do your best work, your most innovative work.... This is a market in which you can make money."Ballmer gave a demo of a variety of products running Windows 8, everything from an 82-inch touch screen monitor from Perceptive Pixel, a company Microsoft recently purchased, to Microsoft's new lightweight Surface tablet. He also showed Windows 8 running on Acer's new Aspire S7-191, a trim laptop with a touch-enabled screen."You say, 'Do people really want to us touch laptops?'" Ballmer said. "Touch laptops really are cool."Microsoft also released a new software development kit for Windows Phone 8, giving developers new tools to create application for the company's mobile phone platform. It's a business that's tiny, relative to rivals Google and Apple. But Microsoft believes that it will benefit from from the push behind Windows 8."The opportunity there is also excellent," Ballmer said.To spark more interest, developers were given a few freebies for attending the conference. Each one got a Microsoft Surface RT, 100 gigabytes of storage on Microsoft's SkyDrive Web service, and a Nokia Lumia 920 mobile phone.Updated at 10:50 a.m. PT with more details and analysis.Updated to clarify that ESPN's app will be available by the end of the year.On Monday, the US Supreme Court will hear arguments in a case that pits a major textbook publisher against Supap Kirtsaeng, a student-entrepreneur who built a small business importing and selling textbooks.Like many Supreme Court cases, though, there's more than meets the eye. It's not merely a question of whether the Thai-born Kirtsaeng will have to cough up his profits as a copyright infringer; the case is a long-awaited rematch between content companies seeking to knock out the "first sale" doctrine on goods made abroad (not to mention their many opponents). That makes Wiley v. Kirtsaeng the highest-stakes intellectual property case of the year, if not the decade. It's not an exaggeration to say the outcome could affect the very notion of property ownership in the United States. Since most consumer electronics are manufactured outside the US and include copyrighted software in it, a loss for Kirtsaeng would mean copyright owners could tax, or even shut down, resales of everything from books to DVDs to cellphones."First sale" is the rule that allows owners to resell, lend out, or give away copyrighted goods without interference. Along with fair use, it's the most important limitation on copyright. So Kirtsaeng's cause has drawn a wide array of allies to his side. These include the biggest online marketplaces like eBay, brick-and-mortar music and game retailers, and Goodwillâ€”all concerned they may lose their right to freely sell used goods. Even libraries are concerned their right to lend out books bought abroad could be inhibited.John Wiley and Sons, the textbook publisher suing Kirtsaeng, has its share of backers as well, including the movie and music industries, software companies, and other book publishers. Those companies argue differential pricing schemes are vital to their success, and should be enforced by US courts. Nearly 30 amicus briefs have been filed in all.Supporters of Kirtsaeng are mobilized, following an alarmingâ€”but not precedentialâ€”loss in an earlier case, Omega v. Costco. On a call with reporters this week, librarians and lawyers for pro-Kirtsaeng companies painted a stark picture of what might happen should he lose the case. If the appellate court ruling against Kirtsaeng is allowed to stand, they suggest copyright owners could start to chip away at the basic idea of "you bought it, you own it.""This case is an attempt by some brands and manufacturers to manipulate copyright law, to control the distribution and pricing of legitimate, authentic goods," said eBay's top policy lawyer, Hillary Brill. "When an American purchases an authentic item, he shouldn't have to ask permission from the manufacturer to do with it what he wants."Without "first sale" doctrine in place, content companies would be allowed to control use of their goods forever. They could withhold permission for resale and possibly even library lendingâ€”or they could allow it, but only for an extra fee. It would have the wild effect of actually encouraging copyrighted goods to be manufactured offshore, since that would lead to much further-reaching powers."When we purchase something, we assume it's ours," said Overstock.com general counsel Mark Griffin. "What is proposed by [the content companies] is that we change the fundamental notion of ownership rights."Book publishers and their content-industry allies say those concerns are overblown. No assault on libraries and garage sales is forthcoming, they argue. These organizations simply have a right to set different prices abroad, without being undermined in the US by importation they say is illegal.The road to the Kirtsaeng clash has been a long one. Ultimately, this confrontation has been brewing since the rise of Internet marketplaces like eBay and Amazon in the mid-1990s. It became easier to get price information about goods being sold overseas, and consumers could see that identical or good-enough products were often being offered for prices much lower than the products being hawked in the US. At the same time, the big shopping sites made it simple for anyone to become their own business, selling and shipping around the globe.The textbook market was an obvious place to look for arbitrage. Students have been complaining about the high cost of books for many years; they also became the first group to enthusiastically embrace life online, and naturally looked for ways to cut costs.Foreign-born students, exposed to the lower-priced textbooks on trips home, became some of the first to see the opportunity. The same textbooks they were using to study medicine, engineering, and mathematics in the US were being sold in their home countries for a fraction of the cost. Often a Chinese, Thai, or Indian edition of a textbook had a more cheaply bound cover, sometimes with the local lettering on the front, and perhaps cheaper paper. The internal contents, however, were often the exact same English words being read by their classmates buying high-priced US editions.By 2003, the secret was out. Students' Internet-age solution to the problem of costly textbooks hit the front page of the New York Times. For some students, it was as simple as logging on to Amazon's UK site to comparison-shop.Â  A biochemistry text was $146.15 on the American Amazon site, but sold on the UK site for a mere $63.48, plus $8.05 shipping, one student found. A math textbook cost $110 in the US, but sold for $41.76 plus shipping in Britain.Even cheaper prices were found in Asia on English textbooks. The local college bookstore at Purdue University began buying overseas after it had to start competing with student-resellersâ€”the Indian Association at Purdue bought hundreds of books on their own.Neither the students nor the bookstores quoted by the Times in 2003 thought they were doing anything illegal. It was thought to be settled law; in a 1998 Supreme Court case called Quality King, the high court found that copyright owners couldn't control the re-importation of goods. They were limited by the "first sale" doctrine, which meant the rights held in a particular copy of a work expired once it was sold or given away.Years passed, and copyright owners found a wrinkle in that ruling. The shampoo bottles in Quality King had been made in the US but then shipped abroad, and re-imported. In cases where goods were actually produced abroadâ€”as foreign textbooks generally wereâ€”copyright owners argued unauthorized importers were guilty of infringement. Because imported foreign textbooks were not "made legally under this title [the Copyright Act]," they weren't subject to first sale at all. Or so the thinking went.It seems like an audacious argument, but sure enough, student book-sellers were hit with copyright lawsuits. They fought back hardâ€”but, for the most part, they have lost.Supap Kirtsaeng lost first and lost hardest. He came to the US from Thailand in 1997 to study at Cornell University, and later went on to get a PhD in mathematics from the University of Southern California. From 2007 to 2008, he financed his educationâ€”and made extra money, doubtlessâ€”by importing textbooks from Thailand and selling them under his eBay handle, bluechristine99.The book publisher, John Wiley and Sons, didn't want to see those books in the USâ€”and it had said so. Each book was marked: "[A]uthorized for sale in Europe, Asia, Africa and the Middle East Only... The Publisher may recover damages including but not limited to lost profits and attorney's fees, in the event legal action is required."Kirtsaeng didn't abide by those warnings. He talked to some Thai friends; he consulted "Google Answers;" and he went ahead and sold books.The warning in the books was not an idle one. Wiley and Sons followed through on their threat and sued Kirtsaeng in 2008. Kirtsaeng's lawyer was unable to get the case thrown out on "first sale" grounds. By the end of 2009 Kirtsaeng was in court, justifying his importation business to a jury.Lawyers portrayed Kirtsaeng to the jury as a Thai "gray market" mogul who had gone far beyond financing his own college educationâ€”a portrayal that US publishers continue toÂ push. Working with friends and family who packaged and shipped his books, he made plenty of money selling extra books on eBay. Publishers' lawyers tallied up his receipts for the jury: $1.2 million in a few short years.The jury found Kirtsaeng guilty of infringing copyrights in eight books he had sold, and he was ordered to pay $600,000 in damagesâ€”$75,000 per book. He appealed, but a panel of judges ruled 2-1 in the publishers' favor.KirtsaengÂ returnedÂ to Thailand in 2010 after earning his doctorate from USC, but his court case continues.Microsoft has just announced that developers at its Build 2012 conference will receive 100GB of SkyDrive storage, and a free 32GB Surface RT. Speaking enthusiastically about the developer opportunity ahead, Microsoft CEO Steve Ballmer guaranteed developers in the crowd that "this will be the best opportunity software developers will see.""Hundreds of millions of people are just aching to use your applications," said Ballmer, before announcing the giveaway for Build attendees. The crowd was understandably excited, and Ballmer promised developers that Microsoft would do more marketing and "better marketing" for Windows 8.Update: Nokia's Richard Kerris joined Microsoft on stage at Build today and also announced a free Lumia 920 for attendees.Microsoft Windows 8 is shipped without the "Start" menu.We put the "Start" menu back in Windows 8. We accurately recreated the most used desktop feature billions of users depend on every day and packed it with additional functionality.Computerworld - Intel researchers are working on a 48-core processor for smartphones and tablets, but it could be five to 10 years before it hits the market."If we're going to have this technology in five to 10 years, we could finally do things that take way too much processing power today," said Patrick Moorhead, an analyst with Moor Insights and Strategy. "This could really open up our concept of what is a computer... The phone would be smart enough to not just be a computer but it could be my computer."Enric Herrero, a research scientist at Intel Labs in Barcelona, said the lab is working on finding new ways to use and manage many cores in mobile devices.Today, some small mobile devices use multi-core chips. However, those multi-cores might be dual- or quad-core CPUs working with a few GPUs. Having a 48-core chip in a small mobile device would open up a whole new world of possibilities.At this point, researchers are working to see how to best use so many cores for one device."Typically a processor with one core would do jobs one after another," Herrero told Computerworld. "With multiple cores, they can divide the work among them."He explained that with many cores, someone could, for instance, be encrypting an email while also working on other power-intensive apps at the same time. It could be done today, but the operations might drag because they'd have to share resources.Tanausu Ramirez, another Intel research scientist working on the 48-core chip, said that if someone was, for example, watching a high-definition video, a 48-core chip would be able to use different cores to decode different video frames at the same time, giving the user a more seamless video experience.Ramirez also said that instead of one core working at near top capacity and using a lot of energy, many cores could run in parallel on different projects and use less energy."The chip also can take the energy and split it up and distribute it between different applications," he added.Justin Rattner, Intel's CTO, told Computerworld that a 48-core chip for small mobile devices could hit the market "much sooner" than the researchers' 10-year prediction."I think the desire to move to more natural interfaces to make the interaction much more human-like is really going to drive the computational requirements," he said. "Having large numbers of cores to generate very high performance levels is the most energy efficient way to deliver those performance levels."Rattner said functions such as speech recognition and augmented reality will push the need for more computational power."If it's doing speech recognition or computer vision... that's very computational intensive," he added. "It's just not practical to just take sound and pictures and send it up to the cloud and expect that some server is going to perform those tasks. So a lot of that will be pushed out to the client devices."Rob Enderle, an analyst with the Enderle Group, said being able to have different device functions, as well as apps all running on their own cores would be a great advance.When you tweet with a location, Twitter stores that location. You can switch location on/off before each Tweet and always have the option to delete your location history. Learn moreWhile working on desktops or laptops, itâ€™s useful to have a second display handy. Another monitor can easily be plugged in, but why not use the screens you already have instead of going off and purchasing another one? With a little bit of effort, the iPad, iPhone, and iPod Touch can be turned into a second screen for your Mac or Windows computer. This can be used in two ways: using the iOS device as a true second display, or mirroring the content of your main display. In this post, youâ€™ll learn how to accomplish both.Air Display is actually two separate applications: one running in Windows or OS X, and an app running in iOS. First off, download and install the client on your computer. Next, youâ€™ll need to buy the iOS app for $9.99 on the App Store. Once both are running, connect both to the same WiFi network, and then follow the on-screen instructions to make sure they are talking to each other.Once theyâ€™re connected on OS X, you can configure them even further. Launch System Preferences, and select the Displays section. On the iOS device, youâ€™ll be able to configure your resolution. Specifically, devices with Retina displays can enable High Dots Per Inch (HiDPI) mode that draws windows as if the resolution was a quarter the size, but with the full detail that your screen allows. Sadly, the Windows version doesnâ€™t support the high resolution mode properly just yet, but the developer promises this will be added in a future update.On your main display in Mac OS X, you can now adjust where the second screen sits in relation to your main screen by switching to the â€œArrangementâ€? tab. In Windows, you need to open the system tray icon and select â€œDisplay Arrangement.â€? In OS X, this screen also displays a toggle called â€œMirror Displays.â€? This will turn your iOS device into a duplicate of your main screen. This is useful if youâ€™re trying to show someone a website or a photo, and you donâ€™t want to huddle in front of your computer. If you want to enable mirroring on Windows, simple click the system tray icon, and navigate to â€œOptions,â€? and click â€œEnable Mirror Mode.â€?If all youâ€™re looking for is display mirroring and control of your main screen on your iOS device, Virtual Network Computing (VNC) might be the best option for you. This is built right into Mac OS X, but Windows users will need something like TightVNC which is available for free. Not only will VNC mirror your screen, but it also allows you to control the computer remotely. Seeing whatâ€™s on your screen is nice, but being able to manipulate your computer when youâ€™re not at your desk is even better.To turn it on in OS X, go into System Preferences under the Sharing section, and check the Screen Sharing toggle. Whichever way you plan on enabling VNC on your computer, make note of your local IP or Bonjour address displayed by your software.Next, youâ€™re going to need a VNC client for your iOS device. Some clients are available for free like Mocha VNC Lite, but apps like iTeleport ($4.99) and Mocha VNC ($5.99) are more feature-rich. Once you have one installed, input your computerâ€™s IP or Bonjour address into the configuration, and youâ€™re good to go.These require a bit of effort to set up, but it certainly worth the hassle. Youâ€™ll be glad to have went jumped through these hoops when you need that display at your desk, or if you want to turn off that download without getting out of bed.PURDUE (US) â€” Objects created with 3D printing often fall apart or lose their shape, but new software anticipates weak spots and increases durability.â€œI have an entire zoo of broken 3D printed objects in my office,â€? says Bedrich Benes, an associate professor of computer graphics at Purdue University.The printed fabrications often fail at points of high stress.â€œYou can go online, create something using a 3D printer and pay $300, only to find that it isnâ€™t strong enough to survive shipping and arrives in more than one piece,â€? says Radomir Mech, senior research manager from Adobeâ€™s Advanced Technology Labs.The 3D printers create shapes layer-by-layer out of various materials, including metals and plastic polymers. Whereas industry has used 3D printing in rapid prototyping for about 15 years, recent innovations have made the technology practical for broader applications, he says.â€œNow 3D printing is everywhere,â€? Benes says. â€œImagine you are a hobbyist and you have a vintage train model. Parts are no longer being manufactured, but their specifications can be downloaded from the Internet and you can generate them using a 3D printer.â€?The recent rise in 3D printing popularity has been fueled by a boom in computer graphics and a dramatic reduction of the cost of 3D printers, Benes says.Researchers at Purdue University and Adobeâ€™s Advanced Technology Labs have jointly developed a program that automatically imparts strength to objects before they are printed.â€œIt runs a structural analysis, finds the problematic part and then automatically picks one of the three possible solutions,â€? Benes says.The researchers detailed their findings in a paper presented during the SIGGRAPH 2012 conference in August.Former Purdue doctoral student Ondrej Stava created the software application, which automatically strengthens objects either by increasing the thickness of key structural elements or by adding struts. The tool also uses a third option, reducing the stress on structural elements by hollowing out overweight elements.â€œWe not only make the objects structurally better, but we also make them much more inexpensive,â€? Mech says. â€œWe have demonstrated a weight and cost savings of 80 percent.â€?The new tool automatically identifies â€œgrip positionsâ€? where a person is likely to grasp the object. A â€œlightweight structural analysis solverâ€? analyzes the object using a mesh-based simulation. It requires less computing power than traditional finite-element modeling tools, which are used in high-precision work such as designing jet engine turbine blades.â€œThe 3D printing doesnâ€™t have to be so precise, so we developed our own structural analysis program that doesnâ€™t pay significant attention to really high precision,â€? Benes says.The paper was authored by Stava, now a computer scientist at Adobe, doctoral student Juraj Vanek; Benes; Mech; and Nathan Carr, a principal scientist at Adobeâ€™s Advanced Technology Labs.Future research may focus on better understanding how structural strength is influenced by the layered nature of 3D-printed objects. The researchers may also expand their algorithms to include printed models that have moving parts.It's a big storm, moving slowly. A gigantic span of ferocious swirl meets a front of chilly resistance. The effect of that collision is amplified by powerful tidal influence. Upheavals and surges swamp the landscape. Many people are displaced; countless others stay with the familiar.Also, in the real world, some nasty weather is happening. But I'm talking about the tech industry of the last five business days, which has aligned and concentrated its forces in a crystal-clear demonstration, if one were needed, that mobile is where the bets are placed and futures will be won and lost.Apple is at the eye of the storm, where its devoted legions expect it, but no longer as a pioneer. Defending its territory rather than breaking new ground, the post-Jobs company did something its late and fabled leader scorned, split hairs to justify it, engaged in implicit combat with four competitors, ticked off some of its best customers and was squeezed by inexorable pressure of a quickly evolving industry.As I noted a week ago, it has been a perfect storm of product announcements and earnings releases. The two are always entwined. Though we like to imagine that companies are solely dedicated to the happiness of consumers at the end of the chain, the drumbeat of quarterly reports is what drives most decisions around product timing and the release of feature sets.This umbilical connection was etched in bold relief last week when Apple announced a new mini-maxi-Mac product lineup just two days before its Q4 earnings call. The mysteries of one were explained by the other.Though the accumulated import of last week's events had a tectonic rumble, there was really only one surprise -- the launch of a fourth-generation iPad, an upgrade that left disciples slack-jawed, and not entirely euphoric. Christina Warren spoke on behalf of incensed iPad owners in a 1,500-word rampage that explored the thesaurus entry for "angry" and invited rugged push-back of the #firstworldproblem type. The disaffected have a point, which is that a seven-month dev cycle (between the third- and fourth-gen iPads) is shorter than usual for Apple, and therefore, arguably, deceptive to third-gen buyers.The argument loses steam when you splash cold water on your throbbing veins and remember that Apple is a down-to-business corporation like any other, its steely eyes focused on managing its public stakeholders. That can be hard to remember during the live event, which is about shiny new features and end-use scenarios.In the earnings call two days later, CEO Tim Cook and CFO Peter Oppenheimer laid out past and future performance metrics like snapshots in a mosaic. Sales of iPads missed projections; iPod sales likewise below expectation. Mac down. Revenue flat against guidance, but earnings-per-share down. Most important to analysts: gross profit margin just below expectation, and projected to dip further. In fact, gross margins have skidded the last two quarters, from 47 percent to 40 percent, and the fiscal Q1 projection (that's the current quarter) is 36 percent, which harks back to fiscal 2008. Against all of this is a backdrop of plunging AAPL stock.When margins slump, volume must make up the difference. In a voracious market of technology adopters, sales come from new and refreshed products. Hence, the mini and the fourth-gen iPad.The post-PC company more clearly entered the post-Jobs epoch as Apple repudiated its previous scorn for small tablets. The mini is not a 7-incher! Tim Cook wants us to be clear on that point. It is a 7.9-incher. That's 35 percent bigger than a 7-inch screen! Put down the Red Bull, Tim, we get the point. But Cook also weirdly and defensively compared the iPad mini to the iPad 2 ("...equal to or better than the iPad 2 in every way"), and a portion of the commentariat complained that the specs were weak, barely competitive with the Google Nexus.The $329 starting price isn't earning many compliments either. This is how Apple works the offense and defense in the same play. Defensively, the company was forced to plug its portfolio gap with an intermediate slate. Forbes divined from Amazon's earnings call (also last week) that the Kindle Fire, with its succulent price point, is eating into iPad's share. Impossible to know for sure, since Amazon doesn't break out Kindle sales.But we know as a corollary that Samsung whipped Apple in smartphone share and units shipped in calendar Q3 by two to one. (56M vs. 27M phones sold; 31 percent vs. 15 percent share.) In a barbed announcement, Samsung noted that its Galaxy S III experienced a sales spike immediately after the iPhone 5 release.Google is another share-stealing tormentor. Sadly, Google scheduled its New York event in conflict with the latest storm of the century, and tiptoed out of the city when the weather forecast firmed up. But the new products came out today anyway: a 10-inch Nexus, plus a memory upgrade and price reduction of the 7-inch tablet line. In Apple's perspective: more pressure. The $329 iPad mini will soon be fighting for holiday gift status with a $200, 16GB 7-inch Nexus.For its offensive game, Apple relies on the concept and reality of premium. "Premium" means different things to different people, and its specifications are always changing. Apple's bankable status as a premium merchant has relied on build quality (still current), brand reputation (ephemeral, but earned and lasting for now), screen display quality (soon to be bettered by a new Nexus), and a safe, curated, huge app ecosystem (hanging onto leadership there for the time being).More than any other quality, though, Apple has accrued premium credibility through innovation leadership. Its destiny as a business titan depends on whether the company has invention left in the gas tank. Without the innovation, Apple is in an assembly-line business of iterating its products, synchronizing release cycles with finance milestones, managing its pipeline and massaging margins. Naturally, any company must do all these things. But last week we didn't see freshness from Apple; we saw a company loading up the pipeline for an earnings assault in Q1 with a barrage of products. In the live event, Tim Cook bragged about "...a truly prolific year for innovation for Apple." Prolific is not breakthrough. Apple did not become the world's most valuable company by making screens thinner, tablets smaller or phones longer. It got there by persuading society to adopt new categories.The dark-horse innovator last week was Microsoft, an aging legacy ruler facing entropic decay in a changing world of unmoored devices. There were no surprises; Microsoft held back no secrets about the radically different Windows 8 and the new Surface tablet. Windows Phone 8 was announced earlier today as the smartphone leg of Microsoft's stool. The boldness and commitment of Redmond's bet is breathtaking; that is universally recognized. But it's uphill for Microsoft's under-developed ecosystem: according to an Associated Press poll, most people haven't even heard of Windows 8.So it's Apple vs. Microsoft on daring, Apple vs. Samsung on smartphone market share and patent conflicts, Apple vs. Google on specifications and price, Apple vs. Amazon on willingness to cut margin, Apple vs. its customers on betrayed expectations, Apple vs. itself on the insurmountable challenge of remaining a true innovator forever. Interesting times. Fortunately for manufacturers and consumers both, it's not a winner-take-all industry. Get out the pie cutters.Brad Hill is a former Vice President at AOL, and the former Director and General Manager of Weblogs, Inc.I had a great idea this morning. I figured Iâ€™d head to the Microsoft Store in Scottsdale around 10am, waltz in, buy a Microsoft Surface, and then be out in 10 minutes. I assumed the store would be empty. I mean, come on, this is a Microsoft tablet weâ€™re talking about, and who goes to the Microsoft Store anyway?I was completely wrong.Â Microsoftâ€™s new tablet, the Surface RT, may not do everything an iPad can, but itâ€™s drawing some pretty big lines to Microsoft retail stores across the country for its launch this morning.Once I got to the Microsoft Store I was shocked to see a line of about 125 people waiting to buy the Surface and was told itâ€™d be a two hour wait before I could get in. The story is the same at other Microsoft Stores across the country with people lining up to purchase Microsoftâ€™s hyped tablet thatâ€™s supposed to compete with the iPad.The line at the Seattle stores have been reported to be the largest, but many people in those lines are associated with Microsoft. Microsoft isnâ€™t used to dealing with long launch lines though. A lot of people on Twitter have complained that itâ€™s taking Microsoft retail employees an hour to to get 15 people or so through the line. Apple usually churns through about one hundred or so customers on launch day every hour.Whether clinging to the inside of a bell jar, or outstretched from floor to ceiling, San Francisco-based artist Dan Grayberâ€™s mechanisms have but one purpose: to stay upright. Combining pulleys, bike brake cables, counterweights, and steel framing, Dan writes,Many of my pieces are small, spring loaded, mechanical objects. They are intricately designed and fabricated to accomplish one of the most simple, yet most essential tasks that an autonomous object can. This task, this need, is that of holding itself up. In most cases, my pieces accomplish this by actively attaching themselves to specific architectural features and individual objects.Some of Danâ€™s mechanisms self-install on walls, creating holes like industrial tracks. Others cling to corners or specific architectural features. More artworks can be seen in Grayberâ€™s online portfolio.One year ago, EFF rang alarm bells about SOPA and PIPA â€” Internet censorship bills threatening online freedom and the very structure of the Internet. Not long after, our members and the Internet community stood up to misguided politicians and deep-pocketed lobbyists and won, sinking SOPA and PIPA forever. It was revolutionary.You have the power to shape this world, and EFF stands with you. For 22 years, donating members have enabled EFF to bring legal and technological expertise into crucial battles about online rights, from defending free speech online to challenging unconstitutional surveillance.Your participation makes a difference, and weâ€™re proud to be a member-supported organization. Please consider becoming an EFF member today â€” every donation, no matter the size, guarantees that we who value freedom online will always have a voice and a formidable advocate.Help protect the free and open Internet. Join or renew your membership with the Electronic Frontier Foundation today!The prospect of growing crops in vertical farms directly inside of cities has been on the collective wish-list of environmentalists, sustainable developers, and futurists for quite some time now. And now it looks like it's finally starting to happen. Land-strapped Singapore has opened its first vertical farm â€” an innovation that will increase the variety of foods it has available and decrease its dependance on foreign imports.And indeed, a major problem facing Singapore (and many other cities) today is land scarcity. Located at the tip of the Malay Peninsula, it is an island country that consists of a mere 710 square kilometers (271 square miles) â€” and most of it is developed and urbanized. Today, only 7% of Singapore's vegetables are grown locally. But by virtue of the new facility, it's looking to change the situation.Developed by Sky Greens Farms, the vertical farm consists of 120 aluminum towers that extend over 9 meters (30 feet) in height. In total, the vertical farm is able to produce vegetables at a rate of 0.5 tonnes per day. The company is hoping to attract investors so that it can devote another USD$21M dollars for upgrades. Ideally, they'd like to construct as many as 300 towers â€” enough to produce two tonnes of vegetables per day.Currently, the farm is able to grow three kinds of vegetables, and they can only be found at the local FairPrice Finest supermarkets, but at a price that's 10 to 20 cents more than vegetables from other sources. But according to Channel News Asia, customers are enthusiastic about the new products and the supermarkets are struggling to keep the vegetables in stock. Moreover, Sky Greens expects the price to drop as the farm ramps up supply.The FSF has fought for years against the threat of Digital Restrictions Management (DRM). Users should have the right to modify, share and learn from the software on their devices, and technical measures put in place in the name of DRM offer a substantial roadblock. It's even worse when those measures have the force of criminal law behind them, threatening people who simply want to change the software on their computers with jail time. The FSF wants to create a world in which there is no DRM. Until then, at the very least, users shouldn't have to worry about legal consequences for disabling these malfeatures on their own devices.The Digital Millennium Copyright Act (DMCA) of course circumvents the rights of users by making it illegal to modify your devices in ways that would give you actual access to them, or to share tools to help others do this. Congress did create one small carve-out from this belligerence; that once every three years the Library of Congress (via the Copyright Office), would consider making exceptions to this broad rule. In 2010, the Office recommended exempting the freeing of cellphones. They did not, however, make clear that this exemption extended to people who distributed tools for freeing these devices. In 2012, we had hoped to expand the exempted class of uses, and encouraged the Copyright Office to extend exemptions to tablets, gaming consoles, and computers running restricted boot. We were on the side of organizations like the EFF, and the Mozilla Foundation as well as hundreds of other individuals calling for the protection of those who simply want to be able to use their own devices in freedom.But we were not the only ones to send recommendations to the Copyright Office. Large corporations like Sony, and corporate-backed groups like "Joint Creators and Copyright Holders" also sent comments opposing these reasonable exemptions. And the Copyright Office fell for their FUD. The Copyright Office has announced that while freeing your phone in order to install your own software is still permitted, unlocking the phone in order to switch carriers will be phased out. And even that minimal remaining protection has not been extended to tablets. Offering the duplicitous explanation that they weren't sure what a tablet was, the office completely abdicated its responsibility to protect users' rights to run their own software on their devices, as well as their rights to works locked down on those tablets. They similarly rejected exemptions for users wanting to install their own operating system on game consoles, and even worse, failed to extend protection to users who want to install their own operating system on computers with restricted boot.This means no longer being able to switch your own cell phone carrier without permission. This means no modifying tablet operating systems without legal threat. It means that trying to install a different operating system on your game console could result in the FBI breaking down your door. It means that you cannot even be sure of your right to remove proprietary software from devices encumbered with restricted boot.The Copyright Office picked Sony over you. They had an opportunity to protect users, but instead chose to protect corporate interests. This is a terrible outcome for users everywhere, and just proves that we need wholesale elimination of the anti-circumvention laws.We need to band together. Here is what you can do to help:South Carolinaâ€™s Department of Revenueâ€™s computer system was hacked, resulting in the compromise of some 3.6 million Social Security numbers on top of nearly 400,000 credit and debit card numbers exposed. The actual breaches occurred in September and October.Adding insult to injury, none of the Social Security numbers were encrypted; nor were 16,000 credit card numbers. The South Carolina Division of Information Technology apparently informed the Department of Revenue of the breach Oct. 10, according to local news reports. Anyone who filed a tax return in South Carolina after 1998 is urged to call 866-578-5422.â€œThis is not a good day for South Carolina,â€? governor Nikki Haley told an Oct. 26 press conference, according to WACH Fox News Center, adding about the hacker responsible: â€œI want this person slammed against the wall.â€?On Oct. 26, Haley filed an executive order to beef up the stateâ€™s security. â€œI hereby direct all cabinet agencies to immediately designate an information technology officer,â€? it read, â€œto cooperate with the State Inspector General who is authorized to make recommendations to improve information security policies and procedures in state agencies.â€?The order also stipulates cooperation with national cyber-security sources such as the Sharing Analysis Center, collaboration with in-state agencies to identify vulnerable points in cyber-security systems, and improvement in the training of government employees in information security measures.In the meantime, the current breach is under intense investigation by state authorities. Various local news sources are reporting that the attack came from a â€œforeign country.â€?According to Census.gov, the population estimate for the state of South Carolina is a bit over 4.67 million souls, meaning that roughly three-quarters of its citizensâ€™ Social Security numbers are in the hands of hackers.â€œFrom the first moment we learned of this, our top priority has been to protect the taxpayers and the citizens of South Carolina, and every action weâ€™ve taken has been consistent with that priority,â€? South Carolina DOR director James Etter wrote in an Oct. 26 statement. â€œWe have an obligation to protect the personal information entrusted to us, and we are redoubling our efforts to meet that obligation.â€?To reduce online piracy, Google has implemented several changes to its search engine in recent years. Among other things, Google has blacklisted dozens of piracy related terms from appearing in its autocomplete and instant services. Megaupload is one of these search terms, and nine months after the last infringement took place the name of Kim Dotcomâ€™s file-hosting service is still being censored. This begs the question, what other terms are needlessly censored by Googleâ€™s blacklist?Since January 2011, Google has been filtering â€œpiracy-relatedâ€? terms from its â€˜Autocompleteâ€˜ and â€˜Instantâ€˜ services.Google users searching for terms like â€œtorrentâ€?, â€œBitTorrentâ€? and â€œMegauploadâ€? will notice that no suggestions and search results appear before they type the full word. While no search results are removed from Googleâ€™s index, there is sharp decrease in searches for these terms.What triggers a keyword to be included in the blacklist is not clear, but a Google spokesperson previously told TorrentFreak that they remove terms that are â€œclosely associated with infringing results.â€?â€œItâ€™s not easy and the list will undoubtedly change over time. When evaluating terms for inclusion, we examine several factors, including correlation between the term and results that have been subject to valid DMCA takedown notices,â€? Google told us.Sounds deliberate, and as weâ€™ve documented in the past the list has indeed been changed. Many new terms have been added since the start, most recently to include several of The Pirate Bayâ€™s domain names.However, these changes appear to go only one way.Megaupload, for example, is still among the censored terms even though the site has been offline for more than nine months. There are simply no accurate â€œcopyright infringementâ€? grounds to keep it blacklisted, one would think.Nevertheless, searching for â€œMegauploaâ€? today still shows no Autocomplete and Instant results at all.Funnily enough, Googleâ€™s search algorithm bypasses the filter to some extent, suggesting â€œMegauplauploadâ€? when typing â€œMegauplâ€? and displaying instant results for a â€œMegauploadâ€? search because thatâ€™s a far more popular search term.That said, the concern remains that once a term is placed on Google piracy blacklist itâ€™s not so easy to get it taken off.At this point itâ€™s still unclear what factors dictate a term being placed on Googleâ€™s piracy blacklist. Itâ€™s also unknown how many piracy related terms are censored as the list is not made public.To get a better understanding of Megauploadâ€™s continued presence in the blacklist and what the update policy is, TorrentFreak asked Google for a comment, but we have yet to receive a reply.In the meantime we decided to compile our own list of terms that are currently blocked from Instant and Autocomplete. Most terms are related to torrent sites and cyberlockers. In many cases the full url is not blocked, which then simply takes over as an Autocomplete suggestion.Readers are welcome to add more censored keywords in the comment so we can add to the list.Status Symbols are devices that transcend their specs and features, and become something beautiful and luxurious in their own right. They're things that live on after the megapixel and megahertz wars move past them, beacons of timeless design and innovation.2005 was a good year for Nintendo handhelds. The original DS was on its way to becoming the most successful portable device of all time, while the Game Boy Advance SP let you play your entire Game Boy library â€” dating back to the monochromatic original â€” on one, handy machine. So it was a bit curious, then, when the company decided to release the $99 Game Boy Micro, a small, streamlined version of the handheld that could only play GBA games. It improved form at the expense of functionality, creating a device that wasn't strictly necessary, but was amazing anyways.The most important thing about the Micro was its size â€” it was downright miniscule. The screen was only two inches across and the entire thing weighed just 0.18 pounds. That's less than half the weight of the original Game Boy (0.49 pounds) and a drop even from the ultralight iPhone 5's 0.25 pounds. It was so small and light you could leave it in a bag â€” or even your pocket! â€” and forget it was there. But it wasn't just that the Micro was small, it was also stylish in a way no Nintendo device had ever been. Unlike the clunky DS or any version of the Game Boy or GBA, the Micro wasn't something you'd be embarrassed to pull out in public. It felt like a gadget, not a toy. The 20th anniversary edition was particularly lovely, with a gold and red color scheme reminiscent of the original Famicom controller (the Japanese version of the NES).It was stylish in a way no Nintendo device had ever beenWhile its size made it an ideal companion for just about any trip â€” I particularly enjoyed using it for grinding through Final Fantasy V levels in between, and occasionally during, university classes â€” the screen is what made the Micro a great game system. It was small, but it was beautiful. Shrinking down games made them appear crisper, and the brilliant backlight made older games pop with new life and color. You haven't played The Legend of Zelda: The Minish Cap until you've played it on a Micro with the brightness cranked up to 11. And if you wanted to feel extra cool, the Micro was ideal for playing the Japan-exclusive Bit Generations line of GBA games â€” sleek, minimalist games in sleek, minimalist packaging, just begging to be played on a sleek, minimalist Game Boy.Like many beautiful devices, the Micro also had its share of problems. The smaller screen wasn't ideal for text-heavy games, the faceplate was prone to scratches, and the ergonomics could feel a tad cramped after lengthy sessions. But sometimes you have to make sacrifices, and with the Micro it was more than worth it. The combination of its size, style, and screen made it the first machine from Nintendo that looked as good as it played. And unlike later releases, like the iPod-influenced DS Lite, the Micro had a look all its own, and one that has yet to be duplicated. It was the last device to feature the Game Boy name, and though it was far from the most popular, it was definitely the coolest.Do not buy a Microsoft Surface RT yet.Iâ€™m typing this with gritted teeth.Â  My 24 hours with the half-baked Surface have been a frustrating challenge, a mix of love and hate.Â  I want want want this to work, but one problem after another have led me to come to the conclusion â€“ a temporary one at least â€“ that this thing just isnâ€™t ready to ship.Every time Apple unveils a new gadget or laptop, my jaw drops and I wonder how they pulled off executing their industrial designs.Â  Their v1 designs look so beautifully put together, not a mishmash of plastic parts and lids like the PC counterparts.Â  Every now and then, a PC maker will bring out something similar, but itâ€™s the very rare exception rather than the rule.The Surface RT is Microsoft shoving their hardware partners aside and saying, â€œLemme show you how this should be done. Pay attention, kids.â€?This tablet hardware doesnâ€™t just compete with the iPad â€“ it bypasses the iPad in many ways that are significant and valuable for me.I plugged in my USB presentation remote and it just worked.I plugged in a 64GB micro SD card with all my presentations and files and it just worked.I popped out the kickstand and started typing and it just worked.Â  Well, almost â€“ if thereâ€™s one significant compromise in the Surface RT, itâ€™s the kickstand.Â  You get two and only two positions for the kickstand: open and closed.Â  Thereâ€™s no adjustments.Â  I think the kickstand angle was designed for airplane use by short people, because the screen hardly goes back at all.Â  Itâ€™s probably perfect for Danny DeVito when he puts it on the seat back tray in coach class, but for me on a desk, itâ€™s too steep.The built-in front-facing camera for Skype is angled so that itâ€™ll work great when the kickstand is open, but again, only for Danny DeVito, or maybe for people who want to show off their chests in Skype.There are other hardware compromises, but theyâ€™re pretty small.Â  The speakers are laughably quiet; I fired up one of my favorite movies, Once Upon a Time in Mexico, and I couldnâ€™t even hear the actorsâ€™ dialog in the opening scenes.Â  Not couldnâ€™t understand â€“ couldnâ€™t even hear it.Â  The magnetic power cord doesnâ€™t snap in with authority, but rather requires careful positioning.Â  The volume up/down buttons are exactly opposite the USB port, so when I plug in USB devices I often push the volume up/down by accident.But who cares? I HAVE A USB PORT! Oh, Steve Jobs, I understand that you were a design deity, but I really needed that USB port, and I didnâ€™t want a stupid dongle to get it.Â  The iPad has a USB dongle available, but it was useless to me because I needed it for my presentation clicker at the same time I also needed video out, but I couldnâ€™t use both simultaneously.The Type Cover (the one with real keys) just works.Â  Iâ€™ve got big hands that often struggle on undersized keyboards, but I can type very quickly on the Type Cover.Â  So quickly, in fact, that I can outrun Microsoft Word on the Surface.Â  I get the feeling that the Surface RTâ€™s CPU or Word code just canâ€™t keep up with my typing.Â  Hereâ€™s an example video:But thatâ€™s not a hardware problem â€“ and itâ€™s time for us to talk about the ugly problem with the Surface RT.The hardware makes promises that the software canâ€™t deliver â€“ and the ability to type faster than Word can digest is a great example of that.Â  Sure, I understand that the shipped version is â€œMicrosoft Word Preview,â€? but you canâ€™t deliver software like this.Â  Itâ€™s a recipe for returned products â€“ and frankly, thatâ€™s exactly what Iâ€™m going to do with the Surface RT, return it.Wordâ€™s problems arenâ€™t limited to slow typing.Â  Once youâ€™ve banged out a document, saving your work is another adventure:I can understand problems with Word because itâ€™s a new piece of software that Microsoft has never released bef â€“ wait, hold on. Iâ€™m being told by my staff that Word is not a new program, and has been out since the 1980s.Â  If I want to see a v1 program, theyâ€™re telling me to look at the Mail app.Â  Alright, letâ€™s give that a shot:After waiting over a minute for the machine to boot and launch the mail app, I got a blank gradient screen. User interface 101: if the app needs to be set up on the first launch, offer to do that, please.Â  Folks from Twitter suggested that I swipe out from the right side and click Accounts, Add, and I did, but the Surface just sat there as shown in the video.Â  Eventually, after setting the unit aside and going on with my day, I noticed several minutes later that it popped up and said it couldnâ€™t detect the email servers for brento@brentozar.com.Â  User interface 102: when youâ€™re doing something, say something.The Surface Pro comes out in a few months.Â  The hardware design is very similar, but heavier, thicker, and with a â€œrealâ€? processor that requires a fan.Â  Yes, those are drawbacks, but they come with a very, very powerful advantage: the Surface Pro will run real Windows 8.Â  This means (hopefully) none of the buggy Windows RT problems, and perhaps more importantly, a full stable of applications.See, the Surface RT only runs Metro (whatever) apps, of which there are woefully few.Â  I didnâ€™t even get to the point of testing the very few that I found â€“ forget it, because the built-in stuff is so incredibly bad.Â  The lack of apps wasnâ€™t a problem for me â€“ I explained why I preordered a Surface RT â€“ but the quality of the built-in apps was.The whole point of the Surface RT was supposed to be a tablet thatâ€™s ready for work.Â  Itâ€™s not.Â  Donâ€™t touch it.After getting linked from HN and Reddit, Iâ€™ve gotten a bazillion comments that boil down to â€œYou should have updated Office.â€?Â  Yes, if only I could have figured out how.Â  Since this post went live, Microsoft has explained how to get it:For Windows RT Surface users, the update can be had by:Emphasis mine.Â  I had no idea that there were multiple places for Windows Update on the same tablet.Â  One tablet, but multiple places to get Microsoft updates?Â  And weâ€™re not even counting the Windows Store here.Â  This just isnâ€™t realistic to expect end users to find this buried treasure.Other commenters have suggested that the Office updates apply automatically overnight â€“ they do not.Â  Iâ€™d left my Surface RT plugged in overnight, but even so, that only lets automatic updates apply, not optional ones like this Office update.And of course, keep in mind that I still donâ€™t know if these updates fix the problem â€“ they certainly donâ€™t fix the camera or mail problems, both of which were already updated through Windows Update.Yesterday this got posted to a bunch of news sites. I was out shopping with Erika when I got a tweet saying Iâ€™d hit the front page of HackerNews, LoopInsight, and Reddit, plus getting linked to from comments at CNet and Techmeme.Hereâ€™s what that looks like in Google Analytics:Yesterday was supposed to be a fun shopping day, just Erika and I out looking at furniture and clothes before my trip out to DevConnections and the PASS Summit. Increasingly, though, I kept turning to my phone and typing frantically, trying to explain things to commenters. My stress level went through the roof, and eventually I realized that being out and about was probably the best thing that could happen. I stopped trying to keep up, and just went back to my life â€“ taking Ernie for a long walk, going out for dinner, reading the paper.Yesterday was frustrating as all hell.Iâ€™m a geek. Iâ€™ve been using computers since my first Commodore 64, then writing code in Topspeed Clarion, VBscript, Java, and .NET before switching over to Microsoft SQL Server database administration. I know bugs. Iâ€™ve coded bugs. (Thatâ€™s probably all Iâ€™ve ever coded, come to think of it.) Iâ€™m used to poking around to discover workarounds to get things to work. Iâ€™m very used to doing updates to devices before I start working with â€˜em, and I repeatedly did updates on the Surface RT trying to get it to work.Iâ€™m not a zealot. I use both Microsoft and Apple gear, and while a lot of my SQL Server friends rant against cloud-based and NoSQL databases, I like those too. Iâ€™m all about using whatever works best â€“ or to be more specific, whatever sucks the least. No software or hardware is perfect, although Iâ€™ll be the first to tell you that the Surface RTâ€™s hardware comes pretty darned close to being perfect for 2012 tablets. The iPad isnâ€™t. I hate that Apple continues to burden their products with wacko connectors, and now theyâ€™re even changing the connectors. Give me a freakinâ€™ USB port, memory card port, and video out port, and letâ€™s call it a day.I really, really wanted the Surface RT to work. I need a lightweight backup PowerPoint device when Iâ€™m on the road presenting at conferences. That device needs to show PowerPoint presenter view while driving an external projector, while being plugged in for electricity (some of my sessions are 8-9 hours long), and take a presentation clicker. Keynote Remote doesnâ€™t cut it because it loses reception in noisy radio areas like big conference rooms. The iPad only has one miserable dock connector or Lightning port, so it can either drive video OR be plugged in, but not both. The Surface RT looked like a great answer to this problem.Iâ€™m fair. If Iâ€™m going to complain about something, I want to have proof. I canâ€™t just say, â€œSurface RT suxxorzâ€? if I get frustrated. Rather than just return it and call it a day, I restored the device from scratch and tried the setup experience again. (Remember, Iâ€™m a former developer, so Iâ€™m used to trying to reproduce bugs.) I recorded videos of it in action to prove what was going on.But none of these mattered yesterday. Even with the restores, even with recording video of the problems, I got hammered. Hundreds of commenters on all kinds of sites said it was my fault.Last night, I went to bed with a plan. Iâ€™d drive down to the Microsoft store, buy another Surface RT, film the unboxing process, show how hard it is to find the behind-the-scenes desktop update panel on your own, and find out if it fixes the Skydrive and keyboard problems. (I already know the Mail updates donâ€™t fix the login/freeze problem, because Iâ€™d done those before filming the videos.)This morning, I woke up with a better plan. Iâ€™m moving on. I donâ€™t think thereâ€™s anything I could do to convince the hard-core fanboys out there that the Surface RT has problems â€“ because I realized that most of the commenters donâ€™t even own Surfaces. So many of the comments were flat out wrong, like saying thereâ€™s only one place for Surface updates and that Windows RT doesnâ€™t have a desktop mode. I think Iâ€™ve done a fair job of documenting the problems I ran into, and Iâ€™ve burned enough of my weekend time on it.And no, Iâ€™m not heading down to the Apple store to buy a new iPad, either. Iâ€™m still using a first-generation iPad 1, and believe me, itâ€™s just as flaky as the Surface RT is. Thereâ€™s no good presentation solution, the keyboards pale in comparison to the Surfaceâ€™s, and many apps are crashtastic.I donâ€™t have a single right answer for my gadget needs yet, but the fun part about being a geek in 2012 is that the options are nearly endless. The journey of finding the right gadget is just as much fun as the destination, and Iâ€™m looking forward to giving the next gadget a shot.Got a solution thatâ€™s available to buy today? Tell me in the comments.Itâ€™s not completely official yet, but it appears that Steven Sinofsky, Microsoftâ€™s President of Windows Division, agrees that the Word typing problem is a known issue and another update is forthcoming.Everybody who called me incompetent, please take your time in apologizing. Iâ€™m sure my blog would fall over immediately if all of you apologized at once.The real-world reviews are coming in, and theyâ€™re not good. Â Hereâ€™s a very long and detailed review from Chris Pirillo:The drones and other military aircraft have crowded the skies over the Horn of Africa so much that the risk of an aviation disaster has soared.Since January 2011, Air Force records show, five Predators armed with Hellfire missiles crashed after taking off from Lemonnier, including one drone that plummeted to the ground in a residential area of Djibouti City. No injuries were reported but four of the drones were destroyed.Predator drones in particular are more prone to mishaps than manned aircraft, Air Force statistics show. But the accidents rarely draw public attention because there are no pilots or passengers.As the pace of drone operations has intensified in Djibouti, Air Force mechanics have reported mysterious incidents in which the airborne robots went haywire.In March 2011, a Predator parked at the camp started its engine without any human direction, even though the ignition had been turned off and the fuel lines closed. Technicians concluded that a software bug had infected the â€œbrainsâ€? of the drone, but never pinpointed the problem.â€œAfter that whole starting-itself incident, we were fairly wary of the aircraft and watched it pretty closely,â€? an unnamed Air Force squadron commander testified to an investigative board, according to a transcript. â€œRight now, I still think the software is not good.â€?Djibouti is an impoverished former French colony with fewer than 1Â million people, scarce natural resources and miserably hot weather.But as far as the U.S. military is concerned, the country's strategic value is unparalleled. Sandwiched between East Africa and the Arabian Peninsula, Camp Lemonnier enables U.S. aircraft to reach hot spots such as Yemen or Somalia in minutes. Djiboutiâ€™s port also offers easy access to the Indian Ocean and the Red Sea.â€œThis is not an outpost in the middle of nowhere that is of marginal interest,â€? said Amanda J. Dory, the Pentagonâ€™s deputy assistant secretary for Africa. â€œThis is a very important location in terms of U.S. interests, in terms of freedom of navigation, when it comes to power projection.â€?The U.S. military pays $38Â million a year to lease Camp Lemonnier from the Djiboutian government. The base rolls across flat, sandy terrain on the edge of Djibouti City, a somnolent capital with eerily empty streets. During the day, many people stay indoors to avoid the heat and to chew khat, a mildly intoxicating plant that is popular in the region.Hemmed in by the sea and residential areas, Camp Lemonnierâ€™s primary shortcoming is that it has no space to expand. It is forced to share a single runway with Djiboutiâ€™s only international airport, as well as an adjoining French military base and the tiny Djiboutian armed forces.Apple has just announced a major executive shake-up: Senior VP of iOS software Scott Forstall is leaving Apple at the end of the year â€” he'll be serving in an advisory role to CEO Tim Cook until his departure. Additional executive changes include the departure of retail head John Browett, with Jony Ive, Bob Mansfield, Eddy Cue and Craig Federighi being tapped for additional responsibilities.To make up for the departure of Forstall, Jony Ive will now provide leadership and direction for human interface across the entire company â€” it sounds like Ive will be getting a major opportunity to bring his famed hardware design sensibility to Apple's software. Eddy Cue, who has been responsible for Apple's digital storefronts, will get increased responsibility in the form of Maps and Siri. Obviously, that's a major challenge for Cue to take on, and it isn't unreasonable to think that the failure of iOS 6 Maps at launch may have directly led to his removal as iOS VP.Craig Federighi, who previously served as VP of Mac software, will now be in charge of both iOS and OS X. Apple says this move will help unify software strategy across the two platforms; it sounds like he'll be the one most responsible for assuming Forstall's duties. Finally, VP Bob Mansfield â€” whose retirement was announced earlier this year before he announced his intentions to stay on in a less defined role â€” will head up a group known as Technologies, with a focus on semiconductor and wireless hardware.As for John Browett, Apple's Senior VP of retail is out after less than a year on the job. There's no word as to why he left (or was dismissed), but Apple says that a search for a replacement is underway. In the meantime, the company's retail team will report directly to Cook. All told, removing Browett and Forstall from Apple is a significant shake-up, as Forstall was a huge component behind the rapid rise and success of the iOS platform. Adam Lashinsky, author of Inside Apple, theorized on Twitter that Forstall was the "DRI" â€” directly responsible individual â€” for Maps and Siri, and thus "paid the price" for Apple's troubles with those two key iOS features. The DRI model was one that Steve Jobs believed strongly in during his role as Apple's CEO, and it looks like the concept lives on under Tim Cook's direction.CUPERTINO, Calif.--(BUSINESS WIRE)--AppleÂ® today announced executive management changes that will encourage even more collaboration between the Company's world-class hardware, software and services teams. As part of these changes, Jony Ive, Bob Mansfield, Eddy Cue and Craig Federighi will add more responsibilities to their roles. Apple also announced that Scott Forstall will be leaving Apple next year and will serve as an advisor to CEO Tim Cook in the interim. "We are in one of the most prolific periods of innovation and new products in Apple's history," said Tim Cook, Apple's CEO. "The amazing products that we've introduced in September and October, iPhone 5, iOS 6, iPad mini, iPad, iMac, MacBook Pro, iPod touch, iPod nano and many of our applications, could only have been created at Apple and are the direct result of our relentless focus on tightly integrating world-class hardware, software and services." Jony Ive will provide leadership and direction for Human Interface (HI) across the company in addition to his role as the leader of Industrial Design. His incredible design aesthetic has been the driving force behind the look and feel of Apple's products for more than a decade. Eddy Cue will take on the additional responsibility of SiriÂ® and Maps, placing all of our online services in one group. This organization has overseen major successes such as the iTunes StoreÂ®, the App Storeâ„ , the iBookstoreâ„  and iCloudÂ®. This group has an excellent track record of building and strengthening Apple's online services to meet and exceed the high expectations of our customers. Craig Federighi will lead both iOS and OS XÂ®. Apple has the most advanced mobile and desktop operating systems, and this move brings together the OS teams to make it even easier to deliver the best technology and user experience innovations to both platforms. Bob Mansfield will lead a new group, Technologies, which combines all of Apple's wireless teams across the company in one organization, fostering innovation in this area at an even higher level. This organization will also include the semiconductor teams, who have ambitious plans for the future. Additionally, John Browett is leaving Apple. A search for a new head of Retail is underway and in the interim, the Retail team will report directly to Tim Cook. Apple's Retail organization has an incredibly strong network of leaders at the store and regional level who will continue the excellent work that has been done over the past decade to revolutionize retailing with unique, innovative services for customers.Update: 9to5Mac has posted a team-wide email from Tim Cook thanking Forstall for his "many contributions to Apple over his career" and explaining that Mansfield will remain with the company for an additional two years. The full text is below.We are in one of the most prolific periods of innovation and new products in Appleâ€™s history. The amazing products that weâ€™ve introduced in September and October â€“ iPhone 5, iOS6, iPad mini, iPad, iMac, MacBook Pro, iPod touch, iPod nano and many of our applications â€“ could only have been created at Apple, and are the direct result of our relentless focus on tightly integrating world-class hardware, software and services. Today, I am announcing changes that will encourage even more collaboration between our world-class hardware, software and services teams at all levels of our company. As part of these changes, Jony Ive, Bob Mansfield, Eddy Cue, and Craig Federighi will be taking on more responsibilities. I am also announcing that Scott Forstall will be leaving Apple next year and will serve as an advisor to me during the interim. I want to thank Scott for all of his many contributions to Apple over his career. Jony Ive will provide leadership and direction for Human Interface (HI) across the company in addition to his longtime role as the leader of Industrial Design. Jony has an incredible design aesthetic and has been the driving force behind the look and feel of our products for more than a decade. The face of many of our products is our software and the extension of Jonyâ€™s skills into this area will widen the gap between Apple and our competition. Eddy Cue will take on the additional responsibility of Siri and Maps. This places all of our online services in one group. Eddy and his organization have overseen major successes such as the iTunes Store, the App Store, the iBookstore and iCloud. They have an excellent track record of building and strengthening our online services to meet and exceed the high expectations of our customers. Craig Federighi will lead both iOS and OS X. We have the most advanced mobile and desktop operating systems on the planet, and bringing together our OS teams will make it even easier to deliver our best technology and user experience innovations to both platforms. Craig recently led the very successful release of Mountain Lion. Bob Mansfield will lead a new group, Technologies, which combines all of our wireless teams across the company in one organization, allowing us to innovate in this area at an even higher level. This organization will also include all of our semiconductor teams, who have some very ambitious plans. As part of this, I am thrilled to tell you that Bob will remain with Apple for an additional two years. Bob has led some of our most challenging engineering projects for many years. Additionally, John Browett is leaving Apple. Our search for a new head of Retail is already underway. In the meantime, the Retail team will report directly to me. Retail has an incredibly strong network of leaders at the store and regional level, and they will continue the excellent work theyâ€™ve done over the past decade to revolutionize retailing with unique, innovative services and a focus on the customer that is second to none. This phenomenal team of talented and dedicated people works their hearts out making our customers happy. They have our respect, our admiration and our undying support. Please join me in congratulating everyone on their new roles. Iâ€™d like to thank everyone for working so hard so that Apple can continue to make the worldâ€™s best products and delight our customers. I continue to believe that Apple has the most talented and most innovative people on the planet, and I feel privileged and inspired to be able to work with all of you.Update: In response to the impact of Hurricane Sandy, Comcast is opening its XFINITY WiFi hotspots to non-Comcast subscribers in PA, NJ, DE, MD, DC, VA, WV, MA, NH and ME until Nov. 7. Users should search for the network "xfinitywifi" and click on "Not a Comcast subscriber?" at the bottom of the sign-in page. Users should select the "Complimentary Trial Session" option from the drop down list. The Open Wireless Movement thanks Comcast for helping out!In troubled times, it's important to help each other out. Right now, we're witnessing an unprecedented hurricane hitting the Eastern Seaboard of the United States, and the ensuing damage and power outages are crippling rescue efforts, businesses large and small, and personal communications.Communication is critical in time of crisis, and the Internet allows for the most effective way of getting information in and out. With readily available networks, governmentÂ officials could use tools like Twitter to quickly spread information, citizen reports could help focus assistance where it is needed most, and social media updates could help reassure friends and loved onesâ€”keeping mobile phone lines open for emergencies.To take advantage of the Internet, people should not have to attempt to skirt restrictive Terms of Service to attempt to tether their smartphones. And tethering would not be necessary if there were ubiquitous open wireless, so that anyone with a connection and power can share their networkÂ with the neigborhood.Last year, we wrote a post titled "Why We Need An Open Wireless Movement." Today,Â EFF is proud to announce the launch of the Open Wireless Movementâ€”located at openwireless.orgâ€”a coalition effort put forth in conjunction with nine other organizations: Fight for the Future, Free Press, Internet Archive, NYCwireless, the Open Garden Foundation, OpenITP, the Open Spectrum Alliance, the Open Technology Institute, and the Personal Telco Project.Aimed at residences, businesses, Internet service providers (ISPs), and developers, the Open Wireless Movement helps foster a world where the dozens of wireless networks that criss-cross any urban area are now open for us and our devices to use.The Open Wireless Movement envisions a world where people readily have access to open wireless Internet connectionsâ€”a world where sharing one's network in a way that ensures security yet preserves quality is the norm. Much of this vision is attainable now. In fact, many people have routers that already feature "guest networking" capabilities. To make this even easier, we are working with a coalition of volunteer engineers to build technologies that would make it simple for Internet subscribers to portion off their wireless networks for guests and the public while maintaining security, protecting privacy, and preserving quality of access. And we're working with advocates to help change the way people and businesses think about Internet service.We're also teaching the world about the many benefits of open wireless in order to help society move away from closed networks and to a world in which open access is the default. We are working to debunk myths (and confront truths) about open wireless while creating technologies and legal precedent to ensure it is safe, private, and legal to open your network.We believe there are many benefits to having a world of open wireless. Two of the big ones for us have to do with privacy and innovation.Open wireless protects privacy. By using multiple IP addresses as one shifts from wireless network to wireless network, you can make it more difficult for advertisers and marketing companies to track you without cookies. Activists can better protect their anonymous communication by using open wireless (though TorÂ is still recommended).Innovations would also thrive: Smarter tablets, watches, clothing, carsâ€”the possibilities are endless.Â In a future with ubiquitous open Internet, smartphones can take advantage of persistent, higher quality connections to run apps more efficiently without reporting your whereabouts or communications. Inventors and creators would not have to ask permission of cell phone companies to utilize their networks, both freeing up radio spectrum and reducing unnecessary barriers to entry.This movement is just beginning, but in a sense it has always been around. People, businesses, and communities have already been opening up their wireless networks, sharing with their neighbors, and providing an important public good. We want this movement to grow without unnecessary legal fears or technical restraints.Join the Open Wireless Movement. Whether you're a household or small business, a technologist or a student, we need your support. Check out openwireless.org for more information, and spread the word.A backlash among Reddit users has seen BitTorrent Inc. criticized over the way revenue-generating addons were presented in parallel with uTorrent client downloads. The company informs TorrentFreak that it always considers feedback, aims to provide a good customer experience, and will introduce changes soon. But whatever they are, is it really possible to please all of the people all of the time, especially ones whose requirements are â€œno-strings freeâ€? at all times?Apparently everything is available for free on the web these days. Music, movies, TV shows, games â€“ you name it â€“ itâ€™s all just a click away.New business models must be found, the tide is way too strong to hold back, the genie is out of the bottle. Itâ€™s reportedly get real or get out time, or so the sound bites go.BitTorrent users, in one form or another, have been held to blame for much of the above scenario, along with their main weapon of choice, uTorrent. But market forces are interesting beasts and ones that donâ€™t exist in a vacuum.BitTorrent Inc., the company behind the completely legal uTorrent, has worked hard to develop both itself and its software, but as it grows so do its costs. Somehow revenue has to be generated and these days, when youâ€™re a company employing around 80 staff, that has to be a significant amount.So, just like the entertainment companies who struggle to make money against free, BitTorrent Inc. has to employ techniques to give away their free product, in this instance uTorrent, and bring in the bucks at the same time.In part this is achieved by selling uTorrent Plus, which is essentially the regular uTorrent with anti-virus, media playing and conversion functions built in. Revenue is also generated by bundling optional addons, such as a toolbar, with the free uTorrent, but a new method of offering these extras has managed to irritate a bunch of Reddit users.The complaint centers around a single but very important button on the uTorrent site â€“ the â€œFree Downloadâ€? button, as illustrated below.The problem is that the button isnâ€™t a simple one-click download. Once a user hovers over it ready to click, the button and surrounding areas quickly change to include extra information.The very eager user will simply see â€œDownloadâ€? directly under their mouse pointer and will just click away, but the more cautious will notice that there are three options â€“ all preselected â€“ which relate to extra features and bundled revenue-generating software. You can test for yourself here.Obviously BitTorrent Inc. need to make money, but the main complaints seem to center around the way this download page has been configured to encourage a skipping over the details (and therefore the installation of potentially unwanted software) in order to obtain a quick download.While critics might argue that people should read what theyâ€™re agreeing to before clicking, BitTorrent Inc. say that the changes are recent and were implemented to streamline the uTorrent installation experience.â€œWeâ€™ve been offering the toolbar for years as a way to support the development of our software so users can get it free,â€? a spokesman told TorrentFreak.â€œWe recently moved the toolbar to the download page so we could have more flexibility in how we describe the toolbarâ€™s torrent-specific features and also shorten and clean up our installer, an ongoing process.â€?But what is clear from the posts on Reddit and elsewhere is that the changes arenâ€™t popular. With that in mind, BitTorrent Inc., which has a record of listening to its users, says it will do some restructuring.â€œWe have read feedback including the Reddit posts, and are planning adjustments to improve the experience,â€? their spokesperson concludes.While we wait for the changes to be confirmed (they will apparently arrive tomorrow), what is interesting to observe is how relatively easily some BitTorrent users, despite getting a free product in return, are upset by tactics they perceive as being less than upfront.The Reddit thread is full of threats to switch to different clients and as always there is a tendency to suggest clients with less intrusive revenue generating mechanisms, fewer adverts, then ultimately ones that offer a plain client with nothing added at all.It seems that having to compete with free is a reality even for BitTorrent clients these days. How times change.We first posted about the situation at our data center 8:57 am on Tuesday. 60 hours later, it has stabilized. What does that mean? Mostly, it means that the methods being used to power our services are unremarkable. Data centers throughout New York City and the surrounding area are using the same types of generators to keep countless hosted services running.It also means that we will spare you the hourly status reports on the nuts and bolts of maintaining power at our data center. Barring a completely new problem, the only further post here will be to let you know that our data center is back on the grid.The total actual downtime during this incident was approximately three hours, from about 10:45am to about 2pm on Tuesday. This was self-imposed, to protect our customers against data corruption. If this has materially impacted your ability to do business, please let us know.As is our policy with any unplanned downtime, we are planning a full postmortem, which will appear on this site. Though you will see no new evidence of it, the entire Fog Creek team continues to work full steam on contingency plans. If something unforeseen happens in the near future, or when the next natural disaster strikes, we will be able to respond quickly and effectively.The Bulgarian blogger and digital rights activist who made headlinesÂ on Tuesday when he reported acquiring more than one million Facebook data entries for just $5, said Friday he is cooperating with Facebook as it conducts an internal investigation, but won't comply with the company's request to remove blog posts or not talk about the investigation.In an interview with ReadWrite, Bogomil Shopov said he had been contacted by Facebook's Platform Policy Team after revealing on his blog that he had acquired the list, which included email addresses of active Facebook users who were primarily located in the U.S., Canada and Europe. Shopov said officials with the company were upset because they feared his public revelation would upend an internal investigation.(Read Shopov's new blog post: Mixed Feelings After Conversation With Facebook.)Â Facebook declined elaborate on the details of its investigation.â€œFacebook is vigilant about protecting our users from those who would try to expose any form of user information. In this case, it appears someone has attempted to scrape information from our site," Facebook spokesman Chris Kraeuter said in an email statement. "We have dedicated security engineers and teams that look into and take aggressive action on reports just like these. We continue to investigate this specific individual.â€?Â In addition to requesting that he keep conversations with Facebook private, the company also requested that Shopov destroy the data after sending a copy to Facebook. Shopov said he complied with the request to destroy the data but was continuing to speak with news outlets to make Facebook users aware of the breach.That didnâ€™t sit well with Facebook, according to Shopov.Â â€œTheir version is [they are conducting] an â€˜internal investigationâ€™ and one of the reasons they are angry about my blog posts is that the seller can â€˜go deepâ€™,â€? Shopov said, explaining Facebook is concerned the seller will disappear before the investigation can figure out how the data was obtained.Shopov provided ReadWrite with a cached link to the site where he purchased the data. The offer was removed within two days after his initial blog postÂ on Tuesday, October 23, but the cached version shows that the seller obtained the data through an unidentified, third-party application. This raises the question of whether there's an international black market where anyone can buy supposedly secret Facebook user data.Â Shopov verified that some of the addresses were legitimate and had planned to notify people on the list that he had purchased the data. Facebook asked him to not notify people included on the list, Shopov said.â€œWe agreed with Facebook not to do that,â€? he said. â€œThat was actually my first reaction, to tell them and to teach them about their rights.â€?Who says that Android tablets arenâ€™t cool? Research firm Strategy Analytics says that shipments of Android tablets surged to a new high in the third quarter of 2012, accounting for 41% of all tablets shipped.Â Neil Mawston, Strategy Analyticsâ€™ executive director, says that thereâ€™s no one Android tablet responsible for the surge, which is more due to a large influx of devices from a wide variety of vendors including â€œASUS (2357), Samsung (005930) and Nook.â€? Shipments of Appleâ€™s (AAPL) iPad lineup, meanwhile, shrank to 57% of the market as â€œdemand for tablets slowed due to ongoing economic uncertainty and consumers holding off purchases in anticipation of multiple new models, like the iPad Mini, during the upcoming Q4 holiday season.â€? Strategy Analyticsâ€™ full press release is posted below.BOSTONâ€“(BUSINESS WIRE)â€“According to the latest research from Strategy Analytics, global tablet shipments reached 25 million units in the third quarter of 2012. Apple iOS slipped to 57 percent global market share, allowing Android to capture a record 41 percent share.Peter King, Director at Strategy Analytics, said, â€œGlobal tablet shipments reached 24.7 million units in Q3 2012, rising a sluggish 43 percent from 17.2 million in Q3 2011. Demand for tablets slowed due to ongoing economic uncertainty and consumers holding off purchases in anticipation of multiple new models, like the iPad Mini, during the upcoming Q4 holiday season. Apple shipped a disappointing 14.0 million iPads worldwide and captured 57 percent share in the third quarter of 2012, dipping from 64 percent a year ago. Appleâ€™s slowdown allowed the Android community to make gains and Androidâ€™s global share of the tablet market now stands at a record 41 percent.â€?Neil Mawston, Executive Director at Strategy Analytics, added, â€œAndroid captured a record 41 percent share of global tablet shipments in Q3 2012, jumping from 29 percent a year earlier. Global Android tablet shipments doubled annually to 10.2 million units. No single Android vendor comes close to Apple in volume terms at the moment, but the collective weight of dozens of hardware partners, such as Asus, Samsung and Nook, is helping Googleâ€™s Android platform to register a growing presence in tablets.â€?Other findings from the research include:* Global tablet shipments grew just 43 percent annually in Q3 2012, compared with 289 percent annually in Q2 2011. This was the weakest growth rate since the modern tablet industry began in Q2 2010;* Microsoft captured a niche 2 percent global tablet share in Q3 2012. The imminent release of the new Windows 8 operating system will likely drive Microsoft tablet volumes higher during the Q4 2012 holiday season.The full report, Global Tablet OS Market Share: Q3 2012, is published by the Strategy Analytics Tablet & Touchscreen (TTS) service, details of which can be found here: http://tinyurl.com/bpqpnbs.Last night, a transformer exploded at a Con Edison plant in lower Manhattan, sparking a flurry of tweets, texts and Facebook posts from residents who witnessed or caught the event on camera. Power failed from 39th Street all the way to the southern tip of Manhattan, and the affected area likely will not regain power for up to a week. So far, authorities donâ€™t know whether the explosion was directly related to the storm since it happened just as Con EdÂ intentionallyÂ cut power to 65,000 customers in an effort to protect equipment, CBS News writes.Although we donâ€™t yet know what happened at this particular plant, we do know several general problems that can cause transformers to explode. Popular Mechanics explains:When flooded with too much electricity, the sudden surge can cause a transformer explosion. As transformers detect an energy spike, theyâ€™re programmed to turn off, but it can take up to 60 milliseconds for the shutdown. However fast those milliseconds may seem, they still may be too slow to stop the electrical overload. A chamber full of several gallons of mineral oil keeps the circuits cool, but given too much electricity, the circuits fry and melt, failing in a shower of sparks and setting the mineral oil aflame. Mineral oil, in turn, combusts explosively and rockets transformer scything into the air. All it takes is a trigger, a corroded or faulty wire, and the circuits surge will get ahead of the breaker.Salt from sea water, for example, can create hazardousÂ conditionsÂ for underground electrical systems since it acts as a corrosive agent. Old transformers can explode when their insulating materials begin to fail, too.We should have a more specific answer about what happened during Hurricane Sandy to trigger the transformer explosion soon, but hopefully the thousands without electricity will have their power restored even sooner.An Unholy Alliance of Unusual Weather and Scarce Coal Nuked Indiaâ€™s Power GridÂ  How Smart Can a City Get?Â Since ACTA was decisively beaten on 4th July 2012, the first time a free trade agreement had been scuppered by the people of EU member nations, the big business lobbyists have taken heed and resolved to change in order to be more successful. Hence the secrecy. CETA and the EU-India trade agreement are the next big battles. We need your help.The term â€œFree Trade Agreementâ€? is a misnomer. The idea is to remove barriers, taxes, and tariffs, but since people can end up being shackled to a multinational corporationâ€™s agenda, the only freedom is in the ability of the corporations to operate in ways that often end up utterly destroying local economies or harnessing law enforcement agencies to protect their interests. The worst part is that we the taxpayers have to foot the bill for our losses of national sovereignty and civil rights. We saw ACTA off in July, but there are two more major agreements to deal with and we need to be ready to contact our M.E.P.s when the time comes.CETA is the Canada-Europe Treaty Agreement. Itâ€™s so bad, Canadian cities and local authorities want to be able to opt out of it. The issues theyâ€™re having centre on the onerous procurement rules that would favor European corporations over local suppliers but there are implications for the internet, too, in the form of the ACTA-style intellectual property chapter, which Dr. Michael Geist published on his blog. Itâ€™s only an old leaked draft, but getting hold of the actual documents has been an exercise in frustration. However, it seems that Bilaterals.org has been able to preserve a copy of the Draft Consolidated Text. Despite the lack of information available, tech blogs such as Techdirt and Computerworld are picking up the story.The European Union has been secretly negotiating a free trade agreement with India since 2007 that is worryingly similar to ACTA. Intellectual property rights enforcement would include border detention and seizure measures of goods being imported by India, exported by India or in transit via Indiaâ€™s ports or airports. This could affect the generic drugs that India produces for its people. Needless to say, intellectual property rights are on the menu, mostly for pharmaceuticals, it has to be said, but since we have no access to the documents involved itâ€™s fair to say itâ€™s likely to include internet provisions, too. David Martin MEP, rapporteur for the European Unionâ€™s International Trade Committee, whose recommendations helped to pull ACTA down in July, is joining unions and international NGOs to oppose the treaty and the secrecy that goes with it. Indian business groups agree, fearing that European imports will jeopardize local production.It is essential that we mobilize opposition to these free trade agreements, not just because they are unjust, but because, if they are ratified, they will bring back the spectre of ACTA, just as E.U. Trade Commissioner Karel De Gucht assured us back in July.Microsoft has just announced that developers at its Build 2012 conference will receive 100GB of SkyDrive storage, and a free 32GB Surface RT. Speaking enthusiastically about the developer opportunity ahead, Microsoft CEO Steve Ballmer guaranteed developers in the crowd that "this will be the best opportunity software developers will see.""Hundreds of millions of people are just aching to use your applications," said Ballmer, before announcing the giveaway for Build attendees. The crowd was understandably excited, and Ballmer promised developers that Microsoft would do more marketing and "better marketing" for Windows 8.Update: Nokia's Richard Kerris joined Microsoft on stage at Build today and also announced a free Lumia 920 for attendees.Last week Glassdoor published its most recent software engineering salary report. Short version: it pays to code. Google and Facebook employees earn a base salary of ~$125K, not counting benefits, 401k matching, stock options/grants, etc., and even Yahoo! developers pull in six figures. Everyone knows why: ask anyone in the Valley, or NYC, or, well, practically anywhere, and theyâ€™ll tell you that good engineers are awfully hard to find. Demand has skyrocketed, supply has stagnated, prices have risen. Basic economics.But why has the supply of good engineers remained so strained? Weâ€™re talking about work that can, in principle, be performed by anyone anywhere with a half-decent computer and a decent Internet connection. Development tools have never been more accessible than in this era of $100 Android phones, free-tier web services, and industry-standard open-source platforms. Distributed companies with employees scattered all around the world are increasingly normal and acceptable. (I work for one. Weâ€™re hiring.) And everyone knows that software experts make big bucks, because software is eating the world. Whatâ€™s more, technology may well be destroying jobs faster than it creates them. Basic economics would seem to dictate that an exponentially larger number of people will flood into the field, bringing salaries back down to earth despite the ever-increasing demand.But reality has stubbornly refused to follow that dictation. Even way back during the first dot-com boom people were already predicting that American and European coders would soon be driven into the poorhouse by a flood of competition from low-cost nations like India and Brazil. But thereâ€™s still no sign of that happening. Why not? And when will it happen, if ever?Well. I have a theory. Iâ€™ve spend the last couple of days chilling out in Chiang Mai, northern Thailand, a city where you could live like royalty and save money while making merely half of Googleâ€™s average developer salary. Which doesnâ€™t tempt me â€“ I prefer Where Things Happen to Away From It All â€“ but has tempted thousands of expats who now live here. And their presence has sparked a possible explanation for this apparent paradox.To be clear, Iâ€™m only talking about very-good-to-excellent developers. Everyone claims to only hire â€œA-listers,â€? and that may even be true of a select few companies, including Facebook and Google. (Though even B-listers and C-listers are in relative demand.) Think of such skilled engineers as emerging from the end of a pipeline which draws from the entire population of the world. Economic incentives act like gravity, pulling almost everyone down that pipe â€“ so what are the stages that filter people out of it nonetheless?First, you have to grow up wealthy enough to have a decent education, some exposure to technology, and the ability to choose between options in your life, which immediately rules out most of the planet. Then you have to have both an interest in and a talent for development, and thereâ€™s evidence that that talent is rare: â€œbetween 30% and 60% of every university computer science departmentâ€™s intake fail the first programming course.â€œ. Then you either have to get a good professional education â€“ eg at a good university like Indiaâ€™s IIT campuses â€“ or supplement a crappy one with home hacking or on-the-job training.(Or maybe, maybe, learn-coding-at-home sites like Codecademy and the likeâ€“but Iâ€™m pretty skeptical about those. Iâ€™ve said before that I think think such services are like learning French from books, and then going to France and finding out that you canâ€™t actually communicate and it would take you years to be become fluent. Programming is like English: itâ€™s fairly easy to learn the rudimentary basics, but very hard to master.)Regardless, all of those filters should be allowing many more people through every year. The world as a whole is much wealthier than it was twelve years ago. (Thatâ€™s when I was last in Thailand. This time around itâ€™s a different and far more prosperous place.) A fixed proportion of people may have the programming gene â€” though Iâ€™ll be watching Estoniaâ€™s experiments with interest â€” but thereâ€™s little doubt that interest has erupted. Top-notch university courses are available online worldwide, and industry-standard development tools are within reach of all.But itâ€™s the very last stage that matters most. Even after youâ€™ve gotten your basic programming education, you still have to put in your thousands of hours to achieve mastery. That doesnâ€™t mean doing the same thing again and again for thousands of hours; it means challenging yourself with new tools, new languages, new objectives. Otherwise you get people writing code of the sort I see all too often these days, when HappyFunCorp (my employer) is brought on to clean up someone elseâ€™s hot mess:My theory that if itâ€™s sheer economics, the lure of a better paycheck, that initially draws you into software engineering, then youâ€™re much less likely to master it. Instead youâ€™ll advance to the point at which youâ€™re reasonably happy with your paycheck, which studies indicate is about $70,000/year in America. (But much less in Chiang Mai or Bangalore.) So my theory is that there are many more software engineers out there â€” but the ones drawn in by economic forces are content to compete with each other for mediocre (but happy-making) jobs, rather than put in the thousands of hours of mentally gruelling work required to become really good at what they do.(Donâ€™t get me wrong: that work is fun, too. But undeniably gruelling.)So why arenâ€™t there more people drawn into the field out of sheer interest? Because when youâ€™re poor, which most of the world is, money is more important than passion. Itâ€™s not until you reach a near First-World level of development that pursuing your passions rather than escaping poverty seems like a reasonable and/or admirable thing to do. So if my theory is correct, the shortage of excellent engineers will eventually alleviate or even end, as the world grows wealthier everywhere â€¦ but not for another decade or more.When you have a question, finding the answer should be effortlessâ€”wherever you are and whatever device youâ€™re using. The new Google Search app for iPhone and iPad helps you to do just that with enhanced voice search that answers any question with the comprehensive Google search results you know and love.Fast and accurate voice recognition technology enables Google to understand exactly what youâ€™re saying. Getting an answer is as simple as tapping on the microphone icon and asking a question like, â€œIs United Airlines flight 318 on time?â€? Your words appear as you speak, you get your answer immediately andâ€”if itâ€™s short and quick, like the status and departure time of your flightâ€”Google tells you the answer aloud.You can get answers to an increasingly wide variety of questions thanks to Knowledge Graph, which gives our search technology an understanding of people, places and things in the real world. Here are a few of the questions that Google can answer:â€œWhat does Yankee Stadium look like?â€? Google will show you hundreds of pictures instantly.â€œPlay me a trailer of the upcoming James Bond movie.â€? The trailer starts playing immediately right within Google Search. â€œWhen does daylight savings time end?â€? The answer will appear above the search results, so you can set your clock without having to click on a link.  â€œWhoâ€™s in the cast of The Office?â€? See a complete cast list and find out who made you crack up last night. Hue is a series of light-emitting-diode bulbs controlled from a handheld Apple device through a household Wi-Fi network. At the Apple end, users can control the lights using a free app on their iPhone, iPod or iPad.The bulbs offer a variable white light, mimic incandescent lights and will produce more than 16 million colours. While LED lighting has been praised for its extreme power-saving attributes, the harsh whiteness of the light has taken longer for technology to control."I was able to change the colours of the light bulbs in different rooms, adjust the brightness level or turn the lights off and on with one touch from my iPad," wrote Mashable reviewer Andrea Smith, who tested the system for several days.As well, the system can memorize lighting combinations for people to reuse in the future and can operate on a timed on-off basis. Lighting combinations and programs can be shared through social media."I pressed a button on the bridge which immediately identifies all three lights," Smith wrote."Using the app on my iPad, I was able to rename the lights, calling them living room, family room and office. I had fun sliding the bar from left to right, which changes the intensity of the bulb's colour; it was like having a dimmer switch built into my mobile device."The system offers flexibility and control that was once limited to lighting systems worth thousands of dollars in commercial applications.For all that, however, it isn't cheap. The introductory kit â€” three bulbs and a ZigBee bridge that attaches to a Wi-Fi router â€” costs $199 in Canada. Additional bulbs cost $59 each. As many as 50 bulbs can be operated on one system.In terms of power, the bulbs are rated at up to 8.5 watts, and each produces light of 600 lumens â€” roughly equivalent to a 50-watt incandescent bulb.Dear Lord: Please make my words sweet and tender, for tomorrow I may have to eat them.Connection woes hit popular services across the Internet. So far, though, it's unclear if they are related.A mysterious rash of outages struck the Internet today, crippling major services for hours at a time. It isn't clear whether they're related.Google Apps Engine. Google said that at about 7:30 a.m., an unnamed component of App Engine "began experiencing slow performance and dropped connections." Users began seeing slow response times and had trouble connecting to services. At the moment, most App Engine users and services are being affected. "Google engineering teams are investigating a number of options for restoring service as quickly as possible, and we will provide another update as information changes, or within 60 minutes," Google's Max Ross said.Tumblr. Around the same time Google Apps Engine began having problems, Tumblr tweeted it was having problems of its own.Dropbox. The Next Web and other sites also reported having issues with Dropbox, though the service was working fine when we checked.Meanwhile, there's evidence that the outages have affected the wider Web. The Internet Traffic Report showed a sharp decline in traffic today:It also showed an increase in packet loss, which is a measurement of a connection's reliability.Update, 1:10 p.m. Tumblr and Google App Engine have been restored.Napier & Son was the most successful British manufacturer of aircraft engines in the 1920s and 30s with their 12-cylinder Napier Lion powering 163 different types of aircraft between 1918 and 1935. Over that 17 year period the Lion grew from 450 to 1350 horsepower and was, for awhile, the most powerful aircraft, boat, and car engine in the world, holding world speed records in all three venues at the same time. And then the Napier Lion was suddenly gone â€” a lesson from which Microsoftâ€™s Steve Ballmer could benefit if he and his company donâ€™t repeat it.Napier perfected their Lion engine over those 17 years, improving it in every way until it was the best and most efficient engine of its class in the world. Then, seemingly overnight, the class changed as air forces and record setters alike suddenly needed more than the 1,350 horsepower a finely-tuned Lion could deliver. Napierâ€™s Lion gave way to Rolls-Royceâ€™s larger and innately more powerful Merlin and Griffon engines and Napier, for all intents and purposes, was gone.Napier milked its technical and market advantages for a little too long.What does this have to do with Steve Ballmer and Microsoft? They are Napier, circa 1935 and their Lion is called Windows.Windows 8 shipped last week to mixed reviews. Ballmer himself called it â€œa bold re-imaginingâ€? of Windows. Itâ€™s bold alright, but not bold enough. Windows is doomed.We can argue all day about whether Windows 8 is better or worse than Windows 7 or even Windows 9, but the real issue here isnâ€™t the software at all but the platform, by which I mean the desktop PC. Companies, governments, families, schools, and individuals are all buying fewer desktop PCs than they used to. Desktop growth has reversed and international desktop expansion is slowing as even that market matures. This year will probably mark Microsoftâ€™s highest desktop sales ever in dollar volume, which sounds good, except that next year sales will be less as they will again the year after and every year past that.Six years from now (four hardware generations) Windows will be dead. Or free.And for all his bold re-imagining in New York last week, Steve Ballmer knows this, and thatâ€™s his dilemma.Desktops are fading now, notebooks will be fading soon, both to be replaced by tablets and smart phones where Microsoft not only doesnâ€™t dominate, they arenâ€™t even among the major players.Death of the desktop is clear not because Windows desktop sales are declining but because Macintosh desktop sales are declining. When Mercedes (Apple) begins to suffer declining unit sales, what does it mean for GM (Microsoft)? Not good.The only option is to invent the future, which Ballmer and Microsoft are attempting to do by entering the tablet hardware business (again emulating Apple) and cutting bold smart phone deals with outfits like Nokia. But Microsoft, for all its posturing and $1 billion marketing budgets, isnâ€™t any good at inventing the future and knows it. Ballmer lacks confidence that Redmond can invent itâ€™s way out of the current hole. And because he lacks confidence, as does nearly everyone else at Microsoft, of course it wonâ€™t happen.Microsoft didnâ€™t invent the PC but benefited from its invention. Microsoft didnâ€™t invent BASIC, they didnâ€™t invent the PC operating system, they didnâ€™t invent word processor, spreadsheet, or presentation applications, they didnâ€™t invent PC games, they didnâ€™t invent the graphical user interface, they didnâ€™t invent the notebook or the tablet, they didnâ€™t invent the Internet, they didnâ€™t invent the music player or the video game, but they benefited from all these things.Like Blanche DuBois, Microsoft has relied on the kindness of strangers.Microsoft may have invented the smart phone. More on that below.Having not invented any of the products it is known for, why should we expect Microsoft to invent its way out of declining markets? We shouldnâ€™t.Even video games are in decline and we now see Microsoft trying to turn its 30 million-strong xBox installed base into something like a cable TV network in order to milk that franchise beyond what would otherwise be its death.Ballmer knows all this. And like Napier, he can keep building his old product line with a twist or two until the market drops out from under him or he can do some real re-imagining and turn Microsoft into a completely different company.I donâ€™t think he will do it, though, because I donâ€™t think he can do it. Even if Steve Ballmer could envision a better future for Microsoft built on true technical leadership, I donâ€™t think he or his company could follow-through. They are just making too much money doing the old stuff to truly embrace anything new.Until itâ€™s too late.This does not mean Microsoft is going away. Their smart phone patents score them $15 for every new Android license of which there are 1.3 million every day. Thatâ€™s $20 million per day ($7.3 billionÂ per year) to Microsoft for doing, well, nothing.What Steve Ballmer and Microsoft need to do is clean up their act, quietly trim expenses, maybe even sell a few product lines, and start to seriously stash away cash toward the post-Windows, post-Office world of 2018.Yes, post-Office. What else can be meant by bundling Office with Windows RT than its value is headed to zero?If Microsoft can continue to pretend it is big while actually becoming small, they might end up in 2018 with a small residual product line sitting atop $100 billion in cash. Then Ballmer can hand that money to Warren Buffett or to Buffettâ€™s successor and let them manage Microsoft as a mutual fund rather than a technology company.This is the only future I see for Microsoft because I think Steve Ballmer is a rational man, he understands this, and he sees himself as the only plausible steward for such a sneaky transition. Otherwise, simply as a huge Microsoft shareholder he would have long ago fired himself.I think this is exactly what has been happening at Microsoft for at least the last 2-3 years, ever since the plan to buy Yahoo cratered.Ballmer isnâ€™t stupid and he isnâ€™t deluded, heâ€™s a man with a plan â€” a plan weâ€™re just not supposed to know about yet.Nothing else makes sense to me.This entry was posted on Sunday, October 28th, 2012 at 12:15 am and is filed under 2012, Business, Companies, Computing, Internet, Predictions, Software, Tablets, Technology. You can follow any responses to this entry through the RSS 2.0 feed. You can leave a response, or trackback from your own site.Sitting U.S. President Ford was visiting San Francisco in 1975 when a woman attempted to shoot him. A former marine named Oliver Sipple grabbed the gun, preventing the assassination attempt. When the press began contacting him, he asked that his sexuality not be discussed. While Sipple was very active in the gay menâ€™s scene in the Castro, he was not out to family or work. But Harvey Milk, a famous gay rights activist, chose to out him so the public could see that gay men could be heroes, too.The cost to Sipple was devastating. The White House distanced itself from him, his family rejected him, and he sunk into a dark depression. He gained massive amounts of weight, began drinking profusely, and died at the ripe young age of 47. Many around Sipple reported that he regretted his act of heroism and the attention resulting from it. But for Harvey Milk, the potential social good from using Sippleâ€™s story far outweighed what he perceived as the costs of outing him.This is a hard moral conundrum, in part because Sipple was clearly a â€œgoodâ€? guy who had done a good deed. But what if he wasnâ€™t? What are the moral and ethical costs of outing people and focusing unwanted attention on them?Two weeks ago, Gawker journalist Adrian Chen decided to unmask the infamous Reddit troll â€œViolentacrezâ€? as Michael Brutsch. When Chen contacted him, Brutsch did not attempt to deny the things he had done. He simply begged Chen not to publish his name, citing the costs that publicity would have on his disabled wife. Chen chose to publish the piece â€“ including Brutschâ€™s pleas and promises to do anything that Chen asked in return for not ruining his life. As expected, Brutsch lost his job and the health insurance that paid for his wifeâ€™s care; Chen reported this outcome three days later. Many celebrated this public shaming, ecstatic to see a notorious troll grovel.Although none of his actions appeared to be illegal, itâ€™s hard to call Brutsch a â€œgoodâ€? guy. He had created settings where people could share deeply disturbing content. He enticed people to reveal their ugliest sides. In many ways, Brutsch was a classic troll, abusing technology and manipulating the boundaries of free speech to provoke systematic prejudices and harassment for his own entertainment. He got joy from making others miserable.There are many different reasons to unmask people, out them, or make them much more visible than they previously were. Sometimes, the goal is to celebrate someoneâ€™s goodness. At other times, people are made visible to use them as an example â€¦ or to set an example. People are outed to reveal hypocrisy and their practices are made visible to shame them.In identifying Butsch and shining a spotlight on his insidious practices, Chenâ€™s article condemns Butschâ€™s choice of using the mask of pseudonymity to hide behind actions that have societal consequences. Public shaming is one way in which social norms are regulated. Another is censorship, as evidenced by the Reddit communityâ€™s response to Gawker.Yet, how do we as a society weigh the moral costs of shining a spotlight on someone, however â€œbadâ€? their actions are? What happens when, as a result of social media, vigilantism takes on a new form?Â How do we guarantee justice and punishment that fits the crime when we can use visibility as a tool for massive public shaming? Is it always a good idea to regulate what different arbiters consider bad behavior through increasing someoneâ€™s notoriety â€“ or censoring their links?As the Gawker/Reddit story was unfolding, another seemingly disconnected case was playing out. In a town outside of Vancouver, a young woman named Amanda Todd committed suicide a few weeks after posting a harrowing YouTube video describing an anonymous stalker she felt ruined her life. The amorphous hacktivist collective known as â€œAnonymousâ€? decided to make a spectacle of the situation by publishing personally identifiable information on â€“ â€œdoxxingâ€? â€“Â Toddâ€™s stalker. They identified a 32-year-old man, enabling outraged people to harass him. Yet it appears they got the wrong person. Earlier this week, Canadian police reported that Toddâ€™s stalker was someone else: reportedly a 19-year-old.Needless to say, this shift in information doesnâ€™t relieve the original target of the public shame he felt from Anonymousâ€™ pointed finger. It doesnâ€™t wipe his digital record clean. He has to deal with being outed â€“ in this case, wrongly â€“ going forward.By enabling the rapid flow of information, technology offers us a unique tool to publicly out people or collectively tar and feather them. Well-meaning people may hope to spread their messages far and wide using Twitter or Facebook, but the fast-spreading messages tend to be sexual, horrific, or humiliating.Gossip is social currency. And in a networked world, trafficking in gossip is far easier than ever before.When someoneâ€™s been wronged â€“ or the opportunity arises to use someone to make a statement â€“ it is relatively easy to leverage social media to incite the hive mind to draw attention to an individual.Â The same tactic that trolls use to target people is the same tactic that people use to out trolls.More often than not, those who use these tools do so when they feel theyâ€™re on the right side of justice. Theyâ€™re either shining a spotlight to make a point or to shame someone into what they perceive to be socially acceptable behavior. But each act of outing has consequences for the people being outed, even if we do not like them or what theyâ€™ve done.This raises serious moral and ethical concerns:Â In a networked society, who among us gets to decide where the moral boundaries lie?This isnâ€™t an easy question and itâ€™s at the root of how we, as a society, conceptualize justice.Governance and the construction of a society is not a fact of life; itâ€™s a public project that we must continuously make and remake. Networked technologies are going to increasingly put pressure on our regulatory structures as conflicting social values crash into one another. In order to benefit from innovation, we must also suffer the destabilizing aspects of new technology.Yet â€¦ that destabilization and suffering allow us, as a society, to interrogate our collective commitments. The hard moral conundrums are just beginning.After falling behind Asia and Europe in the great race, where success is measured in FLOPS (floating-point operations per second), the US has struck back at the new high-tech Olympians with Titan: quite possibly the fastest supercomputer in the world.When Tennesseans hear the word Titan, their first thought is going to be gains on the gridiron, rather than leaps and bounds on the field of science.All of that might now change, as a new supercomputing giant hailing from the Smokey Mountains was unveiled by the US Department of Energyâ€™s (DOE) on Monday.More than 10 times faster and five times more energy efficient than its predecessor Jaguar, Titan is the brainchild of the DOEâ€™s Oak Ridge National Laboratory (ORNL), nestled in the Tennessee highlands.Titanâ€™s theoretical peak is 20 petaflops â€“ 20 quadrillion calculations per second â€“ with 299,008 CPUs (central processing units) and 18,688 graphics processing units (GPUs) spinning at breakneck speeds to make to make scientific breakthroughs in record times.Titan's blistering computation speed will be the equivalent of â€œthe worldâ€™s 7 billion people being able to carry out 3 million calculations per second,â€? ORNL says.Titanâ€™s precursor Jaguar â€“ which was developed by the Seattle-based Cray Inc. â€“ was the fastest supercomputer in the world in June 2010, though it was later outclassed by the Chinese Tianhe-1A several months later.The fastest computer to date is currently the California-based IBM Sequoia, which whirred to the 16.32 petaflops mark in June. Titan also boosts more than 700 terabytes of memory, and will be manage higher energy efficiency than Jaguar by innovatively combining CPUs and the more recent GPUs to synergistic effect.Power limits have long served to trammel those looking to break world records in the great computational race. Jaguarâ€™s 2.3 petaflops needed 7 megawatts of energy â€“ enough to power a small town.At $7 million dollars a year, Jaguarâ€™s electric bill was nothing to scoff at. Titan â€“ essentially an upgraded version of Jaguar housed in the same 200 cabinets arranged very much like a locker room â€“ will hit nearly 10 times the speed while consuming roughly nine megawatts. That makes Titan approximately five times more energy efficient than its previous incarnation.The race to outclass the Chinese and other international competitors has driven Titanâ€™s development forward, though as an open-science system, its benefits will be global."American competitiveness is very important from a global security and national security perspective," Jeffrey Nichols, associate laboratory director for the computing and computational sciences directorate at ORNL, told PCWorld in an interview."It's absolutely important that we are competitive in this high-tech field so the science solutions we are solving are competitive and put us on the leading edge of where we need to be in solving these problems,"he continued.With Titan poised to help the US conduct research in areas like biosciences, climate change, nuclear energy and space, Nichols believes Oak Ridge has â€œdevelopers that can use these machines at scale,â€? while Chinaâ€™s economic development model precludes it from reaching its research potential.But researchers, academics, government labs and a large swath of industries seeking to expedite the scientific method via Titan's ability to use a powerful computational model of varied natural systems are welcome to give it a spin.ORNL has opened its doors to all comers, and 40 projects a year will continue to be given access to the labâ€™s massive computational facilities based on their scientific merits. With Titan, that will mean hundreds of millions CPU hours per project at their disposal.With the never-ending pace of technological development, Titan will inevitably be overthrown by a race of younger computing gods. The Department of Energy already plans on making Titanâ€™s successor operate at 10 times its speed by 2016, meaning Americaâ€™s drive to maintain this golden age of supercomputing excellence might be far from seeing its last day.With its cryptic â€œthe playground is openâ€? tagline, the impending Google Android event has many pundits speculating on what will be introduced. So, we thought weâ€™d once again ask the real experts â€“ consumers â€“ for their take on the Android platform on the eve of what may be the next big thing â€“ or big bust. After all, the nearly 9,000 consumers BIGinsight talks to each month correctly gauged the room temperature reception of Septemberâ€™s iPhone 5 announcement from Apple.As it turns out, a look at the latest results from our â€œHot or Notâ€? feature reveals that the Google Android OS may be becoming quite the pressure cooker for Appleâ€™s iOS. While the majority of adults deemed both the Google Android platform and Apple iOS as pretty popular in October, Android maintained a slight lead on the pairing with 53.0% voting it â€œhotâ€? to Appleâ€™s 51.4%.These insights become really interesting, though, when divvied up by generation. While more than three out of five of the must-have Millennial demographic concurred that both platforms were â€œhot,â€? it was Android again (with 64.0%) that held the edge over Apple (61.9%). The operating system disparity was greatest among Gen X-ers, who were 10% more likely to side with Android (58.6%) versus Apple (53.4%). Boomers were on the fence for this debate, while Apple finally found some support among the Silent generation. Nearly half (46.8%) of those born before 1946 judged Apple to be â€œhot,â€? four points higher than those who felt the same way about Android (41.4%).Bottom Line: While both platforms are undoubtedly popular, it seems that the children of our future â€“ Millenials and Gen X-ers â€“ are positioning Google Android as the mobile future, at least for the time being. As I recall, playground popularity contests could be pretty competitive.Pam Goodfellow (@BIGinsight_Pam) is Consumer Insights Director forBIGinsight. For additional insights, check out this monthâ€™sConsumer Snapshotand theBIG Consumer Blog. And, access complimentary, on-demand insights through one or more of ourInsightCentersâ„¢.The U.S. Department of Energyâ€™s (DOE) Oak Ridge National Laboratory (ORNL)unveiled their new flagship computer, Titan, on Monday. The Department also announced its latest round of Innovative and Novel Computational Impact on Theory and Experiment (INCITE) award recipients.Titan, according to Oak Ridgeâ€™s announcement, is 10 times more powerful than its predecessor, Jaguar, with a theoretical peak performance of 20 petaflops, or 20,000 trillion calculations per second. The current fastest computer, according to the Top 500 list, is Sequoia, which clocked in at 16.32 petaflops in June.The first phase of Titanâ€™s installation was completed earlier this year, and final updates were completed this fall. Titan consumes slightly more energy than Jaguar, but when its significantly faster processing speed is taken into account, it is five times more energy efficient, according to the national laboratoryâ€™s team. The combination of faster speed and only slightly more energy consumption is critical, since the roughly seven megawatts Jaguar consumed â€” enough to power roughly 7,000 homes â€” cost millions. Titan is estimated to consume roughly nine megawatts.â€œThis power problem is changing everything,â€? said Steve Scott, chief technology officer of NVIDIAâ€™s Tesla business unit. â€œThe fact that the energy isnâ€™t dropping as fast as the transistor budget is increasing is just making us more and more power-constrained. And thatâ€™s really whatâ€™s driving us to reinvent how we make processors.â€?In addition to being faster and more efficient, Titan is the same size as its predecessor. Titan, like Jaguar, occupies a space roughly the size of a basketball court, with each stack approximately the size of a household kitchen refrigerator. Thatâ€™s due to the nature of the upgrade, which primarily involved the incorporation of graphic processing unit (GPU) accelerators. GPUs are primarily used for computer games, but can be used to accelerate central processing units, or CPUs.Titan is a Cray-XK7 system and is the first machine to use NVIDIAâ€™s latest GPU accelerator, the Tesla K20, with each of Titanâ€™s 18,688 nodes holding one CPU and GPU accelerator, according to Oak Ridge and NVIDIA. The GPU used in Titan is no different, said Scott, than the one made for high-end gaming units.â€œThe technology for gaming is the disruptive technology thatâ€™s now impacting computing broadly,â€? said Jeff Nichols, associate director of Oak Ridge National Laboratory.Pairing GPUs and CPUs in and of itself is not novel, but â€œthere were a lot of skepticsâ€? at Oak Ridge, said Scott. It had never been done on this scale before, and Titan had to be more than, in Scottâ€™s words, a â€œstunt.â€? The machine had to be able to run six predetermined applications to Oak Ridgeâ€™s specifications. The programs are in the areas of material science, climate change, biofuels, astrophysics, combustion and nuclear energy.Discovers using Titan could have an impact by leading to cleaner, more efficient engines, faster and cheaper drug testing, climate modeling and even the development of future high-performance computers.â€œThis opens up new vistas of calculations we couldnâ€™t conceive of doing before,â€? said Jeremy Smith, Governorâ€™s Chair at the University of Tennessee and also director of the Center for Molecular Biophysics at Oak Ridge National Laboratory. Smith is likely to be one of the most frequent users of Titan, as he was with Jaguar. But Smith emphasized that Titan is merely one step in high-performance computer evolution. Smith is among many who await the arrival of exascale computing, which, in theory, would allow for, among other things, the simulation of a living cell in atomic detail.â€œItâ€™s really what comes afterwards that will provide the bulk of the discoveries,â€? said Smith. â€œWhat Titan will have done is to set the standard in computer power, identify the challenges in using such a machine, and it will make a couple of useful discoveries that couldnâ€™t be made on any other machine.â€?Smith will not be alone in leveraging Titanâ€™s processing power. Recipients of the 2013 INCITE awards will also have access to Titan. The Department of Energyâ€™s Leadership Computing Facilities (LCFs) awarded a total of 4.7 billion hours to 61 projects in science and engineering â€” 1.84 billion hours on Titan and 2.83 billion hours on two of Argonne National Laboratoryâ€™s supercomputers, Mira and Intrepid. Projects ranged from research around nuclear reactors and electric engines to the development of a unified theory for physical forces.Titanâ€™s public unveiling comes weeks before the release of the latest Top500 supercomputer rankings. The Top500 list, which dates back to 1993, is released twice a year â€” once in June and again in November. The Titan team anticipates their machine will be ranked in the top two, which would make it the fastest high-performance computer open to non-classified projects. Thatâ€™s assuming Sequoia comes in first or second. Sequoia is housed at Lawrence Livermore National Laboratory (LLNL) and is used exclusively by the National Nuclear Security Administration (NNSA) to manage the United Statesâ€™ nuclear weapons stockpile. Jaguar ranked sixth in the latest list.When asked what he would use Titan for, Nichols said he thought there was â€œfascinatingâ€? research to be done in chemical physics, specifically simulating the breaking of chemical bonds. But given his focus in materials science, he said he would most likely use Titan to figure out how to design better photovoltaics.NVIDIAâ€™s Scott, on the other hand, said he would use the supercomputer to help him find Titanâ€™s successor. But a few moments later, added, â€œYou could also maybe use the machine for a really giant multi-user game.â€?Read more news and ideas on Innovations:New database grades lawmakers on their tech-friendlinessâ€˜Iron Manâ€™-style exoskeleton could help in space and here on EarthThe network made it official today that production on the long-running shows is shutting down at the end of the year. Attack Of The Show and X-Play helped define G4â€˜s gamer-culture focus and launched careers for the likes of Olivia Munn and Chris Hardwick, amassing close to 3000 episodes to date. They also provided wall-to-wall coverage of Comic-Con and E3 â€” two events right in the networkâ€™s young-male demo wheelhouse. X-Play launched in 2003 on what was then known as TechTV; Attack followed in 2005. Hereâ€™s the networkâ€™s release about farewell plans for the shows, which will air original episodes through 2012:Los Angeles, CA, October 26, 2012 â€“ Attack of the Show! and X-Play are the longest-running and defining series for G4 through its first decade. With the shows ending production at the end of 2012, G4 is getting set to showcase the landmark series as they wind down their long runs on the network.With upwards of 1,700 and 1,300 episodes, respectively, Attack of the Show! and X-Play defined the gamer culture for a generation of young men, and served as the launch pad for prominent personalities including Kevin Pereira, Olivia Munn, Chris Hardwick and Adam Sessler. Guests James Cameron, Ryan Reynolds, Jimmy Fallon, William Shatner, Sasha Baron Cohen and Joseph Gordon-Levitt are among the notables who got their geek on. The shows also pioneered live-from-the-floor coverage of the two most important conventions in the game culture universe: San Diego Comic-Con and E3.Leading up to their final episodes, Attack of the Show! and X-Play will look back at their most memorable moments, important scoops, entertaining programming and appealing hosts. A rotating lineup of guest co-hosts like John Barrowman, Michael Ian Black, Josh Myers, Paul Scheer, Rob Huebel and Horatio Sanz will join AOTS hosts Candace Bailey and Sara Underwood, and X-Play hosts Morgan Webb and Blair Herter as part of the farewell shows.â€œAttack of the Show! and X-Play have been important for G4, and we want to acknowledge the creative people who have helped inspire and showcase the phenomenon of gamer culture,â€? G4 Media General Manager Adam Stotsky said. â€œWith more than 3,000 episodes aired between them, we have more than enough great material to honor these innovators and their amazing contributions as we bring both shows to a close.â€?Attack of the Show! debuted March 28, 2005 and from the start was the ultimate male guide to everything cool and new in the world of technology, web culture, gaming and pop culture. For the next few months, AOTS will mix new segments with audience favorites, such as the iPhone extravaganza on June 29, 2007, on the eve of the debut of the first generation of Appleâ€™s market-changing smartphone. The July 2006 premiere of the first live-from-the-floor coverage from San Diego Comic-Con will be celebrated as well. Old friends will return to join the celebration, and the showâ€™s signature cheeky attitude and feel-for-the zeitgeist will be very much in evidence.X-Play made its debut almost two years earlier, on April 28, 2003 (on G4â€™s previous incarnation: TechTV), and immediately became the go-to destination for young men seeking the latest video game news, honest reviews, hands-on demos and exclusive video game trailers and footage. The year-end celebration will take viewers back through highlights of this landmark showâ€™s history, including its exclusive live-from-the-floor coverage of the E3 convention in Los Angeles, the most important annual gathering for the gaming community. X-Play has also established a franchise of doing an annual year-end round-up of the best in a wide range of video games, and you can be sure those will be revisited before the show signs-off for good. As with AOTS, expect old friends to return too.Attack of the Show! and X-Play will air original episodes through the end of the year.A core goal for Ubuntu 13.04 is to get Ubuntu running on a Nexus 7 tablet. To be clear, this is not going to be a tablet Unity interface running on the 8/16GB Nexus 7, but instead will focus on getting the current Ubuntu Desktop running on the Nexus so that we can ensure pieces such as the kernel, power management and other related areas are working effectively on a tablet device.Topics such as battery life, memory footprint, and support for sensors are all areas in which needs and expectations vary widely between a PC and a mobile devices. The 13.04 cycle will very much be focused on this exploration and learning and this is why we want to focus our efforts on getting the existing Ubuntu Desktop running on the Nexus 7. This will mean that some user-facing parts of the experience wonâ€™t make a lot of sense on the tablet, but we want to get the foundations optimized before we focus on these higher level challenges.Naturally we want our community to be involved throughout this exploration and I want to talk more about how you can get involved both as a tester and as a developer.To help with testing you will need an 8/16GB Nexus 7 tablet and be willing to replace the Android Operating System with Ubuntu (as such, please be sure to back up any valuable data on your tablet).You can follow instructions of how to install Ubuntu on your device by reading the instructions at https://wiki.ubuntu.com/Nexus7.If you have any questions about the installation and setup, please post on Ask Ubuntu; we will use the mobile tag to track these questions. The Mobile development team will be regularly monitoring the questions, and we would like you folks to help answer the list of questions too if you have the answers.When you find bugs, please use to file the bug (more details about using can be found here). Please also tag the bug with so we can find them more easily.You can also get in touch with our wider testing community in #ubuntu-testing on the Freenode IRC network.If you are interested in contributing to making Ubuntu work flawlessly and optimizing the Ubuntu Desktop core for the Nexus 7, we would love to have you participate in this work.You can find details of many of the areas that we would like to focus on over at Victorâ€™s blog; this provides some great food for thought for performance and functionality goals.Much of this work will be discussed at the upcoming Ubuntu Developer Summit taking place in Copenhagen from 29th Oct â€“ 1st Nov 2012.If you are unable to participate in person you can join the sessions remotely. For instructions of how to participate remote, see this page for instructions. You are also encouraged to join #ubuntu-arm on Freenode to discuss this work.The following sessions are scheduled. Please note times may change, so be sure to click the link below to ensure the date/time is up to date. You can also find the appropriate blueprints linked from the links below too:Made in IBM Labs: Researchers Demonstrate Initial Steps toward Commercial Fabrication of Carbon Nanotubes as a Successor to Silicon ï‚· For the first time, scientists precisely place and test more than ten thousand carbon nanotube devices in a single chip using mainstream manufacturing processes ï‚· Novel processing method helps pave the way for carbon technology as a viable alternative to silicon in future computingYORKTOWN HEIGHTS, NY â€“ 28 Oct 2012: IBM (NYSE: IBM) scientists have demonstrated a new approach to carbon nanotechnology that opens up the path for commercial fabrication of dramatically smaller, faster and more powerful computer chips. For the first time, more than ten thousand working transistors made of nano-sized tubes of carbon have been precisely placed and tested in a single chip using standard semiconductor processes. These carbon devices are poised to replace and outperform silicon technology allowing further miniaturization of computing components and leading the way for future microelectronics.Aided by rapid innovation over four decades, silicon microprocessor technology has continually shrunk in size and improved in performance, thereby driving the information technology revolution. Silicon transistors, tiny switches that carry information on a chip, have been made smaller year after year, but they are approaching a point of physical limitation. Their increasingly small dimensions, now reaching the nanoscale, will prohibit any gains in performance due to the nature of silicon and the laws of physics. Within a few more generations, classical scaling and shrinkage will no longer yield the sizable benefits of lower power, lower cost and higher speed processors that the industry has become accustomed to.Carbon nanotubes represent a new class of semiconductor materials whose electrical properties are more attractive than silicon, particularly for building nanoscale transistor devices that are a few tens of atoms across. Electrons in carbon transistors can move easier than in silicon-based devices allowing for quicker transport of data. The nanotubes are also ideally shaped for transistors at the atomic scale, an advantage over silicon. These qualities are among the reasons to replace the traditional silicon transistor with carbon â€“ and coupled with new chip design architectures â€“ will allow computing innovation on a miniature scale for the future.The approach developed at IBM labs paves the way for circuit fabrication with large numbers of carbon nanotube transistors at predetermined substrate positions. The ability to isolate semiconducting nanotubes and place a high density of carbon devices on a wafer is crucial to assess their suitability for a technology â€“ eventually more than one billion transistors will be needed for future integration into commercial chips. Until now, scientists have been able to place at most a few hundred carbon nanotube devices at a time, not nearly enough to address key issues for commercial applications."Carbon nanotubes, borne out of chemistry, have largely been laboratory curiosities as far as microelectronic applications are concerned. We are attempting the first steps towards a technology by fabricating carbon nanotube transistors within a conventional wafer fabrication infrastructure," said Supratik Guha, Director of Physical Sciences at IBM Research. "The motivation to work on carbon nanotube transistors is that at extremely small nanoscale dimensions, they outperform transistors made from any other material. However, there are challenges to address such as ultra high purity of the carbon nanotubes and deliberate placement at the nanoscale. We have been making significant strides in both."Originally studied for the physics that arises from their atomic dimensions and shapes, carbon nanotubes are being explored by scientists worldwide in applications that span integrated circuits, energy storage and conversion, biomedical sensing and DNA sequencing.This achievement was published today in the peer-reviewed journal Nature Nanotechnology.Carbon, a readily available basic element from which crystals as hard as diamonds and as soft as the "lead" in a pencil are made, has wide-ranging IT applications.Carbon nanotubes are single atomic sheets of carbon rolled up into a tube. The carbon nanotube forms the core of a transistor device that will work in a fashion similar to the current silicon transistor, but will be better performing. They could be used to replace the transistors in chips that power our data-crunching servers, high performing computers and ultra fast smart phones.Earlier this year, IBM researchers demonstrated carbon nanotube transistors can operate as excellent switches at molecular dimensions of less than ten nanometers â€“ the equivalent to 10,000 times thinner than a strand of human hair and less than half the size of the leading silicon technology. Comprehensive modeling of the electronic circuits suggests that about a five to ten times improvement in performance compared to silicon circuits is possible.There are practical challenges for carbon nanotubes to become a commercial technology notably, as mentioned earlier, due to the purity and placement of the devices. Carbon nanotubes naturally come as a mix of metallic and semiconducting species and need to be placed perfectly on the wafer surface to make electronic circuits. For device operation, only the semiconducting kind of tubes is useful which requires essentially complete removal of the metallic ones to prevent errors in circuits. Also, for large scale integration to happen, it is critical to be able to control the alignment and the location of carbon nanotube devices on a substrate.To overcome these barriers, IBM researchers developed a novel method based on ion-exchange chemistry that allows precise and controlled placement of aligned carbon nanotubes on a substrate at a high density â€“ two orders of magnitude greater than previous experiments, enabling the controlled placement of individual nanotubes with a density of about a billion per square centimeter.The process starts with carbon nanotubes mixed with a surfactant, a kind of soap that makes them soluble in water. A substrate is comprised of two oxides with trenches made of chemically-modified hafnium oxide (HfO2) and the rest of silicon oxide (SiO2). The substrate gets immersed in the carbon nanotube solution and the carbon nanotubes attach via a chemical bond to the HfO2 regions while the rest of the surface remains clean.By combining chemistry, processing and engineering expertise, IBM researchers are able to fabricate more than ten thousand transistors on a single chip. Furthermore, rapid testing of thousands of devices is possible using high volume characterization tools due to compatibility to standard commercial processes.As this new placement technique can be readily implemented, involving common chemicals and existing semiconductor fabrication, it will allow the industry to work with carbon nanotubes at a greater scale and deliver further innovation for carbon electronics.A memory leak and a failed monitoring system caused theÂ Amazon Web Services outage on Monday that took out Reddit and other major services.According to a postFriday night, AWS explained that the problem arose after a simple replacement of a data collection server. After installation, the server did not propagate its DNS address correctly and so a fraction of servers did not get the message. Those servers kept trying to reach the server, which led to a memory leak that then went out of control due to the failure of an internal monitoring alarm. Eventually the system groundÂ to a virtual stop and millions of customers felt the pain.The failure in its North Virginia region eventually interrupted Reddit, Foursquare, Minecraft, Heroku, GitHub, imgur, Pocket, HipChat, Coursera and a number of others.In the past, Amazonâ€™s Elastic Block Storage (EBS) servers have proved troublesome. This outage proved not much different. The EBS servers, feeling the memory leak, began losing the ability to process customer requests, causingÂ the number of stuck volumes to increase quickly. The server degradation came all at once, causing a tax on the system as not enough healthy servers could be found to replace them all.The outage started at 10 a.m. PST. Five hours later, AWS discovered the root of the problem. An hour later things got back to normal.AWS says it is taking a number of steps to prevent similar issues going forward. The group plans to deploy monitoring that will sound the alarm if this specific memory leak problem arises again in any of its production EBS servers. Next week it will begin deploying a fix for the memory leak issue.AWS has had its share of outages over the past several months. Its problems are magnified by an increasingly competitive market that is seeking to slow AWSâ€™ momentum by casting doubt on its infrastructure.I get the competitive issues in play here. But customers should not overlook AWSâ€™ uniqueness in providing a service that allows startups to use elastic computing, network and storage to compete on the world stage. It may have outages, but no other service comes even close to what AWS offers its customers.In the final phase of its first operational flight, the commercial cargo ship returns safely to Earth, carrying nearly a ton of supplies and experiment samples.In a major milestone for the space station program, a commercial cargo capsule loaded with nearly a ton of long-awaited experiment samples, broken components, and other gear returned to Earth on Sunday, plunging back through the atmosphere to a Pacific Ocean splashdown and wrapping up the spacecraft's first operational flight.The SpaceX Dragon capsule is the first space station cargo ship since the shuttle capable of carrying large amounts of equipment both to and from the lab complex. As such, it restores a critical capability for NASA -- the return of experiment samples from the station -- along with failed components that require troubleshooting and analysis."We see her moving aft and away from us out of the keep-out sphere," Expedition 33 Commander Sunita Williams radioed from the station as the Dragon capsule departed early today. "It was nice while she was on board. We tamed her, took her (on board), and literally and figuratively, there's a piece of us on that spacecraft going home to Earth."She was referring to urine and other biological samples packed aboard the cargo ship that had been awaiting a ride back to researchers on the ground."Not only is it going to give us a consistent supply chain up, but very critical, particularly to biological research, is the return mass, to be able to have frozen samples returned home," space station Program Manager Mike Suffredini said earlier. "This really is the keystone to what is going to allow the space station to do what it was built to do. It's critical to the success of the station."Designed, built, and operated by Space Exploration Technologies -- SpaceX -- under a $1.6 billion contract with NASA, the Dragon capsule was launched from Cape Canaveral, Fla., on October 7, loaded with nearly a half ton of supplies and equipment. It was captured by the station's robot arm three days later and attached to the Earth-facing port of the forward Harmony module.After unloading its cargo, the station crew repacked the capsule with nearly a ton of experiment samples, station components, and other gear awaiting return to Earth. Williams and Japanese astronaut Akihiko Hoshide, operating the space station's robot arm, detached Dragon from its berthing port at 7:19 a.m. ET today. The astronauts then released the capsule at 9:29 a.m. as the two spacecraft sailed 255 miles above Burma.At that point, SpaceX flight controllers in Hawthorne, Calif., took over active control, using thruster firings to move the capsule away from the space station. At 2:28 p.m., the capsule's braking rockets fired for 9 minutes and 50 seconds, dropping the far side of its orbit deep into the atmosphere over the Pacific Ocean.After enduring the heat of re-entry, the capsule's two drogue parachutes deployed at an altitude of about 45,000 feet, slowing the craft enough to permit the release of three large main parachutes at an altitude of around 10,000 feet. A SpaceX team was standing by in the landing zone 250 miles off the coast of Baja California to recover the spacecraft."The SpaceX recovery boat sees the vehicle with three main chutes out," NASA mission control radioed the station crew at 3:16 p.m."Good news," Williams replied from orbit. "Thanks for the update."A few moments later, at 3:22 p.m., the spacecraft splashed into the Pacific Ocean to complete the return to Earth."Station, Houston on two, Dragon is in the Pacific," mission control advised."Awesome," Williams said. "She made it home to Earth."The SpaceX commercial resupply contract requires the company to deliver 44,000 pounds of equipment and supplies over 12 flights. To pave the way for operational resupply missions, SpaceX carried out two successful test flights, one that tested the capsule's systems in a solo flight and another that included a berthing at the station last May.The Dragon capsule measures 14.4 feet tall and 12 feet wide, with a trunk section, jettisoned just before re-entry, that extends another 9.2 feet below the capsule's heat shield and houses two solar arrays and an unpressurized cargo bay. The spacecraft can carry up to 7,297 pounds of cargo split between the pressurized and unpressurized sections.Under a separate $440 million contract with NASA, SpaceX engineers are working on upgrades to convert the Dragon capsule into a manned spacecraft that can ferry crews to and from the station. SpaceX managers believe they will be ready for initial manned test flights in the 2015 timeframe, assuming continued NASA funding. Two other companies, Boeing and Sierra Nevada, are developing their own spacecraft designs under similar contracts.For Dragon's first Commercial Resupply Service mission -- CRS-1 -- the SpaceX cargo capsule delivered 882 pounds of hardware, supplies, and equipment to the space station, including 260 pounds of crew food and supplies, 390 pounds of science gear, and 225 pounds of spare parts and other station hardware.For its return to Earth, the Dragon was packed with about 1,673 pounds of experiment samples and hardware, including 163 pounds of crew supplies; 518 pounds of station hardware; 123 pounds of computer gear and Russian equipment; and 866 pounds of science gear and experiment samples.Update: This story was originally published at 8:06 a.m. PT after the Dragon left the space station. It was updated at 12:50 p.m. PT with information and quotations regarding re-entry and splashdown.Microsoft's biggest desire is to get you using Windows 8, and fast. Here's how to use that $40 upgrade to flip older versions of Windows to Windows 8.The Windows 8 eagle has landed, which means that Microsoft's $39.99 in-place upgrade is now available. They've made it extremely easy to upgrade your computer from a Windows 7, Vista, or XP computer to Windows 8. Here's how it's done.First, check out our CNET guide on how to prepare your computer for Windows 8. There's also instructions on how to restore your old system, which is important in case something unexpectedly goes awry, or you decide you don't like Windows 8, you can restore what you had before.If you're upgrading a laptop, you must take note of your Wi-Fi passwords. Windows 8 will keep your settings, personal files, and programs if you upgrade from Windows 7. Vista and XP upgraders will have to re-install programs and reconfigure settings.Next, go to Microsoft's Windows 8 site. Scroll down to the offer and click "Get the details." It's $39.99 for the downloadable installer, or $69.99 to have them mail you a disc.When you click on the Download Pro link, it will give to your computer a small "stub" installer. It's a 5 MB file that will run a compatibility check on your computer, tell you which programs will and won't work in Windows 8, and let you know if you have to uninstall any of them.Until Windows 8 begins its installation, there's some babysitting required. After running the stub, it'll tell you how much of your current computer is compatible, and if there's anything you'll have to review. On the Toshiba Satellite running Windows 7 that I tested this on, I learned that Windows 8 is about as fond of bloatware as the rest of us: the upgrade process requested that I uninstall several Toshiba-branded programs.You don't have to stop everything to take care of them, though, because the Windows 8 installer will walk you through that process. After letting you know whether there are details that will require your attention, it asks Windows 7 upgraders what they'd like to keep of their settings, apps, and personal files.After that, it asks you to buy the upgrade. The ordering process happens in the installer, too. Once you've paid by either credit card or PayPal, it will start downloading the 2 GB installer. You get a choice of installing immediately, installing later, or creating a USB key or disc from which to run the installer.After that, it prompts you to remove any programs that cause conflicts on Windows 8, such as the aforementioned Toshiba-built software. It's clearly a nuanced process, though, as I wasn't required to uninstall all of it -- just four programs out of 11 conflicts. If you have to restart your computer, just double-click on the Windows 8 installation icon on your desktop and it will quickly find where it left off.Once any conflicts are eliminated, Windows 8 will install. It's a surprisingly fast process, as long as you remember to babysit it at the beginning.SAN FRANCISCO â€” I.B.M. scientists are reporting progress in a chip-making technology that is likely to ensure that the basic digital switch at the heart of modern microchips will continue to shrink for more than a decade.The advance, first described in the journal Nature Nanotechnology on Sunday, is based on carbon nanotubes â€” exotic molecules that have long held out promise as an alternative to silicon from which to create the tiny logic gates now used by the billions to create microprocessors and memory chips.The I.B.M. scientists at the T.J. Watson Research Center in Yorktown Heights, N.Y., have been able to pattern an array of carbon nanotubes on the surface of a silicon wafer and use them to build hybrid chips with more than 10,000 working transistors.Against all expectations, silicon-based chips have continued to improve in speed and capacity for the last five decades. In recent years, however, there has been growing uncertainty about whether the technology would continue to improve.A failure to increase performance would inevitably stall a growing array of industries that have fed off the falling cost of computer chips.Chip makers have routinely doubled the number of transistors that can be etched on the surface of silicon wafers by shrinking the size of the tiny switches that store and route the ones and zeros that are processed by digital computers.The switches are rapidly approaching dimensions that can be measured in terms of the widths of just a few atoms.The process known as Mooreâ€™s Law was named after Gordon Moore, a co-founder of Intel, who in 1965 noted that the industry was doubling the number of transistors it could build on a single chip at routine intervals of about two years.To maintain that rate of progress, semiconductor engineers have had to consistently perfect a range of related manufacturing systems and materials that continue to perform at evermore Lilliputian scale.The I.B.M. advance is significant, scientists said, because the chip-making industry has not yet found a way forward beyond the next two or three generations of silicon.â€œThis is terrific. Iâ€™m really excited about this,â€? said Subhasish Mitra, an electrical engineering professor at Stanford who specializes in carbon nanotube materials.The promise of the new materials is twofold, he said: carbon nanotubes will allow chip makers to build smaller transistors while also probably increasing the speed at which they can be turned on and off.In recent years, while chip makers have continued to double the number of transistors on chips, their performance, measured as â€œclock speed,â€? has largely stalled.This has required the computer industry to change its designs and begin building more so-called parallel computers. Today, even smartphone microprocessors come with as many as four processors, or â€œcores,â€? which are used to break up tasks so they can be processed simultaneously.I.B.M. scientists say they believe that once they have perfected the use of carbon nanotubes â€” sometime after the end of this decade â€” it will be possible to sharply increase the speed of chips while continuing to sharply increase the number of transistors.This year, I.B.M. researchers published a separate paper describing the speedup made possible by carbon nanotubes.â€œThese devices outperformed any other switches made from any other material,â€? said Supratik Guha, director of physical sciences at I.B.M.â€™s Yorktown Heights research center. â€œWe had suspected this all along, and our device physicists had simulated this, and they showed that we would see a factor of five or more performance improvement over conventional silicon devices.â€?Carbon nanotubes are one of three promising technologies engineers hope will be perfected in time to keep the industry on its Mooreâ€™s Law pace. Graphene is another promising material that is being explored, as well as a variant of the standard silicon transistor known as a tunneling field-effect transistor.Dr. Guha, however, said carbon nanotube materials had more promising performance characteristics and that I.B.M. physicists and chemists had perfected a range of â€œtricksâ€? to ease the manufacturing process.Carbon nanotubes are essentially single sheets of carbon rolled into tubes. In the Nature Nanotechnology paper, the I.B.M. researchers described how they were able to place ultrasmall rectangles of the material in regular arrays by placing them in a soapy mixture to make them soluble in water. They used a process they described as â€œchemical self-assemblyâ€? to create patterned arrays in which nanotubes stick in some areas of the surface while leaving other areas untouched.Perfecting the process will require a more highly purified form of the carbon nanotube material, Dr. Guha said, explaining that less pure forms are metallic and are not good semiconductors.Dr. Guha said that in the 1940s scientists at Bell Labs had discovered ways to purify germanium, a metal in the carbon group that is chemically similar to silicon, to make the first transistors. He said he was confident that I.B.M. scientists would be able to make 99.99 percent pure carbon nanotubes in the future.This post has been revised to reflect the following correction:Because of an editing error, an article on Monday about an I.B.M. breakthrough on chip design defined incorrectly Mooreâ€™s Law, an observation on technology advances named for Gordon Moore, a co-founder of Intel. Mooreâ€™s Law holds that the chip industry doubles the number of transistors it can build on a single chip at routine intervals of about two years â€” not intervals of about 12 to 18 months.Freemium app revenue is now dominating premium for developers on both iOS and Android, said App Annie. The analytics firm said that freemium apps generate 69 percent of the worldwide iOS app revenue and 75 percent of global Android app revenues.The mobile app world took to the freemium model with a passion last year, as revenue from freemium iOS appseclipsed 50 percent mark in the US about a year ago. But in the last year, the momentum behind freemium apps has only grown stronger, according to new data from app analytics firm App Annie.App Annie Intelligence, which tracks more than 700,000 apps, found that global revenues for freemium apps on iOS have quadrupled over the last 24 months. And for Google Play, worldwide freemium revenues have grown 3.5x in 2012. Now, freemium apps generate 69 percent of the worldwide iOS app revenue and 75 percent of global Android app revenues.Â Meanwhile, premium app revenue from paid download apps have remained relatively flat over the same periods.The numbers confirm the trend weâ€™ve been noticing but the fact that thereâ€™s been no let up shows just how app developers continue to embrace the freemium model and how those apps continue to bring in more money. WeÂ reported two years agoÂ that the 1/3 of the top grossing apps on iOS in the US had moved to the freemium model. By the end of 2011,Â Distimo reportedÂ that about half of the revenue from the 200 top grossing iPhone apps came from freemium app while 65 percent of the revenue from top apps in the Android Market came from freemium apps. Hereâ€™s a look at some of the charts worked up by App Annie Intelligence:Â In January,Â IHS saidÂ that in-app purchase in freemium apps brought in $970 million in worldwide sale last year, or 39 percent compared to paid downloads. And freemium app revenue was expected to grow to $5.6 billion by 2015, representing 64 percent of the total market. The App Annie data, which is limited to iOS and Android, suggests we may be on a faster pace than IHS predicted.Itâ€™s not just in the US, where the figures generally mirror the world stats. App Annie said countries like China and Japan have rapidly adopted the freemium model in the last year. Japanese freemium revenues grew by 24x in the last year on Google Play and Chinese freemium revenue grew by nearly 25x on iOS since January 2011.Not every app needs to go freemium. AsÂ Flurry recently pointed out, some apps are better suited to that model. For example, apps with high intensity of usage in a short window creates an opportunity for developers to make money though in-app purchases that users can binge on. And for users who come back repeatedly over a long period of time, thereâ€™s also a chance to keep selling them on more content and add-on functions. Apps that donâ€™t necessarily hold on to users over a long period of time might monetize better through one-time paid downloads, said Flurry.I suspect weâ€™ll see paid downloads remain as a viable option for some developers. Instapaperâ€™s success, for example, has shown thatÂ consumers will pay up front for a good product. But increasingly, the bigger money seems to be found in letting people in for free and then monetizing a smaller group of users over time through in-app purchases, subscriptions and other added features.Streaming video may be the epitome of instant gratification, but that's only after you actually find the content you're looking for. You may know you want to watch "True Grit," but it's not easy to remember whether it's available on Netflix, Amazon Instant, or any of the other countless services available.That's exactly the problem the newly announced Roku Search is designed to fix.The feature upgrade will allow owners of Roku boxes to search for TV and movies available on Netflix, Amazon Instant, Vudu, Hulu Plus, Crackle, and HBO Go via one simple interface. The Roku Search channel will be rolling out to supported players (Roku LT, Roku HD and Roku 2 boxes) over the week and sits right next to the settings menu on Roku's home screen.I had the opportunity to try out the new feature over the weekend and it works well. Search for a movie and Roku will show you which services it's available for, plus whether it's free for subscribers or requires a pay-per-view fee. After you select your service, Roku launches the appropriate channel, bringing you right to the content you selected. The most tedious part is entering text, although you can use Roku's smartphone app (available for iOS and Android) to speed up the process. It's also possible to search for actors and directors and browse their available content.There are a few quirks. While you can use the Roku smartphone app to enter in text, response time is slightly delayed. I found I had to purposefully type slower than usual, otherwise letters would occasionally be left out, despite typing correctly. I also noticed that Roku Search would only specifically note that certain Amazon Instant movies are available to stream free for Prime members; TV shows didn't have the same "free for Prime" designation.Overall, it's definitely a handy feature, albeit one that only helps if you know what you want to watch. Competing platforms like the Xbox 360 and Google TV offers cross-platform browsing, in addition to search, which can help you find content you don't already know you want to watch. But in the back-and-forth battle between Roku and the Apple TV, it's another win for Roku, as Apple's box doesn't offer any cross-platform searching capabilities.Weâ€™ve seen some absurd trademark threats in recent years, but this one sets the bar at a new low: The Village Voice is suing Yelp for trademark infringement based on Yelpâ€™s creation of various â€œBest ofâ€? lists.  Yes, that's correct, the publisher behind the paper (as well as several other weeklies around the U.S.) has managed to register trademarks in the term â€œBest of â€? in connection with several cities, including San Francisco, Miami, St. Louis and Phoenix.   And it now claims that Yelpâ€™s use of those terms infringes those trademarks and deceives consumers.Right.First, a practical question: deceives consumers about what?  Trademark law is supposed to ensure that consumers can trust that the goods and services they buy come from the sources they expect, e.g., that the Pepsi you just bought really was manufactured by Pepsi.  That helps consumers, because it gives mark-owners an incentive to maintain the expected level of quality. And it helps mark-owners, because they can build customer loyalty and good will.   But you donâ€™t need a survey or even a lawyer to figure out that no one actually thinks the Village Voice is associated with Yelp because both publish â€œbest ofâ€? lists â€“ not least because no one associates the term â€œBest ofâ€? with any particular news source. Second, the more important question: What is going on at the Patent and Trademark Office?  For decades, folks have been complaining (with good reason) that the patent examiners need to do a better job of screening out bogus patent applications.  Itâ€™s clear that the problem extends to the trademark side as well. The PTO has allowed companies and individuals to register marks in any number of obviously generic and/or descriptive terms, such as â€œurban homesteadâ€? (to refer to urban farms), â€œgaymerâ€? (to refer to gay gamers), and â€œB-24â€? (to refer to model B-24 bombers).Once a mark is registered, it is all too easy for the owner to become a trademark bully.  And while companies like Yelp have the resources to fight back (as we expect it will), small companies and individuals may not. Just as dangerous, the trademark owner may go upstream, to intermediaries like Facebook who have little incentive to do anything other than take down an account or site thatâ€™s accused of infringement. "Good enough for government work" isn't good enough for free speech. Itâ€™s time the PTO did its part to stop trademark bullies and tightened up the trademark application process. Fewer bogus registrations means fewer bogus threats, and more online creativity and competition.  That's a win for everyone.In case you havenâ€™t seen the news yet, earlier today, AMD made an announcement that represents a new era in the compute landscape and builds on our rich tradition of bringing disruptive technology to the data center. By announcing our intent to build 64-bit ARM technology-based server CPUs, AMD has embarked on a path that will effectively end the one size fits all compute era that has dominated the data center for the past two decades.With the explosion of new devices and business models that touch the internet, the data center has now become the center of the universe.Â  New workloads are placing tremendous demands on the server infrastructure which is forcing the need for accelerating the pace of innovation.Â  The largest data centers in the world are adding compute at an extremely fast pace, and the market is looking for disruptive ways to improve the efficiency and reduce the total cost of ownership in the data center.Small and efficient CPU, like ARM CPUs, bring a very unique capability to the data center.Â  Â Â The compute/$$ and compute/watt is substantially improved in ARM CPUs over large-core CPUs, thus making them ideal for highly parallelizable tasks.Â  However, the challenge with efficient CPUs is that they need to be linked to the network.Â Â  If each individual efficient CPU is linked to the network, it becomes a very inefficient way to operate.This is where AMD can come in and can offer a unique advantage to drive the industry forward. Â Â AMD, through our SeaMicro acquisition, has the industryâ€™s premier fabric, the AMD SeaMicro Freedomâ„¢ fabric.Â  By using Freedom fabric to link ARM-based CPUs into a cluster, and then linking the clusters to the network, AMD can effectively solve the bottleneck of leveraging small, efficient CPUs in the mega data centers of tomorrow.There are a number companies that have talked about 64-bit ARM in the server space but only AMD comes in with the background and expertise to drive and accelerate the ARM 64-bit ecosystem. We start with a deep knowledge of what it takes to be successful in servers; industry-leading 64-bit microprocessor technology, a broad portfolio of IP and the experience of working with OEMs, ODMs and ISVs to really deliver an enterprise-class portfolio of features. In fact, at our press event in San Francisco earlier today, we pulled together a panel of industry leaders from Facebook, Dell, Red Hat, Amazon and ARM to talk about this movement to more flexible and energy-efficient compute solutions and what was required to further drive this data center inflection point.The best part of it is that we provide customers choice.Â  In addition to ARM-based CPUs, AMD will continue to offer x86 CPUs and APUs so that customers can use the right processor for the right workload.We are extremely excited to be driving the industry at this key inflection point in the data center.Â  This is an exciting time to be in our industry and we look forward to partnering with the entire ecosystem to drive this disruptive change.Take a look at the video here for highlights of todayâ€™s panel and event.Lisa Su is senior vice president and general manager of AMDâ€™s Global Business Units.Her postings are her own opinions and may not represent AMDâ€™s positions, strategies or opinions. Links to third party sites, and references to third party trademarks, are provided for convenience and illustrative purposes only. Unless explicitly stated, AMD is not responsible for the contents of such links, and no third party endorsement of AMD or any of its products is implied.OAK RIDGE, Tenn., Oct. 29, 2012 Â— The U.S. Department of Energy's (DOE) Oak Ridge National Laboratory launched a new era of scientific supercomputing today with Titan, a system capable of churning through more than 20,000 trillion calculations each secondâ€”or 20 petaflopsâ€”by employing a family of processors called graphic processing units first created for computer gaming. Titan will be 10 times more powerful than ORNL's last world-leading system, Jaguar, while overcoming power and space limitations inherent in the previous generation of high-performance computers.Titan, which is supported by the Department of Energy, will provide unprecedented computing power for research in energy, climate change, efficient engines, materials and other disciplines and pave the way for a wide range of achievements in science and technology.The Cray XK7 system contains 18,688 nodes, with each holding a 16-core AMD Opteron 6274 processor and an NVIDIA Tesla K20 graphics processing unit (GPU) accelerator. Titan also has more than 700 terabytes of memory. The combination of central processing units, the traditional foundation of high-performance computers, and more recent GPUs will allow Titan to occupy the same space as its Jaguar predecessor while using only marginally more electricity."One challenge in supercomputers today is power consumption," said Jeff Nichols, associate laboratory director for computing and computational sciences. "Combining GPUs and CPUs in a single system requires less power than CPUs alone and is a responsible move toward lowering our carbon footprint. Titan will provide unprecedented computing power for research in energy, climate change, materials and other disciplines to enable scientific leadership."Because they handle hundreds of calculations simultaneously, GPUs can go through many more than CPUs in a given time. By relying on its 299,008 CPU cores to guide simulations and allowing its new NVIDIA GPUs to do the heavy lifting, Titan will enable researchers to run scientific calculations with greater speed and accuracy."Titan will allow scientists to simulate physical systems more realistically and in far greater detail," said James Hack, director of ORNL's National Center for Computational Sciences. "The improvements in simulation fidelity will accelerate progress in a wide range of research areas such as alternative energy and energy efficiency, the identification and development of novel and useful materials and the opportunity for more advanced climate projections."Titan will be open to select projects while ORNL and Cray work through the process for final system acceptance. The lion's share of access to Titan in the coming year will come from the Department of Energy's Innovative and Novel Computational Impact on Theory and Experiment program, better known as INCITE.Researchers have been preparing for Titan and its hybrid architecture for the past two years, with many ready to make the most of the system on day one. Among the flagship scientific applications on Titan:Materials Science The magnetic properties of materials hold the key to major advances in technology. The application WL-LSMS provides a nanoscale analysis of important materials such as steels, iron-nickel alloys and advanced permanent magnets that will help drive future electric motors and generators. Titan will allow researchers to improve the calculations of a material's magnetic states as they vary by temperature."The order-of-magnitude increase in computational power available with Titan will allow us to investigate even more realistic models with better accuracy," noted ORNL researcher and WL-LSMS developer Markus Eisenbach.Combustion The S3D application models the underlying turbulent combustion of fuels in an internal combustion engine. This line of research is critical to the American energy economy, given that three-quarters of the fossil fuel used in the United States goes to powering cars and trucks, which produce one-quarter of the country's greenhouse gases.Titan will allow researchers to model large-molecule hydrocarbon fuels such as the gasoline surrogate isooctane; commercially important oxygenated alcohols such as ethanol and butanol; and biofuel surrogates that blend methyl butanoate, methyl decanoate and n-heptane."In particular, these simulations will enable us to understand the complexities associated with strong coupling between fuel chemistry and turbulence at low preignition temperatures," noted team member Jacqueline Chen of Sandia National Laboratories. "These complexities pose challenges, but also opportunities, as the strong sensitivities to both the fuel chemistry and to the fluid flows provide multiple control options which may lead to the design of a high-efficiency, low-emission, optimally combined engine-fuel system."Nuclear Energy Nuclear researchers use the Denovo application to, among other things, model the behavior of neutrons in a nuclear power reactor. America's aging nuclear power plants provide about a fifth of the country's electricity, and Denovo will help them extend their operating lives while ensuring safety. Titan will allow Denovo to simulate a fuel rod through one round of use in a reactor core in 13 hours; this job took 60 hours on the Jaguar system.Climate Change The Community Atmosphere Model-Spectral Element simulates long-term global climate. Improved atmospheric modeling under Titan will help researchers better understand future air quality as well as the effect of particles suspended in the air.Using a grid of 14-kilometer cells, the new system will be able to simulate from one to five years per day of computing time, up from the three months or so that Jaguar was able to churn through in a day."As scientists are asked to answer not only whether the climate is changing but where and how, the workload for global climate models must grow dramatically," noted CAM-SE team member Kate Evans of ORNL. "Titan will help us address the complexity that will be required in such models."ORNL is managed by UT-Battelle for the Department of Energy. The Department of Energy is the single largest supporter of basic research in the physical sciences in the United States, and is working to address some of the most pressing challenges of our time. For more information, please visit http://science.energy.gov/.For more information, including Titan images and videos, please visit http://www.olcf.ornl.gov/titan/.This video demonstrates how a Barrett WAM arm uses our mixture of motor primitives (MoMP) algorithm to learn successful hitting movements in table tennis using imitation and reinforcement Learning.Anthony here. Just wanted to share a personal update now that I have a moment. Â At around 9:00 this morning upon hearing about the fuel situation at Peer1, I decided to head out and see if I could lend a hand. The streets of Manhattan near where I live (Soho â€“ not in the evacuation zones) are in not-so-bad shape right now, but the damage left from the flooding in the evacuation zones is significant and real.Iâ€™m sitting in our datacenter NOC at 75 Broad St. Not that itâ€™s been pointed out to me, but there are beds set up on the tiled floor here from the great team at Peer1 who stayed to monitor the situation overnight. These guys have incredible commitment to keeping everything running, and itâ€™s great to see.Normally, power loss would not be a major problem for our datacenter â€“ Peer1 stayed online during the major Manhattan power outage in 2003 that lasted for days, and we preemptively shifted to backup power around 4:00pm yesterday predicting that Con Edison would be shutting off power in evacuation zones. Â Given the nature of the flooding, this situation escalated greatly, submerging our reserve fuel in the basement, shutting off the elevators, and damaging the pumps required to get this fuel to the generator on the 17th floor.My reasons for coming to the datacenter were twofold: one was simply to help and do whatever I could to help us (and the whole building) stay online. The other was to send our systems team the absolute final signal to perform a clean shutdown of our infrastructure should we be moments away from total power loss. Generally, clean shutdowns are preferable to abrupt halts, since code halting in a known state is better than code halting in an unknown state.We had an initial warning that 10:45am was going to be the clean shutdown time. To determine how much time we have remaining, engineers are taking readings at particular time intervals to attempt to determine how quickly we are depleting. The tank readings are behaving somewhatÂ erratically, as there is another mechanism replenishing it from a separate fuel header. Some of our recent readings seem more optimistic, but it is impossible to predict how much fuel remains in this header at this time. As of this writing, we have at least 45 minutes left.Bridges to the island are open right now, and we currently have a fuel truck en route. We have approval from the building to manually carry fuel up in plastic water bottles, and we have a number of our team on-site to carry fuel up the stairs as needed. I do not know if the manual plan will be successful, but we will certainly try.Unfortunately, I do not have more information on a final resolution to this issue. You should still expect Squarespace to go offline at some point because of the hurricaneâ€™s aftermath, but we will do our best to keep that downtime to a minimum. Once we have a reliable stream of fuel to the building, it will go online independently of any other grid issues related to ConEdison and lower Manhattan in general.Weâ€™ll continue to keep you posted. Thank you for your patience.This video demonstrates how a Barrett WAM arm uses our mixture of motor primitives (MoMP) algorithm to learn successful hitting movements in table tennis using imitation and reinforcement Learning.MENLO PARK, Calif. â€” Many people cite Albert Einsteinâ€™s aphorism â€œEverything should be made as simple as possible, but no simpler.â€? Only a handful, however, have had the opportunity to discuss the concept with the physicist over breakfast.One of those is Peter G. Neumann, now an 80-year-old computer scientist at SRI International, a pioneering engineering research laboratory here.As an applied-mathematics student at Harvard, Dr. Neumann had a two-hour breakfast with Einstein on Nov. 8, 1952. What the young math student took away was a deeply held philosophy of design that has remained with him for six decades and has been his governing principle of computing and computer security.For many of those years, Dr. Neumann (pronounced NOY-man) has remained a voice in the wilderness, tirelessly pointing out that the computer industry has a penchant for repeating the mistakes of the past. He has long been one of the nationâ€™s leading specialists in computer security, and early on he predicted that the security flaws that have accompanied the pell-mell explosion of the computer and Internet industries would have disastrous consequences.â€œHis biggest contribution is to stress the â€˜systemsâ€™ nature of the security and reliability problems,â€? said Steven M. Bellovin, chief technology officer of the Federal Trade Commission. â€œThat is, trouble occurs not because of one failure, but because of the way many different pieces interact.â€?Dr. Bellovin said that it was Dr. Neumann who originally gave him the insight that â€œcomplex systems break in complex waysâ€? â€” that the increasing complexity of modern hardware and software has made it virtually impossible to identify the flaws and vulnerabilities in computer systems and ensure that they are secure and trustworthy.The consequence has come to pass in the form of an epidemic of computer malware and rising concerns about cyberwarfare as a threat to global security, voiced alarmingly this month by the defense secretary, Leon E. Panetta, who warned of a possible â€œcyber-Pearl Harborâ€? attack on the United States.It is remarkable, then, that years after most of his contemporaries have retired, Dr. Neumann is still at it and has seized the opportunity to start over and redesign computers and software from a â€œclean slate.â€?He is leading a team of researchers in an effort to completely rethink how to make computers and networks secure, in a five-year project financed by the Pentagonâ€™s Defense Advanced Research Projects Agency, or Darpa, with Robert N. Watson, a computer security researcher at Cambridge Universityâ€™s Computer Laboratory.â€œIâ€™ve been tilting at the same windmills for basically 40 years,â€? said Dr. Neumann recently during a lunchtime interview at a Chinese restaurant near his art-filled home in Palo Alto, Calif. â€œAnd I get the impression that most of the folks who are responsible donâ€™t want to hear about complexity. They are interested in quick and dirty solutions.â€?Dr. Neumann, who left Bell Labs and moved to California as a single father with three young children in 1970, has occupied the same office at SRI for four decades. Until the building was recently modified to make it earthquake-resistant, the office had attained notoriety for the towering stacks of computer science literature that filled every cranny. Legend has it that colleagues who visited the office after the 1989 earthquake were stunned to discover that while other offices were in disarray from the 7.1-magnitude quake, nothing in Dr. Neumannâ€™s office appeared to have been disturbed.A trim and agile man, with piercing eyes and a salt-and-pepper beard, Dr. Neumann has practiced tai chi for decades. But his passion, besides computer security, is music. He plays a variety of instruments, including bassoon, French horn, trombone and piano, and is active in a variety of musical groups. At computer security conferences it has become a tradition for Dr. Neumann to lead his colleagues in song, playing tunes from Gilbert and Sullivan and Tom Lehrer.Until recently, security was a backwater in the world of computing. Today it is a multibillion-dollar industry, though one of dubious competence, and safeguarding the nationâ€™s computerized critical infrastructure has taken on added urgency. President Obama cited it in the third debate of the presidential campaign, focusing on foreign policy, as something â€œwe need to be thinking aboutâ€? as part of the nationâ€™s military strategy.Dow Jones Reprints: This copy is for your personal, non-commercial use only. To order presentation-ready copies for distribution to your colleagues, clients or customers, use the Order Reprints tool at the bottom of any article or visit www.djreprints.comApple Inc. executive Scott Forstall was asked to leave the company after he refused to sign his name to a letter apologizing for shortcomings in Apple's new mapping service, according to people familiar with the matter.The incident was the latest clash between Mr. Forstall, who oversaw Apple's mobile software unit, and other executives at the company. It led to one of the most significant management shake-ups in Apple's recent history and its most sweeping changes under Chief Executive Tim Cook.Apple announced the departure of Mr. Forstall on Monday along with the unrelated departure of its new retail chief, ...Google announced a handful of new Nexus-branded products Monday, including the Nexus 4 smartphone, and the Nexus 7 and Nexus 10 tablets. With its new lineup of Nexus gear, Google is prepared to battle Apple for consumers' holiday dollars over the coming months.The Nexus 4 is in fact a rebadged version of LG's Optimus G. It's a fine smartphone, and perhaps the best ever made by LG. Its best features are the incredible 1280 x 768 HD, 4.7-inch display; quad-core Snapdragon processor; and killer 8-megapixel camera. It is going to be sold unlocked, without carrier contracts for the extremely low price of $299. It can be purchased directly from Google starting November 13.The Nexus 7 is a new version of the Asus-made Nexus 7 that's been available since June. Really the only thing that's different is the amount of storage available and the price. Google upped the possible max storage to 32 GB. The 16-GB Wi-Fi version costs $199, the 32-GB Wi-Fi version costs $249 and the 32-GB Wi-Fi and HSPA+ costs $299.The Nexus 10 is a brand new tablet manufactured from Apple-foe Samsung. There should be no doubt in anyone's mind that Samsung is hoping to appeal to consumers who lust after the Retina Display on Apple's iPad. The iPad 3 and 4 have 9.7-inch displays with 2048 x 1536 pixels and 264 pixels per inch. The Nexus 10 has a 10.05-inch display that has a 2560 x 1600 pixel resolution, making for 300 pixels per inch. Neither Google nor Samsung said what kind of technology is behind the display. Samsung typically favors AMOLEDs, while Apple favors LCDs.[ Smartphones and tablets are little without apps. Check out the 10 Best Apps For Samsung Galaxy Notes. ]In addition to the Retina Display-killing screen, the Nexus 10 boasts a dual-core A15 processor, and Mali T604 graphics processor with 2 GB of RAM; 5-megapixel main camera and 1.9-megapixel user-facing camera; 802.11b/g/n Wi-Fi, Bluetooth and NFC; and microUSB and HDMI ports.The Nexus 10 is priced fairly aggressively. The 16-GB version costs $399 and the 32-GB version costs $499. Neither offers 3G or 4G cellular data, though.It will be interesting to see how Samsung and Google market the Nexus 10. If there's one feature of the iPad 3 and iPad 4 that Apple likes to brag about, it's the Retina Display. Now that Samsung has a tablet with a higher-resolution display than the iPad, the mudslinging between the two competitors is probably going to get worse.All of the new Nexus devices run Android 4.2 Jelly Bean. This minor update to Android includes some pretty cool features, such as Photo Sphere. Photo Sphere lets people take 360-degree panoramas to create really wild images. It also adds a Swype-like keyboard and new powers for Google Now.The Nexus 7 and Nexus 10 can also be ordered directly from Google beginning November 13.Time to patch your security policy to address people bringing their own mobile devices to work. Also in the new Holes In BYOD issue of Dark Reading: Metasploit creator HD Moore has five practical security tips for business travelers. (Free registration required.)Google has officially announced the Nexus 4, the latest phone in its Nexus line of flagship Android devices. Built by LG, the phone features a 4.7-inch 1280 x 768 IPS display, a 1.5GHz quad-core Snapdragon S4 Pro processor â€” which Google claims is the fastest on the market â€” an 8 megapixel camera and a 1.3 megapixel front-facing camera, and up to 16GB of storage. Oh, and the back is made of glass â€” etched, layered glass that sparkles with a strange, almost holographic depth.The executive vibe is balanced nicely by the playfulness of the backNot much of that should be surprising, as the phone had been thoroughly leaked around the web in the past few weeks. What is surprising is how much better it all looks in person. Compared to the LG Optimus G, which shares many of the same components, it's no contest â€” the Nexus 4 is a far nicer piece of hardware. It feels weighty and high-end, and the tight construction combined with the soft-touch plastic on the sides and chrome edging give it a solidly executive vibe â€” a vibe that's balanced nicely by the playfulness of Disco City on the back.The device will sell for $299 with 8GB of storage, or $349 with 16GB. A T-Mobile version will sell unlocked for $199 on a two-year contract. Alongside the improved screen and faster CPU, the Nexus 4 has 2GB of RAM, Wi-Fi 802.11b/g/n, NFC, Bluetooth, and built-in compatibility with Google's latest accessory, the Wireless Charging Orb â€” an inductive charging dock. The phone also houses a sizable 2100 mAh battery, which the company claims will get you about 10 hours of talk time.There's no LTE hereAll that battery life would be great if the device was sporting LTE radios â€” but it is not. Google has decided to forgo stricter carrier partnerships in the US, which for now means that the company will only offer the device as an unlocked HSPA+ phone. That's a bit of a crushing blow to many, who expected Google's next flagship phone to go toe-to-toe with the iPhone 5 and the latest crop of Windows Phone devices.On the bright side, the 320 ppi IPS+ LCD screen is terrific â€” a massive upgrade over the so-so Galaxy Nexus display and competitive with the iPhone's 326 ppi Retina Display. And it's not just competitive in pixel density; the screen looks stunning. It's also laminated and uses LG's new "G2" technology which integrates the touch sensor into the Gorilla Glass 2 outer layer, making everything thinner as well as bringing the actual pixels closer to the surface of the display. (Apple uses a similar technique called "in-cell touch" on the iPhone 5, which integrates the touch sensor into the display panel.) The screen is also curved slightly at the edges, like it's been melted over the phone; Google says it's meant to improve swiping in from the sides of the device.Performance on the phone was snappy. Google execs we spoke with pointed out just how fast the new Snapdragon CPU is, and in our short time testing the phone, it seemed to rip through just about anything we threw at it with little or no hesitation.The screen is curved slightly at the edges, like it's been melted over the phoneFor those disappointed with the camera performance of the Galaxy Nexus, there's also a bright spot here. Literally. Photos taken with the Nexus 4 seem greatly improved over the last generation, and Google reps say that a lot of attention has been paid to the low-light performance of the camera. We won't know for sure just how much better it is than previous phones until we put the device through its full paces, but first impressions suggest a big improvement.On the software front, Google is launching Android 4.2 along with the Nexus 4 (and the Nexus 10 tablet), and it's got some killer new features. We have a full look at the software here, not to mention an exclusive feature on the inside story of the Android team here, but there are a few standout components of the OS update that are worth mentioning.For starters, Google has added widget functionality to the lock screen, meaning you can quickly glance at information without having to get into the phone. The camera has also been improved with a completely redesigned UI focused on single-handed input, and Google has added a Street View-like mode called Photo Sphere which makes panorama shots seem tiny by comparison. The company has also improved Google Now significantly (we have a big feature story on that too).Android now has a typing mode called Gesture Typing, which mimics the functionality of Swype in conjunction with standard tap typing. The company has also added a new quick settings menu to the notifications window, tweaked Gmail with much-needed features like swipe to archive and scale-to-fit messages (like the iPhone), and added new accessibility options that make Android easier than ever â€” for all users.We'll have a full review of the Nexus 4 soon; until then, be sure to check into all of the in-depth news on Google's announcements today.You can also watch this video on YouTube.Supercomputer combines gaming and traditional computing technologies to provide unprecedented power for researchOAK RIDGE, Tenn. â€“ The U.S. Department of Energy's (DOE) Oak Ridge National Laboratory launched a new era of scientific supercomputing today with Titan, a system capable of churning through more than 20,000 trillion calculations each second-or 20 petaflops-by employing a family of processors called graphic processing units first created for computer gaming. Titan will be 10 times more powerful than ORNL's last world-leading system, Jaguar, while overcoming power and space limitations inherent in the previous generation of high-performance computers.Titan, which is supported by the Department of Energy, will provide unprecedented computing power for research in energy, climate change, efficient engines, materials and other disciplines and pave the way for a wide range of achievements in science and technology.The Cray XK7 system contains 18,688 nodes, with each holding a 16-core AMD Opteron 6274 processor and an NVIDIA Tesla K20 graphics processing unit (GPU) accelerator. Titan also has more than 700 terabytes of memory. The combination of central processing units, the traditional foundation of high- performance computers, and more recent GPUs will allow Titan to occupy the same space as its Jaguar predecessor while using only marginally more electricity."One challenge in supercomputers today is power consumption," said Jeff Nichols, associate laboratory director for computing and computational sciences. "Combining GPUs and CPUs in a single system requires less power than CPUs alone and is a responsible move toward lowering our carbon footprint. Titan will provide unprecedented computing power for research in energy, climate change, materials and other disciplines to enable scientific leadership."Because they handle hundreds of calculations simultaneously, GPUs can go through many more than CPUs in a given time. By relying on its 299,008 CPU cores to guide simulations and allowing its new NVIDIA GPUs to do the heavy lifting, Titan will enable researchers to run scientific calculations with greater speed and accuracy."Titan will allow scientists to simulate physical systems more realistically and in far greater detail," said James Hack, director of ORNL's National Center for Computational Sciences. "The improvements in simulation fidelity will accelerate progress in a wide range of research areas such as alternative energy and energy efficiency, the identification and development of novel and useful materials and the opportunity for more advanced climate projections"Titan will be open to select projects while ORNL and Cray work through the process for final system acceptance. The lion's share of access to Titan in the coming year will come from the Department of Energy's Innovative and Novel Computational Impact on Theory and Experiment program, better known as INCITE.Researchers have been preparing for Titan and its hybrid architecture for the past two years, with many ready to make the most of the system on day one. Among the flagship scientific applications on Titan:Materials Science The magnetic properties of materials hold the key to major advances in technology. The application WL- LSMS provides a nanoscale analysis of important materials such as steels, iron-nickel alloys and advanced permanent magnets that will help drive future electric motors and generators. Titan will allow researchers to improve the calculations of a material's magnetic states as they vary by temperature."The order-of-magnitude increase in computational power available with Titan will allow us to investigate even more realistic models with better accuracy" noted ORNL researcher and WL-LSMS developer Markus Eisenbach. CombustionThe S3D application models the underlying turbulent combustion of fuels in an internal combustion engine. This line of research is critical to the American energy economy, given that three-quarters of the fossil fuel used in the United States goes to powering cars and trucks, which produce one-quarter of the country's greenhouse gases.Titan will allow researchers to model large-molecule hydrocarbon fuels such as the gasoline surrogate isooctane; commercially important oxygenated alcohols such as ethanol and butanol; and biofuel surrogates that blend methyl butanoate, methyl decanoate and n-heptane."In particular, these simulations will enable us to understand the complexities associated with strong coupling between fuel chemistry and turbulence at low preignition temperatures," noted team member Jacqueline Chen of Sandia National Laboratories. "These complexities pose challenges, but also opportunities, as the strong sensitivities to both the fuel chemistry and to the fluid flows provide multiple control options which may lead to the design of a high-efficiency, low-emission, optimally combined engine-fuel system"Nuclear Energy Nuclear researchers use the Denovo application to, among other things, model the behavior of neutrons in a nuclear power reactor. America's aging nuclear power plants provide about a fifth of the country's electricity, and Denovo will help them extend their operating lives while ensuring safety. Titan will allow Denovo to simulate a fuel rod through one round of use in a reactor core in 13 hours; this job took 60 hours on the Jaguar system.Climate Change The Community Atmosphere Modelâ€“Spectral Element simulates long-term global climate. Improved atmospheric modeling under Titan will help researchers better understand future air quality as well as the effect of particles suspended in the air.Using a grid of 14-kilometer cells, the new system will be able to simulate from one to five years per day of computing time, up from the three months or so that Jaguar was able to churn through in a day."As scientists are asked to answer not only whether the climate is changing but where and how, the workload for global climate models must grow dramatically," noted CAM-SE team member Kate Evans of ORNL. "Titan will help us address the complexity that will be required in such models."ORNL is managed by UT-Battelle for the Department of Energy. The Department of Energy is the single largest supporter of basic research in the physical sciences in the United States, and is working to address some of the most pressing challenges of our time. For more information, please visit http://science.energy.gov.Look out, silicon. IBM has managed to create a computer chip based on newer carbon-nanotube technology with more than 10,000 transistors. While thatâ€™s still a drop in the bucket compared to the billions of transistors on todayâ€™s state-of-the-art silicon microprocessors, itâ€™s an important step in proving the viability of the new tech.You may have heard of Mooreâ€™s Law, which says that the number of transistors that can be put in a computer chip doubles every 18 months. That â€œlawâ€? has held true for four decades, successfully predicting the rapid evolution of computers and smartphones.However, itâ€™s not a law like, say, Boyleâ€™s Law, which is an inviolable tenet of physics. Mooreâ€™s Law is just a prediction, and itâ€™s about to collide with those real physical laws in the next few years as transistors approach the limit of how small they can get. What then?IBM has an answer in the form of a relatively new technology: carbon nanotubes. Each tube is an atom thick, rolled up in a cylinder (one is shown above). Carbon nanotubes actually conduct electricity better than silicon, have the perfect shape to act as a transistor and, most importantly, can scale smaller.However, theyâ€™re also much harder to work with, which is why no oneâ€™s pursued the tech until recently. They have to be aligned perfectly and metallic impurities, which naturally occur, must be completely removed.IBM has met those challenges, however, not only creating a 10,000-transistor-strong processor based on carbon nanotubes, but doing it with standard semiconductor techniques. That means, should todayâ€™s chipmakers end up switching to the technology, they wouldnâ€™t have to spend billions creating new tools and production facilities.It would also mean Mooreâ€™s Law could get a new lease on life, just through a different technology. And the gadget market, which has been reliant on introducing newer and more powerful gadgets year after year, should be safe for another decade at least.Hackers penetrated the computer defenses of South Carolina's Department of Revenue and accessed 3.6 million social security numbers and account data for 387,000 payment cards, officials said. The Associated Press reported the intrusion also exposed citizens' tax returns, which typically contain much more sensitive personal information, but that couldn't immediately be confirmed.The breach, which occurred in mid-September, followed a series of attempted intrusions beginning in August, according to a press release. State officials have known of the data breach since October 16, and suspected an intrusion as early as October 10, but didn't disclose it until Friday, just hours before the start of the weekend. The underlying vulnerability that attackers exploited to access the state network was fixed on October 20.Officials have retained security firm Mandiant to assist in the investigation of the breach and to help secure the system. The state is also offering one year of credit-monitoring and identity-theft protection from Experian."The number of records breached requires an unprecedented, large-scale response by the Department of Revenue, the State of South Carolina and all our citizens," Governor Nikki Haley was quoted as saying in the press release. "We are taking immediate steps to protect the taxpayers of South Carolina, including providing one year of credit monitoring of identity protection to those affected."Of the 387,000 payment cards exposed, all but 16,000 were encrypted using measures "deemed sufficient" under credit card industry standards, presumably a reference to the Payment Card Industry Data Security Standard, which critics say doesn't go far enough in protecting account data. With a state population of about 4.6 million, the exposure could affect as many as much as three-fourths of South Carolina citizens.Malware samples use increasingly refined trickery to avoid being detected by automated threat analysis systems. Anti-virus company Symantec reports that it has found a trojan which attaches its malicious code to the routines for handling mouse events. Since nobody moves the mouse in an automated threat analysis system, the code will remain inactive, and the malware undetected.In view of the exploding numbers of new malware variants â€“ Symantec mentions about 1Â million a day â€“ fully automated threat detection systems must do most of the initial work for creating virus signatures. This includes systems on which a potential malware sample is executed and its behaviour monitored. Evaluating the results is also a largely automated process; only particularly suspicious cases will be investigated further by an actual person.The simplest method of avoiding this form of detection is to allow time to pass, because such analyses are typically aborted after a certain period of time. If, however, as observed by Symantec, a suspicious program only unpacks its malicious code after 5 minutes, then waits another 20 minutes before it inserts itself into the registry, and finally begins its network activities another 20 minutes later, it stands a good chance of remaining undetected.An even cleverer malware variant uses the Windows API function to inject itself into the message handling functions that process mouse events. On a normal Windows system, a user will sooner or later click on something and activate the malware unwittingly; but on a threat analysis system, the trojan stands a good chance of remaining undetected. AV companies will probably need to introduce virtual mouse nudgers now.Around a 100 million first-grade-aged children lack access to schools. A foundation is testing whether poor children who are given computers and learning software can teach themselves.With 100 million first-grade-aged children worldwide having no access to schooling, the One Laptop Per Child organization is trying something new in two remote Ethiopian villagesâ€”simply dropping off tablet computers with preloaded programs and seeing what happens.Â The goal: to see if illiterate kids with no previous exposure to written words can learn how to read all by themselves, by experimenting with the tablet and its preloaded alphabet-training games, e-books, movies, cartoons, paintings, and other programs.Early observations are encouraging, said Nicholas Negroponte, OLPCâ€™s founder, at MIT Technology Reviewâ€™s EmTech conference last week.The devices involved are Motorola Xoom tabletsâ€”used together with a solar charging system, which Ethiopian technicians had taught adults in the village to use.Â  Once a week, a technician visits the villages and swaps out memory cards so that researchers can study how the machines were actually used.Â After several months, the kids in both villages were still heavily engaged in using and recharging the machines, and had been observed reciting the â€œalphabet song,â€? and even spelling words. One boy, exposed to literacy games with animal pictures, opened up a paint program and wrote the word â€œLion.â€?The experiment is being done in two isolated rural villages with about 20 first-grade-aged children each, about 50 miles from Addis Ababa. One village is called Wonchi, on the rim of a volcanic crater at 11,000 feet; the other is called Wolonchete, in the Great Rift Valley. Children there had never previously seen printed materials, road signs, or even packaging that had words on them, Negroponte said.Earlier this year, OLPC workers dropped off closed boxes containing the tablets, taped shut, with no instruction. â€œI thought the kids would play with the boxes. Within four minutes, one kid not only opened the box, found the on-off switch â€¦ powered it up. Within five days, they were using 47 apps per child, per day. Within two weeks, they were singing ABC songs in the village, and within five months, they had hacked Android,â€? Negroponte said. â€œSome idiot in our organization or in the Media Lab had disabled the camera, and they figured out the camera, and had hacked Android.â€?Elaborating later on Negroponteâ€™s hacking comment, Ed McNierney, OLPCâ€™s chief technology officer, said that the kids had gotten around OLPCâ€™s effort to freeze desktop settings. â€œThe kids had completely customized the desktopâ€”so every kidsâ€™ tablet looked different.Â  We had installed software to prevent them from doing that,â€? McNierney said. â€œAnd the fact they worked around it was clearly the kind of creativity, the kind of inquiry, the kind of discovery that we think is essential to learning.â€?â€œIf they can learn to read, then they can read to learn,â€? Negroponte said (see â€œEmtech Preview: Another Way to Think About Learningâ€?).In an interview after his talk, Negroponte said that while the early results are promising, reaching conclusions about whether children could learn to read this way would require more time. â€œIf it gets funded, it would need to continue for another a year and a half to two years to come to a conclusion that the scientific community would accept,â€? Negroponte said. â€œWeâ€™d have to start with a new village and make a clean start.â€?The idea of dropping off tablets outside of the context of schools is a new paradigm for OLPC. Through the late 2000s, the company was focused on delivering a custom miniaturized and ruggedized laptop, the XO, of which about 3 million have been distributed to kids in 40 countries. Deployments went to schools including ones in Peru (see â€œUna Laptop por Ninoâ€?).Giving computers directly to poor kids without any instruction is even more ambitious than OLPCâ€™s earlier pushes. â€œWhat can we do for these 100 million kids around the world who donâ€™t go to school?â€? McNierney said. â€œCan we give them tool to read and learnâ€”without having to provide schools and teachers and textbooks and all that?â€?It appears that you have JavaScript disabled or have an old version of the Adobe Flash Player. Download the latest Flash player to view this video.If you are on a mobile device, you may be able to directly download the video to play.If your browser allows only "trusted sites" to execute Javascript, you should add the "googleapis.com" domain to your whitelist to allow our Flash detection to work properly.On Monday, the US Supreme Court will hear arguments in a case that pits a major textbook publisher against Supap Kirtsaeng, a student-entrepreneur who built a small business importing and selling textbooks.Like many Supreme Court cases, though, there's more than meets the eye. It's not merely a question of whether the Thai-born Kirtsaeng will have to cough up his profits as a copyright infringer; the case is a long-awaited rematch between content companies seeking to knock out the "first sale" doctrine on goods made abroad (not to mention their many opponents). That makes Wiley v. Kirtsaeng the highest-stakes intellectual property case of the year, if not the decade. It's not an exaggeration to say the outcome could affect the very notion of property ownership in the United States. Since most consumer electronics are manufactured outside the US and include copyrighted software in it, a loss for Kirtsaeng would mean copyright owners could tax, or even shut down, resales of everything from books to DVDs to cellphones."First sale" is the rule that allows owners to resell, lend out, or give away copyrighted goods without interference. Along with fair use, it's the most important limitation on copyright. So Kirtsaeng's cause has drawn a wide array of allies to his side. These include the biggest online marketplaces like eBay, brick-and-mortar music and game retailers, and Goodwillâ€”all concerned they may lose their right to freely sell used goods. Even libraries are concerned their right to lend out books bought abroad could be inhibited.John Wiley and Sons, the textbook publisher suing Kirtsaeng, has its share of backers as well, including the movie and music industries, software companies, and other book publishers. Those companies argue differential pricing schemes are vital to their success, and should be enforced by US courts. Nearly 30 amicus briefs have been filed in all.Supporters of Kirtsaeng are mobilized, following an alarmingâ€”but not precedentialâ€”loss in an earlier case, Omega v. Costco. On a call with reporters this week, librarians and lawyers for pro-Kirtsaeng companies painted a stark picture of what might happen should he lose the case. If the appellate court ruling against Kirtsaeng is allowed to stand, they suggest copyright owners could start to chip away at the basic idea of "you bought it, you own it.""This case is an attempt by some brands and manufacturers to manipulate copyright law, to control the distribution and pricing of legitimate, authentic goods," said eBay's top policy lawyer, Hillary Brill. "When an American purchases an authentic item, he shouldn't have to ask permission from the manufacturer to do with it what he wants."Without "first sale" doctrine in place, content companies would be allowed to control use of their goods forever. They could withhold permission for resale and possibly even library lendingâ€”or they could allow it, but only for an extra fee. It would have the wild effect of actually encouraging copyrighted goods to be manufactured offshore, since that would lead to much further-reaching powers."When we purchase something, we assume it's ours," said Overstock.com general counsel Mark Griffin. "What is proposed by [the content companies] is that we change the fundamental notion of ownership rights."Book publishers and their content-industry allies say those concerns are overblown. No assault on libraries and garage sales is forthcoming, they argue. These organizations simply have a right to set different prices abroad, without being undermined in the US by importation they say is illegal.The road to the Kirtsaeng clash has been a long one. Ultimately, this confrontation has been brewing since the rise of Internet marketplaces like eBay and Amazon in the mid-1990s. It became easier to get price information about goods being sold overseas, and consumers could see that identical or good-enough products were often being offered for prices much lower than the products being hawked in the US. At the same time, the big shopping sites made it simple for anyone to become their own business, selling and shipping around the globe.The textbook market was an obvious place to look for arbitrage. Students have been complaining about the high cost of books for many years; they also became the first group to enthusiastically embrace life online, and naturally looked for ways to cut costs.Foreign-born students, exposed to the lower-priced textbooks on trips home, became some of the first to see the opportunity. The same textbooks they were using to study medicine, engineering, and mathematics in the US were being sold in their home countries for a fraction of the cost. Often a Chinese, Thai, or Indian edition of a textbook had a more cheaply bound cover, sometimes with the local lettering on the front, and perhaps cheaper paper. The internal contents, however, were often the exact same English words being read by their classmates buying high-priced US editions.By 2003, the secret was out. Students' Internet-age solution to the problem of costly textbooks hit the front page of the New York Times. For some students, it was as simple as logging on to Amazon's UK site to comparison-shop.Â  A biochemistry text was $146.15 on the American Amazon site, but sold on the UK site for a mere $63.48, plus $8.05 shipping, one student found. A math textbook cost $110 in the US, but sold for $41.76 plus shipping in Britain.Even cheaper prices were found in Asia on English textbooks. The local college bookstore at Purdue University began buying overseas after it had to start competing with student-resellersâ€”the Indian Association at Purdue bought hundreds of books on their own.Neither the students nor the bookstores quoted by the Times in 2003 thought they were doing anything illegal. It was thought to be settled law; in a 1998 Supreme Court case called Quality King, the high court found that copyright owners couldn't control the re-importation of goods. They were limited by the "first sale" doctrine, which meant the rights held in a particular copy of a work expired once it was sold or given away.Years passed, and copyright owners found a wrinkle in that ruling. The shampoo bottles in Quality King had been made in the US but then shipped abroad, and re-imported. In cases where goods were actually produced abroadâ€”as foreign textbooks generally wereâ€”copyright owners argued unauthorized importers were guilty of infringement. Because imported foreign textbooks were not "made legally under this title [the Copyright Act]," they weren't subject to first sale at all. Or so the thinking went.It seems like an audacious argument, but sure enough, student book-sellers were hit with copyright lawsuits. They fought back hardâ€”but, for the most part, they have lost.Supap Kirtsaeng lost first and lost hardest. He came to the US from Thailand in 1997 to study at Cornell University, and later went on to get a PhD in mathematics from the University of Southern California. From 2007 to 2008, he financed his educationâ€”and made extra money, doubtlessâ€”by importing textbooks from Thailand and selling them under his eBay handle, bluechristine99.The book publisher, John Wiley and Sons, didn't want to see those books in the USâ€”and it had said so. Each book was marked: "[A]uthorized for sale in Europe, Asia, Africa and the Middle East Only... The Publisher may recover damages including but not limited to lost profits and attorney's fees, in the event legal action is required."Kirtsaeng didn't abide by those warnings. He talked to some Thai friends; he consulted "Google Answers;" and he went ahead and sold books.The warning in the books was not an idle one. Wiley and Sons followed through on their threat and sued Kirtsaeng in 2008. Kirtsaeng's lawyer was unable to get the case thrown out on "first sale" grounds. By the end of 2009 Kirtsaeng was in court, justifying his importation business to a jury.Lawyers portrayed Kirtsaeng to the jury as a Thai "gray market" mogul who had gone far beyond financing his own college educationâ€”a portrayal that US publishers continue toÂ push. Working with friends and family who packaged and shipped his books, he made plenty of money selling extra books on eBay. Publishers' lawyers tallied up his receipts for the jury: $1.2 million in a few short years.The jury found Kirtsaeng guilty of infringing copyrights in eight books he had sold, and he was ordered to pay $600,000 in damagesâ€”$75,000 per book. He appealed, but a panel of judges ruled 2-1 in the publishers' favor.KirtsaengÂ returnedÂ to Thailand in 2010 after earning his doctorate from USC, but his court case continues.Last Thursday, Microsoft held its formal shindig in honor of the arrival of Windows 8 and Surface in New York. Today, itâ€™s another coast, another Microsoft event and another version of Windows â€” namely Windows Phone 8, which the company launched at a San Francisco press conference this morning.Over the weekend, I tried an HTC Windows Phone 8X, one of the new Windows Phone 8 handsets. (The new software wonâ€™t be available as an upgrade for Windows Phone 7.5 devices, so the only way to get it will be to buy a new phone.) I didnâ€™t have enough time to give the 8X a truly thorough workout, and the review unit supplied by HTC is an international model that doesnâ€™t support LTE in the U.S.; I just used it on wi-fi, and therefore didnâ€™t try making phone calls. So this story isnâ€™t a review.That said, my early impressions of the phone are positive: Itâ€™s got a tapered soft-touch polycarbonate case which feels good in the hand and doesnâ€™t look like a sad iPhone knockoff. At 4.3â€³, the screen is big enough to feel roomy, and small enough that the phone isnâ€™t a behemoth, and the cameras (including a wide-angle front one) seem solid. Along with its cousin the 8S, this is also the first Windows Phone with Beats audio, which boosts bass during headphone listening in a way that adds a jolt of energy to certain types of music.Nice though the 8X hardware is, this phone, like all smartphones, is defined by its operating system. While 2010â€²s Windows Phone 7 was good; last yearâ€™s Windows Phone 7.5 was really good. And Windows Phone 8, from my brief time with it, seems to be really, really good.The new version is a substantial one in terms of new features, but the biggest change is one of fundamental technology: Windows Phone 8 is now based on the same core as Windows 8, rather than Windows Mobile, the aging junior-sized platform thatâ€™s been the basis of all previous versions of Windows for phones. Microsoft says that moving on up to full-strength Windows will permit the operating system to do a better job of supporting more powerful hardware, and will allow Windows developers to more easily write apps which run on both Windows 8 and Windows Phone 8.Iâ€™m not going to step through all the new features in Windows Phone, but theyâ€™re many and varied, from a new mapping application based on Nokiaâ€™s mapping data to â€œlensâ€? add-ins which add additional features to the camera app to better voice input.Microsoft is continuing its emphasis on people-centric stuff with even more social-networking capabilities, such as the ability to group people into â€œRooms.â€? Itâ€™s added a feature called Kidâ€™s Corner which lets you hand over your phone to your children, content that theyâ€™ll only be able to get at the apps and content you permit. And itâ€™s introduced Data Sense, a technology which compresses web pages to help you stay within your data planâ€™s limits. (Verizon will be the first carrier to support it.) It all adds up to an impressive piece of work.Normally, the tech industry is a meritocracy: Impressive pieces of work tend to do well. But if thereâ€™s one thing weâ€™ve learned from Windows Phone to date, itâ€™s that impressive products sometimes fail to take off.With mobile phones, the alchemy of success is particularly complex. An operating system such as Windows Phone has four constituencies: consumers, developers, manufacturers and carriers. Itâ€™s tough for an operating-system company to come up with something compelling for any one of these groups unless it gets all of them excited, all at once. And with the iPhone and Android so deeply entrenched in their own ways, it hasnâ€™t been entirely clear whether the market has room for a strong number three mobile platform.So far, Windows Phone is stuck as an also-ran. While Gartner says that Windows Phone shipments grew by more than 130 percent year-over-year in the second quarter, that only got the platform to a measly 2.7 percent of the market share, compared to 64.1 percent for Android and 18.8 percent for iOS.For Windows Phone to thrive, it needs cool apps â€” both the major cool apps available elsewhere, and some cool apps which are its alone. It needs dynamite phones. And as much as anything else, it needs the salespeople at phone stores to do a good job of selling the platformâ€™s virtues, even though itâ€™s probably much easier to sell the known quantities that are the iPhone and Android.Microsoft is making progress on the cool-app front: At this morningâ€™s event, Windows Phone honcho Joe Belfiore says that Windows Phone 8 will get 46 of the top 50 apps, including Pandora, until now the poster child for Windows Phone unavailability. (He didnâ€™t mention the four which arenâ€™t on their way, but Instagram and Flipboard leap to mind as iOS/Android all-stars that remain no-shows on Windows Phone.) The new phones from Nokia, HTC and Samsung look promising, too.As for whether the carriers will do a good job of getting consumers interested in Windows Phone 8, I chatted with Microsoft Corporate VP Terry Myerson after the event, and he said that the companyâ€™s relationship with AT&T, T-Mobile and Verizon has never been better. (Sprint, however, hasnâ€™t announced any plans to release Windows Phone 8 devices.)Then thereâ€™s the great big wild card known as Windows 8. Until now, Microsoftâ€™s Metro Modern interface, as clever as it is, has been an outlier â€” a radical departure from the one you encounter on all your other computing devices. Now that both Windows 8 and Windows Phone 8 have their own incarnations of the Modern look, Windows Phone could go from feeling a tad foreign to being utterly mainstream.Or, if consumers donâ€™t buy into Windows 8â€²s brave new world, Windows Phone 8 could get caught in the backlash. Itâ€™s just hard to know.Me, Iâ€™m going to give it a try. As soon as I press Publish on this post, Iâ€™m going to take the U.S. version of the 8X phone that I (and everyone else at the event) received and hotfoot it over to the nearest AT&T store. Iâ€™ll ask someone there to switch my account over from the Samsung Galaxy Nexus Iâ€™ve been using for the past few months to the 8X. For a few weeks, at least, Iâ€™ll be a Windows Phone 8 person â€” and Iâ€™ll let you know how it goes.The most obvious UI tweak in 8 â€” the one that users will immediately notice the first time they turn on their phone â€” is that the home screen is now more functional and flexible. Windows Phone 7 is noted for sacrificing precious real estate with a wide black bar on the right side of the home screen, but no more: version 8 spreads out, allowing the Live Tiles to occupy the entire width of the display. You can still get to your full list of apps the same way as before by swiping left (if you prefer to tap, the right arrow icon is still there â€” itâ€™s been moved to the bottom of the Live Tile stack).And speaking of Live Tiles, I think this is my single favorite change in Windows Phone 8: users can now choose from up to three sizes for each tile they pin to the home screen (some apps are limited to two). If you think of Windows Phoneâ€™s home screen as a grid four units wide and infinitely long, the available sizes are 1 x 1, 2 x 2, and 4 x 2; the latter two will be familiar to existing users, but the new 1 x 1 size is a great choice for app shortcuts that donâ€™t need a ton of space to show live information flowing from the app (I use one for my third-party Starbucks card app, for instance). Injecting 1 x 1 tiles throughout your home screen layout really gives it some flair and individuality; I think itâ€™s exactly what Microsoft needed to complete the look. Itâ€™s not a stretch to say that Windows Phone 8 has the best home screen â€” the perfect combination of flexibility, design, and simplicity â€” of any major platform right now.Microsoft has always suggested that meaningful personalization is a critical element of the Windows Phone proposition. Touchpoints like highlight color (which is deeply ingrained throughout the platform) and home screen configurability have always been important to the platform â€” things that let users show hints of individuality while still making sure you can always tell beyond a shadow of a doubt that youâ€™re definitely looking at a Windows Phone. To that end, the lock screen also gets some welcome improvements without losing its "Windows Phone-ness" â€” it still has the big time and date text across the bottom, for instance. Now, though, you can let third-party apps and services plug into it to cycle the background image, which is cooler than it sounds; take Bing, for instance, which is known for its killer imagery. Apps can also make status icons available to the lock screen, and you can choose up to five icon types to show at a time: Facebook messages, Xbox notifications, unread email, text messages, missed calls, and the like.Like the home and lock screens, Windows Phoneâ€™s soft keyboard is another element that users inevitably interact with on an almost constant basis, and that makes its design critical â€” particularly considering that it still (frustratingly) canâ€™t be swapped out for a third party keyboard in version 8. Youâ€™d think that Microsoft would look to the wild success of keyboard like SwiftKey and Swype on Android and admit that the benefits to users of opening up the input method to developers outweigh the risks, but no dice. Fortunately, Windows Phone has always had a fantastic keyboard, and this version is no exception; I felt as though it was lagging me on a couple occasions, but that may have been my imagination because I never had major input problems or uncorrected errors.In Windows Phone 8, the keyboard incorporates something from its Research division that it calls "Word Flow," which operates much like the phrase prediction technology in SwiftKey and the keyboard found in Android 4.1 â€” it can type entire sentences for you, word by word, by looking at what youâ€™ve typed so far. One interesting feature of Word Flow that Iâ€™ve not seen on other keyboards, though, is contextual correction: Microsoft says itâ€™ll actually analyze the sentence you write and make corrections based on context. The example they give is that if you type "come over fir dinner" itâ€™ll correct "fir" to "for," but Iâ€™m not convinced â€” I then tried typing "thatâ€™s a nice fir tree" and it still made the same correction.The loop you're trying to view is pushing more traffic to our server than it can handle. We apologize for the inconvenience, but the loop has been taken down. Please feel free to look at other data on our server - imagery of Hurricane Sandy can be seen here: http://rammb.cira.colostate.edu/products/tc_realtime/storm.asp?storm_identifier=AL182012This video is unlisted. Only those with the link can see it. Learn moremight be a better source of referral traffic, but its got nothing on Twitter when it comes to revenue.Zappos Labs found that while consumers were 13 times more likely to share a purchase on Pinterest than Twitter, tweets generated the most revenue.Using its new PinPointing system â€” a web tool that recommends products based on Pinterest posts â€” the company was able to disprove an earlier study claiming that Pinterest users were more likely to buy and spend twice as much as referrals from other social networks.According to Zappos,Â Twitter referrals averaged $33.66 per order, more than 10 times those of Facebook ($2.08 per order) and Pinterest ($0.75 per order) combined.â€œEven if a person has 100,000 followers on Pinterest and she pins something to a board called â€˜Stuff I Love,â€™ thatâ€™s not as big a deal as an endorsement tweeted to 10,000 followers,â€? explained Will Young, director at Zappos Labs.While this data is not meant to deter you from using Pinterest, it serves as a good reminder not to neglect your strategies on other social media platforms.This video is unlisted. Only those with the link can see it. Learn moreWASHINGTON - It is expected to be the mother of all cyber diplomatic battles.When delegates gather in Dubai in December for an obscure UN agency meeting, fighting is expected to be intense over proposals to rewrite global telecom rules to effectively give the United Nations control over the Internet.Russia, China and other countries back a move to place the Internet under the authority of the International Telecommunications Union, a UN agency that sets technical standards for global phone calls.US officials say placing the Internet under UN control would undermine the freewheeling nature of cyberspace, which promotes open commerce and free expression, and could give a green light for some countries to crack down on dissidents.Observers say a number of authoritarian states will back the move, and that the major Western nations will oppose it, meaning the developing world could make a difference."The most likely outcome is a tie, and if that happens there won't be any dramatic changes, although that could change if the developing countries make a big push," said James Lewis, director of the Technology and Public Policy Program at the Washington-based Center for Strategic and International Studies."But there is a lot of discontent with how the Internet is governed and the US will have to deal with that at some point."Lewis said there was still an overwhelming perception that the US owns and manages the Internet. Opponents have a "powerful argument" to create a global authority to manage the Internet, Lewis said, but "we need to find some way to accommodate national laws in a way that doesn't sacrifice human rights."Terry Kramer, the special US envoy for the talks, has expressed Washington's position opposing proposals by Russia, China and others to expand the ITU's authority to regulate the Internet."The Internet has grown precisely because it has not been micro-managed or owned by any government or multinational organization," Kramer told a recent forum."There is no Internet central office. Its openness and decentralization are its strengths."The head of the ITU, Hamadoun Toure, said his agency has "the depth of experience that comes from being the world's longest established intergovernmental organization."Toure wrote in the British newspaper The Guardian that any change in regulation should "express the common will of ITU's major stakeholders" and "find win-win solutions that will act as a positive catalyst."But Harold Feld of the US-based non-government group Public Knowledge said any new rules could have devastating consequences."These proposals, from the Russian Federation and several Arab states, would for the first time explicitly embrace the concept that governments have a right to control online communications and disrupt Internet access services," Feld said on a blog post."This would reverse the trend of the last few years increasingly finding that such actions violate fundamental human rights."Paul Rohmeyer, who follows cybersecurity at the Stevens Institute of Technology, pointed to a "sense of anxiety" about the meeting in part because of a lack of transparency.He said it was unclear why the ITU is being considered for a role in the Internet."The ITU historically has been a standards-setting body and its roots are in the telecom industry. I'm not familiar with anything they've done that's had an impact on the Internet today," Rohmeyer told AFP.And the analyst noted that the significance of extending "governance" of the Internet to the ITU remains unclear.Some observers point out that the ITU hired a Russian security firm to investigate the Flame virus, which sparked concerns about the dangers in cyberspace and the need for better cybersecurity cooperation.Rohmeyer said it was unclear whether a conspiracy was at hand, but that "the suggestion that the Internet is a dangerous place could be used to justify greater controls."Observers are also troubled by a proposal by European telecom operators seeking to shift the cost of communication from the receiving party to the sender. This could mean huge costs for US Internet giants like Facebook and Google."This would create a new revenue stream for corrupt, autocratic regimes and raise the cost of accessing international websites and information on the Internet," said Eli Dourado of George Mason University.Milton Mueller, a professor of information studies at Syracuse University who specializes in Internet governance, said most of the concerns are being blown out of proportion.Mueller said the ITU "already recognizes the sovereign right of nations to restrict communications into and out of the country.""What gets lost in the confusion over content regulation is that the real motive of most of the reactionary governments is to protect themselves from economic competition caused by telecom liberalization and deregulation, of which the Internet is only one part," he said.Related: US Says It Will Oppose Major Revisions of Global Telecom RulesRelated Reading:Â 'Internet Kill Switch' - Is this Technically Feasible in the US?VMworld is about a month behind us now and Iâ€™ve had a little more time to noodle on the joint survey I did with virtualization management vendor Xangati. There was a tremendous amount of energy at VMworld and the show floor was one of the biggest and busiest Iâ€™ve seen in a long time. This might give one the impression that the VMware franchise is impenetrable, but the survey shows differently.Before I go through some of the data, remember the survey was answered by current VMware customers, so the data is likely to be skewed pro-VMware, which makes the data even more surprising. VMware has had a virtual (pun intended) monopoly on the market, but there does seem to be some chinks in the armor that could be exploited by another solution provider.The first question regarding VMware competition was "What are your plans for implementing Microsoft Hyper-V in your virtual infrastructure?" While 58.5% of the respondent base said they had "no plans," 19.6% said they were currently implementing Hyper-V in production and test and dev environments. Another 20.9% are currently evaluating functionality within Windows Server 2012 for potential future deployment. Considering the survey consisted of existing VMware customers, this is a surprising large number.How to address WAN jitter issues for real-time applicationsThe decision to bring Microsoft into the environment is being brought in by more of the "hands-on" individuals versus IT management. Of the respondents that are considering or using Hyper-V, 53.2% reported it was the technical team. Another 30.6% of the time it was the manager/director level was pushing for the hybrid environment. And only 16.2% said the VP or CIO level makes the decisions to create a hybrid Microsoft/VMware environment.In the survey, we tried to uncover why customers are looking to add Microsoft to their virtualization environment by asking, "what are the executive-level drivers that are pushing a hybrid VMware/Microsoft hypervisor model?" The most common answer (34.7%) was VMware's licensing and pricing. Another 26.2% chose "Perception that Microsoft functionality is now â€˜good enough.â€™" In some way, these are tied together. If one can get good enough functionality for a better price, why not look at it? Now, itâ€™s no secret that VMwareâ€™s vRam pricing scheme wasnâ€™t exactly a hit. The company moving away from vRam may change the minds of some potential defectors. Itâ€™s good to see that VMware listened to its customers and heard them with regard to pricing, and were willing to make the change.The second part of the above paragraph â€“ whether or not Hyper-V is "good enough" - seems to be widely believed. Responding to the question - "based upon what you know of Hyper-V in Windows Server 2012 do you believe it can manage the performance of your infrastructure on par with vSphere?" - 52% of the companies said they did believe the technology was equivalent. Another 16.4% said they wanted different hypervisors for different applications. We didnâ€™t ask much detail around this but Iâ€™m assuming that thereâ€™s a perception that Microsoft applications might perform better on Hyper-V. Only 10.2% responded they were bringing Microsoft in for price leverage, meaning the desire to use Hyper-V seems real.VMware has been an early mover, which is an advantage when combined with a weak competitive landscape for the better part of a decade. As technically sound as Xen is, it doesnâ€™t have near the channel that Microsoft has. So from the survey results, it appears the VMware "free ride" is rapidly coming to an end. The timing of the pricing range was spot on. But watch your back VMware, because Microsoft is coming.Microsoft needs apps. The success of the new, touch-centric Start Screen of Windows 8 and Windows RT depends on building a thriving app ecosystem to compare with the iOS App Store or Google Play. But if one developer's experience is any indication, actually getting an app into the Windows Store is a lot harder than you might expect.Longtime Windows developer Jeffrey Harmon says he first submitted an app to the Windows Store on August 29 â€“ but it wasn't until this week that it was approved and made available to the public.Harmon doesn't fault the Windows 8 SDK. "For the most part, I think they have done a great job, as the tools, documentation and examples are excellent," he writes. "Where they really fall down though is in the last mile: app submission."Harmon says he first began developing his app, Memorylage, in December. He started work using the Windows 8 Developer Preview, then later updated his code for the Consumer Preview and the Release Preview.In the process, he attended both a Microsoft App Excellence workshop and a Hackathon event, winning Microsoft's "App X" contest both times. At the App Excellence event, Harmon and a Microsoft Field Engineer went over a 60-point checklist to ensure that his app met Redmond's design guidelines and was ready for submission to the Windows Store. All seemed well.No such luck, though. When Harmon finally submitted his app in August, he received a rejection notice a day later. Memorylage crashed, he was told, though the notice didn't specify when or how. He was told it had performance problems, but not what kind. He was told it failed a Direct 3D test, which seemed strange since it wasn't a 3D app and it only used standard controls. Furthermore, the notice said, his website wasn't finished.Needless to say, without more information, fixing all of the problems with Harmon's app proved difficult â€“ particularly since Memorylage passed all of the Windows App Certification Kit tests on his own computer.As he worked to narrow down the issues, Harmon engaged at least six different Microsoft employees, both online and over the phone, eventually including no less than Microsoft's Windows group president, Steven Sinofsky. In all, he exchanged 131 emails with Microsoft staffers, he says, but to no avail."I have given my app, and even my source code, to multiple people within Microsoft.Â To date, not a single one of them has been able to cause it to crash, or fail a single test," Harmon wrote earlier this week. "Every issue that I have figured out, I found on my own, but the store still fails it. How do you debug that?"When El Reg reached out to Microsoft for comment, a spokesperson pointed out that Harmon's appÂ is in fact now available in the Windows Store, adding, "We are committed to delivering a great experience for our developers."But although MemorylageÂ was eventually accepted, its journey from submission to approval took nearly two months. Harmon says the delay has cost him plenty, including marketing opportunities and first-mover advantage, to say nothing of time he could have spent improving his app instead of struggling to get it into the Store."I still think that Windows 8 is a great opportunity for developers, but as it stands, they are in for a world of hurt in trying to get through that last hurdle," Harmon writes. "As a long-time Windows developer, I really hope that changes soon." Â®Every sixty seconds, a tidal wave of unstructured data is produced, consumed, and archived. Social technology adoption by consumers is no longer an early adopter market â€” itâ€™s a mainstream activity. Mobile is accelerating this trend. All this means that a â€œnew customer interactionâ€? model powered by big data is emerging.Why is big data analytics a good lens for creating value around social?All this data growth and value creation trends imply that data management, Big Data and real-time analytics is Â a big focus in social and mobile data going forward.The move to mobile computing and the rise of social networking are the two defining trends in computing right now. So what happens when those trends converge?Social networks are going mobile in a big way. What is the data telling usâ€¦.according to comScore, accessing social networking services is one of the fastest-growing activities on mobile phones.Â In September 2012, over 40% of all mobile phone users in the U.S. accessed a social network, performed a check-in, or tweeted on their phones.The increase in mobile social networking is clearly being driven by the rise of smartphones. The iPhone 5 makes it even more easier and a much better experience. Â So the growth is going to be exponential â€“ more users and more content.Mobile phones are primarily communication devices. And social is all about staying connected. So not surprisingly, the most common social networking activity on mobile phones is related to communications. E-mail is going to become a dinosaur technologyâ€¦more of a formal archive than a Â real-time interaction tool. According to some teens, itâ€™s more of a â€œlame-timeâ€? than real-time.Mobile growth is not a new trend. But seems to have caught the major players like Dell, HP, Microsoft and other napping. Â Classic case of â€œInnovatorâ€™s Dilemmaâ€?. Amazing how managers donâ€™t pay attention to mega-trends and simply watch the train-wreck unfold. Â Handling disruptive business model change is never easy.Clearly we are not short on data. What we need are better big data platforms, paired with predictive and sentiment analytics, that allow us to correlate â€œcause and effectâ€? say transactions with social media mentions; Â positive buzz with ad campaigns; Â uplift Â in certain age groups by certain influencers and so on.Instead of learning which customers a company lost; it might be better to predict which customers a company might lose and present timely offers or products motivating customers to stay.I was recently in a Best Buy and had a interesting social experience. Â I used Red Laser to do real-time price compare but eventually decided that the 10% discount on a product is not a good tradeoff of my time.As I checked out, I asked about the return policy and was met with a hostile responseâ€¦.donâ€™t take anything back without a manufacturer defect. Â Itâ€™s interesting that while companies like Target are â€œprice matchingâ€? online competitors they are still not paying attention to the other aspects of the sale like easy (no questions) returns; unlimited return windows etc. The shopping experience is more than price!!!This â€œnew customer interaction modelâ€? example illustrates how much work is ahead of traditional firms as they transform their business model in the Mobile + Social world.In the new â€œMobile + Socialâ€? interaction paradigmâ€¦ the traditional firms â€“ banks, retailers, etc â€“ Â better figure out the future of stores (and brick and mortar) in the age of digital products, same-day delivery and mobile apps that tell you in real-time what is out there.This is definitely accelerating the â€œshowroomingâ€? phenom as traditional players become an expensive fronts for online retailers. Businessweek (October 28, 2012) had a great quote: â€œBest Buy pays for real-estate, sales people and cash registers and Amazon.com rings up the sale.â€? Showrooming put Borders out of business and brought Barnes & Noble to the brink.So this is for real â€” what are you going to do about it. Â Technology convergence (cloud, mobile, social) is the catalyst for a bigger disruption.A mounted laser that projects bike lane lines onto the street at night joins the ranks of lit-up safety gear for cyclists. The question is: Does it actually work?The XFire bike lane safety light was created by a Los Angeles based company with the goal of helping bike commuters stay safe. The patent-pending light costs about $40, contains five bright red LEDs, and projects two visible red laser lines on either side of the bike. It reminded me a little of the BLAZE device, which projects a bright green shared lane symbol on the road ahead of a cyclist.British blogger Trevor Ward recently took the XFire tail-light for a spin and described his experiences in the Guardian online. Although a dog walker was impressed by the lasers, a neighbor who followed Ward in her car said she didn't really notice the lines and didn't feel the need to give him more room.You might be wondering why I try the XFire out myself. The truth is I've already got some bright (and expensive) flashing bike lights, and they've made me realize that lights can only do so much.Many Colorado drivers don't care that my bike is lit front and back, or that I'm in a bike lane with reflective painted lines, or even that the crosswalk just automatically lit up to signal that they should stop for me. There have been a bunch close calls, and I was carefully following the rules.Better city planning could make more of a difference. Recently several main streets in my Denver neighborhood, which hasn't historically been the most bike-friendly area, were painted with shared lane symbols. Two bike shops have also opened up. Lasers are fun, but I'm looking forward to the day when drivers expect to see bikers everywhere.Although maintaining complete anonymity on the internet is very difficult, there are plenty of tools and alternative services out there that can help protect your personal data. Below weâ€™ve listed five of our favourite services and tools that are privacy conscious. Of course, using the below suggestions will not guarantee 100% protection from privacy intrusions, but theyâ€™re a good place to start!If you want to get out of the Google eco-system then the first thing youâ€™ll want is a search engine alternative. You can find big brand alternatives such as Bing and Excite, but DuckDuckGois one of the few search engines that takes user privacy seriously. DuckDuckGo promises that it wonâ€™t track users orÂ  employ filter bubbles â€“ tailoring your search results based on your account history. This anti-Google attitude has been gaining DuckDuckGo a great deal of publicity and the search engine recent broke the million visitors per day milestone. DuckDuckGo also offers a bunch of handy tools such as metric conversions, common calculations and stock price info.Ghostery is an add-on that originally launched on Mozillaâ€™s Firefox browser and is now available for Chrome, IE and Opera (as well as a standalone app for iOS). Along with DoNotTrack, Ghostery is one of the best privacy-orientated add-ons available for browsers. Ghostery essentially blocks tracking from ad-companies via cookie blocking and cookie protection. The add-on also gives you a list of all the ad networks, data companies and publishers tracking your browser on any given page. Itâ€™s a great tool, but it can cause some pages to load incorrectly and mess-up social sharing buttons (if youâ€™re into that kind of thing).If youâ€™re looking for an email service that takes privacy seriously HushMail is a good option. However itâ€™s not perfect. Hushmail has to comply with court-ordered warrants from law enforcement, just like any other email provider (and it drew a lot of criticism for this). If you want more privacy over the content of your emails then you can use Mozilla Thunderbird in combination with an encryption tool like Enigmail. Thereâ€™s also Lavabit, which promises a privacy-orientated email service, but its servers are located in the US, which some say has less-stringent requirements for law enforcement access than Canada, where Hushmail is located.Diaspora was originally billed as a Facebook-killer back in 2010 when it first started out. That scenario is looking ever more unlikely, as the project was fraught with difficulties while Facebook has gone from strength-to-strength. Nevertheless, if youâ€™re looking for a social network that gives you control of your personal data â€“ via a decentralised network â€“ then Diaspora still a good choice. You could also try Friendica as another privacy-orientated social network. A user in the comments section also recommends the decentralised social network Tent.Of course, youâ€™re not really anonymous online unless you use a VPN of some sort to shield your IP address. Tor is a free VPN thatâ€™s aimed at protecting people from state-level privacy intrusions. Tor is a great way to protect yourself online, but it isnâ€™t perfect. The main problem is it allows anyone to set-up â€˜entryâ€™ and â€˜exitâ€™ nodes, through which your data travels (most people setting up nodes have good intentions, but if you donâ€™t know who they are then how can you trust them not to spy on your traffic?). The other problem with TOR is that it generally offers slower speeds than a privately run VPN. Of course, we have to shamelessly toot our own horn here and recommend iVPN if youâ€™re looking for a paid privacy-orientated VPN, with no bandwidth restrictions.Yes we know the headline says top 5, but as commentators have pointed out, omitting I2P is a bit of an oversight. I2P is an overlay network that allows other software to use it for anonymous communication, including web browsing, sending messages, blogging and file transfers. Itâ€™s compatible with BitTorrent clients such as Vuze and the I2P instant messenger. I2P is currently in Beta, but the developers say the code is stable enough for use.Satellites provide important data about potentially dangerous storms, but as many of these satellites reach the end of their lifespan, the United States could be facing a significant gap in weather coverage, reports the New York Times. A new polar satellite called the JPSS-1 is slated to launch in 2017, but several independent reviews suggest that this won't be in time to prevent a gap in coverage that could last a year or more. The reasons for the delayed launch include everything from reported mismanagement to a lack of adequate funding. And despite "urgent restructuring" at the National Oceanic and Atmospheric Association, it doesn't look like the satellite will be launching in time to avoid the impending coverage gap, which could take place at some point between 2016 and 2018.The LG Optimus G and the Samsung Galaxy S III are the best Android can currently offer. Picking between a smartphone that came to the market five months ago and one that is just arriving might have seemed easy at first, but after the somewhat surprising finding in this review, things are less clear cut.The LG Opttimus G chipset is so vastly powerful that we expected it to swim laps around the Galaxy S III Exynos, but the smartphone was obviously let down by its software support. The LG flagship managed to win on many occasions, but the differences were pretty minor.The only place where the Optimus G was able to give its competitor a real trashing was GPU performance at 1080p resolution. On the other hand, the LG Optimus G lost the web browsing performance battle, which is one of the most common applications of smartphones these days.The 13 megapixel camera came as another disappointment to us. LG made quite a big deal about it, but as we found out it's not able to offering any real life advantage over the Samsung Galaxy S III 8MP shooter. Even worse - the Optimus G video recording comes seriously short of the Galaxy S III footage. Don't get us wrong - the LG Optimus G does some pretty good photos and decent videos, but if we had to pick one of these two for its overall camera performance it would probably be the Galaxy S III.Where the LG Optimus G comes out on top is design. It's all subjective, of course, and it might be that the Galaxy S III has been around longer so we are getting a bit bored with it, but we find the LG smartphone to be better looking than it. The extra gig of RAM is also a nice thing to have and makes the Optimus G more future-proof than its competitor.So on which of those two should you spend your hard-earned cash? It depends what you are looking to get from the deal really.If you are going SIM-free and it's value for money you are after, then by all means go for the Galaxy S III. Judging by the current pre-order prices the Optimus G will cost notably more than its competitor when it launches. The Galaxy S III will let you save about 150 euro and still give you impressively solid smartphone experience and even treat you to a newer Android release. Not to mention that the microSD card slot allows for extremely cheap memory expansion.On the other hand, if money is no object for you (which is usually the case with those looking for high-en smartphones) or your carrier has helped even the field with its subsidies things are looking far more favorable for the LG flagship. It might not be able to assert its dominance over its competitor now, but once LG releases its Jelly Bean update, it should become a real beast.There's just no way the Galaxy S III can fend off the attacks of the newer chipset forever. The LG Optimus G has a sharper screen of slightly higher resolution too, which while lacking the wow factor of the Galaxy S III AMOLED, is far better for productivity and can really help put those four Krait cores to good use.So it seems we are one software update away from the moment when the Galaxy S III finally gives up its throne and the LG Optimus G succeeds it. It up to LG to deliver that quickly and make its flagship the power user's dream device before the holiday shopping spree begins.UNITE HERE Local 11 organizer Martha Santamaria at a Holiday Inn LAXstrike on October 11. (Photo via UNITE HERE Local 11â€™s Facebook)During election season, we constantly hear candidates paying lip service to freedom as the highest American ideal.Â What we almost never hear, however, is a real discussion of the place most Americans have their freedoms curtailed: the workplace.Â For example, look at the Hyatt Andaz hotel in West Hollywood, California. The hotel housekeepers, represented by UNITE HERE Local 11, have filed a complaint with the National Labor Relations Board over an electronic tracking system used to monitor their productivity.The housekeepers are given an iPod Touch to carry with them as they workâ€”but not to listen to morale-boosting music, or to communicate with one another as they clean. The iPods are outfitted with a program that tells the housekeepers which room to push their carts full of cleaning equipment to. There's a button to push when they start cleaning the room and another to push when they finish.The program is known as â€œRexâ€? because it features a running, tail-wagging dog animation. â€œWhoever thought of this system thought it was cute,â€? Cathy Youngblood, a housekeeper at the Hyatt Andaz, tells WorkingÂ In These Times. â€œIf you're a housekeeper you're not thought of as highly intelligent. This is American society. You're in a low position anyway. Now the dog has become our symbol at my Hyatt Andaz. We do run around like dogs, but still, we're not dogs.â€?The complaint was filed, not because this type of surveillance at work is illegal, but because it was imposed on the workers from above without a chance for them to bargain through their union. Under the terms of their most recent collective bargaining agreement, which both parties have agreed to abide by, the housekeepers should get some input before their work processes are drastically changed.The NLRB has agreed to hold hearings on the issue on November 26.â€œThey never ask for the housekeeper's input before they change the working rules. What does that tell me? That tells me we don't count for anything,â€? Youngblood says. The Hyatt's stated reason for the new system was â€œefficiency,â€? but, she pointed out, the best way to do things efficiently would have been to sit down and discuss with the people who know the job best: the workers who do it every day.â€œWhoever designed this system has not done hotel housekeeping,â€? Youngblood said. â€œThey may be a business major, and they may be a very good business major, but they have not done hotel housekeeping at Hyatt Andaz.â€?Â Under their old system, Youngblood explained, the housekeepers were given a paper at the beginning of the day listing the rooms they needed to clean, and they could do them in the most efficient manner. Now, with the Rex system, the iPod tells them which room to do next, even if that room is on another floor. They may make the trip from floor to floor, pushing their 100-pound carts on carpet, many times rather than just one. â€œIt creates unnecessary travel time, and a housekeeper doesn't even have an extra minute,â€? she said.In addition to feeling belittled by the choice of a dog as a symbol, Youngblood and the other housekeepers are upset about the way the system monitors their work process. â€œI don't know if it was their intent to also do surveillance on us,â€? she explained, â€œbut it has become a surveillance system.â€?The computer system allows supervisors to see exactly where housekeepers are at any time, how long it takes them to complete a room, and when they clock out for a break. Youngblood said that while she's working, she has gotten surprise phone calls from a supervisor tracking her with the system.Corey Robin, Brooklyn College professor andÂ author of the book Fear: The History of a Political Idea,Â commented to WorkingÂ In These Times:Youngblood noted too that the new system allows the supervisors free time to attend meetings, rather than requiring them to be a presence in the halls to attend to housekeepers' questions immediately. Now, she said, everything goes through the computerâ€”if they are missing something they need, they have to stop and use the iPod to report a problem.Apple could not be reached for comment, but Robin noted the gulf between what the iPod Touch was designed for and its use as a tool of control:One of the items in this story that most reveals the gulf between the lives of workers and the lives of professionals and media types is the iPod. For many people, the iPod is their freedom: they get to choose their own music, fashion their own media, suit everything to their own particular tastes. But for housekeepers in a hotel, it's an instrument of submission and domination. We know the terrible stories about how iPods get produced (in faraway lands). But what about the terrible stories of how they get used, not merely elsewhere but also here, in the US?The housekeepers are already subject to inspection of the rooms they clean, as well as the possibility of guests' complaints if a room is not up to their standards. All of this can subject them to the hotel's â€œprogressive discipline," a series of escalating punishments for each infractionâ€”a verbal warning, one day of lost work, then two, and so on. A severe guest complaint, Youngblood said, can lead to termination right awayâ€”and, she noted, the people they're serving expect a lot from them. â€œYou are serving pretty much the 1%,â€? she said. â€œI call it a high roller hotel.â€?This is not the first complaint the union has made against Hyatt, by a long shot. Earlier this year, UNITE HERE and community and labor allies including the AFL-CIO, NOW and the NFL Players Association launched aÂ boycottÂ of the Hyatt chain over its treatment of employees. The hotel chain has deniedÂ that it mistreats workers.For Youngblood, this episode is symptomatic of how the hotel chain treats her and her colleagues. â€œIf you had a respectful employer-employee relationship, if we are counted as family, if their door is always open, we should not have had to go to the NLRB,â€? she said. â€œWe women, we know when we're being treated wrong.â€?In the midst of an ever-increasing list of multi-million-dollar campaigns, who in their right mind would run a Kickstarter for $1?Right now, 16 projects on Kickstarter have reached and exceeded the million-dollar mark. Some have become household names â€” Ouya, Pebble â€” and while theyâ€™ve engendered heavy media coverage, theyâ€™ve also raised questions about what to expect from Kickstarter as a platform. But what about the little ones â€” the Joe the Plumbers of the Kickstarter world? Theyâ€™re out there, maybe more than you think, raising from $1 to $100. And, just like the behemoths, their stories have something to tell us about how Kickstarter works, and why, and what it means to the people who use it.What good does running such a small campaign do you?Â Publicity, for one thing. An almost guaranteed success, for another.Â We posed this question to the creators of the least ambitious Kickstarters we could find, from $1 for a podcast to $50 for handmade mugs, and their answers offered some insight into bigger questions, the kind that creators and backers wrestle with, no matter how big their projects.Kickstarter as an organization doesnâ€™t encourage lowballing. They even counsel creators to make their goals reflect the cost of their project, says Kickstarter spokesperson Justin Kazmark.â€œTrying to circumvent the all-or-nothing model is not what the Kickstarter experience should be about,â€? Kazmark says, adding that itâ€™s also the backerâ€™s job to decide whether that influences their decision. â€œA creatorâ€™s funding goal should be an accurate reflection of the costs of the project and if itâ€™s clearly not, backers can take that into account.â€?But Kickstarter as a platform can, in some cases, offer benefits to those who aim low. Itâ€™s easier to reach, of course. And backers may be more likely to fund something they think will reach its goal. After all, nobody likes to fail.But if lowballing your goal makes you more likely to reach it, it also brings the risk that, given that amount of money, you canâ€™t fulfill your promises to your backers.Myq Kaplan, a stand-up comedian starting a podcast, reached 99,600 percent of his $1 goal. His bounty of nearly $1,000 will offer a bit of a buffer, he says, in case he incurs unexpected costs. But how would he have completed a podcast had he raised just a dollar, or even ten?â€œThe thing is, number one, I want to have a podcast,â€? he says. â€œAnd so, if there was no Kickstarter, I would be happy to invest my own money into making a podcast.â€?It doesnâ€™t hurt that itâ€™s very cheap to make a podcast, he adds. (Kaplanâ€™s projectÂ is now live, with two episodes posted so far â€” a cool $498 per show.)â€œIâ€™m just a fan of having reasonable to low expectations, like no entitlement to anything in life,â€? Kaplan says. â€œPick something you can achieve, and vastly exceed it if you can.â€?So if Kaplan didnâ€™t need the money, if he was going to do his podcast anyway, why bother? Publicity, for one thing: â€œI figured this would just be a bonus to get people excited about it,â€? he says.In that, heâ€™s not alone. Roots Worship/Live from the Trash Bar, NYC had already raised some funds, according to creator John Barnett. The $2,205 raised for the album â€” recorded at a church service in a bar in August â€” vastly exceeded the projectâ€™s $25 goal, but that wasnâ€™t the point.â€œIt was more of a marketing concept and a unique way to pre-sell the album than a fundraising one, although what money we did raise was gladly appreciated,â€? he says. â€œUltimately, the Kickstarter site is only a piece of the puzzle in getting visibility of the project in a music industry that is bloated and looking for ways to survive in the digital world.â€?But Barnett had already raised some funds. While Kickstarter allows this â€” Kazmark says creators have received funding from grants and foundations â€” it can make for some pretty bad publicity. Ouya founder Julie Uhrman backpedaled frantically after backers jumped on her for telling Develop that Ouya was looking for additional funding. Itâ€™s not just a matter of fidelity; a creator beholden to multiple entities â€” say, a venture capital firm â€” could be forced to fulfill commitments to their investors prior to, or in place of, their Kickstarter backers. But in a small project, the ability to shoot low often means thereâ€™s funding coming from somewhere else, even if itâ€™s the creatorâ€™s own pocket.'Horrible write speeds', 'vanishing storage'... but it IS early in the RCI have been watching a few Storage Spaces discussion threads on Microsoftâ€™s support forums with interest. Storage Spaces is a new way to manage disk storage in Windows 8 and Server 2012. It allows you to create a pool from two or more drives, create virtual drives on them with an option for RAID-like resilience, and add or remove physical drives as needed when drives fail or more storage is needed.It's a great feature, and particularly since it comes from the server team you would expect it to be solid. Nobody can afford to use storage that is unreliable.Look at this thread though, based on Windows 8 Enterprise Evaluation which should be the RTM code:I had three empty discs which I used for it: 320 GB, 1 TB, 2 TB. The manager told me that the maximum capacity for this setup would be ~2 TB. I then proceeded to fill the space up, resulting in a horrible write speed of ~20 MB/sec. Okay, that can be accepted, it is a software solution, after all. Hereâ€™s the kicker, though: Upon reaching ~0.9 TB, the storage space vanished! Yes, vanished. After invoking the Storage Space Manager, I discovered that the space was deemed â€œfullâ€? and that I was to add another disc. I also took a look at the volumes itself. Hmmh. The 320 GB disc was 100% filled, the 1 TB was at 32% and the 2 TB at 16%. And what are 32% of 1 TB and 16% of 2 TB? Why, 320 GB! So, instead of creating a Parity storage space, it simply downsized every hard disc to the lowest denominator, i.e. 320 GB. Which means that there are two massive problems here: Itâ€™s lying about the remaining capacity (which is confusing in itself: The manager talks about the storage space having a 2 TB capacity, but directly above it talks about a 3.01 pool capacity?) It also gives no warning when the real capacity is reached and the pool is deemed â€œfullâ€?. It simply takes the pool offline (instead of, say, reverting to a â€œread-onlyâ€? mode with a warning) and you have to bring it online manually. Not fun.Or have a look at this (which likely refers to the release preview) â€“ the article it is commenting about is worth a read to.Iâ€™ve run into a major problem with storage spaces. My storage space is full. Having a full storage space puts it into an error state, and it goes offline. You can click â€œBring onlineâ€? but it immediately goes offline again. So, I canâ€™t free space on it, because I canâ€™t get it online to delete stuff. And, more importantly, I canâ€™t get anything off of it because it wonâ€™t stay online. It seems my only option is to add three drives, as I had it set to parity. The only problem? I donâ€™t have three more drives to add.Even bugs in the release preview worry me. Storage is so fundamental that I would expect a feature like this to be 100 per cent solid early in the release cycle, or pulled.We asked Microsoft to comment, but the software giant is still investigating. Â®This article first appeared on Tim Anderson's IT Writing.com and is republished with permission.Upgrade to the latest Flash Player for improved playback performance. Upgrade now or more infoOnce you have Windows 8 up and running, the first thing you'll want to do is start installing the apps you need to get things done. Thankfully, Microsoft's new Windows 8 store offers quick access to a number of the applications you'd normally have to go hunt down anyway, but it also has some real treasures worth downloading. Here are some of the best.The Windows 8 Store is surprisingly large and full of useful apps for an OS and product this new, so don't hesitate to try something new if it looks like it'll be useful for you. There were plenty of apps we didn't cover here because they were either really geared towards Windows 8 tablets like the Surface, or because they came from developers we weren't terribly familiar with. Just like with mobile apps, make sure you take a look at the developer and the permissions an app requires before you install it, and a good glance at the reviews won't hurt either, although you should always take those with a grain of salt.We should also note that reading news and browsing headlines on the Start Screen was a joyâ€”and there are plenty of apps for newspapers, magazines, and even some tech blogs. Most of the apps just reformat the top stories and articles for comfortable tiled viewing, but it's definitely a fun and interesting way to surf the headlines. With more apps coming to the Windows 8 Store every day, if you don't find an app specifically for your favorite web site or service, just stay tunedâ€”it'll likely appear quickly.Upgrade to the latest Flash Player for improved playback performance. Upgrade now or more infoA New York businessman has been charged with trying to defraud Facebook by claiming he was owed a 50% share of the social media company, prosecutors say.Paul Ceglia is accused of fabricating and destroying evidence in a lawsuit asking for half-ownership of the firm.Arrested at his home in Wellsville, New York, Mr Ceglia was due in court on Friday afternoon.US Attorney Preet Bharara said the entrepreneur had been chasing a "quick payday based on a blatant forgery".In 2003, Facebook founder Mark Zuckerberg, then a Harvard University student, agreed to do programming work for Mr Ceglia and his fax business, say prosecutors.Mr Ceglia later filed his lawsuit claiming that he and Mr Zuckerberg had signed a two-page contract awarding him a 50% stake in Facebook.But Mr Zuckerberg said he had not yet conceived the idea for the social network at the time.Facebook's lawyers said the contract that Mr Ceglia and Mr Zuckerberg signed in 2003 was to develop street-mapping software.Mr Ceglia subsequently doctored the document to insert Facebook references, it is alleged.The world's largest scientific project is threatened with further delays, as agencies struggle to complete the design and sign contracts worth hundred of millions of euros with industrial partners,Â Nature has learned.ITER is a massive project designed to show the feasibility of nuclear fusion as a power source. The device consists of a doughnut-shaped reactor called a tokamak, wrapped in superconducting magnets that squeeze and heat a plasma of hydrogen isotopes to the point of fusion. The result should be something that no experiment to date has been able to achieve: the controlled release of ten times more energy than is consumed.That's the dream. But so far, ITER has been consuming mostly money and time. Since seven international partners signed up to the project in 2006, the price has roughly tripled to around â‚¬15 billion (US$19.4 billion), and the original date of completion has slipped by four years to late 2020. Many of the delays and cost increases have come from an extensive design review, which was completed in 2009 (seeÂ 'Fusion dreams delayed').Now, sources familiar with the project warn that the complex system for buying ITER's many pieces could put the project even further behind schedule. Rather than providing cash, ITER's partners have pledged 'in kind' contributions of pieces of the machine. Magnets, instruments and reactor sections will arrive from around the world to be cobbled together at the central site in St-Paul-lÃ¨s-Durance in southern France.Â Because no one body holds the purse strings, designs for the machine's components face a tortuous back-and-forth between the central ITER Organization and national 'domestic agencies', which ensure that local companies secure contracts for ITER's components.Nowhere is the problem more pronounced than the tokamak, the central structure that will eventually house ITER. The construction of the building is meant to be contracted outÂ by Fusion for Energy (F4E), Europe's domestic agency. But the ITER Organization could notÂ tell the agency what neededÂ to be built, says Rem Haange, ITER's technical director, until it receivedÂ data from the other domestic agencies on the numerous systems and subsystems that the building must house. That process was seriously behind schedule when Haange arrived in 2011, he says. "Not a single piece of data had been given by the domestic agencies."Haange says, however, that the project remains firmly on schedule, and he is racing to make up for lost time. A task force of engineers is working through the tokamak building design floor-by-floor to finalize it. "We have a deadline for every floor level, and we are just about making it," he says. The final design will be finished in March next year, but to keep the project on schedule, F4E must tender the construction contract by the end of this year.F4E is also encountering trouble on another key contract, for the giant poloidal field coils that will wrap around the girth of the machine. The coils are among the largest in ITER, and the bottommost ones must be completed before the machine can be assembled. The ITER Organization authorized procurement of the coils in 2009, but F4E's tender received just a single, joint bid from the French firm AlstomÂ and the German company Babcock Noell.F4E rejected the bid because it came in far above the agency's cost expectations, according to multiple sources, who declined to be named because of the sensitivity of the bidding process. Isabelle Tourancheau, a spokeswoman for Alstom, said that the bid had failed after "long and difficult technical and commercial negotiations". Aris Apollonatos, a spokesperson for F4E, says that the contract will now be broken into seven parts to make it more attractive to competitors and put it back out to tender. A meeting earlier this month garnered interest from 27 companies, he says.Despite the tight schedule, both Haange and Apollonatos say that they will not ask for more time at next month's ITER council meeting in Cadarache, France. "We remain committed to delivering on all fronts and in line with the ITER schedule," Apollonatos says. Haange says that Osamu Motojima, director-general of the ITER Organization, is already looking at "simplified assembly", a further stripping-down of the already bare-bones first version of the machine, to keep the project on track. "We will ask for more time only if it is absolutely necessary," Haange says.But holding onto the date for start-up may delay the first power-producing experiments, now scheduled for late 2027 or early 2028. Those experiments require a radioactive isotope of hydrogen called tritium to be produced on site. The necessary tritium plant may have to be delayed to keep to the current budget and schedule, Haange says. That delay may be politically unacceptable, Â he says. "We will have to find ways of recovering potential time delays."Diigo, a social bookmarking and annotation site, is finally back online 50 hours after the domain was first hijacked. Itâ€™s an incredible story that involves crisis management, blackmail, investigative research, payoffs, a clever thief, and points to potential problems with the domain name registry system that could affect anyone with a website. Diigoâ€™s co-founder called it a nightmare and crisis that heâ€™d like to help other companies avoid.Diigo has 5 million registered users. For two days this week, they couldnâ€™t access the site. The service is both a collaborative research tool, and a social content site. TechCrunch called Diigo â€œa research tool that rocksâ€?, back in 2006. Iâ€™m a big fan and started using Diigo (pronounced Deeâ€™go) to bookmark websites after Yahoo shut down its popular bookmarking site Delicious.This past Wednesday, I tried using Diigoâ€™s browser bookmarklet to save a site to my library. But, it didnâ€™t work. I went to the Diigo.com site and it got one of those junky parked domain pages that you see when you mistype a URL. My first thought was, did the site close or perhaps their domain name expire? I checked Diigoâ€™s twitter account and learned their domain was hijacked. The twitter account directed users to an emergency announcement that was put up at diigo.net, not diigo.com.The message also included a way users could help:On Friday afternoon, after 50 hours, the Diigo.com came back online.I contacted Wade Ren, Diigoâ€™s Co-founder and Executive Chairman to get the details of what happened. He agreed to share his story in the hope that other companies will learn some valuable lessons and not have a similar crisis.Ren told me â€œitâ€™s a nightmare since it was unexpected. It was a crisis because it may damage Diigo the brand if it isnâ€™t resolved quickly. And it was an ordeal to go begging for help and getting frustrating go-arounds.â€?The Diigo team learned their site was being redirected Wednesday morning. They did a WHOIS search and learned their domain was moved from their Yahoo domains to another domain registrar called Aust Domains.Ren called Yahoo to find out what happened. Ren says he had several calls with Yahoo over the course of 30 hours, but Yahoo staffers repeatedly told him they couldnâ€™t do anything to help. They insisted the only option was to file a police report, which Ren knew, at best, would take a long time to get his domain back.Ren also discovered Yahoo is not an official domain name registry operator, like GoDaddy, eNom, Tucows, and Melbourne IT. It turns out Yahoo is a domain reseller, and anyone using Yahoo Domains really uses a third party DNS registry operator. Renâ€™s account used Melbourne IT Ltd., based in Australia.I discovered that Yahoo discloses this in the fine print in our Small Business Terms of ServiceRen discovered that the actual DNS registry operator, Melbourne IT, would need to get involved to get this resolved. After much pleading, a Yahoo staffer called Melbourne IT to help, and was told that since the domain was transferred out, there was nothing they can do.At the same time, Ren called and sent an email to Aust Domains, where diigo.com was now registered. His email, titled â€œhigh traffic domains stolen, please help!â€? got a boilerplate reply from customer support saying:Aust Domains and Yahoo werenâ€™t going to help Ren get his domain back quickly. But then Ren was contacted by someone who could. The thief.The thief, who had a yahoo email address, wanted money in exchange for Diigo to get their domain back. Ren says the thief bragged about how he had done this many times before and was very careful.Of course, Ren in principle didnâ€™t want to do business with a cyber blackmailer. But, he wanted to get his site back as quickly as possible for his users and didnâ€™t want to deal with this problem much longer. He said the thief was well aware of the timing. He said the criminal knew it may still take 2 weeks for Diigo to get their site back even with the help of Yahoo, and it would be a lot quicker to pay him to get the domain back, otherwise known as blackmail.Weighting options, Ren decided to pay the money and was given the account information at Aust Domain so Diigo could get their site back, by pointing the DNS settings back to his servers. Ren doesnâ€™t want to disclose the exact amount of the payment, but it was in the 3-figures.Searching the web, Ren found many cases of domain hijacking, and in one case, by the same hijacker at HowardForum.com, the thief was paid $400. You can read the timeline of that attack here.In that case, the website owner says his registrar, GoDaddy, worked with Aust Domains to get the domain back. It took 13 days. Howard shared some of the emails he got from the thief:Back to Diigo, Ren says that at the same time he was in contact with the criminal, a more senior person at Yahoo got in touch with him. This person was much more eager to help.I sent requests via email and phone to Yahoo for comment. After 22 hours, Yahooâ€™s PR department told me they will look into this. Iâ€™m still awaiting their reply and will update this post with any response.Ren says heâ€™s learned several lessons this past week that he wants to share.Ren isnâ€™t sure how the thief got the accountâ€™s password. He speculates it could have happened on some public wifi network and was perhaps sold to the blackmailer. But, all the thief needed to transfer the domain was his email and password.The thief was very careful according to Ren. He doesnâ€™t let his target know that heâ€™s hijacking their domain until itâ€™s too late. The thief didnâ€™t change his Yahoo account password. He just took actions to transfer the domain to the new registrar.Since the thief still had access to the Yahoo accountâ€™s email, Ren suspects the thief was watching his emails and quickly deleted ones that might have warned Ren of the domain transfer. This wasnâ€™t Renâ€™s main email account so he didnâ€™t check it as often.He says 2-step verification of logins could have prevented all this. Yahoo offers 2-step verification where â€œany sign-in attempt Yahoo! deems suspicious will require a second verification, either answering your accountâ€™s security question or entering a verification code we send to the mobile phone or non-Yahoo! alternate email address we have on file.â€?Ren says that unfortunately, this security feature is still in beta and does not seem to work as promised. After the hijacking happened, Ren says he tested his account and was surprised to find that he could still login without the verification step. When Ren told Yahoo about this problem during the hijacking, they asked him to fill out a bug ticket to report it.Would the domain locking featured offered by Yahoo and other registrars have helped? Ren says no, it only provides false hope. Since the thief had access to his account, the thief was simply able to turn domain locking off. And the thief was able to get the domain transfer authorization code, designed to prevent fraudulent or unauthorized transfer, because he had access to the account.Ren says heâ€™s learned itâ€™s better to use a domain name registry operator, rather than a reseller.Based on his experience, Ren says the the domain name registry system is flawed and it needs a system to freeze a domain transfer and revert the domain to its pre-transfer state, immediately after a transfer dispute is submitted, pending further investigation.Ren makes a comparison to the online banking industry. If someone steals you financial account, you have more recourse and security since further verification steps are typically required. But even though your website might be your most business important asset, you donâ€™t have the same protection from your domain host, and there ought to be better procedures and recourse in place to prevent this from happening.Until that happens, criminals will still be out there taking advantage of the situation and prying on unsuspecting website owners.Despite the inclement weather, Google was still able to announce the new LG-made Nexus 4 handset yesterday, and like the Optimus G on which it is based, this new phone should be quite speedy. Both phones use a 1.5GHz quad-core version of Qualcomm's Snapdragon S4 Pro (part number APQ8064) paired with an Adreno 320 GPU. To put that in context, the dual-core versions of the S4 routinely match or beat the quad-core Tegra 3 and Exynos 4 from NVIDIA and Samsung, respectively, so the quad-core version of the chip should be a real monster.To explore just how fast the new Nexus phone will be, I asked our own Florence Ion to send me the benchmark results from the LG Optimus G she's currently reviewing. While there will be some subtle differences between the performance of the two phonesâ€”the Nexus is running Android 4.2, for example, while the Optimus G is still stuck on 4.0.4 for the time beingâ€”looking at how its non-Nexus cousin runs is going to tell us a lot about the latest Google-branded phone and whether it can stand up to the competition on both the iOS and Android sides of the fence.Let's dive right into the benchmarks to see just what kind of performance these phones will be able to deliver.In the Sunspider test, the quad-core Snapdragon handily beats the other Android devices in the lineup and the A5X in Apple's third-generation iPad (and, by extension, the A5 chips in the iPad 2, iPad mini, iPhone 4S, and iPod touch). The combination of the A6 and mobile Safari's generally faster JavaScript engine help the iPhone 5 stay ahead, though. The story is slightly different for the Google Octane test, where the Optimus G bests the iPhone 5 but can't outscore the dual-core Snapdragon in the Galaxy SIII, possibly a sign that the Optimus G's extra CPU cores are going unused.Moving on to our other CPU tests, Geekbench shows the Optimus G pulling ahead of the dual-core A5 in the number-crunching integer and floating point benchmarks but falling behind in the memory bandwidth tests. Memory bandwidth has long been a bottleneck for ARM chips (particularly those using Cortex A9 CPU cores, as we can see in the low iPad 3 and Nexus 7 scores), and its high memory and stream scores are probably what's helping the iPhone 5 outscore the competition in Linpack by such a ridiculous margin (the Optimus G can't beat the iPhone 5 here, but it does clobber the older Android devices).The quad-core version of the S4 also includes a beefed up Adreno 320 GPU, and its results are less ambiguous than our CPU testsâ€”after years of playing second fiddle to the graphics performance in iOS devices, Android is beginning to catch up. In the GLBenchmark offscreen tests, which render the same scene at 1080p on all GPUs to put them on even footing, the Optimus G keeps pace with the A6 and A5X in the Egypt HD test but falls behind in the older Egypt Classic test. As we can see in the onscreen test, however, this discrepancy shouldn't affect games too much when played on the phone's 1280Ã—768 display.The Nexus 4 will wipe the floor with the Galaxy SIII and Nexus 7 in both CPU and GPU performance, and while it doesn't always beat the Apple A6 in the iPhone 5, it's always very close in synthetic benchmarks. Between the two, the iPhone's dual-core A6 may have the advantage in real-world performance, since not all apps will be able to take advantage of all four of the Snapdragon's CPU cores, but we need more real-world comparison time to say for certain. If you can get past the lack of LTE, the Nexus 4 (and by extension the Optimus G, which will give you LTE but take away the Nexus line's guaranteed updates) is easily the fastest Android handset you can buy today. Look for our full review of both the Nexus 4 and Optimus G in the coming weeks.The GPU performance in particular is a good sign for Android devicesâ€”taken with the Nexus 10 tablet, which ships with a powerful Cortex A15-based Exynos 5 chip and a quad-core GPU, it shows an Android ecosystem that is finally beginning to take graphics performance as seriously as Apple's devices do. Expect our review of the Nexus 10 to go up next week, if Hurricane Sandy doesn't get in the way.Wikipedia, the encyclopedia for and by the internet, might just be done: Many of the main articles that the encyclopedia might possibly contain, from history to math and science, are almost complete. The Atlantic writes:It may seem impossible for an encyclopedia of everything to ever near completion, but at least for the major articles on topics like big wars, important historical figures, central scientific concepts, the English-language Wikipediaâ€™s pretty well filled out. (There is, of course, room for improvement in articles that have received less attention, but that is a different, yet still very important, set of challenges.) Thereâ€™s always going to be some tidying â€” better citations, small updates, new links, cleaner formatting â€” but the bulk of the work, the actual writing and structuring of the articles, has already been done.Of course, Wikipediaâ€™s not entirely done. New pages are added every day, for both new events and other odd nooks and crannies of humanity. And there are some pages that will be disputed forever, like the entry onÂ the bookLolitaÂ (should Humbert Humbert be referred to as the bookâ€™s â€œheroâ€??)Â and the one on the Israeli-Palestinian conflict.Some entries are being updated as news comes in, like the current entry on theSyrian civil war. When big events happen like the Japan tsunami, and the 2011 Tucson shooting of Gabrielle Giffords, entries pop up immediately.But for many, the best part of Wikipedia is its extensiveness. Its blanketing of our human experience. There is little that isnâ€™t included, even really weird things. In honor of the weirdness of Wikipedia, here are some of the strangest Wikipedia entries out there.1. A list of places with fewer than ten residents. This list includes several towns in Canada and towns with names like Mule Barn and Zug Island.2. The worldâ€™s littlest skyscraperÂ â€” which is in Wichita Falls, Texas, and is really just a regular sized building.3. The Pope Lick Monster is a part-man, part-goat, part-sheep (theyâ€™re not specific about which parts) that haunts a bridge in Louisville, Kentucky.4. Lists of lists of lists. Yes, this is a thing, and itâ€™s exactly what it sounds like.5. Mike the Headless Chicken lived for 18 months without a head. It might have been a hoax. But heâ€™s got his own Wikipedia page, regardless.6. Three Wolf Moon shirts swept the internet, and real life, around 2008. They have their own entry, explaining the irony and the phenomenon.7. Lion-Eating Poet in the Stone DenÂ is a poem consisting of the sound â€œshiâ€? repeated over and over again. But since there are many different tones used while pronouncing â€œshi,â€? to Chinese speakers, the poem makes total sense.8. Ghost ridingâ€”commonly used in the phrase â€œghost-riding the whipâ€?â€”as explained by Wikipedia.9. YOLO, the current awful catch phrase of young people, means â€œyou only live onceâ€? and is generally said before doing something dangerous or stupid.10. Robert Shields died in 2007, leaving behind a diary of 37.5 million words that chronicled every five minutes of his life.So, go forth and Wikipedia.How Many Women Does It Take To Change Wikipedia? Help Illustrate the Internet With Wikipediaâ€™s Photo ContestBlockbuster executive leadership change at Apple; Scott Forstall has been shown the door. Hereâ€™s the key passage:Jony Ive will provide leadership and direction for Human Interface (HI) across the company in addition to his role as the leader of Industrial Design. His incredible design aesthetic has been the driving force behind the look and feel of Appleâ€™s products for more than a decade. Eddy Cue will take on the additional responsibility of Siri and Maps, placing all of our online services in one group. [â€¦] Craig Federighi will lead both iOS and OS X.Forstall has long been a polarizing executive within Apple. Remember this piece by Austin Carr for Fast Company six weeks ago, on the tensions within the company regarding skeuomorphic UI design?:Inside Apple, tension has brewed for years over the issue. Apple iOS SVP Scott Forstall is said to push for skeuomorphic design, while industrial designer Jony Ive and other Apple higher-ups are said to oppose the direction. â€œYou could tell who did the product based on how much glitz was in the UI,â€? says one source intimately familiar with Appleâ€™s design process. But before Forstall, it was Steve Jobs who encouraged the skeuomorphic approach, some say.The biggest tell, though, might have been this interview with Jony Ive by Shane Richmond for The Telegraph, back in May:When I mention the fake stitching, Ive offers a wince but itâ€™s a gesture of sympathy rather than a suggestion that he dislikes such things. At least, thatâ€™s how I read it. He refuses to be drawn on the matter, offering a diplomatic reply: â€œMy focus is very much working with the other teams on the product ideas and then developing the hardware and so thatâ€™s our focus and thatâ€™s our responsibility. In terms of those elements youâ€™re talking about, Iâ€™m not really connected to that.â€?Heâ€™s connected to it now.Forstall has been around for a long time: he started at NeXT in the early â€™90s and had been involved in the evolution of NeXTStep, Mac OS X, and iOS ever since. That makes it all the more telling that Appleâ€™s press release contains no quote from Tim Cook offering kind words or thanks to Forstall. Compare and contrast to the quote from Cook when Mansfieldâ€™s (now cancelled) retirement was announced in May, or the personal quote from Bertrand Serlet when he stepped down in March 2011. Forstall is not walking away; he was pushed. Potential factors that worked against Forstall: his design taste, engineering management, abrasive style, and the whole iOS 6 Maps thing. I also wonder how much Forstall was effectively protected by his close relationship with Steve Jobs â€” protection which, obviously, no longer exists.Say this for Forstall, though: heâ€™s been in charge of iOS from its inception, and my understanding is that he, along with Bertrand Serlet, were the leading proponents of using OS X as the foundation of the iPhone (as opposed to something more like the embedded OS that runs iPods other than the Touch). No one is more excited than I am to see Jony Iveâ€™s design taste spread to Appleâ€™s software, but under Forstallâ€™s leadership, iOS has been an unprecedented success.In what was almost a mere postscript to the press release, Apple also announced that theyâ€™ve canned retail chief John Browett, whose performance has garnered zero acclaim. Canning Forstall is a big change; Browett, on the other hand, is still so new that he never even got around to managing a single holiday quarter. I wouldnâ€™t read anything more into Browettâ€™s departure than that Tim Cook knows how to recognize a mistake and correct it. (Although it was Cook who hired Browett in the first place.)One of the things I admire about Apple is their plainspokenness, both in advertising and in press releases. Just today I linked to a piece by Derek Thompson for The Atlantic, in which he makes the interesting observation that Appleâ€™s quarterly earnings releases contain remarkably fewer words than other large corporations. At first glance, the headline of the press release announcing Forstallâ€™s departure seemed to go against this: â€œApple Announces Changes to Increase Collaboration Across Hardware, Software & Servicesâ€?. That was followed by a subhead: â€œJony Ive, Bob Mansfield, Eddy Cue and Craig Federighi Add Responsibilities to Their Rolesâ€?.Thinking about it some more, though, and considering what I know about Forstallâ€™s reputation within the company, I think that headline, euphemistic though it is, tells the plain truth: Forstall was an obstacle to collaboration within the company. Now heâ€™s gone, and his responsibilities are being divided between four men who foster collaboration: Ive, Mansfield, Cue, and Federighi.Federighi, like Forstall, dates back to NeXT, and has moved up the ladder quickly after returning to Apple in 2009. Mansfield has had a curious year â€” five months ago he was retiring, then he un-retired, and now heâ€™s taking over a new â€œTechnologiesâ€? group encompassing all wireless and semiconductor engineering. Who better to take over Maps than Eddy Cue, the guy who took over the disaster that was MobileMe and turned it into the far-from-perfect-but-pretty-good-overall and steadily improving iCloud?But the big news today is about Jony Ive. I donâ€™t think it can be overstated just how big a deal it is that he now oversees all product design, hardware and software. For the last year, outside observers have been left to wonder just where the buck stopped for UI design at post-Jobs Apple. That question has now been answered: Jony Ive.Internet Explorer 9 gives you control over your privacy by blocking online tracking. To use this feature, you need to select a Tracking Protection List that tells your browser which trackers to block. Your browser will automatically check for updates to your list every week.Note: This new feature and our lists are still under development. Your browsing experience may be different and subject to changes when you use this beta. Please help us make this service better by reporting any problems.Microsoft's new Surface tablet is generating enough interest to grow lines and pack stores.CENTURY CITY, Calif.--As of this weekend, Microsoft has a hot product on its hands.Reviews notwithstanding (some have been pretty negative), on Friday my local Microsoft store in Century City (in Los Angeles) was buzzing with curious customers keen on trying the Surface RT tablet, as lines snaked outside. Other stores drew crowds too.(And all three Surface models are back-ordered three weeks on Microsoft's online store.)I was surprised to see any line at all. After reading some reviews, you would have thought that the thing was DOA.Fortunately, I had plenty of time to try out the tablet for myself. Ill-conceived, unusable keyboard? Nope. Yeah, it takes getting used to, but the 3mm-thick keyboard is far from unusable and beats a virtual keyboard any day.And besides, for a few bucks more you can get the other Surface keyboard that Microsoft is selling, which is a real keyboard -- responsive and easy to use.And as I've been saying for a while now, as an interface, I like Windows 8 and its split personality.For Microsoft, one of the more encouraging signs (I saw) was the intensity of interest. Customers had lots of questions about Surface and some sat there for 30 minutes or even an hour kicking the tires (or, in this case, pounding on the 3mm keyboard).If Microsoft can maintain that kind of enthusiasm, it has a chance to make a run at the iPad and MacBook.The other unmistakable change at the Microsoft store (which I visit often) was a crop of new Windows 8 laptops with touch screens.There were new Asus, Acer, and Sony clamshell laptops -- all touch capable. For me, this is a watershed feature and big leg up on Apple.Some reviewers believe that touch screens and clamshells go together like oil and water. Not me. I want the option to use the touch screen. I mean, why not have a touch display? It's there if you need it. And I know I need it.And new touch-capable Windows 8 laptops, like the razor-thin $1,299 Acer Aspire S7 (it boasts a 13.3-inch 1,920x1,080 display), are very capable rivals to the MacBook Air.And there are less expensive touch-screen laptops too, like the $699 Acer Aspire V5 and the $549 Asus VivoBook X202E.And note that these all run the full Windows 8 on Intel. So you're not getting shortchanged on applications -- a common complaint cited by Windows RT reviews.Which brings us to the next Surface tablet -- the Intel version with Windows 8 Pro. Though under 2 pounds and only 0.53 inches thick, it will pack a 10.6-inch 1,920x1,080 display, Mini DisplayPort, 4GB of memory, up to 128GB of solid-state drive storage, and a Core i5 chip.It will obviously be more expensive, but it may be a more viable version of Surface for consumers worried that RT won't cut it. (Or for those who take it home only to find that RT doesn't run all of their favorite Windows applications.)Will the Pro version prove to be more popular than Surface RT? We should know by early next year when it debuts at the Microsoft store.If you want to find the secret of Apple's success boiled down to its simplest form, look no further than an interview with Apple Senior Vice President of Marketing Phil Schiller. In comments given to Time, Mr. Schiller said that old technologies are anchors holding the world, or at least his company, back, and that his company isn't afraid to ditch them.Mr. Schiller was asked about the new Mac hardware introduced during Tuesday's iPad mini media event, including the lack of optical drives in the company's new iMac line."These old technologies are holding us back," he told Harry McCracken. "They're anchors on where we want to go. We find the things that have outlived their useful purpose. Our competitors are afraid to remove them. We try to find better solutions â€” our customers have given us a lot of trust."Contrast this with Microsoft, a company desperately afraid of leaving Windowsâ€”the source of the company's vast wealth and successâ€”behind. Microsoft's Windows 8 strategy has been to anchor media tablets down by marrying them to the desktop metaphor where Windows matters.Microsoft hopes that it can have its Windows cake and eat into Apple's iPad empire, too, but that strategy has seen Windows-based touch tablets stagnate. The company released Surfaceâ€”its own version of the toaster-fridge conceptâ€”on Friday, and I will be very surprised if it any way changes anything.Microsoft and its PC OEMs are far too terrified to simply shuck aside legacy technologies, whereas Apple will ditch something it no longer wants without a second thought. For instance, you can still find VGA ports on Dell computers...why?Note to Dell: Your website still sucks, and it doesn't even consistently suck. Different UI elements on different device pages? Different layouts? Please, it's 2012.Apple has gone through, what, six display technologies since VGA mattered? DVI, Mini-DVI, HDMI, DisplayPort, mini DisplayPort, and now Lightning? That's six, and with each move, Apple dumped the predecessor with little or no concern for those with legacy hardware.Floppy drives? ADC? FireWire? FireWire 800? Gone the way of the dodo. Now we have optical drives, and sooner, rather than later, hard drives will be few and far between on any Mac. On the iOS side, Apple just recently gave its own 30-pin Dock connector the boot.Offering some insight on the company's thinking, Mr. Schiller said, "In general, it's a good idea to remove these rotating medias from our computers and other devices. They have inherent issues â€” they're mechanical and sometimes break, they use power and are large. We can create products that are smaller, lighter and consume less power."The company has been very successful doing this, too. Apple has outgrown the PC market since George W. Bush was president, and the company is selling record numbers of its Mac computers, even while its iOS empire has grown larger still.Simple, streamlined, integrated, smaller, lower power...this combination has been part and parcel to Apple's stellar growth during the last ten-plus years.Admittedly, Apple has often gotten pushback for its decisions to drop legacy products. As someone who prefers to buy music on CD and rip it in a lossless format (Apple Lossless currently), and who prefers Blu-ray movies for the quality and the extras, I personally lament the loss of optical drives and wish I could watch my Blu-ray movies on my Mac.Apple doesn't care, however, and that's for the best. Also, and this is important, those of us who get anxious when our beloved legacy thing gets axed eventually get over it. There was much gnashing of teeth and wailing when the original iMac was introduced without ADC or a Floppy, and that was from Mac fans. Do you remember how the PC world laughed and pointed?Who's laughing now? (Hint, it's Apple on the way to the bank to drop of sacks full of cash.)Even Blu-ray, a technology that many Mac users clamored for (see above), gets nary a peep from customers these days, according to Mr. Schiller.The Apple marketing guru also spoke to the rush-to-the-bottom approach of all of its competitors, saying, "Our approach at Apple has always been to make products we're proud to own and use ourselves. We wouldn't make something cheap or low quality."This also is part and parcel to Apple's success. When the economy fell off a cliff in 2008, Apple's stock tanked like the rest of the markets, but the astounding thing was that Apple's results accelerated, rather than declining."When the economy is difficult," he said, "people care a great deal about the things they spend their money on. Customers have come to understand that Apple's products aren't priced high â€” they're priced on the value of what we build into them."To that end, he pointed to netbooks, once the (bleak) future of the PC market. Today, no one talks about netbooks, and that's entirely because Apple didn't jump on the bandwagaon."People said they were the future," Mr. Schiller said. "We rejected them because we thought they were poor. Even if the market was going there, we weren't going to chase everybody downhill."He added, "This is what Apple has always been about, and the Mac has been about, from the first Mac and first iMac. It's always been about making the best Mac we know how. Among the many benefits are making it easy to use and affordable, with great features. This high level of integration is part of delivering on that."If Apple's competitors were smart, they would break into Harry McCracken's office, steal his computer, find the full interview, listen to it over and over again, take copious notes, develop an action plan based on those notes, and then do the things on that action plan.If they were concerned about such subtleties as "the law," they would at least read the Time story over and over again and spend some time thinking about how their businesses differ from the ideals and thoughts laid out by Mr. Schiller.The truth is, however, that few of Apple's competitors are capable of running their businesses anything close to Apple's model. They don't control their ecosystem, they don't control their own hardware and software, they're tied into legacy technologies and ideas, they're afraid to charge a price that will actually sustain innovation, and they have little or no vision.That's why Mr. Schiller and other Apple execs can be so open about these things, and why Mr. McCracken's computer is safe.The hacker group says layoffs at Zynga will lead to the "end of the US game market as we know it" as jobs get shipped overseas, and it vows to take action.The hacktivist group Anonymous apparently is perturbed by the financial situation at Zynga.A posting on the AnonNews site this morning posits that layoffs at Zynga will help to bring about the "end of the US game market as we know it" as jobs get shipped overseas, a plan that the AnonNews report says was discovered in confidential files leaked from the games maker.During the last few days anonymous has been targeting Zynga for the outrageous treatment of their employees and their actions against many developers. We have come to believe that this actions of Zynga will result in massive layoff of a thousand people and legal actions against everyone that speaks to the public about this plan. It will also come to end of the US game market as we know it as all this jobs will be replaced in other more convenient financial countries. With a billion dollars cash sitting in a bank we do believe that such actions are an insult to the population and the behaviour of corporations like Zynga must change.Beyond merely publicizing the alleged plan, Anonymous says it stands ready to retaliate -- it is threatening to "release also all the games we've taken from their servers for free," if Zynga doesn't call off the offshoring effort. The group did not specify what games it has taken but set a deadline of November 5 -- also known as Guy Fawkes Day, named for the English historical figure from which Anonymous derives inspiration.Zynga this week said that it is planning to lay off about 140 employees, or approximately 5 percent of its worldwide workforce. It is also closing its Boston office and expects to shutter its U.K. and Japan studios as well. That word came just a day before the FarmVille maker reported that it lost $52.7 million in the third quarter. The company also said it has a cash stockpile of about $1.6 billion.Financial troubles aside, Zynga has 5 of the 10 most popular games on Facebook, the massive social network that helped propel it into widespread popularity.Hackers penetrated the computer defenses of South Carolina's Department of Revenue and accessed 3.6 million social security numbers and account data for 387,000 payment cards, officials said. The Associated Press reported the intrusion also exposed citizens' tax returns, which typically contain much more sensitive personal information, but that couldn't immediately be confirmed.The breach, which occurred in mid-September, followed a series of attempted intrusions beginning in August, according to a press release. State officials have known of the data breach since October 16, and suspected an intrusion as early as October 10, but didn't disclose it until Friday, just hours before the start of the weekend. The underlying vulnerability that attackers exploited to access the state network was fixed on October 20.Officials have retained security firm Mandiant to assist in the investigation of the breach and to help secure the system. The state is also offering one year of credit-monitoring and identity-theft protection from Experian."The number of records breached requires an unprecedented, large-scale response by the Department of Revenue, the State of South Carolina and all our citizens," Governor Nikki Haley was quoted as saying in the press release. "We are taking immediate steps to protect the taxpayers of South Carolina, including providing one year of credit monitoring of identity protection to those affected."Of the 387,000 payment cards exposed, all but 16,000 were encrypted using measures "deemed sufficient" under credit card industry standards, presumably a reference to the Payment Card Industry Data Security Standard, which critics say doesn't go far enough in protecting account data. With a state population of about 4.6 million, the exposure could affect as many as much as three-fourths of South Carolina citizens.Windows 8 is finally here, and if you're used to previous versions of Windows then you're going to notice that quite a bit has changed. In fact, Windows has seen the biggest changes since the jump from Windows 3.1 to Windows 95.Out goes the Start menu, in comes the new touch-oriented Start screen, new apps, new interface conventions - even experienced PC users may be left feeling a little lost.Don't despair, though, help is at hand. We've been investigating every part of Windows 8, uncovering many of its most important tips and tricks, so read our guide and you'll soon be equipped to get the most out of Microsoft's latest release.Windows 8 opens on its lock screen, which looks pretty but unfortunately displays no clues about what to do next.It's all very straightforward, though. Just tap the space bar, spin the mouse wheel or swipe upwards on a touch screen to reveal a regular login screen with the user name you created during installation. Enter your password to begin.Windows 8 launches with its new interface, all colourful tiles and touch-friendly apps. And if you're using a tablet then it'll all be very straightforward: just swipe left or right to scroll the screen, and tap any tile of interest.On a regular desktop, though, you might alternatively spin the mouse wheel to scroll backwards and forwards.And you can also use the keyboard. Press the Home or End keys to jump from one end of your Start screen to the other, for instance, then use the cursor keys to select a particular tile, tapping Enter to select it. Press the Windows key to return to the Start screen; right-click (or swipe down on) apps you don't need and select Unpin to remove them; and drag and drop the other tiles around to organise them as you like.The Start screen apps are initially displayed in a fairly random order, but if you'd prefer a more organised life then it's easy to sort them into custom groups.You might drag People, Mail, Messaging and Calendar over to the left-hand side, for instance, to form a separate 'People' group. Click the 'minus' icon in the bottom right corner of the screen to zoom out and you'll now find you can drag and drop the new group (or any of the others) around as a block.Right-click within the block (while still zoomed out) and you'll also be able to give the group a name, which - if you go on to add another 20 or 30 apps to your Start screen - will make it much easier to find the tools you need.Right-click in the bottom left corner (or hold down the Windows key and press X) for a text-based menu that provides easy access to lots of useful applets and features: Device Manager, Control Panel, Explorer, the Search dialog and more.The Win+X menu is useful, but no substitute for the old Start menu as it doesn't provide access to your applications. To find this, hold down the Windows key and press Q or either right-click an empty part of the Start screen or swipe your finger up from the bottom of the screen and select 'All Apps' to reveal a scrolling list of all your installed applications. Browse the various tiles to find what you need and click the relevant app to launch it.If there's an application you use all the time then you don't have to access it via the search system. Pin it to the Start screen and it'll be available at a click.Start by typing part of the name of your application. To access Control Panel, for instance, type 'Control'. Right-click the 'Control Panel' tile on the Apps Search screen, and click 'Pin to Start'. If you're using a touchscreen, press and hold the icon, then flick down and select 'Pin to Start'.Now press the Windows key, scroll to the right and you'll see the Control Panel tile at the far end. Drag and drop this over to the left somewhere if you'd like it more easily accessible, then click the tile to open the desktop along with the Control Panel window, and press the Windows key to return you to the Start screen when you're done.To shut Windows 8 down, just move the mouse cursor to the bottom right corner of the screen, click the Settings icon - or just hold down the Windows key and press I - and you'll see a power button. Click this and choose 'Shut Down' or 'Restart'.Some of the tricks available in previous versions of Windows still apply. Press Ctrl+Alt+Del, for instance, click the power button in the bottom right-hand corner and you'll be presented with the same 'Shut Down' and 'Restart' options.And if you're on the desktop, press Alt+F4 and you'll be able to choose 'Shut Down', 'Restart', 'Sign Out' or 'Switch User' options.At Yahoo!, we aspire to make the worldâ€™s daily habits more inspiring and entertaining. Our users have come to expect a personalized Yahoo! experience tailor-made for their lives â€” whether theyâ€™re checking local weather, sports scores, stock quotes, daily news, or viewing ads on our site. We fundamentally believe that the online experience is better when it is personalized.That said, we also believe that there should be an easy and transparent way for users to express their privacy preferences to Yahoo!. Thatâ€™s why we offer our own tools and resources such as Ad Interest Manager, to give users more control over personalized advertising on Yahoo!, and why we participate in industry-wide programs such as AdChoices, which allows users to learn why theyâ€™ve been shown an ad.Yahoo! has been working with our partners in the Internet industry to come up with a standard that allows users to opt out of certain website analytics and ad targeting. In principle, we support â€œDo Not Trackâ€? (DNT). Unfortunately, because discussions have not yet resulted in a final standard for how to implement DNT, the current DNT signal can easily be abused. Recently, Microsoft unilaterally decided to turn on DNT in Internet Explorer 10 by default, rather than at usersâ€™ direction. In our view, this degrades the experience for the majority of users and makes it hard to deliver on our value proposition to them. It basically means that the DNT signal from IE10 doesnâ€™t express user intent.Ultimately, we believe that DNT must map to user intent â€” not to the intent of one browser creator, plug-in writer, or third-party software service. Therefore, although Yahoo! will continue to offer Ad Interest Manager and other tools, we will not recognize IE10â€™s default DNT signal on Yahoo! properties at this time.Yahoo! is committed to working with the World Wide Web Consortium (W3C) to reach a DNT standard that both satisfies user expectations and provides the best Internet experience possible. We will closely evaluate our support for DNT as the industry makes progress in reaching a meaningful, transparent standard to promote choice, reduce signal abuse, and deliver great personalized experiences for our users.This entry was posted on Friday, October 26th, 2012 at 5:49 pm and is filed under Privacy. You can follow any responses to this entry through the RSS 2.0 feed. You can leave a response, or trackback from your own site.In July, EFF called for the immediate release of open source developer and Creative Commons volunteer Bassel Khartabil, who had been detained in Syria since March 12, 2012 as part of a wave of arrests made in the Mazzeh district of Damascus. We felt that the situation was especially urgent in light of a recent Human Rights Watch report documenting the use of torture in 27 detention facilities run by Syrian intelligence agencies. Now it appears that our concerns were well-founded. According to a new Amnesty International report, a released detainee has informed Bassel Khartabilâ€™s family that he is being held at the Military Intelligence Branch in Kafr Sousseh and had been tortured and otherwise ill-treated.In response to this alarming news, Bassel's friends and supporters around the world have launched a letter-writing campaign, hoping to flood Syrian officials and diplomats with physical mail demanding that Khartabil be formally charged and given access to a lawyer or released immediately. Participants are encouraged to send photographs of their letters to info@freebassel.org.EFF has sent the following letter to Syrian officials: I am writing to you on behalf of the Electronic Frontier Foundation (EFF) to express my concern over Bassel Khartabil, a Palestinian man born and raised in Syria, who has been detained incommunicado since his arrest in Damascus, Syria, on March 15. One week after his arrest, Khartabil was briefly brought to his home by some members of security forces who confiscated his computers and files. The Electronic Frontier Foundation does not have information about the reasons for his arrest, but we fear it may be connected to the ongoing unrest and armed conflict in Syria. A few weeks later when relatives inquired about him, security officials at the Kafr Sousseh Military Intelligence branch confirmed that Khartabil was detained, without revealing his whereabouts, his state of health, or if charges had officially been brought against him. International human rights standards require that detaineesâ€™ families are notified promptly after their arrest, and are allowed to communicate with detainees. Khartabil has also not been granted access to a lawyer, although international human rights standards require that detainees have access to a lawyer of their choice. A few weeks later, a released detainee informed Bassel Khartabilâ€™s family that he was being held at the Military Intelligence Branch in Kafr Sousseh and had been tortured and otherwise ill-treated, heightening our concern for his safety. Khartabil is also diabetic. It is not known if he has access to the medication he needs, if he has been provided with a diet that takes into account his diabetes, or if he has been granted a proper medical assessment. EFF urges the people detaining Kartabil to grant him immediate access to his family, a lawyer of his choice, and all necessary medical treatment. We urge you to protect him from torture and other ill-treatment. Additionally, we call on you to release Khartabil, unless he is promptly charged with an internationally recognizable criminal offence and tried in proceedings that respect international fair trial standards.EFF stands with Amnesty International, Creative Commons, Mozilla, and others in demanding Bassel Khartabil's safe return. We will continue to follow this case as it develops.This is the complete 50 minutes of my speech at the Belfast Media Festival 2012 see http://www.belfastmediafestival.co.uk/sessions/ on the future of media and the creative industries. You can download the PDF with most of the slides here http://gerd.fm/QB1fyz or just browse my Slideshare channel at http://www.slideshare.net/gleonhard/presentations In this talk I cover most of the key topics such as 'the people formerly known as consumers', the shift from ownership to access, advertising becoming content, independence replaced by Interdependence, the end of attention monopolies, the social OS aka SoLoMo.Special thanks to the BBC NI for making a great video and sharing it with me and everyone else. Also special thanks to Tiffany Shlain and her great work - be sure to watch 'Connected the Movie' asap!!Please note: You can now download most of my videos by simply subscribing to this iTunes video feed (via Blip.tv) http://gerd.fm/itunesfeed *** audio-only versions are now available here: http://gerd.fm/gerdaudiofeed or on the web at http://www.futuretalks.comMy vimeo channel is here: https://vimeo.com/gerdfuturistEnjoy!Gerd LeonhardFuturist, Author and Keynote SpeakerBasel / Switzerlandhttp://www.gerdfuturist.comCEO www.thefuturesagency.comMedia Blog: http://www.mediafuturist.com/Gerd's mobile apps: http://road.ie/futuristThe Future of Business blog http://www.futureof.biz/Public Speaking schedule: http://gerd.fm/meetgerdTwitter: http://www.twitter.com/gleonhardNeed even more links? http://about.me/mediafuturistDanish industrial enzymes maker Novozymes on Tuesday launched an enzyme that it said produces more ethanol from corn, addressing concern that growth in biofuels has come at the expense of food production.The new enzyme, called Novozymes Avantec, can â€œsqueeze an extra 2.5 percent of ethanol out of the corn,â€? it said.â€œIt allows you to save a lot of corn and still produce the same amount of ethanol,â€? said Peder Holk Nielsen, executive vice president at Novozymes.Corn is the main raw material used in US biofuel production. Holk Nielsen said that â€œif all ethanol plants in the US started using Avantec, they would save 3 million tonnes of corn.â€?Claus Felby, professor of biomass and bio energy at the University of Copenhagen, said that technologically, the enzyme was not a revolution, but that itâ€™s â€œvery smart to use the resources more efficiently.â€?â€œFirst generation bio ethanol is often criticised. But one tends to forget that just as much animal feed is produced when you produce ethanol from corn,â€? he said.First generation biofuels are made from the sugars and oils found in arable crops, while second generation biofuels are based on feedstocks that include crop residues, waste, algae and woody material.Dan Belusa, a sustainable agriculture campaigner with Greenpeace in Copenhagen, suggested Novozymes focus on second generation biofuels instead, a process in which enzymes can be used to convert municipal waste into resources.â€œThereâ€™s a world of difference between worsening a food crisis and â€¦ taking real waste and using that as a resource,â€? Belusa said.Earlier this month a UN official called for the European Union and the United States to abandon biofuels altogether as the land used to produce them was needed by farmers to grow food instead.Food security has emerged as a top item on the international agenda and critics claim that biofuels have pushed out food production in some areas, contributing to a global rise in food prices.This is the complete 50 minutes of my speech at the Belfast Media Festival 2012 see http://www.belfastmediafestival.co.uk/sessions/ on the future of media and the creative industries. You can download the PDF with most of the slides here http://gerd.fm/QB1fyz or just browse my Slideshare channel at http://www.slideshare.net/gleonhard/presentations In this talk I cover most of the key topics such as 'the people formerly known as consumers', the shift from ownership to access, advertising becoming content, independence replaced by Interdependence, the end of attention monopolies, the social OS aka SoLoMo.Special thanks to the BBC NI for making a great video and sharing it with me and everyone else. Also special thanks to Tiffany Shlain and her great work - be sure to watch 'Connected the Movie' asap!!Please note: You can now download most of my videos by simply subscribing to this iTunes video feed (via Blip.tv) http://gerd.fm/itunesfeed *** audio-only versions are now available here: http://gerd.fm/gerdaudiofeed or on the web at http://www.futuretalks.comMy vimeo channel is here: https://vimeo.com/gerdfuturistEnjoy!Gerd LeonhardFuturist, Author and Keynote SpeakerBasel / Switzerlandhttp://www.gerdfuturist.comCEO www.thefuturesagency.comMedia Blog: http://www.mediafuturist.com/Gerd's mobile apps: http://road.ie/futuristThe Future of Business blog http://www.futureof.biz/Public Speaking schedule: http://gerd.fm/meetgerdTwitter: http://www.twitter.com/gleonhardNeed even more links? http://about.me/mediafuturistMicrosoft's Windows 8 operating system went on sale on October 26th, and the company has just announced it has already sold four million upgrade copies. At a keynote address in Seattle today, Microsoft CEO Steve Ballmer revealed the first Windows 8 statistics â€” four million upgrade copies over the first weekend of sales. Ballmer mentioned the launch of Surface, but did not reveal any specific sales figures for that particular device.â€œStaff was rude, bad location, voter intimidation, chads hanging all over the place. One out of five stars; would not vote there again.â€?If you have a noteworthy voting experience on Nov. 6, whether itâ€™s particularly good or bad, you probably want to share it. Thatâ€™s the idea behind MyFairElection.com, a new site that creator Archon Fung calls â€œYelp for Democracy.â€?â€œIf the election of 2012 is anything like 2008 or 2004, thousands of Americans will be unable to vote because polling places will be closed, thereâ€™ll be long lines, machines will be broken, and some may even face intentional intimidation,â€? Fung, a professor of Democracy and Citizenship at Harvard, said on YouTube.Calling out which polling sites do a good job can â€œhelp ensure all Americans can exercise the right to vote,â€? he said.Thereâ€™s only a few categories to fill out: how long you had to wait to vote, whether one actually was allowed to vote, to rank to total experience from one to five stars, and a comment box.Fung wants at least 10,000 people to participate in crowdsourcing reviews of polling places across America. Weâ€™ll be able to see what election conditions are like all over the United States, in real time.â€?The voting map will be broken down to precincts, and color coding (red for one star, green for five) will show how accessible polling places are as voters review them.Just be sure to only review one spot a year.Most people know Nikon as a purveyor of pro and consumer-grade digital cameras. But the company's expertise with optics bleeds over into related marketsâ€”it's one of the science community's major suppliers of microscopes. And each year the company asks the community to send it some of their favorite images of tiny objects. A panel of scientists and journalists have chosen the best of this past year's submissions, which Nikon has placed on its Small World site.We've gone through and picked out some of our favorite images from this year, and Nikon provided some high-resolution versions. In keeping with the Ars tradition, where possible, we'll tell you a bit more about the subjects than you might get from the brief description on the original site.The grand prize winner at top highlights the blood vessels as they form in the brain of a zebrafish. The fish itself is transparent at this stage of development, and the blood vessels are tagged with a fluorescent protein, which allowed the researchers to image these tiny vessels at 20 times their normal size. The image is actually a composite of many individual images taken with a confocal microscope.Confocals only capture light from a single plane of focus, so each individual image is like an optical slice through the tissue. By changing the plane of focus and taking additional pictures, it's possible to create a stack of images (called a z-stack) that captures the three-dimensional details of the sample. In this case, the authors colored the blood vessels differently at different depths, allowing them to capture the sample's complexity.Lynx spiders are a very successful genus, with members found on every continent. Their most notable feature is the hexagonal arrangement of six of their eight eyes (the remaining two vary in position). Some members of the species are hunters and don't build webs. These newly hatched spiders were photographed at 6x magnification using reflected light. Like a number of the other winners, this image relied on a different type of image stacking. Rather than providing depth, a series of short exposures are merged to create a single image with pixels being averaged. This helps get rid of any noise in each individual exposure.Cancer's an ugly disease, but damn, this image of a cancerous cell looks good. The cell is outlined in purple by structures called actin stress fibers, which essentially form a tiny skeleton made of protein that helps give the cell its shape. The yellow spaghetti-like structures are groups of mitochondria, a small structure within the cell that helps convert sugars and other energy sources into the ATP that powers most proteins. Finally, the nucleus glows blue thanks to a dye called DAPI that sticks to DNA. In this case, the image is magnified at 63x, and is the merger of three separate images, one for each color.The red compound eyes of Drosophila have been such a huge part of the history of genetics, they're almost iconic. But for all of its early existence as a maggot, the fly uses a completely different set of eyes; the adult eyes only form while it's tucked away in a pupal case. This image captures the developing adult eye, showing its array of light-sensitive cells in (of course) red. These cells send signals back to the brain (green) using a huge bundle of axons, colored blue. That bundle of axons is much larger, relative to the eye itself, than the optic nerve we use to connect our eyes to the brain. This is another confocal image, and was probably made by flattening a z-stack of images, which is why there's such a good sense of depth.If you told me this was a computer generated image of a mothership hovering over a planet's surface, I would have believed you. Instead, I had to look up desmids, which turned out to be a form of green algae. I would have guessed this is a cell in the process of dividing, but it turns out that one of the characteristic features of desmids is that they're a single cell divided into two compartments. (See, even I'm learning something from this.) Desmids are so tiny that this image was taken at 100x power. The green backdrop? It's a moss.This image of an ant is much closer to life-sized, with only a 5x magnification. It's a pretty standard photo of an animal that everybody knows well, carrying its young (a pose I recall from my grad school days, when some ants tried to house their young in my shower). But the beauty is in the details, as the image stacking technique beautifully captures the delicate filaments and the fine details of the ant's antennae.Fossils, on their own, are pretty spectacular. But the mineralization of the sediments that often surrounds them adds a chance that they'll turn into something that more closely resembles a work of art. That's what happened in this case, where fossilized snail shells and ostraods have been embedded in a spectacular looking agate, which has since been sliced open and polished. The microscopy equipment needed to bring this to the fore is pretty minimal.When you work on animal development, you get used to watching tissues like a limb or spinal cord start out looking like a somewhat amorphous, cartoonish version of their later selves. Normally, this sort of thing is limited to the embryo, which is why biologists tend to be the only ones who see it. But for plants, this sort of developmental unfolding can literally take place thousands of times every year. In this particular case, the microscopists has captured a flower in the process of forming, with its various parts building up the cells needed to construct a colorful bloom, but still compressed into a compact form. A bonus is that it's a plant we don't even think about in terms of flowers: garlic.When the very first microscopes were made, their developers often turned them on a sample of water from a local source. Much to their surprise, the water was teeming with life. (You can now read one of the earliest descriptions online.) They had to attempt to capture what they saw by sketching it. We no longer face that kind of limitation, which is why we can look at spectacular images like this, at a magnification (400x) that the original microscopists never dreamed of. This image was taken with differential interference contrast, a technique that (as its name suggests), increases the contrast between objects, including ones that otherwise appear transparent. It also gives may structures a three-dimensional appearance, as you can see in the ciliated cells at center.This is a frond of red algae, captured in a darkfield image, where any area that doesn't have signal appears black. There's not a lot to say about it other than it seems to blur the boundaries between life and art.If you find that you disagree with any of the choices made by the judges of this contest, Nikon is accepting votes for alternative winners on its Facebook page.Wellington Secondary School has always been full of passionate citizens of the global community. Every year, the Student Council, environmental club, and other groups in the school devote time and energy towards projects that contribute supplies and finances to worthy causes. Wellingtonâ€™s focus for many years has been humanitarian charities. This year we have expanded our focus so our initiatives address not only humanitarian concerns but also environmental issues. The environmental club initially worked to help keep a local stream healthy, removed invasive species from parks, and conducted fish surveys. Â Now the club is taking on its greatest project yet, the building of aquaponics system in the schoolâ€™s inner courtyard.We hope to create a fully self-sustained system that promotesÂ Â  Aquaponics as a tool in Island food security.Â  In order to do this we are asking for community involvement.Â  We hope you will give us a discount on two deep cycle batteries so that we can run all of our pumps on Solar power.Â  We are very willing to publish thank you statements to your company in our contact with parents, the press and in our grant proposals.Â  We are also willing to mount a plague on our equipment.Â  Please go to Wellington Aquaponics @facebook to see more information.Â  The Aquaponics Project plans have been altered many times in order to construct the best possible blueprint for the project. What was originally going to be a 20ft wall covered in plants has morphed into what will become a smaller plant-covered wall attached to a tank. Water will be pumped up the vertical plant-covered wall and flow down into a large tank containing fish. The fish produce ammonia, which bacteria convert into nitrate. When the water from the tank is pumped, the plants on the wall benefit from the nitrate in the water and filter the water before it goes back into the fish tank. This system will be free of artificial fertilizers making it entirely natural.The positive outcomes from this project are numerous. We will grow eatable plants on the wall and raise tilapia fish so that what is produced by the Aquaponics System can be used by Wellingtonâ€™s cooking classes. Once the project is firmly established we can experiment with raising trout to maturity, which the school could contribute to help the repopulation of lakes and streams. The plants on the wall will act as a natural insulator, lowering school heating costs as well as reducing energy usage. As well as directly benefitting the environment, the system will provide students with the opportunity to get involved and to learn more about the environment through firsthand experience.One of the goals of the Aquaponics Project is to educate the public about the benefits of aquaponics. We want the community to know what we are doing and how they can help us and the environment. To reach this goal, we have created a MP4 video to present an understandable yet detailed description of the project. Because the multimedia form we chose is easy to upload to our online site, our Twitter page, and our Facebook page, we are able to spread the word through technology. The video shows images of hardworking students enjoying the work they are doing. This is fitting seeing as the spirit of the Aquaponics Project lies with the passion of the students.Wellington is proud of the work our environmental club has done on this project. We will continue to work towards our projects goals â€“ to efficiently build the system, educate the public, and promote sustainability in our school and greater community.We're looking for Linux gamers to install and test our new Steam for Linux client. We are primarily interested in experienced Linux users.In order to take the survey or update your existing submission, you need to first login with your Steam account to link your response with your Steam ID.Note: You must have cookies enabled in your browser to continueClick here to login with your Steam accountApple appears to have altered a service which was finding prostitutes for users in China.State-run China Daily reported that, when asked, the voice-activated assistant Siri directed users to brothels, despite prostitution being banned in the country.It prompted millions of comments from users, becoming a hot topic on Sina Weibo, the Chinese version of Twitter.Now Siri has changed its responses, offering no advice.Nearly nine million users of Sina Weibo have commented on the function since the Mandarin version of Siri was launched in the summer.Chinese lawyers questioned whether the escort services and brothels provided by Siri were "endangering social stability".China is the second biggest market for Apple after the US.One user of Sina Weibo pointed out that Siri seemed to be more efficient at finding brothels than restaurants that serve typically Chinese dishes."When I ask Siri about beef noodle soup or hotpot, she has no idea," the user wrote.Another commented: "A mobile phone can know all this while the police do not?"According to China Daily, the police have not been able to assess whether the answers given by Siri were accurate.Best smartphone?By the beginning of the week, Apple appeared to have acted and now, when asked about brothels, Siri replies with more diplomatic responses such as "There seems to have been a mistake" or "I didn't find anybody by that name".At the time of publishing Apple had not responded to requests for a comment.It is not the first time that Apple has intervened over its digital assistant Siri.Last year it was forced to deny claims that Siri was anti-abortion, following reports that it failed to located nearby abortion clinics in the US and, in some cases, suggest pregnancy advice centres as an alternative.And in the summer Apple became embroiled in a row with Nokia when Siri appeared briefly to favour the Finnish smartphone over the iPhone.When asked "what is the best smartphone ever", Siri replied that it was the Nokia Lumia 900.But the response was shortlived, changing to the more jokey: "Wait - there are other smartphones?"The change prompted Nokia to accuse Apple of overriding the software, something that the iPhone maker would not confirm.As Hurricane Sandy barrels up the coast, many in the United States hope the storm veers right and heads â€œsafely out to seaâ€?, but for a few people, there is nothing safe about this possibility.When a hurricane approaches port, ship captains must make hard decisions about speed and direction of approaching storms. The worst place for a ship to find itself is in the eye of a major hurricane, but the second worst place is theÂ harbor.â€œThe term Safe Harbor doesnâ€™t pertain to storms the size of Hurricane Sandy,â€? says CaptainÂ John Konrad, who has experienced hurricanes first hand. â€œThe safest place for a ship is out to sea and as far away from the storm as possible.â€?Ships are built with hardened steel, but if left tied up to the dock, they can be easily damaged as waves push them against concreteÂ pilings. Â If a ship were to break loose from the dock, it would turn into a floating wrecking ball.For this reason, the United States Coast Guard recently closed most ports along the hurricane path and ordered all ships to leave port and head east at the best possible speed.With top speeds ranging between 15 and 30 miles per hour, commercial ships donâ€™t move very fast. Â Their only hope is to leave early enough to cross ahead of the hurricane path, hoping they donâ€™t get nailed by the storm. But this is not like a foolish teenagerâ€™s game of chicken with an approaching train. Â Hurricanes do not move on tracks and even the smallest veering of a storm in the direction of the ocean (east) will cause ships to get caught in its destructive path.â€œWhen battling a storm at sea, sizeÂ andÂ mass are your friend. Ships are built of heavy steel and designed to be capable of riding out most storms. â€? says Konrad. â€œ Even the largest ships however, like the 1,302 foot long,Â Â 170,974 ton container ship, Emma Maersk, can sink if she is beaten by massive waves for too long a period of time. This is why shipping companies keep a close eye on their ships and the path of all developing stormsâ€?.In theÂ CopenhagenÂ headquarters of Maersk, there is a room that looks more like a NASA control center than the offices of a major shipping company. Ship captains,Â meteorologistsÂ and executives sit behind banks of phones and computers while massive hurricane maps plotted with the location of every ship inÂ theÂ companyâ€™s fleet, are projected on the wall. Information from NOAA gets combined with weather data from the ships and experts in the movement of storms send alerts to each individual ship with guidance on the best route to take for avoiding the storm.With new mega-shipsÂ costingÂ hundreds of millions of dollars and with lives at stake, companies like Maersk spare no time or expense in providing weather advice and guidance to individual ship captains. But advice is all they can provide. â€œAt the end of the day,â€? says Konrad, â€œthe decision on where to pilot the ship is made by the ship captain. He is the person ultimately responsible for avoiding the storm.â€?The following video is an interview withÂ Steffen Conradsen, Head of Global Execution at Maersk Line, the worldâ€™s largest containership owner. Â ConradsenÂ gives us some insight into the decision-making process when ships encounter storms like Hurricane Sandy.For more information, video and pictures of ships caught in the hurricane check out gCaptain.comâ€˜s official shipping and transportation blog here on Forbes.Hurricane Sandy: How do Maersk ships ride out the storm?HootSuite just took another big step towards becoming the one dashboard you need to manage your social news feeds.The company announced Tuesday that it has added support for five additional social platforms including Reddit and StumblUpon to its social media dashboard. Now, users can view and share content from both of these services directly from HootSuite.With the Reddit add-on, users can see a stream of the most popular posts on the social news website, as well as any subreddits they may be subscribed to, and share posts to their social networks. Likewise, the StumbleuUpon add-on lets users view pages from the social network in their HootSuite stream and track how many times a page has been Stumbled.In addition to Reddit and StumbleUpon, HootsSuite added support for Scoop.it, CMP.LY and Nexalogy. In total, Hootsuite now offers support for 35 applications, including Flickr, Tumblr, YouTube and Instagram.SUNNYVALE, CA--(Marketwire - Oct 29, 2012) - Â In a bold strategic move, AMD ( NYSE : AMD ) announced that it will design 64-bit ARM technology-based processors in addition to its x86 processors for multiple markets, starting with cloud and data center servers. AMD's first ARM technology-based processor will be a highly-integrated, 64-bit multicore System-on-a-Chip (SoC) optimized for the dense, energy-efficient servers that now dominate the largest data centers and power the modern computing experience. The first ARM technology-based AMD Opteronâ„¢ processor is targeted for production in 2014 and will integrate the AMD SeaMicro Freedomâ„¢ supercompute fabric, the industry's premier high-performance fabric.Â AMD's new design initiative addresses the growing demand to deliver better performance-per-watt for dense cloud computing solutions. Just as AMD introduced the industry's first mainstream 64-bit x86 server solution with the AMD Opteron processor in 2003, AMD will be the only processor provider bridging the x86 and 64-bit ARM ecosystems to enable new levels of flexibility and drive optimal performance and power-efficiency for a range of enterprise workloads."AMD led the data center transition to mainstream 64-bit computing with AMD64, and with our ambidextrous strategy we will again lead the next major industry inflection point by driving the widespread adoption of energy-efficient 64-bit server processors based on both the x86 and ARM architectures," said Rory Read, president and chief executive officer, AMD. "Through our collaboration with ARM, we are building on AMD's rich IP portfolio, including our deep 64-bit processor knowledge and industry-leading AMD SeaMicro Freedom supercompute fabric, to offer the most flexible and complete processing solutions for the modern data center.""The industry needs to continuously innovate across markets to meet customers' ever-increasing demands, and ARM and our partners are enabling increasingly energy-efficient computing solutions to address these needs," said Warren East, chief executive officer, ARM. "By collaborating with ARM, AMD is able to leverage its extraordinary portfolio of IP, including its AMD Freedom supercompute fabric, with ARM 64-bit processor cores to build solutions that deliver on this demand and transform the industry."The explosion of the data center has brought with it an opportunity to optimize compute with vastly different solutions. AMD is providing a compute ecosystem filled with choice, offering solutions based on AMD Opteron x86 CPUs, new server-class Accelerated Processing Units (APUs) that leverage Heterogeneous Systems Architecture (HSA), and new 64-bit ARM-based solutions.This strategic partnership with ARM represents the next phase of AMD's strategy to drive ambidextrous solutions in emerging mega data center solutions. In March, AMD announced the acquisition of SeaMicro, the leader in high-density, energy-efficient servers. With this announcement, AMD will integrate the AMD SeaMicro Freedom fabric across its leadership AMD Opteron x86- and ARM-technology based processors that will enable hundreds, or even thousands of processor clusters to be linked together to provide the most energy-efficient solutions."Over the past decade the computer industry has coalesced around two high-volume processor architectures -- x86 for personal computers and servers, and ARM for mobile devices," observed Nathan Brookwood, research fellow at Insight 64. "Over the next decade, the purveyors of these established architectures will each seek to extend their presence into market segments dominated by the other. The path on which AMD has now embarked will allow it to offer products based on both x86 and ARM architectures, a capability no other semiconductor manufacturer can likely match."At an event hosted by AMD in San Francisco, representatives from Amazon, Dell, Facebook and Red Hat participated in a panel discussion on opportunities created by ARM server solutions from AMD. A replay of the event can be found here as of 5 p.m. PDT, Oct. 29.About AMDAMD ( NYSE : AMD ) is a semiconductor design innovator leading the next era of vivid digital experiences with its groundbreaking AMD Accelerated Processing Units (APUs) that power a wide range of computing devices. AMD's server computing products are focused on driving industry-leading cloud computing and virtualization environments. AMD's superior graphics technologies are found in a variety of solutions ranging from game consoles, PCs to supercomputers. For more information, visit http://www.amd.com.AMD, the AMD Arrow logo and combinations thereof, are trademarks of Advanced Micro Devices, Inc. Other names are for informational purposes only and may be trademarks of their respective owners.This release contains forward-looking statements, concerning among other things: AMD's strategy and future products, including the features and timing of production of these products, which are made pursuant to the safe harbor provisions of the Private Securities Litigation Reform Act of 1995. Forward-looking statements are commonly identified by words such as "would," "may," "expects," "believes," "plans," "intends," "projects," and other terms with similar meaning. Investors are cautioned that the forward-looking statements in these presentations are based on current beliefs, assumptions and expectations, speak only as of the date of these presentations and involve risks and uncertainties that could cause actual results to differ materially from current expectations.Â The material factors that could cause actual results to differ materially from current expectations include, without limitation, the following: that Intel Corporation's pricing, marketing and rebating programs, product bundling, standard setting, new product introductions or other activities may negatively impact our plans; that we may be unable to develop, launch and ramp new products and technologies in the volumes that are required by the market at mature yields on a timely basis; that our third party foundry suppliers will be unable to transition our products to advanced manufacturing process technologies in a timely and effective way or to manufacture our products on a timely basis in sufficient quantities and using competitive process technologies; that we will be unable to obtain sufficient manufacturing capacity or components to meet demand for our products or will not fully utilize our projected manufacturing capacity needs at GFs microprocessor manufacturing facilities; that our requirements for wafers will be less than the fixed number of wafers that we agreed to purchase from GF in 2012 or GF encounters problems that significantly reduce the number of functional die we receive from each wafer; that we are unable to successfully implement our long-term business strategy; that customers stop buying our products or materially reduce their operations or demand for our products; that we inaccurately estimate the quantity or type of products that our customers will want in the future or will ultimately end up purchasing, resulting in excess or obsolete inventory; that we are unable to manage the risks related to the use of our third-party distributors and add-in-board (AIB) partners or offer the appropriate incentives to focus them on the sale of our products;Â that we may be unable to maintain the level of investment in research and development that is required to remain competitive; that there may be unexpected variations in market growth and demand for our products and technologies in light of the product mix that we may have available at any particular time; that we will require additional funding and may be unable to raise sufficient capital on favorable terms, or at all; that global business and economic conditions will not improve or will worsen; that demand for computers will be lower than currently expected; and the effect of political or economic instability, domestically or internationally, on our sales or supply chain.Because our actual results may differ materially from our plans and expectations today, we encourage you to review in detail the risks and uncertainties in our filings with the Securities and Exchange Commission, including but not limited to the Quarterly Report on Form 10-Q for the quarter ended June 30, 2012."With its planned 64-bit ARM solutions, AMD brings the experience of a proven enterprise CPU provider to the ARM ecosystem," said Jimmy Pike, vice president and senior fellow of the Dell Data Center Solutions group. "ARM has the promise of being a serious player in areas like web front-end servers and as a worker node in a Hadoop environment.Â AMD's opportunity is to deliver serious value in performance-per-dollar and performance-per watt-where low-power server platforms running massively scale out workloads can shine. The availability of 64-bit ARM solutions is an essential milestone needed to accelerate enterprise adoption of this technology.""In order to handle evolving workloads, business demands and the information explosion, enterprises are looking for flexible compute solutions that drive optimal performance and reduced energy consumption," said Paul Santeler, vice president and general manager, Hyperscale Business Unit, Industry Standard Servers and Software, HP. "As part of HP's Pathfinder Program, AMD and HP are continuing their decade-long relationship to innovate power-efficient computing with the development of a rich ecosystem of highly energy-efficient, dense server technology.""The ecosystem for hyperscale computing is starting to take shape as workloads quickly evolve.Â Red Hat and AMD have been at the forefront of this movement, and today we are announcing our collaboration efforts to support the next-generation ARM-powered 64-bit architecture, ARMv8," said Jon Masters, Chief ARM Architect, Red Hat.Â "This is only the first step, and we're excited about sharing our enterprise Linux expertise with AMD and the ecosystem as they are striving to become a disruptive force for choice in the emerging ARM-based server market.Â As part of this effort, Red Hat's ARM team is looking forward to supporting AMD's processors in a future release of Fedora, our community-powered Linux distribution."Whoever wins the presidential election will command not just a military with a bigger budget than the militaries of the next ten nations combined, but a â€˜homeland securityâ€™ surveillance state which we taxpayers have paid nearly $700 billion to construct.Central to the intelligence dragnet is the National Counterterrorism Center (NCTC), which was established in 2004 to â€œserve as the nationâ€™s primary organization for analyzing and integrating all foreign and domestic terrorism-related intelligence possessed or acquired by the United States.â€?If the NCTC has not been on your radar before, you should pay close attention to it now. According to The Washington Postâ€™sGreg Miller, the NCTC is the designer and host of a futuristic â€œnew blueprint for pursuing terrorists, a next-generation targeting list called the â€˜disposition matrixâ€™,â€? which will not just provide names for kill lists, but map plans â€œfor the â€˜dispositionâ€™ of suspects beyond the reach of American drones.â€?And donâ€™t think what goes on at the NCTC only concerns the â€œbad guys.â€?Think instead of all the personal information that is collected about you and held in various databases. As ACLU staff attorney Alexander Abdo has written, under its new 2012 guidelines, â€œthe NCTC could potentially combine all the databases that store that sensitive and private information into a single, massive searchable and data-minable database.â€?He goes on:â€œThe guidelines accomplished this sweeping transformation of the NCTCâ€™s data-mining abilities primarily by allowing the NCTC to intentionally collect data on US citizens even where those people have no suspected ties to terrorism, and to keep that data for 5 years.â€? Before the guidelines were changed on March 22, 2012, data about ordinary Americans with no link to terrorism had to be discarded within 180 days.From the start, the NCTC has been a mega fusion center by design in search of an identity. And now it has emerged as nationâ€™s leading practitioner of â€˜Total Information Awareness.After the 9/11 Commission called for the establishment of a new intelligence unit which would compile â€œall-sourceâ€? information on terrorism and at the same time plan counterterrorism activities, the NCTC was established by Executive Order 13354 in August 2004. It was given an expansive statutory charter and placed in the newly-created Office of the Director of National Intelligence (ODNI) by the December 2004 Intelligence Reform and Terrorism Prevention Act.As befitting its dual information collection/operation planning mission, its director (now former NSA general counsel Matthew Olsen) has a unique dual reporting role. He reports to the Director of National Intelligence when dealing with the collection and analysis of intelligence and directly to the President for planning joint counterterrorism operations. In time, this access to the White House would make the NCTC a logical choice for â€œdisposition matrixâ€? activities.But first, the new bureaucracy needed to muscle its way into territory locked down by various intelligence agencies, most prominently, the CIA Counterterrorism Center, which had in 2003 collaborated with the FBI, DHS and DOD to set up a new Terrorist Threat Integration Center (TTIC).Eventually, the TTIC was integrated with the NCTC, and agents from the CIA, FBI, DOD, State Department, Treasury, National Geospatial Intelligence Agency among many other government agencies were enlisted as NCTC collaborators.But not everyone was happy with the results.In the spring of 2006, Rep. Bennie Thompson, a member the House Committee on Homeland Security, wrote an article for a law journal entitled â€œThe National Counterterrorism Center: Foreign and Domestic Intelligence Fusion and the Potential Threat to Privacy.â€?He warned that having the CIA, FBI and other agencies at the same table could pose a major threat to constitutional rights:â€œIn the NCTCâ€™s zeal to help root out terrorists and their plans, it is possible that the rules of foreign intelligence gathering, which are largely free of civil liberties concerns, will overtake traditional rules that apply to both domestic intelligence and law enforcement operations. Given the risk of â€˜mission creep,â€™ Congressional oversight alone will not ensure that the NCTC will adequately respect privacy rights.â€?And would it protect national security? In mid 2006, Karen DeYoungÂ in the Washington Post described a counterterrorism infrastructure â€œthat has become so immense and unwieldy that many looking at it from the outside, and even some on the inside, have trouble understanding how it works or how much safer it has made the country.â€?During the next few years, the safety issue would move from a behind-the-scenes concern to a public scandal.The NCTC was the keeper of the giant TIDE (Terrorist Identities Datamart Environment) system, which had by January contained the identities of some 500,000 people suspected of terrorist ties.According to Rep. Brad Miller, the chairman of the House Committee on Science and Technologyâ€™s Subcommittee on Investigations and Oversight, â€œthe TIDE database is suffering from serious, long-standing technical problemsâ€? and the supposed â€œfixâ€? represented by the $300 million Railhead software â€œwill leave our country more vulnerable than the existing yet flawed system in operation today.â€?TIDE, he wrote to the Inspector General of the ODNI on August 21, 2008, was unable to properly process tens of thousands of â€œpotentially vital CIA messages.â€? It contained fundamental design flaws that made the data in the system difficult or even impossible to search. It had a tendency to crash, and â€œthere is no fool proof way to ensure that only good data gets into the TIDE database and unqualified data stays out.â€?Just over a year later, the nationâ€™s intelligence flaws hit the headlines.After the father of a 23-year-old Nigerian national, Umar Farouk Abdulmutallab, told the US Embassy in Abuja as well as CIA officials about his sonâ€™s possible ties to extremists in Yemen, the youthâ€™s name was placed in the TIDE database.Despite the fact that Abdulmutallab had been listed on a UK watch list in May 2009, and despite intelligence about a plot involving a â€œNigerianâ€? trained in Yemen, his name was never moved from the TIDE system to the master watch list in the Terrorist Screening Center, maintained by the FBI, a NCTC partner. The giant US intelligence apparatus was therefore none the wiser when, on Christmas Day 2009, Abdulmutallab boarded a plane for Detroit with an explosive device in his underwear.Judging from thereport on the NCTC which Richard Best prepared for the Congressional Research Service in December 2011, questions about the appropriate role of the NCTC, about its relationship with the CIAâ€™s Counterterrorism Center and its ability to â€œconnect the dotsâ€? in a timely manner remain unanswered.Some 16 different agencies are now involved in NCTC information collection and analysis, and more than half of its staff of 500 are on detail from other agencies. Best highlights the problem of different bureaucratic cultures, and the fact that people who work there can be more loyal to their own agencies. He points to concerns that the NCTC approach â€œmay jeopardize privacy rightsâ€? especially in the case of â€œhome-grown terrorists.â€?Just how accurate is the information in the TIDE database?A recent Congressional subcommittee report on fusion centers suggests that being in the TIDE database is not necessarily a red flag for Department of Homeland Security officials. â€œWhile reporting information on an individual who is listed in the TIDE database sounds significant, the Subcommittee found that DHS officials tended to be skeptical about the value of such reporting, because of concerns about the quality of data contained in TIDE.â€?NCTC head Matthew Olsen told the Senate Homeland Security Committee on September 19, 2012 that key reforms have been undertaken to improve â€œNCTCâ€™s receipt, processing, and quality of information sharing.â€?How? By â€œtaking a more aggressive and innovative approach to seek methodologies and data repositories to ingest biographic, biometric, and derogatory information. As the threat continues to evolve, our watchlisting experts are proactively working with NCTCâ€™s Pursuit Group and the counterterrorism community to expedite the sharing of information to build more complex terrorist identities. We have also enhanced our ability to store, compare, match, and export biometrics such as fingerprint, facial images and iris scans.â€?So we now know that the NCTC has a â€˜Pursuit Groupâ€™ set up â€œto develop tactical leads and pursue terrorism threatsâ€? and is in hot pursuit of biometric data. We also know that â€œthe community watchlisting guidance was revised in 2010 to provide flexibility to push forward information that previously had not met the requirements.â€?Community watchlisting guidance? NCTC director Olsen hastens to add the following:â€œNevertheless, nominations of US persons to a watchlist must still be supported by â€˜reasonable suspicionâ€™ that the person is a â€˜known or suspected terrorist,â€™ and a person cannot be watchlisted based solely upon a First Amendment protected activity.â€?Coming immediately after his claim that the FISA Amendments Act was â€œthoughtfully crafted and carefully implemented to ensure the privacy and civil liberties of Americans are protected,â€? and his insistence that the newly-adopted NCTC guidelines â€œensure we protect civil liberties and privacy when executing our mission,â€? Olsenâ€™s rhetorical nod to constitutional rights seems unlikely to reassure Rep. Bennie Thompson, for one.And needless to say, the existence of a â€œdisposition matrixâ€? never gets a mention.January this year the U.S. Government destroyed Megaupload, but founder Kim Dotcom is a not done with the file-hosting business yet and is preparing a comeback with something bigger and better. Over the past months a group of coders have been working hard on the new â€œMegaâ€? venture and Dotcom announced today that the raid-proof service will launch exactly one year after Megaupload was shut down.With 50 million visitors per day at its peak, Megaupload was one of the largest websites on the Internet.This abruptly ended January this year when the U.S. Government took down the file-hosting service and had several key employees arrested including founder Kim Dotcom.Despite ongoing criminal proceedings Dotcom and his team are determined to launch a new Megaupload, which will simply be called â€œMegaâ€?.Initially the new Mega was expected to launch in 2012, but according to the latest information the launch is now scheduled for January 19 2013, exactly one year after Megaupload was shut down.â€œThe new Mega will launch exactly 1 year after the raid,â€? Dotcom announced a few hours ago, adding that thereâ€™s a Doomsday launch button in place, a reference to the device U.S. authorities claimed could have been in place to self-destruct the old Megaupload in the event of a raid.Previously Dotcom said that the coding work for the new Megaupload was nearly finished and that the servers had been ordered. Investors are lining up to join the new venture that Dotcom has described as a â€œmassive global network.â€?â€œAll non-US hosters will be able to connect servers & bandwidth,â€? he explained.According to Dotcom we can expect a Mega with an even greater range of applications than just file-sharing. Developers of file managers are being encouraged to get in touch for early API access, and Dotcom is also calling out to those involved in email and fax tools, VOIP and video apps.For users the new Mega will also mean more security. Uploaded files will be encrypted using the AES algorithm. Users will then be provided with a unique decryption key giving them sole responsibility for who can have future use of their files.Former Megaupload users who expect â€œMegaâ€? to give them access to their old files will be disappointed. While Megaupload is trying to convince the court to help users retrieve their old files, the new Mega is going to start from scratch.One detail that still remains a secret is the domain name the new Mega will be operating on. Megaupload.com remains seized and is therefore unavailable.Dotcom told TorrentFreak that he hasnâ€™t made a definite choice for a domain yet. He did register a few options this summer that would be fitting for the new service, and his other upcoming project Megabox.Whatever the choice turns out to be, January 19 is going to be an eventful date once again.The new version of Windows is now available on store shelves, and we have the complete lowdown on Microsoft's latest operating system. Join us as we thoroughly dissect the Windows 8 UI (Metro), Apps, Desktop, Gestures, IE10, SkyDrive, and Windows Store.During the past year, all corners of the technology community were abuzz with news, rumors, and opinions regarding Windows 8. The vast majority of that chatter involved the operating system's completely new tile-based user interface. Up until the end of this summer, the new UI was referred to as Metro. But Microsoft's marketing department decided to change the interface's name to Windows 8 UI.Big logo, right? Well, perhaps that's fitting, since Windows 8 is the biggest thing to happen to Windows since...well, windows. At this point, Microsoft could quite justifiably change the operating system's name to Tiles.As the resident â€œLinux guy,â€? I'm no stranger to drastic changes and bizarre user interfaces, though. I've seen plenty of both in Linux, and the shift to something new no longer scares me. Naturally, then, I was tasked with writing our Windows 8 review.My first foray into Windows 8 was with the Developer Preview released back in September of last year. Like (seemingly) everyone else, I was taken aback by the changes Microsoft presented in its then-Metro UI. But I thought, "Hey, it's just a developer preview. Most of this will probably change anyway."Next came the Consumer Preview in February. This release actually moved Windows 8 further away from the classic Windows experience. I rationalized the changes yet again. After all, it was just a beta, and carrying the label ofConsumer Preview, maybe it would yield enough negative feedback that Microsoft would have no choice but to reverse direction.Then, in May, Microsoft released its Windows 8 ReleasePreview. Surely this one would address the serious workflow and usability issues that bloggers were publicly skewering. Nope, not even close.Finally, a 90-day trial of Windows 8 Enterprise Edition was made available this past August, and I grabbed that too. Very quickly, I realized that Microsoft had no plans to pull the plug and back out of its bold design departure.Which brings us to the here and now: Window 8 is officially available for purchase. If you were waiting for Microsoft to jump out from behind a bush and yell "April Fools!" after all of those early peeks at the operating system, you're no doubt flabbergasted by the operating system's final form.But don't count Microsoft out too quickly. I didn't take Windows 8 very seriously until a few days ago either. But, during the course of writing this review, found my stubborn disdain turning into something else.Along with Windows 8 RTM, I had early access to two genuine Windows 8-based notebooks from Toshiba: the Satellite S955 and P845t. Between my time with those two laptops and installing Windows 8 on every x86-based platform I could find, I finally understand Windows 8, and I'm confident that I can explain it to you, too.Over the next 20 pages, we'll break down the Windows 8 UI, piece-by-piece in sometimes-sickening detail. We'll use the keyboard, mouse, and touch. We cover the installation and setup. We have the apps, the Store, and the settings. Then, we get into the "classic" desktop, following up with an exploration of how Windows 8 affects the traditional Windows experience. Plus, we show you how to either create synergy between Windows 8 UI and the desktop, or to ignore the new stuff altogether.Let's kick this story off by going over the vitals: system requirements, upgrade paths, available versions, and pricing.Google this week launched its Voter Information Tool, an online resource for information on this year's presidential election. On the site, users can locate their nearest polling place, as well as nearby early vote venues. The tool also includes information on voting rules and requirements, in addition to basic details on each presidential candidate, with links to their respective social media sites. The tool is essentially a revamped version of the US Voter Info site Google launched ahead of the 2008 presidential election, and, like its predecessor, is open source and easily embeddable.Googleâ€™s autonomous vehicle project uses a spinning range-finding unit, called lidar, on top of the car. It has 64 lasers and receivers.Used for lane-keeping and back-up assistance. Image-processing software can detect lane stripes, signs, stop lights, road signs and other objects.Used for adaptive cruise control. Reflected microwaves can identify location and speed â€” but not always type â€” of nearby vehicles.Global positioning system unit determines carâ€™s position. Accelerom- eters and wheel sensors help with naviga- tion when satellite signals are blocked.Used for assisted parking. Reflected sound waves detect distance to nearby objects. Some cars use short-range radar instead.The device creates a detailed map of the carâ€™s surroundings as it moves. Software adds information from other sensors and compares the map with existing maps, alerting the system to any differences.Sorry, but this area needs the Macromedia Flash Player - click here to download the latest versionRobots that kill. In the movies, this scenario is presented as a future in which things have gone terribly wrong. But, as revealed in the new Zoot Pictures documentary Remote Control War, such robots are no longer science fiction. Â From todayâ€™s CIA drone strikes to the next generation of armed autonomous robot swarms, killer robots are about to change our world. The question chillingly posed in Remote Control War is how this shift will affect not only warfareâ€¦.but mankind.Robotic war is already here. Every evening in Indian Springs, Nevada, an hour outside of Las Vegas, a group of ordinary-looking men and women say goodbye to their families and go to war. They fight insurgents in Afghanistan and on the mountainous borders of Pakistan. They watch, they bomb, and they kill. Sometimes their vehicles crash, but the pilots always go home to their families in the morning. They are remote control warriors.Remote Control War illustrates how warfare is being revolutionized in a monumental shift unlike anything in our human history. The current campaigns in Iraq and Afghanistan exemplify the worldâ€™s first Robotic War.Â  The American robotic fleet, almost non-existent when the US and its allies invaded Iraq in 2003, has today grown to number 7,000 robots in the air and 12,000 others on the ground.Â  Some 43 other countries, including Canada, are now using robots in combat.Military robots are appealing: they save soldiersâ€™ lives â€“ avoiding the negative publicity of planes repeatedly returning home with flag-shrouded coffins.But, as Remote Control War shows us, today's drones and robot tanks are like "the first horseless carriage" compared to new generations of robots already being developed. Robot warriors will soon move beyond taking directions - they will become autonomous, acting independently. Surveillance and other non-lethal tools will be turned into attack weapons, as the military reconfigures todayâ€™s R2-D2 and C-3PO into RoboCop and Terminator. We see in the film how this is already happening.Remote Control War producers Leif Kaldor and Leslea Mair of Regina-based Zoot Pictures (read an interview) hunt down the most up-to-date information on military robotics. They travel to Europe, Israel and across North America, gaining entry to the Pentagon, robotic production facilities and cutting-edge research laboratories. While discovering the latest technology, they pose the serious ethical questions we need to ask: When robots are used to kill human beings, what are the new rules of engagement?Robots only have the ethics with which they are programmed, and human/robot wars raise many ethical questions.Â  Does the ability to kill anyone, anywhere, using a robot, amount to lawlessness?Â  What happens when future robots can decide, on their own, whom to kill?Â  Would the military send out an autonomous swarm of micro-robots to kill an enemy?Â  Will having no casualties on your own side make going to war too easy a decision?The development and deployment of militarized robots also opens a Pandoraâ€™s Box. Currently, the West has the upper hand, but very soon, all sides will have access to remote control weapons.Â  In that frightening scenario, will robots become the futureâ€™s suicide bombers?To contribute to our understanding of what is going on right now in the world of military robotics, and the implications of these developments, Kaldor and Mair talk to such knowledgeable experts and insiders as:"This started as a documentary about military robots and ended up more like a science fiction film,â€? says Remote Control War director Leif Kaldor. â€œThe technology is almost unbelievable, yet very few people know there are thousands of robots on the battlefield right now, let alone what the next generation of lethal, autonomous robots will be capable of.â€?Kaldor adds: Â â€œWhen a leading roboticist tells you he wouldn't be worried if we had Terminators because heâ€™s far more concerned with the lethal, autonomous flying robot â€˜swarmsâ€™ that are being developed and tested right now, you know this is something weâ€™d better be aware of and talking aboutâ€¦.soon!â€?Produced by Leslea Mair and directed by Leif Kaldor for Zoot Pictures in association with CBC-TV.The feature that helps users avoid having to upload every song individually to Google's cloud will be offered free of charge to consumers, first in Europe and then in the U.S.Google announced plans today to roll out its version of a scan-and-match feature for the company's music service in Europe in two weeks and then in the United States soon after.The company was to announce the feature today, as well as other updates to Google Play entertainment media during a press event in New York that was supposed to mark the debut of the latest version of its Android operating system, according to multiple music industry sources. The search company cancelled the event due to Hurricane Sandy.Last month, CNET reported that Google was trying to obtain the licenses it needed to launch the service. Google said in a blog post that it will launch scan-and-match in Europe on November 13 and the United States soon after.Scan-and-match is the term used to describe a process whereby a user's music can be stored on the computer servers of a host service. The service can then stream songs over the Internet to the user's choice of Web-connected music players. The one deciding benefit of scan-and-match is that it saves the user from the time-consuming process of uploading each individual track to the host's servers.There's an arms race in online music to offer consumers cheaper music and more conveniences. Scan-and-match was one of the areas where Apple, Amazon, and Google were trying to one-up each other. Google certainly appears to have bested its competition in the area of price. The company said in the announcement that it would offer the scan-and-match feature free of charge to consumers.Last month, CNET reported that Google planned to offer the feature free. Apple and Amazon require a $25 annual fee for their versions of the feature. In addition to the news about scan-and-match, Google also said it was launching Google Play in Europe, and the company is offering customers the ability to buy movies -- rather than just rent -- in Canada, the U.K., France, Spain and Australia.In addition, the company has ended a year-long stalemate with Warner Music Group, one of the top three record companies. In October, when Google Music went live, it did so without that label's music.Updated at 9:30 a.m. PT to include Google's announcement on scan-and-match.Our lives are governed by centuries of advances that havenâ€™t been random, as mathematician and network scientist Samuel Arbesman argues thereâ€™s a pattern that reveals how our knowledge has changed over time.I had my first experience with the internet in the early 1990s. I activated our 300-baud modem, allowed it to begin its R2-D2-like hissing and whistling, and began to telnet. A window on our Macintoshâ€™s screen began filling with text and announced our connection to the computers at the local university. After exploring a series of text menus, I began my first download: a text document containing Platoâ€™s The Republic, via Project Gutenberg. After what felt like a significant fraction of an hour, I was ecstatic. I can distinctly remember jumping up and down, celebrating that I had this entire book on our computer using nothing but phone lines and a lot of atonal beeping.It took me almost a decade to actually get around to reading The Republic. By the time I did, the notion that I expressed wonder at such a mundane activity as downloading a text document seemed quaint. In 2012, people stream movies onto their computers nightly without praising the modem gods. We have gone from the days of early web pages, with their garish backgrounds and blinking text, to slick interactive sites with enough bells and whistles to make the entire experience smooth and multimedia based. No one thinks any longer about modems or the details of bandwidth speeds. And certainly no one uses the word baud anymore.The changes havenâ€™t ended there. To store data, I have used floppy disks, diskettes, zip discs, rewritable CDs, flash drives, burnable DVDs, even the Commodore Datasette. Now, I save many of my documents to storage thatâ€™s available anytime I have access to the internet: the cloud.The technological revolution weâ€™re currently experiencing is not a one-off, technology has been changing over the centuries. But whatâ€™s surprising is that if you look below the surface you discover that this progress is not random or erratic, it almost always follows a pattern. And understanding this pattern helps us to appreciate far more than faster download speeds or improved data storage. It helps us to understand something fundamental to our success as a species. It helps us to understand how our knowledge changes and evolves.In technology, the best-known example of this pattern is Mooreâ€™s Law, which states that the processing power of a single chip or circuit will double every year. Gordon Moore, a retired chemist and physicist as well as the co-creator of the Intel Corporation, wasnâ€™t famous or fabulously wealthy when he developed his law. In fact, he hadnâ€™t even founded Intel yet.In 1965, Moore wrote a short paper, entitled Cramming More Components Onto Integrated Circuits, where he predicted the number of possible components placed on a single circuit for a fixed cost would double every year. He didnâ€™t arrive at this conclusion through exhaustive amounts of data gathering and analysis; in fact, he based his law on only four data points.The incredible thing is that he was right. This law has held roughly true since 1965; it has weathered the personal computer revolution, the march of processors from 286 to 486 to Pentium, and the many advances since then. While further data has shown that the period for doubling is closer to eighteen months than a year, the principle stands. Processing power grows every year at a constant rate rather than by a constant amount. And according to the original formulation, the annual rate of growth is about 200%.But when processing power doubles rapidly it allows much more to be possible, and therefore many other developments occur as a result. For example, the number of pixels that digital cameras can process has increased directly due to the regularity of Mooreâ€™s Law. This ongoing doubling of technological capabilities has even reached the world of robots. Rodney Brooks, a professor at MIT and a pioneer in the field, found that how far and how fast a robot can move goes through a doubling about every two years: right on schedule and similar to Mooreâ€™s Law.Copy and paste the code below:<a href="http://www.flickr.com/photos/gsfc/8131382839/" title="NASA Satellites See Sandy Expand as Storm Intensifies by NASA Goddard Photo and Video, on Flickr"><img src="http://farm9.staticflickr.com/8475/8131382839_9c82cb8d3a.jpg" width="500" height="500" alt="NASA Satellites See Sandy Expand as Storm Intensifies"></a> <a href="http://www.flickr.com/photos/gsfc/8131382839/" title="NASA Satellites See Sandy Expand as Storm Intensifies by NASA Goddard Photo and Video, on Flickr"><img src="http://farm9.staticflickr.com/8475/8131382839_9c82cb8d3a_t.jpg" width="100" height="100" alt="NASA Satellites See Sandy Expand as Storm Intensifies"></a> [url=http://www.flickr.com/photos/gsfc/8131382839/][img]http://farm9.staticflickr.com/8475/8131382839_9c82cb8d3a_t.jpg[/img][/url][url=http://www.flickr.com/photos/gsfc/8131382839/]NASA Satellites See Sandy Expand as Storm Intensifies[/url] by [url=http://www.flickr.com/people/gsfc/]NASA Goddard Photo and Video[/url], on Flickr <a href="http://www.flickr.com/photos/gsfc/8131382839/" title="NASA Satellites See Sandy Expand as Storm Intensifies by NASA Goddard Photo and Video, on Flickr"><img src="http://farm9.staticflickr.com/8475/8131382839_9c82cb8d3a_s.jpg" width="75" height="75" alt="NASA Satellites See Sandy Expand as Storm Intensifies"></a> [url=http://www.flickr.com/photos/gsfc/8131382839/][img]http://farm9.staticflickr.com/8475/8131382839_9c82cb8d3a_s.jpg[/img][/url][url=http://www.flickr.com/photos/gsfc/8131382839/]NASA Satellites See Sandy Expand as Storm Intensifies[/url] by [url=http://www.flickr.com/people/gsfc/]NASA Goddard Photo and Video[/url], on Flickr <a href="http://www.flickr.com/photos/gsfc/8131382839/" title="NASA Satellites See Sandy Expand as Storm Intensifies by NASA Goddard Photo and Video, on Flickr"><img src="http://farm9.staticflickr.com/8475/8131382839_9c82cb8d3a_q.jpg" width="150" height="150" alt="NASA Satellites See Sandy Expand as Storm Intensifies"></a> [url=http://www.flickr.com/photos/gsfc/8131382839/][img]http://farm9.staticflickr.com/8475/8131382839_9c82cb8d3a_q.jpg[/img][/url][url=http://www.flickr.com/photos/gsfc/8131382839/]NASA Satellites See Sandy Expand as Storm Intensifies[/url] by [url=http://www.flickr.com/people/gsfc/]NASA Goddard Photo and Video[/url], on Flickr <a href="http://www.flickr.com/photos/gsfc/8131382839/" title="NASA Satellites See Sandy Expand as Storm Intensifies by NASA Goddard Photo and Video, on Flickr"><img src="http://farm9.staticflickr.com/8475/8131382839_9c82cb8d3a_m.jpg" width="240" height="240" alt="NASA Satellites See Sandy Expand as Storm Intensifies"></a> [url=http://www.flickr.com/photos/gsfc/8131382839/][img]http://farm9.staticflickr.com/8475/8131382839_9c82cb8d3a_m.jpg[/img][/url][url=http://www.flickr.com/photos/gsfc/8131382839/]NASA Satellites See Sandy Expand as Storm Intensifies[/url] by [url=http://www.flickr.com/people/gsfc/]NASA Goddard Photo and Video[/url], on Flickr <a href="http://www.flickr.com/photos/gsfc/8131382839/" title="NASA Satellites See Sandy Expand as Storm Intensifies by NASA Goddard Photo and Video, on Flickr"><img src="http://farm9.staticflickr.com/8475/8131382839_9c82cb8d3a_n.jpg" width="320" height="320" alt="NASA Satellites See Sandy Expand as Storm Intensifies"></a> [url=http://www.flickr.com/photos/gsfc/8131382839/][img]http://farm9.staticflickr.com/8475/8131382839_9c82cb8d3a_n.jpg[/img][/url][url=http://www.flickr.com/photos/gsfc/8131382839/]NASA Satellites See Sandy Expand as Storm Intensifies[/url] by [url=http://www.flickr.com/people/gsfc/]NASA Goddard Photo and Video[/url], on Flickr <a href="http://www.flickr.com/photos/gsfc/8131382839/" title="NASA Satellites See Sandy Expand as Storm Intensifies by NASA Goddard Photo and Video, on Flickr"><img src="http://farm9.staticflickr.com/8475/8131382839_9c82cb8d3a.jpg" width="500" height="500" alt="NASA Satellites See Sandy Expand as Storm Intensifies"></a> [url=http://www.flickr.com/photos/gsfc/8131382839/][img]http://farm9.staticflickr.com/8475/8131382839_9c82cb8d3a.jpg[/img][/url][url=http://www.flickr.com/photos/gsfc/8131382839/]NASA Satellites See Sandy Expand as Storm Intensifies[/url] by [url=http://www.flickr.com/people/gsfc/]NASA Goddard Photo and Video[/url], on Flickr <a href="http://www.flickr.com/photos/gsfc/8131382839/" title="NASA Satellites See Sandy Expand as Storm Intensifies by NASA Goddard Photo and Video, on Flickr"><img src="http://farm9.staticflickr.com/8475/8131382839_9c82cb8d3a_z.jpg" width="640" height="640" alt="NASA Satellites See Sandy Expand as Storm Intensifies"></a> [url=http://www.flickr.com/photos/gsfc/8131382839/][img]http://farm9.staticflickr.com/8475/8131382839_9c82cb8d3a_z.jpg[/img][/url][url=http://www.flickr.com/photos/gsfc/8131382839/]NASA Satellites See Sandy Expand as Storm Intensifies[/url] by [url=http://www.flickr.com/people/gsfc/]NASA Goddard Photo and Video[/url], on Flickr <a href="http://www.flickr.com/photos/gsfc/8131382839/" title="NASA Satellites See Sandy Expand as Storm Intensifies by NASA Goddard Photo and Video, on Flickr"><img src="http://farm9.staticflickr.com/8475/8131382839_9c82cb8d3a_c.jpg" width="800" height="800" alt="NASA Satellites See Sandy Expand as Storm Intensifies"></a> [url=http://www.flickr.com/photos/gsfc/8131382839/][img]http://farm9.staticflickr.com/8475/8131382839_9c82cb8d3a_c.jpg[/img][/url][url=http://www.flickr.com/photos/gsfc/8131382839/]NASA Satellites See Sandy Expand as Storm Intensifies[/url] by [url=http://www.flickr.com/people/gsfc/]NASA Goddard Photo and Video[/url], on Flickr <a href="http://www.flickr.com/photos/gsfc/8131382839/" title="NASA Satellites See Sandy Expand as Storm Intensifies by NASA Goddard Photo and Video, on Flickr"><img src="http://farm9.staticflickr.com/8475/8131382839_9c82cb8d3a_b.jpg" width="1024" height="1024" alt="NASA Satellites See Sandy Expand as Storm Intensifies"></a> [url=http://www.flickr.com/photos/gsfc/8131382839/][img]http://farm9.staticflickr.com/8475/8131382839_9c82cb8d3a_b.jpg[/img][/url][url=http://www.flickr.com/photos/gsfc/8131382839/]NASA Satellites See Sandy Expand as Storm Intensifies[/url] by [url=http://www.flickr.com/people/gsfc/]NASA Goddard Photo and Video[/url], on Flickr <a href="http://www.flickr.com/photos/gsfc/8131382839/" title="NASA Satellites See Sandy Expand as Storm Intensifies by NASA Goddard Photo and Video, on Flickr"><img src="http://farm9.staticflickr.com/8475/8131382839_fbee4fb25c_h.jpg" width="1600" height="1600" alt="NASA Satellites See Sandy Expand as Storm Intensifies"></a> [url=http://www.flickr.com/photos/gsfc/8131382839/][img]http://farm9.staticflickr.com/8475/8131382839_da9a3d256e_o.jpg[/img][/url][url=http://www.flickr.com/photos/gsfc/8131382839/]NASA Satellites See Sandy Expand as Storm Intensifies[/url] by [url=http://www.flickr.com/people/gsfc/]NASA Goddard Photo and Video[/url], on Flickr <a href="http://www.flickr.com/photos/gsfc/8131382839/" title="NASA Satellites See Sandy Expand as Storm Intensifies by NASA Goddard Photo and Video, on Flickr"><img src="http://farm9.staticflickr.com/8475/8131382839_da9a3d256e_o.jpg" width="3072" height="3072" alt="NASA Satellites See Sandy Expand as Storm Intensifies"></a>In Windows 8 and Windows RT, Microsoft is aiming for a pleasant out-of-the-box experience. There's an app store for filling in gaps and adding functionality that isn't provided up front, but the core apps to power your communications with friends and colleagues come bundled with the operating system. There is Mail, Messaging, Calendar, and an innovative â€œPeopleâ€? app that brings all your contacts from various sources together into one central, interactive hub.All four core apps have promise in one way or another, especially the People app, which integrates with social media sites to provide more than the basic functionality youâ€™d expect from a contacts application.Microsoft isn't trying to create a replacement for Outlook hereâ€”after all, they don't want to give users any reasons not to buy Office. In general, the apps have just enough functionality to get by. Theyâ€™re passable for casual tablet usage, but Windows 8 is for both tablets and PCsâ€”and these applications will be lackluster if you try to use them to power your whole work day. Thereâ€™s also a chance youâ€™ll run into some bugs that make life a bit more frustrating than it was in Windows 7 or on competing tablet interfaces.In this article we will look at the four core communication apps. In addition, there is now Skype, which was released a couple of days before Windows 8 as a downloadable program from the Windows Store. The presence of Skype makes the Messaging applicationâ€™s limited functionality more tolerable, and Skypeâ€™s integration into People helps turn a Windows 8 tablet into something very much like a phone. As such, weâ€™ll look at how Skype provides some crucial functionality beyond whatâ€™s strictly out-of-the-box.Iâ€™ve been using the core apps for the past few weeks, on both a tablet (the version of the Samsung Series 7 11.6â€? Slate given to Windows developers for Windows 8 testing purposes) and in a virtual machine with a traditional mouse-and-keyboard setup. Iâ€™ve been keeping the OS and applications updated to make sure Iâ€?m not missing out on any new bits of functionality or bug fixes.As mentioned, there are bugs. I wonâ€™t claim these bugs will affect everyone, or even the majority, as Iâ€™ve heard from others that theyâ€™re running the apps without incident. However, searchingÂ Microsoftâ€™s support forumÂ will show various problems with the apps, and I suffered through several of them. In particular, I had trouble starting conversations with certain contacts in the instant messaging app, and problems getting the Mail/Calendar integration to work (e.g. accepting invitations from Mail).These applications are updated through the Windows Store, which provides a simpler update method than the traditional Windows Update. We've seen the apps updated a few times in the past few weeks, adding functionality such as conversation view in e-mail. There's nothing stopping Microsoft from continuing to improve them: hopefully, future updates will fix any remaining bugs and perhaps even add some new features.Weâ€™ll start with the highlight. The People app (which originated in Windows Phone) brings together contacts from Facebook, Twitter, LinkedIn, and your e-mail accounts, including Hotmail, Exchange, and Gmail. Oddly, Yahoo Mail contacts cannot be added to People, even though Yahoo Mail can be used in the Windows 8 Mail application.Once youâ€™ve linked all those accounts to People, youâ€™ll have a sprawling mass of contacts thatâ€™s not easy to get a handle on. Luckily, thereâ€™s an option to show contacts only from certain accounts, limiting the list to, say, just e-mail contacts rather than ones from social networks. Even if you do this, it's still useful to keep the social integration intact because the app will combine your Facebook and Twitter notificationsÂ into one giant feed.Inside the application, you can see recent activity from Twitter and Facebook:There's also a notification stream that shows the last week's worth of Twitter mentions and Facebook notifications youâ€™ve received. Clicking on any one ofÂ them opens a new screen in which you can post a reply to Facebook or Twitter without having to leave the People application:On the Windows 8 Start screen, the People live tile will scroll through your most recent social notifications. This is handy, because as of yet the Windows Store has no official Facebook or Twitter application to provide those updates in the live tile format. There's one annoying side effect to this, related to the fact that clicking a live tile doesn't necessarily take you directly to the content being shown that moment by the live tile. For example, you might see a Facebook notification on the live tile, but clicking it will bring you to whichever part of the People app you've accessed most recently.Thus, I would often click the tile expecting to see my latest Facebook and Twitter updates, and find that I'd have to perform a few touch gestures to get into the notifications page I was looking for. If you go into notifications from another part of the app, it will refresh them with the latest tweets and Facebook posts. But in cases when the notifications screen was the last one you accessed, and it thus appears immediately upon opening the app, you'll have to manually refresh the page to see the latest content. This requires swiping up from the bottom or down from the top to reveal the "app bar," which includes the refresh icon.Once you've got a fully updated notifications screen, it's not exactly perfect. For one thing, the updates are truncated to less than 140 characters, so you can't see a whole tweet unless you click on it.Back to the app's main screen, you'll see your contacts:Drilling down into a single contact shows you the person's latest social updates, new photos, and the like. The app bar includes options for saving them as a favorite or pinning them to the Start screen, while swiping in from the right to bring up the charm bar lets you share the contact via e-mail. The individual contact pages, of course, also let you contact the personÂ via e-mail or IM, or call them via Skype.Throughout most of Windows 8's availability in its RTM phase, the call button wouldn't work because Skype for Windows 8 didn't exist yet. That was rectified several days ago when Skype appeared in the Windows Store. Assuming you have it installed, clicking "call" in someone's contact page now takes you to Skype and lets you call their landline or cell phone, if you've got money in your account:If the person is a Skype contact of yours, you can call them for free, of course. In that case, you'll see the option to start a voice or video call within their People page:Click call, and you've got some free video call action going:Between the integration with Skype, and blurring the lines between a traditional contacts list and social networks, Microsoft's People app is a smart take on how to provide a central hub for keeping in touch with friends and colleagues on mobile devices and PCs. While not perfect, it goes beyond whatâ€™s offered out-of-the-box in rivals iOS and Android. Unfortunately, the rest of the core communication apps in Windows 8 aren't nearly as interesting, and rarely go past the most basic features you'd expect in typical mail, messaging, and calendar applications.Upgrade to the latest Flash Player for improved playback performance. Upgrade now or more infoNEW YORK (CNNMoney) -- As Hurricane Sandy battered the Northeast on Monday, a different kind of storm was brewing in Cupertino, Calif.Apple (AAPL, Fortune 500) shook up its management team, announcing that two of its top executives had been shown the door.Scott Forstall -- responsible for the iOS software running iPhones and iPads, and often considered an heir-in-waiting to CEO Tim Cook -- is the most prominent executive departing. He'll stick around as an advisor for the rest of this year, then leave the company, Apple said in a press release.The move is a surprise: Forstall was one of the top executives at Apple over the past decade, and his team's software fuels Apple's premiere devices.Yet Forstall was also behind Apple's Maps software, a debacle that was widely mocked on social media. The debut of Maps was so disastrous that Cook issued a public apology for the app and recommended rival applications while Apple worked on improvements-- including the Google Maps software that it replaced.Siri, the iPhone and iPad's electronic personal assistant, is also an incomplete product. The service is frequently down and remains very hit-or-miss when delivering answers.A group of Apple executives will replace Forstall, each sharing some of his responsibilities.Eddy Cue, head of Apple's iTunes and iCloud services, will take over Siri and Maps. Mac OS chief Craig Federighi will take control of iOS, uniting Apple's two operating systems into one product group. And Jony Ive, Apple's head of hardware design, will be in charge of Apple's software look and feel going forward as well.Cook said the management changes will "encourage even more collaboration" between the company's hardware and software teams."We are in one of the most prolific periods of innovation and new products in Apple's history," Cook said in a written statement.Apple made a few other executive changes as well.Apple's widely criticized retail store chief, John Browett, is leaving after just nine months of the job. Since coming over from British electronic store giant Dixons, Browett has had one stumble after another, including slashing the number of workers in stores -- for which Cook also had to apologize.As the company searches for an executive to replace Browett, Cook will personally oversee the retail unit.Apple also announce that Mac hardware guru Bob Mansfield -- who planned last year to retire, but backtracked two months later -- will head a new group called "Technologies."The unit will focus on mobile devices, putting all of Apple's wireless products under one roof. Mansfield will also head the semiconductor teams, "who have ambitious plans for the future," Apple said.Upgrade to the latest Flash Player for improved playback performance. Upgrade now or more infoMIAMI -- While complaints can be heard far and wide that it's hard to find the right IT security experts to defend the nation's cyberspace, the real problem in hiring security professionals is the roadblocks put up by lawyers and human resources personnel and a complete lack of understanding of geek culture, says security consultant Winn Schwartau.Take Janet Napolitano, U.S. secretary of the Department of Homeland Security, who has said the country can't find the right people for network defense. The real problem is a misunderstanding of computer geeks, their personalities, habits and their backgrounds, said Schwartau today during his talk at the Hacker Halted information security conference here.MIAMI -- While complaints can be heard far and wide that it's hard to find the right IT security experts to defend the nation's cyberspace, the real problem in hiring security professionals is the roadblocks put up by lawyers and human resources personnel and a complete lack of understanding of geek culture, says security consultant Winn Schwartau.Take Janet Napolitano, U.S. secretary of the Department of Homeland Security, who has said the country can't find the right people for network defense. The real problem is a misunderstanding of computer geeks, their personalities, habits and their backgrounds, said Schwartau today during his talk at the Hacker Halted information security conference here.NEWS: Gartner: 10 critical IT trends for the next five yearsÂ MORE: Ernst & Young's IT Security survey shows struggle to secure mobile, social media, cloudComputer geeks are discriminated against under hiring rules and legal niceties that often categorize them as undesirables. "We do not fit the mold. We at the outer limits of normal," Schwartau said.According to Schwartau, there's a gauntlet of hiring obstacles today that actually work to discriminate against computer geeks who have the expertise to do the job of protecting government networks. Demands for college degrees and IT certifications and the ability to get IT security clearances should not be a priority in hiring, said Schwartau. "Forget education," he said, adding, "We need to re-design clearances -- they're a Cold War relic designed for nuclear secrets and 1950s crypto." The era of 9-to-5 is also over, he added.He said what's holding up hiring IT security professionals can be found in the thinking of human resources departments that frown on conditions such as attention deficit disorder and autism, or obsessive-compulsive personalities which are typical of computer geeks willing to focus on an issue through the night. And although hiring rules in place tend to go the extra mile to accept alcoholism, the slightest type of illegal drug infraction makes it tough for job applicants. "We've got to start getting politically incorrect if we want to get the job done," said Schwartau.If there are tests that need to be done to probe the basic trustworthiness of job applicants for sensitive network security jobs in government or industry, said Schwartau, it would be better to try industrial psychological profiling, making it clear that anyone that passed it and got hired would be subject to it over and over again during the time they were in their job.Computer geeks could be asked something like, "If your wife and daughter were kidnapped, will you turn against my company?" he suggested. The answer would likely need to be "yes," because "anything else is deceptive.""Do you need a secret clearance to defend a network? They say you do," said Schwartau, alluding to government rules. But the government is competing against private industry and, yes, the criminal world, for the kind of talent held by those who really know about network weaknesses.I sat staring at the screen, my emotions lodged somewhere between dumbfounded and despondent. From what I was seeing, I knew I'd made a horrific mistake, and restitution must be made immediately. I'd been told time and time again there was no going back; what's done is done, you have to accept it, there's no living in the past. But a violation this total demanded only one response from me.I had to uninstall Windows 8, and I had to do it immediately.What possessed me to put the latest version of Microsoft's flagship operating system on my home computer this past fateful weekend, I'll never know. To some extent, I'm sure, it was the persistent ministrations of my colleagues Michael Muchmore and Samara Lynn, who had been trying to sell me on Windows 8 for months. I'd dabbled in every major version since the Developer Preview, and never warmed to it, but I'd somehow succeeded in convincing myself that this time things would be different.Yet the instant I saw my entire 1,920 x 1,200 monitor consumed with only the Windows 8 update notifications â€“ the rest of the screen a field of white vast enough to drive Alaska to fits of murderous envy â€“ it was clear I'd been drastically mistaken. Windows 8 is not, by any stretch of the imagination, for me. And it's time I stopped pretending otherwise.Don't get me wrong: My feelings about it have evolved, and even softened, over the past year. At first I saw nothing of worth in this radical new spin on the tried-and-true Windows formula. But as I explored it on touch systems, rather than on my beloved (and â€“ pardon me if I brag â€“ insanely powerful) desktop PC, I began to discover some virtues in it. To my eye (and fingers), it's at least as good at driving such devices as iOS, and perhaps even better: It's slicker, livelier, and treats the user as more innately capable of making intelligent decisions.More power still revealed itself when I did additional research. Being a big traditional computer guy, I live by the keyboard â€“ and discovering and mastering Windows 8's myriad Windows key shortcuts increased and improved the level of my accomplishments. It was partially this experience, I think, that led me to believe that maybe I could deal with this on a 24/7 basis away from work.Unfortunately, the disjointed time I'd spent with Windows 8 before did not prepare me for what using it at home would entail. After (an admittedly painless) installation, I was faced with the garish Start screen, loaded with apps that didn't interest me at all. I clicked on a couple to see how I'd respond to them. The Weather and Stock apps were pretty, no doubt â€“ but did each one need to occupy upwards of two million pixels on my screen? Because all the Start apps open full-screen, too little information was looking much too big â€“ and there's no way to change this.Frustrated, I decided to check my Hotmail account (also the source of the Microsoft ID I entered while configuring Windows 8). I clicked on one new message, then another. The first wasn't marked read. Clicking on a third did mark the second one read, for some reason. I decided I wanted to file these, so I held down the mouse button and dragged the message just as on Outlook.com, but that didn't work as it had for some 17 years of Windows history. To move the message now, you have to click an icon on the bottom right of the screen to start the process; this is an unintuitive change whether you're using your finger or a mouse.I was certain that Internet Explorer must be better. Launching it revealed the ITProPortal home page, centred on my enormous display, with gaping chasms of white on each side. Naturally, I couldn't resize the window. So I went to open a new tab. Except I couldn't do that, either: One browser window per screen.I then fled to my safe haven, the Desktop â€“ now treated just as any other app. No Start button, right. But I could launch Internet Explorer here. Finally! Separate windows! Tabs! Except... things didn't look very good. The smoothly elegant rounded glass of Aero has been replaced by sharp, unfriendly two-dimensional corners I was sure had gone the way of Microsoft Bob. I moved to use Windows key-D to show my bare desktop, but my finger slipped half a second too early and I was thrown back to Start.From there, I decided maybe I should see the Control Panel. That shunted me back to the Desktop. Ditto Task Manager. Ditto any of several other deep-dive settings functions I use on a daily basis. But changing the image on the Start or Lock screens, or powering off the computer, could only be done through the new Windows 8 interface.I gritted my teeth and endured it for as long as I could, the constant schizophrenic flipping between Start and Desktop environments propelling me ever nearer to total mental breakdown. When I decided to update a few apps from the Microsoft Store, and received the indication that wasted more 90 per cent of the screen, I knew it was time for this experiment to end. I wiped the hard drive, reinstalled Windows 7, and have not looked back since.As I struggled to try to make sense of what was where, and more importantly why things were where they were, it became clearer than ever to me that Microsoft had never actually intended the Start screen and the Desktop to work together. So haphazard, so clunky, so confusing was everything, one could only conclude that all the company cared about was the touch market, and it was doing everything it could to discourage Desktop (and desktop) use once and for all.Microsoft is not necessarily wrong for doing this. With tablets and other mobile systems increasing in popularity, any tech company should be courting them. And, as far as Windows 8 and its kid cousin, Windows RT, are concerned, ruling over the kingdom of touch is a real possibility. Although I'm not sure I can really say I've liked using Windows 8 on touch devices, I can absolutely say I haven't hated it.Using it on anything else is another story. It makes everything I do more difficult. Michael and Samara have expounded at great length on what Windows 8 has to offer (see Michaelâ€™s review here), and I don't dispute much of what they have to say. But for people who want or need to use non-touch desktop or laptop computers in anything resembling the classic way, the learning curve isn't just steep â€“ it's vertical. Windows 8 was not designed to be used that way, but I was shocked at just how unfriendly it was towards me and my way of working, and how unwelcome it made me feel for wanting to do things with minimal convolution.I realise I'm not part of Microsoft's target audience anymore, but I still think power users like myself â€“ I've been using Windows for 22 years â€“ deserve better. If I've been using GUI-based operating systems for nearly three decades and this one regularly for over a year, and it still fails to suffice for basic tasks, there's something seriously wrong.The danger Microsoft faces is also the danger it's scrupulously trying to avoid: The industry isn't the same as it once was. Phones and tablets may be taking over, but Microsoft's dominance is also threatened as it's never been before. Real alternatives are getting real attention, and they've never had a better opportunity to gobble up the people Microsoft is casting aside.The latest versions of Mac OS X are far more usable and appealing than Windows 8. Many Linux distributions, starting with the well-known Ubuntu, have made rapid-fire about-faces in recent months to get themselves in shape to fill the vacuum Windows 8 has been creating. Both operating systems make multi-window multitasking a clean, smooth reality, acknowledging, as Microsoft will not, that most people still work that way.Hope for us Windows lovers, however, is not necessarily lost. Microsoft has demonstrated some ability to learn from its mistakes and come back stronger. Nearly six years ago, Windows Vista fizzled upon its release, but was redeemed by a comprehensive service pack and then, within two and a half years or so, Windows 7. There's no reason it can't weave similar magic on 2012's deeply flawed OS.But Microsoft must have the will to do so. If the future is touch, why should it waste time and resources considering how Windows 8 works with creaky keyboards and mice? What Microsoft has forgotten is that you can't get to the future without moving through the present. In trying to skip over today, the folks in Redmond have angered a lot of people â€“ and wasted their time and monitor real estate just like they've wasted mine.I've been forgiving of Microsoft's foibles and idiosyncrasies for a long time, but my patience has about run out. If Microsoft wants me to use Windows 8 or a touch system, it has to give me a concrete reason â€“ and one boring app per screen ain't gonna cut it. Otherwise, I'll stick with Windows 7 â€“ and maybe even dual-boot Linux with it at the same time. Those two operating systems together give me everything I need. Windows 8 doesn't come close. Worse still, it doesn't even try.Published under license from Ziff Davis, Inc., New York, All rights reserved.Copyright Â© 2012 Ziff Davis, IncDow Jones Reprints: This copy is for your personal, non-commercial use only. To order presentation-ready copies for distribution to your colleagues, clients or customers, use the Order Reprints tool at the bottom of any article or visit www.djreprints.comMicrosoft Corp. officially released an overhaul for its nascent Windows Phone software, in its latest attempt to catch up to Apple Inc. and devices running software from Google Inc.The new software, dubbed Windows Phone 8, will include a bevy of new features, including the ability for apps, such as those from Facebook Inc. or Groupon Inc., to display recently posted photos or the latest daily deal on the device's home screen.But Microsoft said some of the new Windows 8 phones won't launch until mid-November or later. The timing means that Microsoft could lose out on some sales in ...Ok, so this app made me feel really dirty when I downloaded it. Itâ€™s called Badabing! and it basically goes through your friendsâ€™ photos on Facebook to pull out the ones of them at the pool or beach. In other words, weâ€™re talking about scantily clad photos here.I of course, for the sake of technology journalism, had to download the app and give it a whirl. It actually kind of works and itâ€™s really creepy. To protect the innocent, Iâ€™m not going to post any actual screenshots of my Facebook friends. Theyâ€™d kill me. And probably the folks who made this app.The app is $1.99 and all you have to do is log in with your Facebook account and then choose a few friends to dig up some dirt on. The company has some sort of image recognition technology that looks forâ€¦skin?After your search is complete you can bookmark your favorite photos. Now letâ€™s get to the heart of the matter, is this wrong to do? I mean, technically, your friends have uploaded these photos and shared them with you anyway. All this app does is do a search, albeit a search with icky intent.Moral of the story, donâ€™t upload photos to Facebook and share them with friends unless you want them looking at them. Especially if youâ€™re in a bikini or tight swim trunks.Creep you out? Cool use of tech? Tell us in the comments.Visit our directory for more information about Google blogs.Federal authorities said they uncovered an advanced bank heist that defrauded Citigroup of more than $1 million by exploiting a security loophole in the way it handles electronic payments.The scam worked by simultaneously withdrawing funds from cash advance kiosks maintained in at least 11 casinos located in California and Nevada, according to an indictment unsealed late last week in federal court in San Diego. Alleged ringleader Ara Keshishyan recruited at least 13 people to make transactions from different kiosks in each location. To exploit the weakness, the multiple advance requests had to be near identical and had to be made in the same 60-second window, FBI officials said in a press release."In order to obtain the case, the conspirators exploited a loophole in Citi's account security protocols, which caused Citi's account reconciliation systems to treat identical, near-simultaneous withdrawals as duplicates of a single withdrawal from an individual Citi Checking account," prosecutors alleged in the indictment. "In exploiting this loophole, the conspirators withdrew identical sums of money in succession from a single Citi checking account all within a specific time window. This allowed the conspirators to fraudulently withdraw several times the amount of money deposited into each account."The defendants obtained more than $1 million from Citigroup, prosecutors said. To conceal the scam, they kept withdrawal below $10,000 to avoid federal transaction reporting requirements. The kiosks were operated by Global Cash Access, a Las Vegas-based financial transaction services company. They allow casino patrons to get cash that's held in personal banking accounts. The Citigroup loophole has been closed, The Press-Enterprise reported.Prosecutors said Keshishyan caused sums of $10,000 or less to be deposited into various Citi checking accounts. The conspirators he allegedly hired would then use Citi ATM cards to obtain cash amounts from the kiosks that collectively exceeded the account balances. The defendants allegedly used the stolen funds to gamble at the casinos, allowing them to receive free rooms and other perks in return for high-roller status.All 14 defendants were charged with conspiracy to commit bank fraud and conspiracy to illegally structure financial transactions to avoid reporting requirements. The maximum penalty if convicted on those charges is five years in prison and a $250,000 fine. Keshishyan has also been charged with 14 counts of bank fraud, each of which is punishable by up to 30 years in prison and a $1 million fine. Prosecutors are also seeking forfeiture of money and property belonging to the defendants.It's unknown if any of the defendants have issued a plea in the case.Hurricane Sandy may have stopped Google's Android event, but it couldn't stop the Google website. There will be no swanky event in downtown New York City, but Google's Android team has taken to a blog post to announce the latest Android devices, including the long-rumored Nexus 4 phone made by LG and Nexus 10 tablet made by Samsung.Google is also refreshing its 7-inch Nexus 7 tablet, bringing the total number of Nexus devices on the market to three.Nexus devices, unlike all the other hundreds of Android phone and tablets out there, are built in close partnership between Google and other phone or tablet makers. They are also the first devices to run the new version of Android. In this case, all the devices being announced today run Android 4.2, the next version of Jelly Bean. Android 4.2 isn't a complete overhaul of the software, but adds such features as a new keyboard, wireless video streaming services, a 360-degree photo feature, and a new Google Now service."People increasingly have more than one device, and they switch between them many times a day. Nexus â€” Google's hardware line for Android devices â€” gets rid of the hassle," Google's Senior Vice President of Android, Andy Rubin, said in the post. "Just sign in with your Google Account and everything is there ready to go, whatever device you're using: photos, emails, contacts, bookmarks, even your entertainment on Google Play."Below are details on all of the new devices:Nexus 4 (Starts at $299) The new Nexus 4 phone, which is made by LG, will replace the Samsung Galaxy Nexus phone that came out about a year ago. The phone has a large 4.7-inch screen with a high-resolution 1280 x 768 display, and a fast quad-core S4 Pro processor. The camera on the phone has also been updated (it was one of the major pain points of the last version) -- it now has an 8-megapixel camera on the back and a 1.3-megapixel camera on the front for video chatting.The $299 base version has 8GB of storage and a $349 version will have 16GB of space. For now, Google will only offer the phone unlocked through T-Mobile, meaning it won't be available through Verizon, Sprint or AT&T. That also means it will not have LTE service in the U.S.The new Android 4.2 software brings new gesture typing, "which lets you glide your finger over the letters you want to type on the keyboard," Google says. It also supports wireless video and new photo features. The phone will be available to order through Google's Play store starting today and in select T-Mobile retail stores and online on Nov. 14.Nexus 7 (Starts at $199) Moving up to the 7-inch screen, Google has slightly refreshed its Nexus 7 tablet, which it announced back in June in collaboration with Asus. The new version will run Android 4.2, but there is also a 32GB version now that will cost $249. There will be a 32GB version with HSPA+ cellular connectivity for $299. That version will work with AT&T SIM cards and service. The 16GB version with WiFi only costs $199.Apple's iPad Mini, which has a larger 7.9-inch screen, goes on sale this Friday for $329, while Amazon's Kindle Fire HD, which has 16GB of storage, starts at $199.Nexus 10 ($399) Of course, there's one more! The Nexus 10, as you might guess, has a 10-inch screen and the latest Android 4.2 software. Built by Samsung, the tablet has a high-resolution 2560 x 1600 resolution screen, similar to the Retina display on the new iPad. Internally, the tablet has a dual-core processor and 2GB of RAM. The 16GB version will start at $399.ABC News has been promised a hands-on look at the new devices. Stay tuned for more information.Icrontic has been around for twelve years. With thousands of people coming and going, variously circling in and out of the group as lives and times and interests change, old online communities like ours become a magnifying glass into the ebb and flow of the human experience.Of course, death is a natural part of that experience, and weâ€™ve had our fair share over the years. From natural causes to tragic accidents, our community has been through a lot of down moments. Thankfully, weâ€™ve also experienced the joyous news of families, new children, marriages, and career successes that far outnumber the sad times.This past week, however, hit us harder than weâ€™ve ever been hit. One of our core community members lost his father suddenly and unexpectedly, right before our annual Oktoberfest gathering. The community reeled; we didnâ€™t know how to help our dear friend cope with his shocking loss. For a man who has done so much for Icrontic over the years, we wanted to turn the tables and be there for him, but we didnâ€™t know how. All we could do is take up a collection for his family to help with the funeral costs, and to make a small donation to a local charity in his fatherâ€™s name. People sitting behind keyboards thousands of miles away, some in other countries, some on other continents, had only this one mechanism by which to extend their condolences. They canâ€™t hug their friend while he weeps, so they do the only thing they can do. They write some words, maybe they call, maybe they email, maybe they open up Paypal. What can they do? None of it seems sufficient, especially when you cannot get there. This is the only true downside of online communityâ€”when your friends need you, physically, distance can be an insurmountable obstacle.Soon after, those who could began gathering together for Oktoberfest, here in Detroit. This is an event thatâ€™s been going on for five years, and is our second largest annual community gathering. We anticipated over 50 people coming in from all over the country for this event. This was going to be an especially poignant gathering because itâ€™s the first in our new headquarters.The Icrontic gatherings have been going on since 2004. From small and humble beginnings, we have blossomed into a full-blown convention organization, culminating in Expo Icrontic every summer. Many community members save up their vacation days and travel accounts to come up, over, or down to Detroit to be with their online family. This event was going to be incredible.On the first day, tragedy struckâ€”again. What was supposed to be a fantastic party and community gathering has turned into a memorial service and an extended wake. For days now, a group of Icrontians has been together in a large house in Detroit coming to terms with the sudden loss of our friend.Itâ€™s still abstract for me to type those words out. They happened just days ago. Spencer was in my living room, fifteen feet from where Iâ€™m sitting. I hugged him hello, told him I was glad he was here, and we struck up a normal nerdy conversation. He looked around the house, proud of the work he had done to help the progress of ICHQ Detroit (he did a ton of work sanding our front entrance ceiling, helping with wall repairs, and helping scrub grout stains off our new tile in the bathroom), and marveled at how far it had come in such a short time. He was just here.I am extremely fortunate. I was here. I have extremely recent memories of Spence. I was part of the small group that last saw him alive. I feel guilty that people who were closer to him did not get that same treasure. I saw him moments before he died, and he was laughing. I have that memory and so many others donâ€™t. I feel terrible about that.I returned from the hospital after a long and horrible night, and came up to the front door. There was a group of people standing on the porch, crying. I grabbed the first person I saw and didnâ€™t let go. We wept.People milling around. From every corner of the house, you could hear either laughter or tears. Spencer was a tremendously comical person. He laughed loud and hard and often. When we tell stories of him, itâ€™s almost impossible not to laugh. You can only cry so much.Should the party go on? Should I cancel my trip? Should we do the beer tasting? What should we do?The group came to the consensus that the costume party and gaming would carry on. Spencer would definitely not have wanted us to cancel the event on his behalf, and he most certainly wouldnâ€™t want us to not game. Gaming was his greatest joy.Fuck it, we said, weâ€™re carrying on. For Spencer.I had guilt about this new sudden tragedy overshadowing the other recent tragedy, the loss of one of my best friendsâ€™ dad. I sent him a text message. â€œIâ€™m thinking about you.â€? Here is a person who is suffering alone, hundreds of miles from his Icrontic family, who has just lost his father, and now he has to deal with finding out one of his good friends died in a senseless car accident, before his fatherâ€™s memorial service is even complete. Why can I not have a magic wand? I am the community manager for this group, and more than ever I felt completely and utterly powerless. I wanted to be able to get everybody into a room together for a group hug.Being thousands of miles away when your friend dies, without enough money to get an emergency plane ticket. What can you do? You need information, you want to talk to people. The group is thereâ€”awayâ€”inaccessible. They are healing, talking, laughing, hugging, crying. You need to be a part of that, yet you cannot.The Icrontic community is the most generous online community in the worldâ€”I am convinced of that. In this past week, thousands of dollars have been raised to help with funeral expenses and plane tickets. People made discreet arrangements. People flew in. Friends arrived, and got the laughter, tears, screams, and hugs out that they so desperately needed. If only it could have been everyone. If only.There is a lot of survivorâ€™s guilt going on. Two cars left for the restaurant that night. My son was in one, and I am so, so glad he wasnâ€™t in the other. My other son decided not to come that night because he was having a party with his friends. If he had come, he almost certainly would have been in that car. I am so, so glad he wasnâ€™t. I feel terrible about that, and I am struggling with my guilt for thinking those thoughts, while at the same time understanding that itâ€™s completely rational and normal for me to have them. Group therapy has been helpful. Weâ€™re all starting to share our feelings and dark thoughts. If I had chosen a different restaurant, Spencer would be alive. If Spencer had gotten in the other side, it may have been Nick instead. If Spencer came with me. If I hadnâ€™t stopped to pee on the way out of the house. If we had left ten seconds later or sooner. If, if, if.There was a lot of speculation about the driver of the other vehicle. Violent, angry rants about revenge. Calm, rational discourse. Drunk, not drunk. Male, female. We were looking for a focus. We needed a bad guy to pin this on. We needed to make sense of this. Of courseÂ it was a loud, obnoxious, easy-to-hate drunk driver. What else could it be? Or a mother. Or a grandfather. Or a brother or cherished son with a promising career ahead of him. Maybe a teacher. Maybe a volunteer. Maybe a social worker. Maybe a drug addict or a thug. Maybe a dealer or a criminal. We donâ€™t know, so we create characters.Today we say goodbye. Today is the funeral, and today is the end of the gathering. After people grieve again, they will scatter and disperse back to their homes around the country.Icrontic is forever changed by this. We have had a unique opportunity to really come to terms with the death of a dear friend, in a group setting full of open communication, no barriers, and true companionship. We are very, very lucky for that. This is not the first tragedy in our community, nor will it be the lastâ€¦ It was, however, one of the most educational.Icrontic will carry on. For Bart, for Keith, for Angel Heather, for Ericâ€™s dad, for all the others who we have lost along the way. For Spencer.The U.S. Supreme Court on Monday considers whether to allow a challenge to a federal law that provides for large-scale electronic surveillance of international phone calls and emails. The case is not a direct test of the Foreign Intelligence Surveillance Act. Rather, it is a test of whether the law can even be challenged in court at all.How FISA Came To BeCongress first passed the law in 1978 to prevent the kind of warrantless surveillance of Americans that had been uncovered by congressional investigators. Known by the acronym FISA, it required the government to obtain a warrant from a special intelligence court when conducting electronic surveillance of individuals abroad â€” surveillance that could pick up communications to and from people in the United States.After Sept. 11, 2001, the Bush administration secretly circumvented the law. When its warrantless wiretapping was disclosed, the administration proposed legislation to quell the resulting furor. In 2008, Congress passed a new version of the law, loosening the reins considerably. It limited the FISA court's supervision, did away with the previous requirement for individual targeting, and instead allowed the government to monitor large swaths of people. Critics called it the "vacuum cleaner" approach to electronic surveillance.Groups and individuals with frequent international contacts challenged the law in court, contending that FISA, by authorizing "dragnet surveillance," violates the Constitution's ban on unreasonable searches. But Monday's Supreme Court arguments do not get to that issue. Instead, the court is focusing on a threshold question: whether the case can be brought at all because the challengers cannot prove with certainty that their communications were intercepted.Among those suing to invalidate FISA are human rights groups such as Amnesty International, journalists and lawyers for detainees. The lawyers, for instance, routinely have telephone conversations with the families of detainees, with witnesses and with investigators. The government, however, contends that without proof positive, the claims to have been spied upon are speculative, and the challengers have no legal standing to bring a case to court.The challengers counter that the government's position amounts to a Catch-22 because in a secret program, there is no way to prove you've been monitored."Their argument is you can't challenge the statute if you can't show your own communications have been acquired under it," says Jameel Jaffer, deputy legal director of the ACLU, who is representing the groups. But the government, he adds, refuses to "tell you if your own communications have been acquired under it."A federal appeals court in New York agreed with the challengers that they have suffered a concrete injury that justifies allowing the case to go forward. That court said that based on the challengers' reasonable fear of being monitored, they have largely abandoned international phone and email communications, and have spent time and money to travel overseas to meet with people in person in order to be free from government surveillance.Todd Hinnen, who served as acting assistant attorney general for National Security in the Obama administration, concedes that because of the secret nature of the surveillance, "it's very difficult for a plaintiff to make specific and concrete allegations."But, he adds, in an age of terrorism, the intelligence community needs greater latitude, and therefore Congress "consciously limited the circumstances" under which FISA can be challenged.Basically, the government argues that the civil liberties protections in the law are internal. For example, the statute requires the attorney general and National Intelligence director to periodically assess the steps taken to minimize the effect of the surveillance on U.S. citizens.But at the same time, the law does not contemplate a direct challenge in the courts. As Hinnen puts it: "It is a statute that governs foreign intelligence practices, targeting foreign citizens overseas, subjects that traditionally have been viewed as the core of Congress and the executive branch's prerogative."Jaffer, of the ACLU, replies that if the Supreme Court accepts the government's position, the justices "will be accepting that this statute is immune to the kind of judicial review that we generally think federal statutes ought to be subject to."After all, the issue being argued on Monday is not whether the law is constitutional, he observes, but "whether we have the right to challenge the constitutionality of the law."It may seem like a technicality, but it is â€” at this point â€” the whole ball of wax.The shrinking size of features on modern processors is slowly approaching a limit where the wiring on chips will only be a few atoms across. As this point approaches, both making these features and controlling the flow of current through them becomes a serious challenge, one that bumps up against basic limits of materials.During my visit to IBM's Watson Research Center, it was clear that people in the company are already thinking about what to do when they run into these limits. For at least some of them, the answer would involve a radical departure from traditional chipmaking approaches, switching from traditional semiconductors to carbon nanotubes. And, while I was there, the team was preparing a paper (now released by Nature Nanotechnology) that would report some significant progress: a chip with 10,000 working transistors made from nanotubes, formed at a density that's two orders of magnitude higher than any previously reported effort.During my visit to Watson, I spoke with George Tulevski, who is working on the nanotube project, and is one of the authors of the recent paper. Tulevski described nanotubes as a radical rethinking of how you build a chip. "Silicon is a solid you carve down," he told Ars, "while nanotubes are something you have to build up." In other words, you can't start with a sheet of nanotubes and etch them until you're left with the wiring you want.One possible alternative is to use graphene, a sheet of carbon a bit like an unrolled nanotube, which can potentially be etched into distinct features. The problem, according to Tulevski, is that graphene doesn't naturally have a bandgap, the feature of semiconductors that makes them useful for circuitry. It's possible to manipulate graphene so that it develops a bandgap, but that adds to the complexity of manufacturing devices. Some carbon nanotubes, in contrast, are semiconductors without the need for any manipulation (others are metals).This still left IBM with a choice, Tulevski said. You could potentially attempt to grow a pure population of carbon nanotubes in place, on your chip. We've gotten much better at controlling the growth of nanotubes, and IBM has equipment in house that be been used to produce them. The problem there is that, if anything goes wrong with just one of the tubes, the whole chip would be lost. We may have gotten much better, but we've not gotten that good.So, Tulevski's group is taking a different approach: buy off-the-shelf nanotubes, isolate the ones they want, and then assemble them on a chip.The first couple of steps of this is easier than it sounds. Tulevski showed off a large jar, obtained from a chemical manufacturer, that contained a mixture of carbon nanotubes. As it turns out, the two types of nanotubes, metals and semiconductors, interact differently with a standard column of the type commonly used in chemistry and biochemistry labs. Simply run a mixture down the column, and it's possible to separate out a relatively pure population of one type. To make matters even more convenient, the two populations are slightly different colors.Once you have a collection of semiconducting nanotubes, you have to build circuits out of these. If we're ever going to make processors out of them, this has to be done quickly, cheaply, and consistently. As Tulevsky described it in referring to purifying the right nanotubes, a one part-per-billion error rate just isn't good enough when you consider the number of transistors on a modern chip.The team at Watson is working on solution processing, which is where the new paper comes in. The idea is to pre-pattern the needed circuitry onto a chip using IBM's existing foundry experience. Once that's in place, a solution containing carbon nanotubes can be washed across the chip, at which point they'll drop out of solution and attach to the chip based on the pattern.In the paper, the pattern was set up by etching away silicon dioxide to reveal an underlying layer of hafnium dioxide. The HfO layer could interact with a charged organic molecule (4-(N-hydroxycarboxamido)-1-methylpyridinium iodide), creating a charged surface. The carbon nanotubes could then be floated across this surface while encased in a coating of an organic molecule with the opposite charge. A simple ion exchange reaction locks the nanotube in place above the hafnium layer.With the hafnium features at 70nm wide, this process was used to create field-effect transistors (FETs), and it worked with an efficiency of over 90 percent. The density of these FETs was 10 per square centimeter, 100 times higher than the previous reported best. And these devices could be made en masse: the researchers were able to test over 10,000 of the FETs on a single chip, and found over 7,000 functional ones (most of the rest ended up with a metallic nanotube instead of a semiconductor).This still isn't ready for chip manufacture. But it's a lot closer than most previous efforts, and gives IBM's team some obvious things to troubleshoot if they want to boost the efficiency further.The two have been benefiting from losses at rivals like Nokia and Motorola, Canaccord Genuity says, and that trend should continue.Controlling all of the mobile market's profits doesn't appear to be enough for Apple and Samsung anymore. Now they're actually generating more than 100 percent of the industry's earnings -- 106 percent, to be precise -- according to a report from Canaccord Genuity.That may seem impossible, but it's largely because rivals -- like Research In Motion, Nokia, and Motorola -- posted operating losses during the September quarter, the firm said."With Samsung extending its overall smartphone and Android market share combined with Apple's strength in high-end smartphones, competing smartphone [original equipment manufacturers] continued to struggle to compete with these dominant smartphone OEMs," Canaccord analyst T. Michael Walkley noted today.It's actually the second quarter in a row that the two companies captured greater than 100 percent of the industry's profits, Walkley added. In the second quarter, Apple and Samsung held 108 percent shareWalkley estimates that Apple captured 59 percent of the industry's operating profits in the calendar third quarter, with only 6.3 percent of global handset unit sales and 15.4 percent of smartphone unit sales.Samsung, meanwhile, controlled 47 percent of the profits, up from 37 percent in the second quarter. It held 25.6 percent of the global handset unit market share in the third quarter, up from 25.3 percent in the second quarter, in part because of strong Galaxy S3 sales. Walkley expects Samsung to maintain its leading unit market share position during the fourth quarter and beyond, continuing to supplant longtime leader Nokia.The two companies' dominance should continue in the current quarter, Walkley said, with Apple likely to take some share from Samsung during the period because of strong global demand for the iPhone 5.The numbers continue to paint a dismal picture for the handset industry at large, with barely anyone being able to make money aside from Apple and Samsung. The giants continue to dominate and squeeze rivals like Motorola while low-cost handset makers like ZTE are applying pressure on the low end.The Internet is experiencing severe outages across North American and AsiaTake in the sights from the torch balcony at the Statue of Liberty, where the public has not been permitted to visit in person since 1916, and see unique, one-of-a-kind perspectives of the torch, crown, face and tablet, in addition to ultra widescreen panoramic images and live HD streaming video. Enjoy unmatched streaming video of Lady Liberty from Brooklyn, as well. Click on the links below to learn more about the TorchCams: The Associated Press Â Â Â Â |Â Â Â Â One of the notable features announced with the release of Android 4.2 yesterday was support for multiple users on a single Android device. Google's list of 4.2 features, though, makes it very clear that multiple users is supported only on Android 4.2 tablets, not phones.TechCrunch speculates that the limitation is due to a patentâ€”US 2005/0107114 A1, "Multi-user mobile telephone," to be specific. The patent was filed in late 2004, granted in 2005, and was penned by then-current Symbian employee Tim O'Cock. The abstract makes it pretty clear that it envisions several different people, each with their own personalizations, using a single device:A mobile telephone is designed to be used by several different end-users at different times. A first end-user can alter the mobile telephone so that it operates in a manner specific to that first end-user and a subsequent end-user can alter the mobile telephone so that it operates in a manner specific to that subsequent end-user; each end-user has only to respond to prompts displayed on a screen in order to alter the mobile telephone so that it operates in a manner specific to that end-user.The USPTO lists the patent's current assignment with both Tim O'Cock and Symbian Limited, with both pointed back to Nokia. TechCrunch guesses that the original intent behind the patent was to take revenue from emerging markets by providing an easy method for lots of different folks to share a single phone; in areas of the world where cellular phones are expensive, a feature which lets several people use the same phone gives that phone a competitive advantage.It's easy to see how this patent might be a potential stumbling block to any company wanting to implement a similar feature. The patent language is broad enough to cover just about any possible implementation of multiple user accounts, and even though no Nokia phone has shown up with anything like "multiple users" on the feature list, anyone with something similar in mind would have to deal with licensing from Nokia.The loophole which Google is using to bring the feature to tablets is that the patent language very clearly states "mobile telephone" over and over again. In 2004 when the application was filed, consumer-grade tablet devices were but a twinkle in technologists' eyes (stylus-driven "tablet" notebook computers notwithstanding). The patent narrowly applies to phones, not "mobile communications devices" or anything else.However, the "freedom to tinker" mindset which pervades the Android ecosystem might win out here. If the feature is available in tablets, it is likely only a matter of time before enterprising Android 4.2 hackers (and I mean hackers in the good sense of the word) find a way to enable the functionality on their handsets.BERLIN â€” Angry Birds, the top-selling paid mobile app for the iPhone in the United States and Europe, has been downloaded more than a billion times by devoted game players around the world, who often spend hours slinging squawking fowl at groups of egg-stealing pigs.While regular players are familiar with the particular destructive qualities of certain of these birds, many are unaware of one facet: The game possesses a ravenous ability to collect personal information on its users.When Jason Hong, an associate professor at the Human-Computer Interaction Institute at Carnegie Mellon University, surveyed 40 users, all but two were unaware that the game was storing their locations so that they could later be the targets of ads.â€œWhen I am giving a talk about this, some people will pull out their smartphones while I am still speaking and erase the game,â€? Mr. Hong, an expert in mobile application privacy, said during an interview. â€œGenerally, most people are simply unaware of what is going on.â€?What is going on, according to experts, is that applications like Angry Birds and even more innocuous-seeming software, like that which turns your phone into a flashlight, defines words or delivers Bible quotes, are also collecting personal information, usually the userâ€™s location and sex and the unique identification number of a smartphone. But in some cases, they cull information from contact lists and pictures from photo libraries.As the Internet goes mobile, privacy issues surrounding phone apps have moved to the front lines of the debate over what information can be collected, when and by whom. Next year, more people around the world will gain access to the Internet through mobile phones or tablet computers than from desktop PCs, according to Gartner, the research group.The shift has brought consumers into a gray legal area, where existing privacy protections have failed to keep up with technology. The move to mobile has set off a debate between privacy advocates and online businesses, which consider the accumulation of personal information the backbone of an ad-driven Internet.In the United States, the data collection practices of app makers are loosely regulated, if at all; some do not even disclose what kind of data they are collecting and why. Last February, the California attorney general, Kamala D. Harris, reached an agreement with six leading operators of mobile application platforms that they would sell or distribute only mobile apps with privacy policies that consumers could review before downloading.In announcing the voluntary pact with Amazon, Apple, Google, Hewlett-Packard, Microsoft and Research in Motion, whose distribution platforms make up the bulk of the American mobile app market, Ms. Harris noted that most mobile apps came without privacy policies.â€œYour personal privacy should not be the cost of using mobile apps, but all too often it is,â€? Ms. Harris said at the time.But simple disclosure, in itself, is often insufficient.The makers of Angry Birds, Rovio Entertainment of Finland, discloses its information collection practices in a 3,358-word policy posted on its Web site. But as with most application makers around the world, the terms of Rovioâ€™s warnings are more of a disclaimer than a choice.The company advises consumers who do not want their data collected or ads directed at them to visit the Web site of its analytics firm, Flurry, and to list their details on two industry-sponsored Web sites. But Rovio notes that some companies do not honor the voluntary lists.As a last resort, Rovio cautions those who want to avoid data collection or ads simply to move on: â€œIf you want to be certain that no behaviorally targeted advertisements are not displayed to you, please do not use or access the services.â€?Despite multiple requests by phone and Internet over five days, Rovio did not respond to questions.Policy practices like Rovioâ€™s often do little to inform consumers. Most people simply click through privacy permissions without reading them, said Mr. Hong, the Carnegie Mellon professor. His institute is developing a software tool called App Scanner that aims to help consumers identify what types of information an application is collecting and for what likely purpose.In Europe, lawmakers in Brussels are planning to bring Web businesses for the first time under stringent data protection rules and to give consumers new legal powers, the better to control the information that is being collected on them.Proposed revisions to the European Unionâ€™s General Data Protection regulation now before the Civil Liberties, Justice and Home Affairs Committee of the European Parliament would require Web businesses to get explicit consent from consumers to collect data. A proposal would also give consumers the ability to choose what information an app can store on them without losing the ability to use the software.But the drafting of the revisions, which are not expected until late 2013 at the earliest, has set off a concerted lobbying battle by global technology companies, most of which are based in the United States, to weaken the consent requirements, which could undermine the advertising-financed business models that drive many free applications.Everything you need to know to make the right choice.Our selection of recommended PCs for WindowsÂ 8 and WindowsÂ RT.Discover new ways to personalize your PC with WindowsÂ 8 and WindowsÂ RT.See what you can do with the world of apps at the Windows Store.1 of 6.An automated train dumps ore in a sorting area after transporting it from thousands of meters underground at Vale's Copper Cliff mine near Sudbury, Ontario October 16, 2012.Once filled, the automated train will snake through a series of narrow tunnels, emerge from a rocky outcropping, then loop past St-Jean's window and dump its payload for sorting.Vale SA, the Brazilian company that owns the mine near this nickel-rich Canadian town, has spent nearly $50 million in two years to install and test the "rail-veyor." The company believes the transport system will revolutionize how it builds and extracts new mineral deposits.The equipment is made locally by Rail-Veyor Technologies Global Inc. It is one of many mining technologies that developers hope will allow future production to be run almost entirely by people safely above ground.Such advances may prove crucial as easy-to-exploit deposits run dry and miners drill deeper in more remote places to supply China, India and other emerging economies. The technology could make mining cheaper and safer, avoiding the need to dig wide tunnels and hire large numbers of expensive, skilled workers."As we go deeper, if we continue to apply existing thinking and existing technologies, it's a death spiral" for company profits, said Alex Henderson, who heads Vale's technology team in Sudbury."We need to begin to look at a step-change in mining rather than just incrementally improving our existing processes."The rail-veyor is one such step-change. At the test site, it has halved the time to build a mine, and Vale expects a 150 percent boost in production rates before year end.In Australia, Rio Tinto Ltd, one of the world's largest miners and an automation pioneer, is rolling out a fleet of self-driving trucks and trains at its iron ore operations. Vale, BHP Billiton and Chile's Codelco are in hot pursuit.Gold miner AngloGold Ashanti is eyeing automation in South Africa, where miners spend hours each shift traveling up and down shafts and ounces of gold are left behind in support pillars each year.Organized labor has made its peace with the automation drive, although there were some concerns that robots would displace humans."We're ok with automation, it's part of the changing times and it's a good thing for productivity," said Myles Sullivan of the United Steelworkers Canada, whose workers ended a year-long strike at Vale over bonuses and wages in 2010.New challenges in mining are driving technological changes. Large, accessible deposits have all but disappeared. Resources of tomorrow are in far-flung corners of the globe or hundreds of meters beneath the surface.Add a shortage of skilled labor - expected to worsen as the baby-boom generation retires - and mining costs have surged.While soaring demand means higher metal prices, rising costs are crimping profits. Canada's S&P/TSX Mining share index has fallen more than 38 percent since the beginning of 2011.Experts say mining companies must change how they operate.Making that shift is not easy for an industry steeped in tradition, especially when change doesn't come cheap. Rio Tinto is spending more than $500 million on train automation alone."This is a very conservative industry that has been very productive over the last 30 years doing it the way they're doing it now," said Douglas Morrison, chief executive of the Centre for Excellence in Mining Innovation (CEMI), an industry-funded research center in Sudbury."But is the old way going to work for us into the future? I think probably not, so we need to make some changes."After decades of production, the nickel mines around Sudbury are getting deeper and deeper. At Vale's Creighton mine, the No. 8 shaft drops nearly 8,000 feet into the ground - equivalent of a 700-story condo tower.At that depth it is very hot, around 50 degrees Celsius (120 Fahrenheit), so tunnels must be pumped full of cooled air to make temperatures manageable for people and heavy machinery."The bigger issue is when we get much deeper we start to generate our own earthquakes - very small earthquakes - these are called 'rock bursts,'" said Morrison.Smaller tunnels and new ways of digging can hopefully reduce the danger of these rock bursts, which create a safety concern and slow development.Rio Tinto is working with CEMI on automated tunnel borers, currently used to build subway and sewer tunnels. By cutting through the rock instead of blasting, Rio aims to quadruple its underground advance rates to 20 meters a day.But while automated tunnel borers will build shafts and tunnels more quickly, massive mining equipment still handicaps the industry, which is where Vale's rail-veyor comes in.A train hauling 50 tonnes of ore uses a far smaller tunnel than a truck with the same load. By taking the massive trucks and scooptrams - large vehicles with shovels on the front - out of the equation, Vale can build more compact and stable tunnels.The rail-veyor, built on tracks that zig-zag down to the deposit, actually eliminates the need for expensive shafts and may eventually move people and equipment, along with ore.Vale's Henderson believes the technology - which the company plans to roll out in five upcoming projects - is a game-changer that will help usher in a new era of mining."Just as the scooptram was the key enabler for the mechanized era, is the rail-veyor a key enabler for the next?" he said.What that "next era" will look like is still up for debate. Some innovators believe robots will do most of the labor in mines of the future, as in automobile assembly plants. This would ease likely shortages in skilled labor in many countries.Over the next decade Canada's mining sector will need more than 100,000 skilled new hires to sustain even modest growth, according to the Mining Industry Human Resources Council.In Australia, the labor crunch is already so intense that truck drivers can make upwards of $100,000 a year, with turnover rates at some mines still near 40 percent."One of the biggest problems that the mining industry faces worldwide is trained personnel. We can't get them," said John Meech, director of CERM3, a mining research center at the University of British Columbia in Vancouver."One of the ways we are going to have to deal with that is to automate the systems so that the human becomes the supervisor, rather than the direct means of control."It is a concept already used at remote open-pit mines in Australia, where Rio's new fleet of driverless trucks can be run from a control room hundreds of miles away.Canada's Nautilus Minerals Inc is using automated rovers to explore the ocean bed for mineral deposits that underwater robots will eventually mine.In addition to boosting productivity, the advances will enhance safety. As labor leader Sullivan says, "so long as there's underground mining, there will be women and men working underground."Safety is the focus at a converted schoolyard just outside Sudbury, where a duo of mine rescue robots roll through a makeshift obstacle course. Their thick tires grind over logs and through mud pits.Designed by Canada's Penguin Automated Systems Inc, the equipment is being tested by Codelco at its Andina copper mine in Chile, doing dangerous jobs like checking stability after blasting and surveying tunnels at risk of flooding."Our mining industry is not quite there yet in Canada and it needs to get there to be competitive with the rest of the world," said Penguin Chief Executive Greg Baiden. "It comes back to the culture. Who wants to do it? Who wants to be first?"(Additional reporting by Bhaswati Mukhopadhyay in Bangalore; Editing by Frank McGurty, Janet Guttsman and David Gregorio)Symantec provide overview and analysis of the year in global threat activity via its Internet Security Threat Report (ISTR) , with aÂ exclusiveÂ details that 400 million new variants of malware were created in 2011, which is an average of 33 million new variants of malware a month, or an average of one million new variants a day.."Â Symantec said in a blog post. Political activism and hacking were two big themes in 2011 themes that are continuing into 2012. There were many attacks last year that received lots of media attention. Hacking can undermine institutional confidence in a company, and loss of personal data can result in damage to an organizationâ€™s reputation.Also,Â Many companies are keen to adopt cloud computing. It can reduce costs by outsourcing routine services.Â The first risk is unmanaged employee use of cloud services. The proportion of phishing emails varied considerably by company size with the smallest and largest companies attracting the most, but the proportion of spam was almost identical for all sizes of business. The United States was the number one source of all activities, except for malicious code and spam zombies, where India took first place. Around 12.6% of bot activity originated in the USA as did 33.5% of web-based attacks, 16.7 % of network attacks and 48.5% of phishing websites.A new class of electronics that are biocompatible and can dissolve completely in liquid mean that implantable medical treatments are closer to reality for on-the-go warfighters.DARPA researchers have created electronic systems and components using ultrathin sheets of silicon and magnesium encapsulated in silk, a biocompatible material. The thickness and crystallinity of the silk determines how long the electronics take to dissolve: days, hours, or even minutes. Silicon and magnesium are naturally occurring at low levels in the human body, and since the amount of material used in these devices is below physiological levels these electronics are biocompatible and eco-friendly.A paper appearing in the September 28, 2012 issue of Science explains how DARPA researchers were able to use this technology to create an implantable device that acts as a non-antibiotic, programmable bactericide that can dissolve harmlessly into the body to prevent surgical site infection. This is one driving example of biodegradable medical treatments for remote patient care that does not require extraction surgery while warfighters are deployed.â€œTransient electronics applied to localized antimicrobial therapy would be a major advance,â€? said Alicia Jackson, DARPA program manager for this effort. â€œA limitation of current implanted devices such as pacemakers and artificial joints is localized infection. Applying thin film appliquÃ©s to implant devices for localized surface heating and sterilization may help counter these infections, even when antibiotic resistant bacteria are present. Having means of eradicating infections could enhance the efficacy of many implant devices and ultimately reduce patient morbidity and mortality.â€?This work was funded by a study in the DARPA Microsystems Technology Office (MTO).If you are running an open network, it is NOT the case that anyone can break into your computer, and you are still, by and large, in a safe situation. If you are running a separate â€œguestâ€? network apart from your primary network, you have no reason to worry. If you are running an open wireless network as your primary home network, it is important that you understand whether or not your network is set up to allow sharing, or if you can enable wireless isolation to create a firewall between users on the network so that sharing is not possible. If your network is set up to allow sharing, then you should be aware that users of your open network might be able to use devices that are attached to the network, e.g. printers, smart TVs, etc. Moreover, if your computer is set to share files over the network, those files will be accessible to anyone on your network. So if you are running an open network, and don't want strangers printing things or reading your network files, it is important to research whether you can disable sharing on your network, or to carefully check the sharing settings for each computer or device attached to the network.Understanding why open networks are generally safe for users requires a little more background. Websites and services that take security seriously use transport layer encryptionâ€”most notably Transport Layer Security (TLS), which underlies HTTPS. Using transport layer encryption is the gold standard for security. Since it encrypts data between your computer and the web service you are using, TLS provides a strong level of communication security whether or not you are on an open wireless network. It protects against snooping and attacks from anyone who can read the traffic passing between your computer and the website you are visiting, such as ISPs and governments as well as people on your local wireless network. The security gain from using HTTPS as much as possible is quite significant. This is why we encourage everyone to use our HTTPS Everywhere browser extension. On the other hand, WPA2 and other Wi-Fi security schemes protect only against an attacker on your local network, and provide only nominal protection. Very often, "securing" your wireless network will not be enough to thwart a determined attacker on your local network from being able to read and manipulate your data. Therefore, the security loss from moving to an open wireless network is less significant than you might realize, especially if you set up your network to firewall users from each otherâ€”as we recommend in our tutorialswhenever possible.Four years after discovering that militants were tapping into drone video feeds, the U.S. military still hasnâ€™t secured the transmissions of more than half of its fleet of Predator and Reaper drones, Danger Room has learned.Â The majority of the aircraft still broadcast their classified video streams â€œin the clearâ€? â€” without encryption. With a minimal amount of equipment and know-how, militants can see what Americaâ€™s drones see.Unmanned aerial vehicles, or UAVs, have become the single most important weapon in Americaâ€™s far-flung pursuit of violent extremists. Hundreds of American Predators and Reapers fly above Libya, Yemen, Somalia, Pakistan, and Afghanistan â€” watching suspected enemies, and striking them when necessary.Â Nearly 3,000 people have been killedÂ in the decade-long drone campaign.â€œIf somebody could obtain reliable access to real-time Predator or Reaper video â€” without attribution or alerting U.S. military â€” that would Â a tremendous intel coup,â€? says Micah Zenko, a fellow at the Council on Foreign Relations. â€œThere is an insatiable demand from Predator and Reaper imagery in Afghanistan and elsewhere. Any reluctance to use those for spying or missile strikes places operations in Afghanistan, Pakistan, Yemen, and Somalia at some risk.â€?Military officials have known about â€” and mostly shrugged off â€” the vulnerability since the development of the Predator in the 1990s. But the problem drew increased attentionÂ in 2008, when drone video footage was found on the laptops of Shiâ€™ite militants in Iraq, who were able to intercept the feed using a piece of $26 software. The Pentagon and the defense industry assured the public that theyâ€™d close the hole by retrofitting the robotic aircraft with new communications protocols and encrypted transceivers that would keep the video from being intercepted again.Four years into the effort, however, only â€œ30 to 50 percentâ€? of Americaâ€™s Predators and Reapers are using fully encrypted transmissions, a source familiar with the retrofitting effort tells Danger Room. The total fleet wonâ€™t see its communications secured until 2014. This source and others who work closely with drone operations say that drones flying overseas are among the first to get the newly secured equipment. They also noted that they are unaware of any incidents of militants using Americaâ€™s unmanned eyes in the sky to their advantage. â€œBut Iâ€™m surprised I havenâ€™t,â€? the source adds. â€œAnd that doesnâ€™t mean itâ€™s not happening.â€?This isnâ€™t the only vulnerability in the drone fleet. In March of 2011, an unknown software glitch caused a PredatorÂ stationed at a U.S. base inÂ Africa toÂ start its engine without human direction.Â Last October, as Danger Room first reported, Air Force technicians discovered aÂ virus infecting the dronesâ€™ remote cockpitsÂ in Las Vegas. It tookÂ weeks of sustained effortÂ to clean up the machines. The aircraft, which rely on GPS to guide them through the air, can run into problems if GPS signals are jammed in a particular area â€” something that can be done with cheap, commercially available hardware.Â Iranian officials claimed they hacked the GPS control signal of an advanced drone, though itâ€™sÂ impossible to verify that lofty claim.No one who works with UAVs is questioning the fundamental integrity of the drone fleet at the moment; it would take an incredibly sophisticated hacker toÂ commandeerÂ a Predator, for example. Nor is anyone pretending that this premiere tool of the U.S.global Â counterterror campaign is flawless.Predators and the larger, better-armed Reapers transmit video and accept instructions in one of two ways. The first is via satellite, to remote pilots and sensor operators who are often on the other side of the planet; these satellite communications are encrypted, and are generally considered secure.The second is through a radio frequency signal called the Common Data Link, which is used to share the droneâ€™s video feed with troops on the ground. The CDLâ€™s carrier signal â€” its specific pattern of frequencies, in a given order and for a given length of time â€” tells both transmitter and receiver on how to function. The problem is that the Predatorsâ€™ version of the CDL carrier signal (also known as a â€œwaveformâ€?) didnâ€™t include an order to encrypt the signal. So neither the transmitter on the drone nor the receivers that troops used on the ground employed encryption, either.There were reasons for this.Â The original Predator, just 27 feet long, was little more than a scaled-up model plane with an 85-horsepower engine. It had a payload of just half a ton for all its fuel, cameras and radios. And encryption systems can be heavy. (Big crypto boxesÂ are a major reasonÂ the Armyâ€™s futuristic universal radio ended up being too bulky for combat, for example.) With the early Predator models, the Air Force made the conscious decision to leave off the crypto.The flying branch was well aware of the risk. â€œDepending on the theater of operation and hostile electronic combat systems present, the threat to the UAVs could range from negligible with only a potential of signal intercept for detection purpose, to an active jamming effort made against an operating, unencrypted UAV,â€?Â the Air Force reported in 1996.Â â€?The link characteristics of the baseline Predator system could be vulnerable to corruption of down links data or hostile data insertions.â€?The Predator models steadily grew in power and payload, and took a big leap in dimensions and capability with the 36-foot-long Reaper version introduced in 2007. The Reaper has a 950-horsepower engine and a nearly 4,000-pound payload â€” more than enough capacity for crypto-enabled systems which, like all electronics, had shrunk in size and weight.The problem was that, by then, the military had rushed to the battlefield hundreds ofÂ Remotely Operated Video Enhanced Receivers, orÂ RoversÂ â€“ rugged, laptop-sized receivers with screens for watching drone footage. And those early version of the Rovers were developed and distributed so fast, the military once again left the crypto off. â€œIt could be both intercepted (e.g., hacked into) and jammed,â€? e-mails an Air Force officer with knowledge of the program.Which mean the Pentagon was stuck, for a time. The military couldnâ€™t replace the old CDL waveform with something encryptable until the Rovers â€” and the radio transmitters aboard the Predators â€” could handle such a signal.Eventually, the Rovers began to be swapped out for newer models. The latest version, the â€œTactical Rover,â€? (.pdf) is about the size of an old-school mobile phone. It can use both the Advanced Encryption Standard an the triple-Data Encryption Standard to secure video feeds. There are now about a thousand of the units in the militaryâ€™s hands.And now, the Predators and Reapers are starting to get enhanced radios, too. â€œThe fleet-wide upgrade begins later this year and carries on for several years,â€? says Maj. Mary Danner-Jones, an Air Force spokesperson. The service is spending $12 million on crypto-enabled Vortex transceivers (.pdf).Thatâ€™s allowing a new, hardened waveform to be introduced throughout the Predator and Reaper fleet. The Air Force recently gave Predator-maker General Atomics Aeronautical SystemsÂ a $26 million contract to retrofit its drone cockpits to accept the carrier signal, among other enhancements.The question is why hasnâ€™t this happened sooner. After all,Â the Navy installed multiple layers of encryption inÂ theirÂ â€™bots some time ago. Navy spokesman Jamie Cosgrove tells Danger Room that â€œthe vast majorityâ€? of naval drones are encrypted â€“Â  â€œand have been since development.â€?One source who works on developing Navy UAVs, but is not authorized the speak on the record, explains why:Â â€?Standard unencrypted video is basically a broadcast to whoever can figure out the right carrier frequency, so essentially, we are simulcasting to battlefield commanders and the opposing force. If that opposing force knows we can see them and from where, they can take better evasive maneuvers.â€?Itâ€™s possible that none of the militants America is trying today are as sophisticated as the ones who intercepted that drone video in 2008. Itâ€™s possible that the value of such footage-from-above is so fleeting that extremists have never again bothered to grab it. But itâ€™s worth noting that Predator and Reaper video is considered by the U.S. military to be classified information. And when U.S. commanders on the ground get into a firefight, the first call they usually make is for a drone, so they can take a look at the battlefield through the eyes of a drone.You can see more of what Linus Torvalds shares on his profileThe Department of Energy's Oak Ridge National Laboratory has today unveiled its new supercomputer Titan, claimed to be the world's most powerful system.The Cray XK7 system's 20 petaflops of power will be put to use researching climate change and other data-intensive tasks.It contains 18,688 nodes, each based around a 16-core AMD Opteron 6274 processor and an NVIDIA Tesla K20 graphics processing unit (GPU) accelerator, and has more than 700 terabytes of memory.The combination of traditional central processing units and more recent GPUs means Titan occupies the same amount of space as its Jaguar predecessor and uses only marginally more electricity."One challenge in supercomputers today is power consumption," says Jeff Nichols, associate laboratory director for computing and computational sciences."Combining GPUs and CPUs in a single system requires less power than CPUs alone and is a responsible move toward lowering our carbon footprint. Titan will provide unprecedented computing power for research in energy, climate change, materials and other disciplines to enable scientific leadership."Because they handle hundreds of calculations simultaneously, GPUs can get through a lot more work than CPUs in a given time. While the 299,008 CPU cores guide simulations, the new NVIDIA GPUs do the 'heavy lifting',Â  allowing scientific calculations to be run with greater speed and accuracy."Titan will allow scientists to simulate physical systems more realistically and in far greater detail," says James Hack, director of ORNL's National Center for Computational Sciences."The improvements in simulation fidelity will accelerate progress in a wide range of research areas such as alternative energy and energy efficiency, the identification and development of novel and useful materials and the opportunity for more advanced climate projections."The system will be used for several different applications, including a nanoscale analysis of important materials such as steels, iron-nickel alloys and advanced permanent magnets that will help drive future electric motors and generators.Titan will also allow researchers to model large-molecule hydrocarbon fuels such as the gasoline surrogate isooctane; commercially important oxygenated alcohols such as ethanol and butanol; and biofuel surrogates that blend methyl butanoate, methyl decanoate and n-heptane.|Meanwhile, the Denovo application will model the behavior of neutrons in a nuclear power reactor, simulating a fuel rod through one round of use in a reactor core in 13 hours - a job that took 60 hours on the Jaguar system.Its most important task, though, is to simulate long-term global climate, enabling researchers to better understand future air quality as well as the effect of particles suspended in the air."As scientists are asked to answer not only whether the climate is changing but where and how, the workload for global climate models must grow dramatically," says Kate Evans of ORNL. "Titan will help us address the complexity that will be required in such models." Â Huge news out of Apple today, as its senior vice president of iOS software, Scott Forstall, will leave the company next year after putting in some 15 years. Furthermore, John Browett -- head of Apple retail -- is also on his way out. The memo was delivered late today, on a day that is littered with other news that the company may hope will bury the bulk of it -- and, on a day where trading on the New York Stock Exchange is halted due to Hurricane Sandy. It's practically a given that Forstall is taking the brunt of the impact from its decision to forge ahead with an obviously subpar Maps application, all while trumpeting it as one of the pillars of iOS 6 during his keynote speech at WWDC 2012. The introduction of Siri as a beta product is also on Forstall, and we all know what happens to executives who flub something related to iPhone....As the shakeup unfolds, Jony Ive, Bob Mansfield, Eddy Cue and Craig Federighi will add more responsibilities to their roles. In other words, Tim Cook isn't about to usher in new help who may thwart the company's efforts to continue at its breakneck pace. Curiously, Mansfield will be heaping more on his own plate just months after he had originally planned to retire. As for Ive? He'll be responsible for providing "leadership and direction for Human Interface (HI) across the company in addition to his role as the leader of Industrial Design." Eddy Cue will be burdened with Siri and Maps, while also keeping an eye on the iTunes Store, the App Store, the iBookstore and iCloud. Needless to say, he probably won't be seeing too many walls outside of Cupertino for the foreseeable future. Federighi is being tasked to lead both iOS and OS X, while Mansfield chairs a new Technologies group that bundles Apple's wireless teams across the company. (Of note, Dan Riccio -- who was scheduled to take over for Mansfield prior to his retirement retraction -- isn't among those who are gaining duties.)Just months after Browett was brought in from Dixons in order to lead up Apple's retail efforts, he's on the outs as well. Of course, he's also responsible for the branch having to tell stores that it "messed up" when he fiddled with staffing levels back in August. A search for a new head of Retail is underway and in the interim, the Retail team will report directly to CEO Tim Cook.Update: The Wall Street Journal is reporting that Forstall was asked to resign after refusing to sign his own name to Apple's Maps apology, leaving Tim Cook to sign his name instead. Yikes.Apple Announces Changes to Increase Collaboration Across Hardware, Software & Services Jony Ive, Bob Mansfield, Eddy Cue and Craig Federighi Add Responsibilities to Their Roles CUPERTINO, California-October 29, 2012-AppleÂ® today announced executive management changes that will encourage even more collaboration between the Company's world-class hardware, software and services teams. As part of these changes, Jony Ive, Bob Mansfield, Eddy Cue and Craig Federighi will add more responsibilities to their roles. Apple also announced that Scott Forstall will be leaving Apple next year and will serve as an advisor to CEO Tim Cook in the interim. "We are in one of the most prolific periods of innovation and new products in Apple's history," said Tim Cook, Apple's CEO. "The amazing products that we've introduced in September and October, iPhone 5, iOS 6, iPad mini, iPad, iMac, MacBook Pro, iPod touch, iPod nano and many of our applications, could only have been created at Apple and are the direct result of our relentless focus on tightly integrating world-class hardware, software and services." Jony Ive will provide leadership and direction for Human Interface (HI) across the company in addition to his role as the leader of Industrial Design. His incredible design aesthetic has been the driving force behind the look and feel of Apple's products for more than a decade. Eddy Cue will take on the additional responsibility of SiriÂ® and Maps, placing all of our online services in one group. This organization has overseen major successes such as the iTunes StoreÂ®, the App Storeâ„ , the iBookstoreâ„  and iCloudÂ®. This group has an excellent track record of building and strengthening Apple's online services to meet and exceed the high expectations of our customers. Craig Federighi will lead both iOS and OS XÂ®. Apple has the most advanced mobile and desktop operating systems, and this move brings together the OS teams to make it even easier to deliver the best technology and user experience innovations to both platforms. Bob Mansfield will lead a new group, Technologies, which combines all of Apple's wireless teams across the company in one organization, fostering innovation in this area at an even higher level. This organization will also include the semiconductor teams, who have ambitious plans for the future. Additionally, John Browett is leaving Apple. A search for a new head of Retail is underway and in the interim, the Retail team will report directly to Tim Cook. Apple's Retail organization has an incredibly strong network of leaders at the store and regional level who will continue the excellent work that has been done over the past decade to revolutionize retailing with unique, innovative services for customers. Apple designs Macs, the best personal computers in the world, along with OS X, iLife, iWork and professional software. Apple leads the digital music revolution with its iPods and iTunes online store. Apple has reinvented the mobile phone with its revolutionary iPhone and App Store, and is defining the future of mobile media and computing devices with iPad.Want to play old school Nintendo games on your iPad? Download Google Play apps from foreign countries to your Galaxy Tab? If so, you'll have to break the law. That's because under new rules issued by the U.S. government, jailbreaking (or in the case of Android, rooting) tablets becomes a violation of the Digital Millennium Copyright Act on Sunday, October 28. On Thursday, the Librarian of Congress issued its latest set of exemptions to the DMCA. By default, digital rights management (DRM) mechanisms cannot legally be flouted by consumers, but the DMCA allows the government to periodically define exemptions to this rule. In 2010, tinker-happy iPhone owners breathed a sigh of relief (and Steve Jobs likely just sighed) when it was ruled that jailbreaking smartphones was perfectly legal under the DMCA. This remains the case, but the updated list of exemptions explicitly excludes tablets, a category of devices that the government found to be too "broad and ill-defined" to allow their owners free reign when using them. So as of now, it is illegal to jailbreak an iPad or root a tablet running Android or any tablet-focused flavor of Windows. This Makes No SenseThe tablet exemption is a bit of a head scratcher. I'm free to jailbreak my iPhone and do as I please with it, but if I want to run the same jailbreak tool on a larger device running the same exact operating system, it's against the law?Accessing Cydia on my iPhone 4 is cool, but doing it on a screen a few inches bigger? That's illegal. Other than its size, the only significant difference between these two devices is that the iPhone makes and receives calls. The new rules also forbid personal copying of DVDs. And starting in January 2013, it will be illegal to unlock new smartphones for the purpose of switching carriers. Unlocking older handsets will continue to be fine. The whole thing illustrates what Ars Technica's Timothy B. Lee calls "the fundamentally arbitrary nature of the DMCA's exemption process."Explains Lee: In order to convince the Librarian to allow DVD ripping in order to watch it on an iPad, a court would first need to rule that doing so falls under copyright's fair use defense. To get such a ruling, someone would have to rip a DVD (or sell a DVD-ripping tool), get sued in court, and then convince a judge that DVD ripping is fair use. But in such a case, the courts would probably never reach the fair use question, because - absent an exemption from the Librarian of Congress- circumvention is illegal whether or not the underlying use of the work would be a fair use.Lee goes on to make the case that new rules surrounding DVD copying and eBook DRM don't make sense either and suggests that perhaps DRM schemes should not be legally protected from tampering by default. His take is well worth a read. How Will This Impact iOS Jailbreaking? When the news broke, iOS jailbreak developer MuscleNerd expressed concern about it on Twitter. When I asked him for his perspective, he declined to comment because of potential legal repercussions.SAN FRANCISCO â€” I.B.M. scientists are reporting progress in a chip-making technology that is likely to ensure that the basic digital switch at the heart of modern microchips will continue to shrink for more than a decade.The advance, first described in the journal Nature Nanotechnology on Sunday, is based on carbon nanotubes â€” exotic molecules that have long held out promise as an alternative to silicon from which to create the tiny logic gates now used by the billions to create microprocessors and memory chips.The I.B.M. scientists at the T.J. Watson Research Center in Yorktown Heights, N.Y., have been able to pattern an array of carbon nanotubes on the surface of a silicon wafer and use them to build hybrid chips with more than 10,000 working transistors.Against all expectations, silicon-based chips have continued to improve in speed and capacity for the last five decades. In recent years, however, there has been growing uncertainty about whether the technology would continue to improve.A failure to increase performance would inevitably stall a growing array of industries that have fed off the falling cost of computer chips.Chip makers have routinely doubled the number of transistors that can be etched on the surface of silicon wafers by shrinking the size of the tiny switches that store and route the ones and zeros that are processed by digital computers.The switches are rapidly approaching dimensions that can be measured in terms of the widths of just a few atoms.The process known as Mooreâ€™s Law was named after Gordon Moore, a co-founder of Intel, who in 1965 noted that the industry was doubling the number of transistors it could build on a single chip at routine intervals of about two years.To maintain that rate of progress, semiconductor engineers have had to consistently perfect a range of related manufacturing systems and materials that continue to perform at evermore Lilliputian scale.The I.B.M. advance is significant, scientists said, because the chip-making industry has not yet found a way forward beyond the next two or three generations of silicon.â€œThis is terrific. Iâ€™m really excited about this,â€? said Subhasish Mitra, an electrical engineering professor at Stanford who specializes in carbon nanotube materials.The promise of the new materials is twofold, he said: carbon nanotubes will allow chip makers to build smaller transistors while also probably increasing the speed at which they can be turned on and off.In recent years, while chip makers have continued to double the number of transistors on chips, their performance, measured as â€œclock speed,â€? has largely stalled.This has required the computer industry to change its designs and begin building more so-called parallel computers. Today, even smartphone microprocessors come with as many as four processors, or â€œcores,â€? which are used to break up tasks so they can be processed simultaneously.I.B.M. scientists say they believe that once they have perfected the use of carbon nanotubes â€” sometime after the end of this decade â€” it will be possible to sharply increase the speed of chips while continuing to sharply increase the number of transistors.This year, I.B.M. researchers published a separate paper describing the speedup made possible by carbon nanotubes.â€œThese devices outperformed any other switches made from any other material,â€? said Supratik Guha, director of physical sciences at I.B.M.â€™s Yorktown Heights research center. â€œWe had suspected this all along, and our device physicists had simulated this, and they showed that we would see a factor of five or more performance improvement over conventional silicon devices.â€?Carbon nanotubes are one of three promising technologies engineers hope will be perfected in time to keep the industry on its Mooreâ€™s Law pace. Graphene is another promising material that is being explored, as well as a variant of the standard silicon transistor known as a tunneling field-effect transistor.Dr. Guha, however, said carbon nanotube materials had more promising performance characteristics and that I.B.M. physicists and chemists had perfected a range of â€œtricksâ€? to ease the manufacturing process.Carbon nanotubes are essentially single sheets of carbon rolled into tubes. In the Nature Nanotechnology paper, the I.B.M. researchers described how they were able to place ultrasmall rectangles of the material in regular arrays by placing them in a soapy mixture to make them soluble in water. They used a process they described as â€œchemical self-assemblyâ€? to create patterned arrays in which nanotubes stick in some areas of the surface while leaving other areas untouched.Perfecting the process will require a more highly purified form of the carbon nanotube material, Dr. Guha said, explaining that less pure forms are metallic and are not good semiconductors.Dr. Guha said that in the 1940s scientists at Bell Labs had discovered ways to purify germanium, a metal in the carbon group that is chemically similar to silicon, to make the first transistors. He said he was confident that I.B.M. scientists would be able to make 99.99 percent pure carbon nanotubes in the future.This post has been revised to reflect the following correction:Because of an editing error, an article on Monday about an I.B.M. breakthrough on chip design defined incorrectly Mooreâ€™s Law, an observation on technology advances named for Gordon Moore, a co-founder of Intel. Mooreâ€™s Law holds that the chip industry doubles the number of transistors it can build on a single chip at routine intervals of about two years â€” not intervals of about 12 to 18 months.Picture an eerily human-like tangle of metal, wiring and lights, cables dangling from somewhere above like puppet strings. Imagine it springing to life, lifting a long, lanky leg that bends 180 degrees at the hips like the eerie biomechanical GekkoÂ inÂ Metal Gear Solid 4, then placing one foot on a high bench and flexing its ankle, probing, testing, as it leans its thick cage of a torso forward, its arms splayed against plastic and wood walls on either side.And then itâ€™s up, hoisting its bulk into the air, its arms swinging forward just as yours or mine would, finding its feet, gently quaking, balancing.Now picture it leaping back down, landing first one foot, then the other, making a thunderous sound like someone swinging a sledgehammer at sheet metal (or the noise youâ€™d imagine a hulking robot might generate as it falls from above, like a BattleTech mech).Next â€” and you can see all this and more in the video above â€” itâ€™ll straddle a shallow pit teeming with deadly lizards and snakes (okay, just rubber ones, but still scary!) using both legs, edging past the gap fluidlyâ€¦Meet Pet-Proto, a Boston Dynamics-designed bipedal robot, related to the companyâ€™s anthropomorphic PETMAN project.Â Itâ€™s capable of analyzing and navigating complex obstacle courses, making decisions autonomously, and with, if not the actual dexterity of a human being, at least the functional semblance of one.Itâ€™s all part of DARPAâ€˜s (Defense Advance Research Projects Agency) work to promote its ambitious DARPA Robotics Challenge (DRC), which initiated its second phase on Wednesday, Oct. 24 since launching back in April. The contest will test the sort of capabilities illustrated above and others â€œinÂ a series of tasks that will simulate conditions in a dangerous, degraded, human-engineered environment.â€?â€œRobot enthusiasts, the time has come,â€? says DARPA on its website. â€œThe DARPA Robotics Challenge (DRC) begins today. Will you be part of it?â€?Itâ€™s just the start of whatâ€™ll amount to a two-year ordeal for teams competing to design, tweak and test rescue either humanoid or non-humanoid robots: ultra-agile, durable mechanical servants capable of going where most humans wouldnâ€™t dare, say exploring collapsed mines and helping to rescue trapped miners, defusing improvised explosive devices, or working around nuclear meltdown incidents like Fukushima, Chernobyl or Three Mile Island.The prize? A cool $2 million. All teams have to do is create robots that can perform tasks like: drive a utility vehicle, climb a wobbly industrial ladder, shatter a concrete wall using a power tool, cross a debris-littered field, isolate and close a valve in a leaking pipe and replace industrial equipment. Simple, right?If youâ€™re from the future, maybe, but todayâ€™s robots do almost none of these things â€” ergo DARPAâ€™s two-year challenge, designed to make some or all of the above a reality, and which as of Wednesday just got even more interesting.Take the newly announced Track C, which allows participants to compete without touching actual machine parts. Itâ€™ll involve using something DARPA calls its â€œDRC Simulator,â€? an open-source, cloud-based robotics design tool, and all you need to work it is a little software development know-how and an appetite for robotic simulation.â€œThe DRC Simulator is going to be one of DARPAâ€™s legacies to the robotics community,â€? says DRC program managerÂ Gill Pratt. â€œOne of DARPAâ€™s goals for the Challenge is to catalyze robotics development across all fields so that we as a community end up with more capable, more affordable robots that are easier to operate. The value of a cloud-based simulator is that it gives talent from any location a common space to train, design, test and collaborate on ideas without the need for expensive hardware and prototyping. That opens the door to innovation.â€?The DRC Simulator has only been in development for a month, according to DARPA, and its future already sounds bright, with a melange of improvements in the offing, including new â€œmodels of robots, perception sensors and field environmentsâ€? that should ultimately allow the simulator to â€œfunction as a cloud-based, real-time, operator-interactive virtual test bed that uses physics-based models of inertia, actuation, contact and environment dynamics.â€?What about Pet-Proto? As its name suggests, itâ€™s just a prototype â€” part of how DARPAâ€™s promoting the contest. Pet-Proto is really a predecessor to something theoretically more sophisticated that Boston Dynamics is working on, dubbed â€œAtlas.â€?DARPA says challenge participants selected to advance will receive Government Funded Equipment (GFE) â€œin the form of a modified robot platform based on the Atlas robot.â€? In other words, if you make it through the initial hurdles, you get to play with (and work on) something likeÂ that.New technology has allowed researchers to come closer than ever to cracking the worldâ€™s oldest undeciphered writing system.Researchers from the University of Oxford and the University of Southampton have developed a Reflectance Transformation Imaging (RTI) System for Ancient Documentary Artefacts (funded by the UK Arts and Humanities Research Council and the Andrew W. Mellon Foundation) to capture images of some of the worldâ€™s most important historical documents. Recently this system was used on objects held in the vaults of the Louvre Museum in Paris.These images have now been made available online for free public access on the Cuneiform Digital Library Initiative website.Among the documents are manuscripts written in the so-called proto-Elamite writing system used in ancient Iran from 3,200 to 3,000 BC and which is the oldest undeciphered writing system currently known. By viewing extremely high quality images of these documents, and by sharing them with a community of scholars worldwide, the Oxford University team hope to crack the code once and for all.Dr Jacob Dahl, a co-leader of the Cuneiform Digital Library Initiative and a member of Oxford Universityâ€™s Faculty of Oriental Studies, said: 'I have spent the last ten years trying to decipher the proto-Elamite writing system and, with this new technology, I think we are finally on the point of making a breakthrough.'The quality of the images captured is incredible. And it is important to remember that you cannot decipher a writing system without having reliable images because you will, for example, overlook differences barely visible to the naked eye which may have meaning. Consider for example not being able to distinguish the letter i from the letter t.'The reflectance transformation imaging technology system designed by staff in the Archaeological Computing Research Group and Electronics and Computer Science at the University of Southampton comprises a dome with 76 lights and a camera positioned at the top of the dome. The manuscript is placed in the centre of the dome, whereafter 76 photos are taken each with one of the 76 lights individually lit. In post-processing the 76 images are joined so that the researcher can move the light across the surface of the digital image and use the difference between light and shadow to highlight never-before-seen details.'We have never been able to view documents in this quality before,' Dr Dahl explained.Dr Dahl believes this writing system might be even more interesting than previously thought. He said: 'Looking at contemporary and later writing systems, we would expect to see proto-Elamite use only symbols to represent things, but we think they also used a syllabary â€“ for example 'cat' would not be represented by a symbol depicting the animal but by symbols for the otherwise unrelated words 'ca' and 'at'.'Half of the signs used in this way seem to have been invented ex novo for the sounds they represent â€“ if this turns out to be the case, it would transform fundamentally how we understand early writing where phonetecism is believed to have been developed through the so-called rebus principle (a modern example would be for example "I see you", written with the three signs 'eye', the 'sea', and a 'ewe').'Some features of the writing system are already known. The scribes had loaned - or potentially shared - some signs from/with Mesopotamia, such asÂ  the numerical signs and their systemsÂ  and signs for objects like sheep, goats, cereals and some others. Nevertheless, 80-90% of the signs remain undeciphered.The writing system died out after only a couple centuries. Dr Dahl said: 'It was used in administration and for agricultural records but it was not used in schools â€“ the lack of a scholarly tradition meant that a lot of mistakes were made and the writing system may eventually have become useless as an administrative system. Eventually, the system was abandoned after some two hundred years.'Dr Dahl joked: 'This is probably the worldâ€™s first case of a collapse of knowledge because of the under-funding of education!'The Louvre gave the researchers access to the c. 1100 proto-Elamite tablets in its collections, half of which can now be viewed on the Cuneiform Digital Library Initiative website.Dr Dahl said: 'The Louvre collection of early writing from Mesopotamia and Iran is incredibly important â€“ it contains the first substantial law code, the first record of a battle between kings, the first propaganda, and the first literature. Being able to put these documents online would be a great achievement.'Dr Dahl said making important documents from early human history publicly accessible is becoming increasingly important, both as a consequence of the ever-expanding influence of cyberscholarship in academic research, but also in many cases more pressingly as a matter of cultural heritage preservation in areas of the world threatened by armed conflict and collapse of security.'Iraqâ€™s cultural heritage has been pillaged in the last 20 years, and the situation in neighbouring Syria is looking dire as well,' he said.has headed the FT's San Francisco bureau since 2002 and covers Google and Microsoft, among other things. A former New York bureau chief for the FT, he is intrigued by Silicon Valley's unique financial and business culture, and is looking forward to covering his second Tech Bust. has been online and messing around with computers for more than 20 years and since 2004 has reported from the FT's San Francisco bureau on semiconductors, video games, consumer electronics and all things interwebby. has been writing about technology for the FT since 1999 and is facinated by cybercrime, privacy and all the other issues of the information society. Based in London, she covers European tech companies and hopes that they won't all get acquired by American rivals. is the FT's technology, media and telecoms page editor in London. Formerly he was the Taipei correspondent and wrote about the companies that manufacture the vast majority of the world's computers and gadgets. He is interested in the intricacies of the technology supply chain and how China is increasingly changing the tech landscape. is the FT's digital media correspondent, and has just moved from London to join our team in San Francisco. He has covered start-ups such as Twitter and Spotify, as well as the online ambitions of more established media companies, such as the BBC iPlayer. He also covers the advertising, marketing and video-game industries. Tim has been writing about technology, business and finance since 2003.Nuclear reactors in the mid-Atlantic and Northeast are being monitored for potential impacts by Hurricane Sandy, a Category 1 storm that may strike anywhere from Delaware to southern New England.â€œBecause of the size of it, we could see an impact to coastal and inland plants,â€? Neil Sheehan, a spokesman based in Philadelphia for the U.S. Nuclear Regulatory Commission, said by phone today. â€œWe will station inspectors at the sites if we know they could be directly impacted.â€?The NRC met earlier today to discuss the necessary precautions to take for the storm, Sheehan said. Plants must begin to shut if wind speeds exceed certain limits, he said.As of 2 p.m. New York time, Sandy had winds of 75 miles (121 kilometers) per hour, according to the National Hurricane Center in Miami. It was about 430 miles south-southeast of Charleston, South Carolina, moving north at 7 mph.The current Hurricane Center track calls for the system to come ashore just south of Delaware Bay on Oct. 30.Contingency Plans Nuclear plants in the projected path of the hurricane include North Anna and Surry in Virginia, Calvert Cliffs in Maryland, Hope Creek and Salem in New Jersey, Indian Point in New York and Millstone in Connecticut. The NRC is considering enhancing inspector coverage of these reactors, Sheehan said in an e-mail today.Public Service Enterprise Group must shut all units at the Salem and Hope Creek plants two hours before the onset of hurricane-force winds greater than 74 mph, according to Sheehan. An â€œunusual eventâ€? would be declared if the winds are sustained for greater than 15 minutes or if the water level reaches 99.5 feet or higher, he said. Such an event is the lowest of four level of emergency used by the commission.Salem Unit 2 is currently shut for refueling, while Unit 1 was operating at 83 percent of capacity today during maintenance on the circulating water system. Hope Creek ran at full power. The three units have a combined capacity of 3,365 megawatts.â€œWe are in phase one of our severe-weather plan,â€? Joe Delmar, a company spokesman, said in an e-mail responding to questions. â€œThis includes inspecting, removing and securing outside areas for potential missiles, objects that could go airborne, and staging of emergency equipment and supplies.â€?Millstone Reactor Nuclear generation in the Northeastern region dropped 1.1 percent to 18,016 megawatts, with seven plants shut, an NRC report today showed.Dominion Resourcesâ€™s Millstone plant is monitoring Sandyâ€™s progress and preparing to adjust staff as it comes closer, according to Ken Holt, a plant spokesman based in Richmond, Virginia. The plant must shut if winds reach 90 mph.â€œWe would shut down in advance of the storm if they were expected to be 90 miles per hour at the site,â€? Holt said by phone today. â€œFloods and high winds are a threat because they can knock off off-site power and weâ€™d then need to activate emergency generators for power to put the plant to safe conditions.â€?A recent update to the Xbox 360 dashboard made Internet Explorer available as a free download. This is exciting news for an HTML5 game company like us, as it means that our games are now playable on Xbox 360 consoles.In an interview with ImpactJS creator Dominic Szablewski, we talked about some of the developer frustrations revolving around Microsoft and HTML5. Dominic has his game Biolab Disaster running natively on an Xbox 360, but at a completely unplayable 3 frames per second. Itâ€™s so close to working but thereâ€™s no apparent interest from Microsoft to seal the deal, despite their repeated pushes into the HTML5 game space.Microsoft has financed or otherwise produced a handful of HTML5 game projects in the past few years, including Pirates Love Daisies, Agent 008 Ball, Cut the Rope, and most recently the apparent game platform Atari Arcade.These projects are beneficial to the HTML5 game development scene and weâ€™re glad Microsoft has sponsored them, but it does contrast the decidedly lackluster support for HTML5 on its Xbox 360 consoles.The release of Internet Explorer on Xbox 360 is a step in the right direction. Hopefully someday youâ€™ll see our HTML5 games running natively via XBIG, but in the meantime, why not fire up Internet Explorer?First, download Internet Explorer onto your console. Then, open Internet Explorer and navigate it to arcade.lostdecadegames.com. Once there, it should look like this:First, I recommend a quick game of Onslaught! Defense. I played a game and happily got my highest score ever! Fair warning, there is some awkwardness with the controls: youâ€™ll need to move Internet Explorerâ€™s cursor to the directional slider at the bottom of the screen. Hold down the A button and you should be able to control the character.Onslaught! Defense isnâ€™t a terribly deep game, so next up how about some Lunch Bug? It feels best with a touch or click interface, but Internet Explorerâ€™s cursor is good enough. Of course, like in many other browsers, the sound playback is buggy and unreliable, but the game runs pretty smoothly and the graphics look great on a big TV.I think youâ€™ll agree that the games show a lot of potential, but there are plenty of issues that would be largely solved by a native wrapper. For example, the audio in Lunch Bug is pretty bad in desktop and mobile browsers, but sounds great in the native Android version.So this is really exciting and awesome, but our question is: will we get native HTML5 games on Xbox 360, or will we have to wait for the next generation of consoles? If someone at Microsoft happens to read this, please do get in touch.All of the Tor Browser Bundles have been updated with the latest Firefox 10.0.10esr release and all of the alpha packages, including the alpha Tor Browser Bundles, have been updated with the latest release of Tor 0.2.3.24-rc.We've been following the core media appsâ€”Music and Videoâ€”since the Windows 8 Consumer Preview. That development hinted Microsoft wanted to become a viable competitor to Apple and Amazon in the multimedia content realm. We found the first glimpse compelling, a signal that perhaps there was a true stake for Redmond to claim.Now with Windows 8 live, the Preview groundwork has been built upon. As you'll see here, things have changed, but not always as expected. The evolution of Music and Video begins up front, where the apps have shed their Zune branding. Instead, Microsoft choseÂ to reuse the Xbox brand, as the company moves to expand the scope of the Xbox name from gaming to allÂ media and entertainment.The Music and Video applications are close siblings. Aside from the obvious difference implied by their names, their structure and organization are essentially identical.In both apps, the first/main screen is dominated by Microsoft's attempts to sell to you. Users are greeted by a mix of promotional areas that highlight "hot" artists or movies, and entryways into the music, movie, and TV stores. Your own media are hidden out of view to the left.Drill into your media, and you get simple browsing. For videos you get a bunch of thumbnails, and the ability to filter the visible videos according to whether they're films, TV shows, or other. (I don't know what it uses to make this distinction because all my videos appear as "other." There doesn't appear to be a way within the application to change that.)The layout is also terribly unscalable. The only option is to see some moderately large thumbnails in a list that scrolls left to right. That's OK if you have a few dozen videos; it's practically worthless if you have any more. It's just too hard to find what you want.In music, you get a spreadsheet-type view with the option to group by song, artist, or album. The most notable bit about this spreadsheet view is just how extraordinarily slow it is. Scroll too fast and you'll just see a blank great space where songs should be listed. A few seconds later it'll manage to populate itself. This slowness, combined with the lack of any apparent "fast scroll" mechanism (such as iOS's ability to scroll down the right edge) makes browsing and selecting files a tedious experience.Songs and albums can be selected by right clicking them or nudging them sideways, allowing group operations such as adding them to a playlist, to the Now Playing pseudo-playlist, or deleting them. Adding to playlists is a little glitchy. There are actually two buttons to add to playlists; one that adds to a new playlist, and one that adds to the last playlist you modified. This is a good idea, but I found the Music app was slow to notice when I'd changed to modifying a different playlist. For example, if I first edit playlist A and then edit playlist B, the "add" button would still show playlist A's name... and then a few seconds later change to playlist B.Like Windows Media Player, Music's Now Playing pseudo-playlist is maintained independently of your current view of the song spreadsheet. This is in contrast to iOS, where changing the sort order of the song list while browsing is also prone to changing the playback order. I prefer this approach, but its implementation in Music seems to leave a lot to be desired. Although it is easy to see what the Now Playing list is, I can't find any facility for actually changing it. Decide that you want to get rid of one of the songs you've cued up? Want to swap them around? For the life of me, I couldn't tell you how (if it's even possible to do at all). This feels like such a glaring oversight that I'm sure I must be missing something.Overall, I feel there's nothing fundamentally wrong with the basic presentation. With a bit of care and attention it could work well, but it's just not there yet.One smart feature: when Music is playing, the volume popup that appears when you use the hardware volume keys also includes playback controls and album art. It's a nice touch.One not at all smart feature: the play/pause key on keyboards with media keys doesn't control playback of the Music app. Want to quickly pause playback to take a phone call? You'll have to go into the app to do it.The main way for people to begin downloading content from BitTorrent is to visit one of the Internetâ€™s many hundreds of torrent sites. There they can download either .torrent files or, in the case of The Pirate Bay, magnet links. This week it became possible to go on a YouTube-like â€œrelated videoâ€? journey through BitTorrentâ€™s Distributed Hash Table to find similar content to that being already downloaded, all without visiting a torrent site.Visiting a torrent site to access content is a fairly simple affair. Select the URL, go to the site and type whatever youâ€™re looking for into the search box.However, if a BitTorrent user doesnâ€™t really know what he or she is looking for and needs some ideas, a torrent siteâ€™s category view comes in useful to allow browsing of specific content such as videos, music or games.But what if there was another mechanism through which to find new content, one that doesnâ€™t involve visiting a torrent site? One that would find content to download based on the activities of other BitTorrent users that have downloaded, to some extent, the same or similar content as you?Now all of that is possible with â€œSwarm Discoveriesâ€?, a new and intriguing feature added to the open source Vuze client this week. The feature uses the Vuze Distributed Hash Table (DHT) to anonymously relate one piece of downloaded content with another.â€œFor a long time users have been asking for a means to find more content that they might like, stuff similar to the kind of things they already download,â€? Paul Gardner from Vuze tells TorrentFreak.â€œExisting sites tend not to offer anything beyond simple categorization (e.g. by format or genre), and only cover their own domain of content â€“ users are looking for something that works â€˜horizontallyâ€™, across sites, while at the same time zooming in on things that may be of interest.â€?Striving towards solving this problem the Vuze team came up with Swarm Discoveries, a behavior-based torrent content discovery system. So what makes it tick?â€œGiven the lack of any standardized metadata for torrents, and the huge diversity of naming conventions, languages etc., any approach based on matching between static torrent data is difficult. So what we decided to concentrate on was the behavioral aspects of torrent selection,â€? Gardner reveals.â€œUsers are already way smarter than us at finding content they like, so why not use their expertise to raise everybodyâ€™s game?â€?And this is where it gets both slightly more complex and much more interesting.â€œSwarm Discoveries is based on the fact that if Alice downloads torrents A, B and C then, in some (unspecified) way there is a link between A, B and C. At the most abstract the link is that Alice likes A, B and C,â€? Gardner explains.â€œNow if Bob downloads B, C and D this re-enforces the fact that B and C are somehow related, but between them we know nothing regarding A and D.â€?Of course, when looking at the habits of just Alice and Bob the dataset is very small. However, millions of people are using the Distributed Hash Table which results in a much larger sample and the creation of ever more interesting links between content.As a side note, Vuze (or Azureus as it was then) debuted the first ever BitTorrent DHT.TorrentFreak gave the feature a test drive, and this is what happened when we tested it on a Fuduntu Linux distro we planned to test in a VirtualBox virtual machine.1. First we loaded up the Fuduntu torrent using Vuzeâ€™s inbuilt torrent search feature. Once underway a right-click revealed the Swarm Discovery option.2. Once selected this short list of related content appeared.Item 1 is for a Knoppix torrent. Knoppix is another Linux distro so the connection to our Fuduntu download is obvious.Item 2 turns out to be Hirenâ€™s Boot CD, a collection of fairly geeky system management tools which is (coincidentally or not) based on Knoppix.3. At this point the discovery can continue simply by right clicking on any result and selecting â€œDiscover Relatedâ€?. If you want to do some research on the torrents already found, the same menu gives access to some research tools.4. Digging down another level produced further related results.Of course, the system doesnâ€™t work only for Linux distros. In our tests popular video and music content hashes produced the richest and most complex results.I donâ€™t want to do anything, just make it work!For those of you too busy (or lazy) to right-click on downloads to find explicit results you can sit back and let Vuze do the work for you. Over time Vuze builds up results in the main Swarm Discoveries tab (youâ€™ll find it under â€˜Plugins & Extrasâ€™) and ranks them â€“ the more ways a torrent is related to your downloads the higher the rank it will be assigned (up to a max of 100).If youâ€™re bored with the current results then right-click on sidebar entry and select â€˜delete all resultsâ€™, Vuze will start generating a new set to inspire you.Although the Swarm Discoveries system might at first appear to be a privacy nightmare, concerned users can rest easy. There are no external databases and relationship data is anonymous. (Not to be confused with anonymous downloads of course, that would require a VPN or similar)â€œSwarm Discoveries is entirely implemented using the Distributed Hash Table (DHT) and results are automatically generated by Vuze clients â€“ there are no centralized components,â€? Gardner explains.â€œIn the same way that the DHT is used to relate content to peers during decentralized tracking it is also used to related one piece of content to another â€“ this relationship is stored anonymously, so when a Vuze client reads a relationship the originator of the relationship is unknown.â€?While Swarm Discoveries often produced fairly predictable results, such as supplying torrents to similar genres of music and movies, it also throws in the occasional curve ball â€“ perfect for those who browse YouTube for pop videos and end up two hours later viewing the mating rituals of a rare breed of mountain goat.Download the latest version of Vuze with Swarm Discoveries here.SUDBURY, Ontario (Reuters) - In an office trailer parked outside a mine shaft in northern Ontario, operator Carolyn St-Jean leans back in her chair and monitors a machine loading nickel-rich ore into rail cars deep underground.Once filled, the automated train will snake through a series of narrow tunnels, emerge from a rocky outcropping, then loop past St-Jean's window and dump its payload for sorting.Vale SA, the Brazilian company that owns the mine near this nickel-rich Canadian town, has spent nearly $50 million in two years to install and test the "rail-veyor." The company believes the transport system will revolutionize how it builds and extracts new mineral deposits.The equipment is made locally by Rail-Veyor Technologies Global Inc. It is one of many mining technologies that developers hope will allow future production to be run almost entirely by people safely above ground.Such advances may prove crucial as easy-to-exploit deposits run dry and miners drill deeper in more remote places to supply China, India and other emerging economies. The technology could make mining cheaper and safer, avoiding the need to dig wide tunnels and hire large numbers of expensive, skilled workers."As we go deeper, if we continue to apply existing thinking and existing technologies, it's a death spiral" for company profits, said Alex Henderson, who heads Vale's technology team in Sudbury."We need to begin to look at a step-change in mining rather than just incrementally improving our existing processes."The rail-veyor is one such step-change. At the test site, it has halved the time to build a mine, and Vale expects a 150 percent boost in production rates before year end. Â  Continued...Quantum entanglement stands as one of the strangest and hardest concepts to understand in physics. Two or more particles can interact in a specific ways that leave them entangled, such that a later measurement on one system identifies what the outcome of a similar measurement on the second systemâ€”no matter how far they are separated in space.Repeated experiments have verified that this works even when the measurements are performed more quickly than light could travel between the sites of measurement: there's no slower-than-light influence that can pass between the entangled particles. However, one possible explanation for entanglement would allow for a faster-than-light exchange from one particle to the other. Odd as it might seem, this still doesn't violate relativity, since the only thing exchanged is the internal quantum stateâ€”no external information is passed.But a new analysis by J-D. Bancal, S. Pironio, A. AcÃ­n, Y-C. Liang, V. Scarani, and N. Gisin shows that any such explanation would inevitably open the door to faster-than-light communication. In other words, quantum entanglement cannot involve the passage of informationâ€”even hidden, internal information, inaccessible to experimentâ€”at any velocity, without also allowing for other types of interactions that violate relativity.Experiments have definitively demonstrated entanglement, and ruled out any kind of slower-than-light communication between two separated objects.Â The standard explanation for this behavior involves what's called nonlocality: the idea that the two objects are actually still a single quantum system, even though they may be far apart. That idea is uncomfortable to many people (including most famously Albert Einstein), but it preserves the principle of relativity, which states in part that no information can travel faster than light.To get around nonlocality, several ideas have been proposed over the decades. Many of these fall into the category of hidden variables, wherein quantum systems have physical properties (beyond the standard quantities like position, momentum, and spin) that are not directly accessible to experiment. In entangled systems, the hidden variables could be responsible for transferring state information from one particle to the other, producing measurements that appear coordinated. Since these hidden variables are not accessible to experimenters, they can't be used for communication. Relativity is preserved.Hidden variable theories involving slower-than-light transfer of state information are already ruled out by the experiments that exclude more ordinary communication. Some modern variations combine hidden variables with full nonlocality, allowing for instantaneous transfer of internal state information. But could non-instantaneous, faster-than-light hidden variables theories still work?To investigate this possibility, the authors of the new study considered the possible experimental consequences. Obviously, one way to test it would be to increase the separation between the parts of the entangled system to see if we can detect a delay in apparently instantaneous correlation we currently observe. Sufficiently fast rates of transfer, however, would still be indistinguishable from nonlocality, given that real lab measurements take finite time to perform (this assumes that both experiments happen on Earth).The researchers took a theoretical approach instead, using something known as the no-signalling conditions. They considered an entangled system with a set of independent physical attributes, some observable, some hidden variables. Next, they allowed the state of the hidden variables to propagate faster than the speed of light, which let them influence the measurements on the separated pieces of the experiment.However, because of the nature of quantum mechanical systems, there was a symmetry between the hidden and measurable attributes of the systemâ€”meaning if the hidden variables could transfer information faster than light, then the properties we can measure would do so as well. This is a violation of the no-signalling condition, and causes serious problems for the ordinary interpretations of quantum physics.Of course, one conceivable conclusion would be that faster-than-light communication is possible; this result provided a possible avenue for testing that possibility. By restricting the bounds on the speed of interaction between entangled systems, future experiments could show whether any actual information is traveling or not.However, the far more likely option is that relativity is correct. In that case, the strong ban on faster-than-light communication would rule out the possibility of faster-than-light transfer of information encoded in hidden variables, and force us to deal with nonlocality. Once again, it would seem that local realism and relativity are incompatible notions in the quantum world.Hurricane Sandy swelled into a major threat to much of the U.S. East Coast on Thursday, U.S. forecasters said, as the storm swirled through the Bahamas after killing 21 people across the Caribbean.HAVANA (Reuters) - Hurricane Sandy swelled into a major threat to much of the U.S. East Coast on Thursday, U.S. forecasters said, as the storm swirled through the Bahamas after killing 21 people across the Caribbean.Strengthening rapidly after tearing into Jamaica and crossing the warm Caribbean Sea, Sandy hit southeastern Cuba early on Thursday with top sustained winds up to 110 miles per hour (177 km per hour) that left a trail of destruction, especially in the historic city of Santiago de Cuba.The Cuban government said on Thursday night that 11 people died in the storm, most killed by falling trees or in building collapses, including nine in Santiago de Cuba province and two in neighboring Guantanamo province.Haiti's civil protection office said nine people had died despite not getting a direct hit from Sandy, and one person was killed by falling rocks in Jamaica when the storm struck there on Wednesday.The Cuban deaths were an unusually high number for the communist island that prides itself on protecting its people from storms by ordering mass evacuations.Images on Cuban television showed downed trees, damaged buildings and debris-clogged streets in the country's second-largest city of Santiago de Cuba, which suffered a direct hit when the storm came ashore in the early morning hours."Everything's destroyed in Santiago. People are going to have to work very hard to recover," Alexis Manduley, a resident of the 498-year-old city, told Reuters by telephone.Santiago de Cuba, with a population of about 500,000, is 470 miles southeast of Havana.U.S. government forecasters warned that much of the U.S. East Coast could get swiped by Sandy, with flooding, heavy rains and high winds beginning late Thursday in Florida. By early next week - amid final preparations for the crucial November 6 presidential election - the storm could hit an area of New England where Hurricane Irene caused severe damage last year.White House spokesman Jay Carney declined to speculate about whether there would be any change in President Barack Obama's campaign travel schedule because of Sandy, as he makes a last-minute blitz to win an edge over Republican Mitt Romney in a close race."The president's concern about this storm is to make sure that citizens in potentially affected areas are aware of this and taking necessary precaution," Carney said.He spoke aboard Air Force One as Obama headed from Florida to Virginia, saying the president had asked his team to hold regular briefings with federal disaster officials as the storm progresses.Sandy is forecast to make landfall as a Category 1 hurricane and the hardest-hit areas could span anywhere from the coastal Carolinas up to Maine, with New York City and the Boston area potentially in harm's way."Regardless of the exact track of Sandy, it is likely that significant impacts will be felt over portions of the U.S. East Coast through the weekend and into early next week," the Miami-based U.S. National Hurricane Center said."It's going to be a high-impact event," said Bob Oravec, a lead forecaster with the National Oceanic and Atmospheric Administration's HydroMeteorological Prediction Center in College Park, Maryland."It has the potential to be a very significant storm with respect to coastal flooding, depending on exactly where it comes in. Power outages are definitely a big threat," he said.In a subsequent report, NOAA's storm-prediction center suggested that Sandy could invite the ghoulish nickname "Frankenstorm," due to upcoming celebrations of Halloween and some of the freakish characteristics of the storm.The late-season cyclone is widely expected to undergo an unusual merger with a polar air mass over the Mid-Atlantic and Northeast on Tuesday, essentially bringing two sources of energy together and giving Sandy the potential to punch above its weight as it sloshes across the U.S. coast.At 11 p.m. EDT), the NHC said Sandy was about 15 miles north-northeast of Eleuthera Island in the Bahamas and packing maximum sustained winds of 90 mph.High winds, rains and pounding surf are expected across parts of Florida's Atlantic coast, with the biggest impact lasting through Friday.Orange juice prices rose in U.S. trading on Thursday on speculative buying as investors bet that Sandy could damage crops in the citrus-rich Sunshine State.Unlike Irene, which caused billions of dollars in damage as it battered the Northeast in August last year, Sandy is forecast to be a weaker storm but will be moving slower than Irene, likely bringing more rain and increasing its potential for damage, weather forecasters said.At $4.3 billion in losses, Irene ranks as one of the 10 costliest hurricanes, adjusted for inflation and excluding federally insured damage, according to the Insurance Information Institute, an industry group.Jeff Masters, a hurricane specialist and blogger with private forecaster Weather Underground (www.wunderground.com), said a landfall by Sandy on Monday along the Mid-Atlantic Coast could trigger "a billion-dollar disaster.""In this scenario, Sandy would be able to bring sustained winds near hurricane force over a wide stretch of heavily populated coast," he said.Alternately, Masters said, some computer forecast models indicated Sandy had the potential to unleash "the heaviest October rains ever reported in the northeast U.S., Nova Scotia and New Brunswick."NOAA's Oravec said there could be tropical-storm to hurricane-force winds on the coast and added: "Coastal flooding will be a big concern."Sandy is expected to hit the United States during a full moon, increasing the flood potential since tides will be at or near their highest."There's a big potential for huge effects from the storm," said Oravec."We can't rule out the potential for snow eventually as we go into the week and the storm moves inland," he said.(Reporting by Jeff Franks and Nelson Acosta in Havana, Neil Hartnell in the Bahamas, Kevin Gray in Miami, Ben Berkowitz and Josephine Mason in New York; Writing by Tom Brown; Editing by David Brunnstrom, Philip Barbara and Lisa Shumaker)At its Windows Phone 8 launch event on Monday in San Francisco, Microsoft (MSFT) announced its Windows Phone Store is now filled with 120,000 apps. The Redmond, Washington-based company also unveiled that Windows Phone is now available in 50 languages. Comparatively, Appleâ€™s (AAPL) iOS App Store has over 700,000 apps and Android has 675,000 apps.Microsoftâ€™s corporate vice president Joe Belfiore didnâ€™t stop there, though. Belfiore said that Windows Phone 8 will have 46 of the top 50 apps on other smartphone platforms including Temple Run, Words With Friends,Â Angry Birds Star Wars and Pandora. To entice user to Windows Phone 8, Microsoft is tossing one year of ad-free Pandora with every device.If you keep all of your contacts in Google you might be interested in seeing a map showing their locations. Tech weblog Digital Inspiration shows how you can use their script to connect to your Google account and display a map of your contacts in Google Maps or Google Earth.You'll need to copy this spreadsheet to your Google Drive account. Inside the spreadsheet will be a custom menu labelled as Google Contacts. Click on that, choose Initialize, and authorize the script to run. When that is done click again on the Google Contacts menu and choose Generate KML file. The file will be generated and automatically emailed to your Gmail address.If you have Google Earth installed you can just open the file on your computer to view the map but if you'd prefer to use online Google Maps you'll just need to upload the file and then copy the link into Google Maps. I used Dropbox.You'll see a standard Google map with all of your contacts that have an address listed on their contact entry. For most of us this may be more gimmick than tool but if you have a list of customers you need to visit having such a list already in Google Maps may cut down on your travel preparations.See All Your Google Contacts on a Google Map | Digital InspirationIn the event that a giant asteroid is headed toward Earth, youâ€™d better hope that itâ€™s blindingly white. A pale asteroid would reflect sunlight â€” and over time, this bouncing of photons off its surface could create enough of a force to push the asteroid off its course. How might one encourage such a deflection? The answer, according to an MIT graduate student: with a volley or two of space-launched paintballs. Sung Wook Paek, a graduate student in MITâ€™s Department of Aeronautics and Astronautics, says if timed just right, pellets full of paint powder, launched in two rounds from a spacecraft at relatively close distance, would cover the front and back of an asteroid, more than doubling its reflectivity, or albedo. The initial force from the pellets would bump an asteroid off course; over time, the sunâ€™s photons would deflect the asteroid even more. Paekâ€™s paper detailing this unconventional strategy won the 2012 Move an Asteroid Technical Paper Competition , sponsored by the United Nationsâ€™ Space Generation Advisory Council, which solicits creative solutions to space-related problems from students and young professionals. Paek presented his paper this month at the International Astronautical Congress in Naples, Italy. The challenge put forth by this yearâ€™s U.N. competition was to identify novel solutions for safely deflecting a near-Earth object , such as an asteroid. Scientists have proposed a wide variety of methods to avoid an asteroid collision. Some proposals launch a projectile or spacecraft to collide with an incoming asteroid; the European Space Agency is currently investigating such a mission. Other methods have included detonating a nuclear bomb near an asteroid or equipping spacecraft as â€œgravity tractors,â€? using a craftâ€™s gravitational field to pull an asteroid off its path. Paekâ€™s paintball strategy builds on a solution submitted by last yearâ€™s competition winner, who proposed deflecting an asteroid with a cloud of solid pellets. Paek came up with a similar proposal, adding paint to the pellets to take advantage of solar radiation pressure â€” the force exerted on objects by the sunâ€™s photons. Researchers have observed that pressure from sunlight can alter the orbits of geosynchronous satellites, while others have proposed equipping spacecraft with sails to catch solar radiation, much like a sailboat catches wind. In his proposal, Paek used the asteroid Apophis as a theoretical test case. According to astronomical observations, this 27-gigaton rock may come close to Earth in 2029, and then again in 2036. Paek determined that five tons of paint would be required to cover the massive asteroid, which has a diameter of 1,480 feet. He used the asteroidâ€™s period of rotation to determine the timing of pellets, launching a first round to cover the front of the asteroid, and firing a second round once the asteroidâ€™s backside is exposed. As the pellets hit the asteroidâ€™s surface, they would burst apart, splattering the space rock with a fine, five-micrometer-layer of paint. From his calculations, Paek estimates that it would take up to 20 years for the cumulative effect of solar radiation pressure to successfully pull the asteroid off its Earthbound trajectory. He says launching pellets with traditional rockets may not be an ideal option, as the violent takeoff may rupture the payload. Instead, he envisions paintballs may be made in space, in ports such as the International Space Station, where a spacecraft could then pick up a couple of rounds of pellets to deliver to the asteroid. Paek adds that paint isnâ€™t the only substance that such pellets might hold. For instance, the capsules could be filled with aerosols that, when fired at an asteroid, â€œimpart air drag on the incoming asteroid to slow it down,â€? Paek says. â€œOr you could just paint the asteroid so you can track it more easily with telescopes on Earth. So there are other uses for this method.â€? Lindley Johnson, program manager for NASAâ€™s Near Earth Objects Observation Program, says Paekâ€™s proposal is â€œan innovative variationâ€? on a method used by others to capitalize on solar radiation pressure. For example, MESSENGER, a spacecraft orbiting Mercury, is equipped with solar sails that propel the craft with solar radiation pressure, reducing the fuel needed to power it. â€œIt is very important that we develop and test a few deflection techniques sufficiently so that we know we have a viable â€˜toolboxâ€™ of deflection capabilities to implement when we inevitably discover an asteroid on an impact trajectory,â€? Johnson says.William Ailor, principal engineer for Aerospace Corp. in El Segundo, Calif., adds that the potential for an asteroid collision is a long-term challenge for scientists and engineers. â€œThese types of analyses are really timely because this is a problem weâ€™ll have basically forever,â€? Ailor says. â€œItâ€™s nice that weâ€™re getting young people thinking about it in detail, and I really applaud that.â€?If you are like us and love R/C, this is the place for you. Every possible type of R/C model can be127 of my files in Dropbox are now gone forever, due to a bug where files were "updated" to be 0 bytes, and Dropbox lost its previous copy of the file.2 other files (precious family photos) were also affected, but it happened recently enough to be recovered manually by Dropbox engineers. 23 other files were also turned to 0 byte dust, but Dropbox kept its version history of these and I could revert them to their original version.Check whether you've been affected (on Mac or Linux) by running this command in a Terminal, it'll spit out a list of 0-byte files to a text file on your desktop.Important: Make sure you sanity check the list. Some systems have hidden 0-byte files, such as Macs' "Icon\r", that are expected and normal.If you find any that look unexpected, let Dropbox know, and reference this blog post to them so they can connect it with the issue I reported.I've included my correspondence with Dropbox on the issue below. They've been very nice about it, and are looking into it, but this is a very serious bug. Because they don't know what the bug is, potentially anyone could be affected. I'll update this post if they find a fix.Update: Some folks on Hacker News, and Matt Holden of Dropbox in the comments, have raised the possibility of filesystem corruption, particularly because of a recently reported ext4 bug. I do use ext4, so this can plausibly explain why my files were 0-byte'd in the first place, and why others have reported finding 0-byte'd files.I also do not use Packrat, a premium Dropbox feature that stores version history for longer than 30 days, so this could plausibly explain why my 127 files that had been 0-byte'd months ago no longer have a version history of before then. I wasn't aware of the 30-day window.However, these do not plausibly explain why the 2 manually recovered files that had recently been 0-byte'd, well within the 30-day window, showed no pre-0-byte version history, and required the assistance of Dropbox engineers.It could be that the bug here has nothing to do with their desktop client - it could be a version history bug in the web frontend that affects some recently edited files. If that's the case, then that still needs to be fixed, so that people in my position can recover files their disk corrupted before they pass out of the 30-day window. It's only by finding and fixing that website bug that Dropbox can say with confidence that there's no desktop client bug.Update 2: A report by someone who is on OS X, uses Packrat, but has lost 70 files they can't recover.If you are like us and love R/C, this is the place for you. Every possible type of R/C model can beFlooding and power outages caused by Hurricane Sandy have forced several New York data centers to switch to generator power. But those generators are quickly running out of fuel, so data center companies are telling their customers to shut down their servers and move workloads elsewhere.One of the worst situations is at 75 Broad Street in Manhattan, where both Internap and Peer1 Hosting are shutting down operations "after basement-level flooding disabled critical diesel fuel pumps," Data Center Knowledge reports. 75 Broad Street is part of the "Zone A" portion of the city that is under emergency evacuation orders, as is another data center operated by Datagram at 33 Whitehall Street. The Datagram outage led to downtime for popular websites Gawker, Huffington Post, and BuzzFeed.Peer1's official network status page reported last night that it was running on emergency generator power. This morning, the company said "we have an estimate of 4 hours for the fuel left on our generators. Our techs and facility are continuously working to get emergency fuel delivery on time and was looking to set-up a temporary tank and pump since the basement is still flooded. In the event of not receiving the fuel on time, worst case scenario is we will have to gracefully shutdown the facility."The worst case scenario has apparently occurred, as the latest update says, "We are going to implement a controlled shutdown of NY Data Center at 10:45 ET." (UPDATE: Peer1 reported good news just before 12:30pm ET. "The New York facility is still on generator power, sustaining longer than initially estimated," Peer1 said. "We will have the latest update on the remaining fuel available, along with the arrival of fuel replacement shortly.")Internap is reporting much the same scenario. In a note to customers made public on Pastebin, Internap said, "The flooding has submerged and destroyed the site's diesel pumps and is preventing fuel from being pumped to the generators on the mezzanine level. The available fuel reserves on the mezzanine level are estimated to support customer loads for approximately 5-7 hours. Once this fuel supply has been exhausted the generator will no longer be able to sustain operation and critical customer power loads will be lost. The building itself is being evacuated and no remote hands support will be available to assist in any equipment shutdown."Internap advised its self-service customers to shut down their servers immediately and is having its customer support team execute a "graceful" shutdown of servers for managed customers. Internap's cloud services are also being shut down, the company said. We've asked Internap for an update and will report back if we get one. But according to iT News, Internap sent customers a follow-up e-mail this morning that said, "Available fuel reserves on the mezzanine level are estimated to be nearly depleted and able to support customer loads for less than 2 hours. Once this fuel supply has been exhausted the generator will no longer be able to sustain operation and critical customer power loads will be lost."UPDATE: Internap is reportedlyÂ out of fuel and offline, but it is trying to get more fuel to the building. As of 12:55pm ET, the Internap network operations center hotline was playing a recorded message that says the facility is "currently without power due to flooding" and that co-location and IP customers can expect "widespread outages." Later in the day, the company posted a blogÂ saying the 75 Broad Street facility was still without power, but that Internap isÂ trying to get its generator farm back up and running. "It is unclear how long it will take ConEd to restore utility power to the site, but we are preparing for the possibility of remaining on generator power for many days," Internap said.Â In addition to running out of fuel in secondary tanks, Internap said the flooding damaged "both our redundant fuel pumps and our generator fuel tank." Internap is coordinating fuel deliveries and pumps, and said it will have engineers "fabricate pipe to bring the fuel directly to the generators on the mezzanine level."In addition to damage caused by flooding, New York power company Con Edison said it preemptively shut off electricity in part of Lower Manhattan last night, and reported today that substation damage and downed wires cut off power to many customers. Con Edison called it "the largest storm-related outage in our history."As mentioned, Gawker, Huffington Post, and BuzzFeed have suffered downtime as a result of flooding at Datagram's data center at 33 Whitehall Street. As of this writing, the main Gawker sites are still offline (stripped-down versions are reachable at live.gawker.com), while the Huffington Post andÂ Buzzfeed have gotten themselves back online.Further outages includedÂ Steadfast hosting at 121 Varick Street in New York City due to "an auxiliary electrical failure," and Init7 at 111 8th Avenue, due to a data center power outage. Init7 operates IP backbone services. As a result of the outage, the company said to expect "possible routing issues from/to the United States." As it turns out, Internap also has servers at the 8th Avenue address, but they are operating under generator power and have enough fuel for several days.It's not as if data centers didn't take any precautions. In advance of the storm, Data Center Knowledge reported that "data center providers in New York, Philadelphia and the Washington, DC area said they are testing and fueling up their emergency backup generators, preparing to maintain services during any utility power outages caused by the hurricane." The cloud storage provider Nirvanix allowed customers to move data out of its data center in New Jersey for free. And cloud service providers such as Amazon are closely monitoring data centers on the East Coast, stocking up on generator fuel, and having extra staff on hand.As various non-storm-related outages at Amazon have shown, customers relying on hosting providers and cloud services may want to build systems that can fail over across multiple regions. Ultimately, when a data center is in the wrong spot at the wrong time, even the most extensive preparations may not be enough to stay online in the face of a storm like Hurricane Sandy.The Internet has evolved quite a bit since I first logged on to CompuServe in 1994. Iâ€™d spent a few years tooling around on BBS (Bulletin Board Systems) connections throughout the country at that point and the most visible portions of a forming World Wide Web were quite innocent in appearance. But as I ramped up my fatherâ€™s 4600 baud modem and looked around at the fringes of online existence, I unknowingly caught a glimpse at the Webâ€™s early underbelly. From there, pornography, craziness and illegal activities were easily accessible. There werenâ€™t many people logging on so, naturally, there werenâ€™t many people to police this new digital space. Eventually, as AOL, Prodigy and other ISPs became more mainstream, the more nefarious outlets vanished into the shadows. But where did it all go? I recently took a plunge into the â€˜Deep Web,â€™ a sub-surface area of the Internet not indexed by search engines and only available to those on the forefront of technology, namely people connected to the Tor Network. This network of hidden websites is the new underbelly of the Web, the New Underground, if you will, chock full of all sorts of illicit activities. Child porn peddlers, drug dealers, hitmen and other criminal groups thrive on the Deep Web and anonymity reigns supreme. The following post outlines my findings and hopefully sheds some light on the true Wild Wild West of the World Wide Web.What is the Deep Web?: Wikipedia has an excellent overview on the Deep Web.The Deep Web (also called Deepnet, the invisible Web, DarkNet, Undernet or the hidden Web) refers to World Wide Web content that is not part of the Surface Web, which is indexed by standard search engines. Mike Bergman, credited with coining the phrase,[1] has said that searching on the Internet today can be compared to dragging a net across the surface of the ocean: a great deal may be caught in the net, but there is a wealth of information that is deep and therefore missed. Most of the Webâ€™s information is buried far down on dynamically generated sites, and standard search engines do not find it. Traditional search engines cannot â€œseeâ€? or retrieve content in the deep Web â€“ those pages do not exist until they are created dynamically as the result of a specific search. The deep Web is several orders of magnitude larger than the surface Web.So if the Internet as you know it is an iceberg, the smallest part of that iceberg, the visible portion, is where you have been surfing your entire life. You visit websites, click links, use search engines to research topics of interest and generally just make your way around the visible Web. But below that visible portion, there is a much larger compilation of destinations beyond the reach of most Internet users. This portion, the Deep Web, is much harder for the average person to access and even harder to navigate. Much of the criminal activity that happens on the Deep Web is cloaked in anonymity, shrouded in secrecy or somehow hidden from the prying eyes that would love to put an end to this virtual land of OZ. Essentially what Iâ€™m saying is this: You may be familiar with the Internet, maybe even the darker side of the Internet. You may know how to find pornography for free, download music illegally, use a torrent program to download pirated movies and other media or purchase prescription pills from some online pharmacy. But if you havenâ€™t visited the Deep Web, you ainâ€™t seen nothing yet. Sure, there are research papers and legitimate and interesting pieces of content to view on The Other Side but thereâ€™s also some pretty nefarious happenings there.How do you connect to the Deep Web?: Though the Deep Web may be beyond those of you with little in the way of technical and Web savvy, itâ€™s not impossible, nor even extremely difficult to visit. First, youâ€™ll need to download Tor, the software that allows you to access the Deep Web. Tor is designed to provide Internet users with as close to complete anonymity as possible. The Tor website describes their software and their mission as follows.You can use Tor on virtually any PC, Mac or even mobile devices like the iPhone and Android-operated smartphones. But, if, like me, youâ€™re using Firefox, you next need to install the Torbutton. With the Tor software up and running and the Torbutton installed, youâ€™ll see a small onion logo near the address bar of your browser. If youâ€™re correctly logged in to the Tor network, you can click this button and begin to explore the Deep Web. This collection of Deep Web links should get you started. But, keep in mind, you wonâ€™t be able to maneuver in this new land quite as easily as you did back on the visible Web. There is no Google-like search engine of these sites that Iâ€™m aware of at the moment. Instead, itâ€™s a collection of Wikis and BBS-like sites that aggregate links to other locations on the Deep Web. These sites generally have bizarre, unmemorable domain names like SdddEEDOHIIDdddgmomionw.onion. Thatâ€™s right, instead of .com, these domains generally end in the .onion suffix. And because youâ€™ll never remember how you got to where you are if you spend any significant time here, itâ€™s best to save URLs or bookmark your way through this journey.What can you find on the Deep Web?: The Silk Road is the most popular place to buy drugs on the Deep Web. From ecstasy, pure MDMA, marijuana, psychedelics and seeds to opiates, they have basically any drug with a userbase. They also have categories for â€˜servicesâ€™ like hacking, â€˜lab suppliesâ€™ like sulfuric acid and liquid mercury, â€˜moneyâ€™ for stolen credit cards, travelers checks and forged bills and coins, â€˜jewelryâ€™ like uncut stones, stolen gold and other precious metals obtained via devious means and finally â€˜weaponsâ€™ where they currently list a Glock 17 for sale out of Canada that â€œincludes 1 clip with 9 live rounds.â€? Another Deep Web drug outlet, the General Store, focuses on Ketamine, MDMA, MDPV and DMT (you may need to Google some of those).Additional items in the â€˜marijuanaâ€™ category on The Silk Road:Forum posts like this are common (and often answered) and even include requests for murders:(Note: This is not from The Silk Road, but a popular message board on the Deep Web)Most transactions on the Deep Web are conducted via Bitcoins. You can purchase virtually anything with this digital currency, ranging from the legit to the oh-so-far-away from legit. You can buy all the items outlined above and you can even hire a prostitute. There is, however, some debate over whether or not these transactions are anonymous (more on that below). 1 Bitcoin = $9 US.You can find literally ANYTHING illegal on the Deep Web. Speaking of illegalâ€¦Let me issue a STRONG WARNING at this point. Be extremely careful what sites you visit and links you click. You could find yourself on a child pornography website or just all-around grotesque sexual deviance-focused site that will ruin your experience (and in the case of child pornography, your life). The wiki page linked to above contains mostly safe sites to search but stay away from anything labeled as a â€˜chanâ€™ or â€˜bulletin boardâ€™ as they probably traffic heavily in child pornography. Anything labeled CP is to be AVOIDED AT ALL COSTS. It will lead you to child porn.There are sites on the Deep Web that offer the services of hitmen, advice to gang members, directions on how to build explosives, how to cheat at virtually anything and pretty much any other illegal activity or service that you can dream of â€“ itâ€™s all there, some of it is frightening, some of it is interesting, all of it is anonymous. Wait, is it really anonymous?Is this all truly anonymous?: Probably not. To the horseâ€™s mouth, we go.Though he may be saying that because Bitcoin hopes to be viewed as a legitimate business.My journey though The New Underground, the Deep Dark Web, was interesting, to say the least. Thereâ€™s a lot of potential for trouble down near the bottom of this iceberg, so always be aware of what youâ€™re doing and the legality of your actions. Still, I have an unquenchable thirst for the unknown so by carefully maneuvering in a way that kept several meters and a snake pit between myself and the most vile content on the Deep Web, I was able to learn a bit about a facet of the Internet I had yet to discover. Iâ€™d encourage you to poke around a bit as well. But, remember, do so at your own risk. Be safe, watch what you click and refrain from purchasing anything along the way.Be careful, itâ€™s a whole new world down there.Last year AMD officially became an ARM licensee, although the deal wasn't publicized at the time. Fast forward to June 2012 and we saw the first fruits of that deal: AMD announced it would integrate ARM's Cortex A5 core into its 2013 APUs to enable TrustZone support.Today comes a much bigger announcement: AMD will be building Opteron processors based on a 64-bit ARM architecture. There are no product announcements today, but the 64-bit ARM Opterons will go into production in 2014. Today's announcement is about a processor license, not an ARM architecture license - in other words, AMD will integrate an ARM designed 64-bit core for this new Opteron. Update: AMD will integrate ARM's new Cortex-A50 series of 64-bit ARMv8 CPU cores.The only other detail we know is that these ARM based Opterons will embed SeaMicro's Freedom Fabric, presumably on-die.AMD offering ARM based Opterons is really to target the microserver market. As for why AMD isn't using Jaguar for these parts, it's likely that by going with ARM it can lower the development time and cost to get into this market. The danger here is the total microserver market is expected to be around 10% of the overall server market, but that includes x86 + ARM. With x86 as the default incumbent, it's going to be an uphill battle for AMD/ARM to carve out a significant portion of that market.AMD was quick to mention that despite today's announcement, it will continue to build x86 CPUs and APUs for client and server markets.Overall the move sounds a lot like AMD trying to move quickly to capitalize on a new market. It's unclear just how big the ARM based server market will be, but AMD seems to hope that it'll be on the forefront of that revolution - should it happen. Embracing ARM also further aligns AMD with one of Intel's most threatening sources of competition at this point. The question is whether or not AMD is doing itself more harm than good by working to devalue x86 in the server space. I suspect it'll be years before we know the real impact of AMD's move here.The other major takeaway is that AMD is looking to find lower cost ways of bringing competitive platforms to market. I do think that a Jaguar based Opteron would likely be the best route for AMD, but it would also likely require a bit more effort than integrating an ARM core.Obviously competition will be more prevalent in the ARM server space, but here is where AMD hopes its brand and position in the market will be able to give it an advantage. AMD will also be relying heavily on the SeaMicro Freedom Fabric for giving its ARM based Opterons a leg up on the competition. This is one time where I really wish AMD hadn't spun off its fabs.Yesterday morning, the Free Software Foundation crashed the Windows 8 launch event in New York City. A cheerful GNU and her team handed out DVDs loaded with Trisquel, FSF stickers, and information about our new pledge, which asks Windows users to upgrade not to Windows 8, but to GNU/Linux.Drag and drop file or link here to translate the document or web page.Drag and drop link here to translate the web page.We do not support the type of file you drop. Please try other file types.We do not support the type of link you drop. Please try link of other types.The U.S. Supreme Court will hear arguments on Monday in one of the most important copyright cases in a decade, over whether works manufactured outside the United States can be resold here without the permission of the copyright owner.The decision could have a huge impact on the $63 billion "gray market" for goods purchased abroad and sold for a higher price in the United States.Both parties to the case believe a loss for their side will result in a doomsday scenario of sorts. One side says that a ruling in their favor is the only way to free American consumers from the potential of copyright holders to exert never ending control over their material. The other side insists that a decision for them is the only way U.S. companies will be able to successfully participate in the global marketplace. A down-the-line victory for one side or the other is likely to result in the loser lobbying Congress for an update to the Copyright Act.At issue in the case, Kirtsaeng v. John Wiley & Sons, are provisions of the Copyright Act that appear contradictory. One section says that the importation into the United States, without the authority of the copyright owner, of works acquired abroad is an infringement of the copyright owner's exclusive right to distribute copies. However, another part of the act limits the copyright holder's distribution rights by saying that the owner of a copy "lawfully made under this title" can sell or otherwise get rid of it. That resell right is known as the "first-sale doctrine."Supap Kirtsaeng, a Thai man who attended college and graduate school in the United States, had his family at home buy textbooks manufactured internationally and ship them to him. He then resold the books on eBay. John Wiley & Sons, a prominent textbook publisher, has the exclusive rights to distribute its textbooks in the United States, and some of the books Kirtsaeng sold were Wiley textbooks that were manufactured abroad. Wiley sued and was awarded several hundred thousand dollars in damages. The student, who maintained that he had the right to resell books he owned, appealed. In August 2011, the 2nd U.S.Circuit Court of Appeals sided with Wiley and held that the first-sale doctrine was inapplicable because the "lawfully made under this title" language referred only to copies manufactured in the United States.In its decision, authored by Judge Jose Cabranes, the 2nd Circuit acknowledged the "particularly difficult question of statutory construction" and said that "if our decision leads to policy consequences ... which Congress now find unpalatable, Congress is of course able to correct our judgment."Those "unpalatable" consequences have been highlighted, in amicus briefs and other public statements by companies like eBay and Costco, whose businesses rely on resales, as well as by libraries and museums who acquire works from around the world.(We wrote about the library group's amicus brief in July.)Kirtsaeng's brief, submitted by a team including Joshua Rosenkranz of Orrick, Herrington & Sutcliffe, also walks through examples of what could happen if the court upholds the 2nd Circuit's decision. The resale or lease of cars imported into the United States, which almost always have copyrighted software, would violate copyright laws, and movie producers could begin manufacturing DVDs abroad and "enjoy a permanent veto over any further rental of the foreign-made DVD," the brief said.Though "anyone who makes a product would love to control what happens to it downstream," the longstanding U.S. law is that if you bought it, you own it, no matter where that purchase was made, Rosenkranz said. That is a point he will put "front and center" to the court, he said.While it sounds like an odd outcome that goods manufactured abroad could receive more far-reaching copyright protection than goods manufactured domestically, John Wiley's team, led by Theodore Olson of Gibson, Dunn & Crutcher, argued in its brief that those fears were much ado about nothing. Kirtsaeng's examples, it argued, focus on scenarios where the copyright owner authorized the original import. The court does not need to address what happens to the first-sale doctrine in the event of an "authorized" importation, the Wiley brief said, and can instead just focus on Kirtsaeng's unauthorized import and sale.Evan Finkel, an intellectual property partner at Pillsbury Winthrop Shaw Pittman, said because of the facts of the case and the section's wording, it's unlikely the Supreme Court will enact such a specific exception in this case. Instead, should the court rule for Wiley, he said, they could note some exception for individual consumers reselling a book or two, or at least note that it is a question for another day.Monday will be like the second time around for this copyright question. In 2010, the Supreme Court upheld a 9th Circuit decision involving Costco's sale of gray-market Omega brand watches. The circuit court had ruled that the first sale doctrine does not apply to works manufactured outside the United States. The Supreme Court's holding came with no opinion, however. It was a result of a 4-4 tie, with Justice Elena Kagan not participating. This time around, Kagan will be on the bench.While both parties argue that history and statutory interpretation are on their side, they recognize to some extent that an increasingly shrinking world might not fit within the confines of the current law. Wiley's brief acknowledges that many of the scenarios, like one involving Netflix and DVD rentals, could not have been considered by Congress because they didn't exist when the first sale-related section was drafted nearly 40 years ago.Follow us on TwitterÂ @AlisonFrankel,Â @erin_gs,Â @ReutersLegalÂ Â |Â Like us onÂ FacebookÂ Â Â Computerworld - The FBI has arrested Paul Ceglia for attempting to defraud Facebook and its co-founder Mark Zuckerberg in a scheme to grab a large stake in the company and billions of dollars.Federal agents picked up 39-year-old Ceglia at his home in Wellsville, N.Y. this morning, according to a report in Forbes.Ceglia first filed a lawsuit in June 2010, claiming he signed a contract with Zuckerberg that entitles him to 84% ownership of what is easily the world's largest social network. In an amended filing last year, though, Ceglia modified his claim, alleging he was owed 50% of Zuckerberg's stake in the social networking company.According to a criminal complaint filed with the Southern District of New York, Ceglia is accused of using the U.S. Postal Service as part of a fraudulent scam against Facebook and Zuckerberg.Ceglia is being charged with mail fraud and wire fraud."Ceglia filed a federal lawsuit falsely claiming that he was entitled to at least a 50% interest in Facebook," the complaint contends. "Ceglia has deliberately engaged in a systematic effort to defraud Facebook and Zuckerberg and to corrupt the federal judicial process."Not surprisingly, today's arrest was met with excitement at Facebook."We commend the United States Attorney for charging Ceglia with federal crimes in connection with his fraudulent lawsuit against Facebook," Orin Snyder, a partner with Gibson Dunn, attorneys for Facebook and Zuckerberg, said in an email to Computerworld. "Ceglia used the federal court system to perpetuate his fraud and will now be held accountable for his criminal scheme."The complaint also contends that Ceglia and Zuckerberg had signed a contract between them, but it had nothing to do with Facebook, did not reference Facebook and did not give Ceglia any interest in the social network.And federal investigators allege that as part of his scheme, Ceglia manufactured and destroyed evidence, for instance replacing a page of the original contract with a fraudulent one that made it look like Zuckerberg had offered Ceglia interest in the company.The complaint even has a section titled: The Founding of Facebook Did Not Involve Ceglia.In 2011, Facebook attorneys filed court documents saying they had found evidence that Ceglia had concealed or destroyed relevant documents, including six missing USB drives.The social network's lawyers said they had uncovered an "authentic" contract that showed that Ceglia wasn't owed any interest in Facebook.Sharon Gaudin covers the Internet and Web 2.0, emerging technologies, and desktop and laptop chips for Computerworld. Follow Sharon on Twitter at Â @sgaudin, on Google+ or subscribe to Sharon's RSS feedÂ . Her email address is sgaudin@computerworld.com.See more by Sharon Gaudin on Computerworld.com.Read more about Social Media in Computerworld's Social Media Topic Center.BASF has been researching into metal-organic frameworks (MOFs), and the processes that can be used to manufacture these highly efficient storage materials for gases on an industrial scale, for more than ten years. In September, BASF was awarded the Pierre Potier Prize in the field of process innovation for its successful research. This prize is awarded for outstanding examples of sustainable innovations in the field of chemistry by the two French chemical associations FÃ©dÃ©ration FranÃ§aise pour les sciences de la Chimie (FFC) and lâ€™Union des Industries Chimiques (UIC) in honour of the chemist and pharmacist Pierre Potier.We spoke with Dr. Manuela Gaab, one of the chemists in the MOF research team at BASF, in order to learn more about the potential of MOFs, their applications and the innovative new manufacturing process.Why is this new manufacturing process so innovative and sustainable? This novel process enables us to produce aluminium MOFs on an industrial scale for the first time. We can now produce batches of several tons, and they can be used commercially in applications such as storage tanks for natural gas. Another important advantage is that this innovative process no longer employs any organic solvents, only water. This makes it safe and environmentally friendly. These MOFs are very easy to produce, so easy that advanced school students can make them in our school laboratory.Why are MOFs so special? The special feature of MOFs is that their crystalline nanostructures enable them to be used to store natural gas and other fuel gases such as hydrogen. MOFs consist of a three-dimensional metal-organic framework with pore sizes in the nanometer range. Their high porosity and their large internal surface area allow them to be used to store large quantities of gas.The huge surface area of these crystals is illustrated very well by MOF-210, which was developed by Professor Yaghi (University of California, Berkeley). These zinc carboxylate crystals have a surface area of more than 10 000 m2 per gram. This corresponds to three football pitches within a material quantity that correlates to a sugar cube! Their enormous surface area enables metal-organic frameworks to be used to store large quantities of gas, just like water in a sponge.What are the applications for MOFs? Mobility is an interesting area of application for MOFs. At BASF, we are researching into alternative power concepts for the future that are environmentally friendly and conserve resources as well as being comfortable. We are investigating several different concepts aimed at improving the performance of vehicles powered by electricity and natural gas. MOFs can make a decisive contribution to the performance of vehicles powered by natural gas. Up until now, very few vehicles powered by natural gas have been approved for use on the roads, even though they represent an environmentally friendly alternative mode of transport. One of the main reasons for this is their low fuel storage capacity, which causes the bulky gas tanks and bottles to take up lots of room, and their limited range. They have to be fitted with an extra tank, and some of the luggage space is used to accommodate large gas bottles. MOFs can play an important role here, because their special properties can be used to obtain a large increase in fuel storage capacity.How can MOFs be used to increase the storage capacity of tanks for natural gas? Gas molecules can be stored at a higher density on the surfaces of MOFs than in conventional tanks. This enables more gas to be stored in tanks with the same volume at the same pressure. Larger quantities of gas in the tank increase the range of vehicles and, in future, cars powered by natural gas will be able to travel twice as far on one tank of gas.What other possible applications are there for MOFs? Separating and purifying gases are examples of industrial applications for MOFs. These applications make use of the different pore sizes of MOFs and differences in the affinity of gases for different materials. Another industrial application is catalysis, and we are also currently exploring other applications such as fuel cells for automobiles. MOFs could be used to store hydrogen fuel in the same way as the natural gas that is used to power vehicles. These are only a few examples of the versatile range of applications for MOFs and their future potential. We are in a position to supply customized MOFs in order to meet the specific demands of different customers, and new classes of MOF will also gradually find their way onto the market.In the space of one hour, my entire digital life was destroyed. First my Google account was taken over, then deleted. Next my Twitter account was compromised, and used as a platform to broadcast racist and homophobic messages. And worst of all, my AppleID account was broken into, and my hackers used it to remotely erase all of the data on my iPhone, iPad, and MacBook.In many ways, this was all my fault. My accounts were daisy-chained together. Getting into Amazon let my hackers get into my Apple ID account, which helped them get into Gmail, which gave them access to Twitter. Had I used two-factor authentication for my Google account, itâ€™s possible that none of this would have happened, because their ultimate goal was always to take over my Twitter account and wreak havoc. Lulz.Had I been regularly backing up the data on my MacBook, I wouldnâ€™t have had to worry about losing more than a yearâ€™s worth of photos, covering the entire lifespan of my daughter, or documents and e-mails that I had stored in no other location.Those security lapses are my fault, and I deeply, deeply regret them.But what happened to me exposes vital security flaws in several customer service systems, most notably Appleâ€™s and Amazonâ€™s. Apple tech support gave the hackers access to my iCloud account. Amazon tech support gave them the ability to see a piece of information â€” a partial credit card number â€” that Apple used to release information. In short, the very four digits that Amazon considers unimportant enough to display in the clear on the web are precisely the same ones that Apple considers secure enough to perform identity verification. The disconnect exposes flaws in data management policies endemic to the entire technology industry, and points to a looming nightmare as we enter the era of cloud computing and connected devices.This isnâ€™t just my problem. Since Friday, Aug. 3, when hackers broke into my accounts, Iâ€™ve heard from other users who were compromised in the same way, at least one of whom was targeted by the same group.â€¬Moreover, if your computers arenâ€™t already cloud-connected devices, they will be soon. Apple is working hard to get all of its customers to use iCloud. Googleâ€™s entire operating system is cloud-based. And Windows 8, the most cloud-centric operating system yet, will hit desktops by the tens of millions in the coming year. My experience leads me to believe that cloud-based systems need fundamentally different security measures. Password-based security mechanisms â€” which can be cracked, reset, and socially engineered â€” no longer suffice in the era of cloud computing.I realized something was wrong at about 5 p.m. on Friday. I was playing with my daughter when my iPhone suddenly powered down. I was expecting a call, so I went to plug it back in.It then rebooted to the setup screen. This was irritating, but I wasnâ€™t concerned. I assumed it was a software glitch. And, my phone automatically backs up every night. I just assumed it would be a pain in the ass, and nothing more. I entered my iCloud login to restore, and it wasnâ€™t accepted. Again, I was irritated, but not alarmed.Â I went to connect the iPhone to my computer and restore from that backup â€” which I had just happened to do the other day. When I opened my laptop, an iCal message popped up telling me that my Gmail account information was wrong. Then the screen went gray, and asked for a four-digit PIN.By now, I knew something was very, very wrong. For the first time it occurred to me that I was being hacked. Unsure of exactly what was happening, I unplugged my router and cable modem, turned off the Mac Mini we use as an entertainment center, grabbed my wifeâ€™s phone, and called AppleCare, the companyâ€™s tech support service, and spoke with a rep for the next hour and a half.It wasnâ€™t the first call they had had that day about my account. In fact, I later found out that a call had been placed just a little more than a half an hour before my own. But the Apple rep didnâ€™t bother to tell me about the first call concerning my account, despite the 90 minutes I spent on the phone with tech support. Nor would Apple tech support ever tell me about the first call voluntarily â€” it only shared this information after I asked about it. And I only knew about the first call because a hacker told me he had made the call himself.At 4:33 p.m., according to Appleâ€™s tech support records, someone called AppleCare claiming to be me. Apple says the caller reported that he couldnâ€™t get into his Me.com e-mail â€” which, of course was my Me.com e-mail.In response, Apple issued a temporary password. It did this despite the callerâ€™s inability to answer security questions I had set up. And it did this after the hacker supplied only two pieces of information that anyone with an internet connection and a phone can discover.At 4:50 p.m., a password reset confirmation arrived in my inbox. I donâ€™t really use my me.com e-mail, and rarely check it. But even if I did, I might not have noticed the message because the hackers immediately sent it to the trash. They then were able to follow the link in that e-mail to permanently reset my AppleID password.At 4:52 p.m., a Gmail password recovery e-mail arrived in my me.com mailbox. Two minutes later, another e-mail arrived notifying me that my Google account password had changed.Â At 5:02 p.m., they reset my Twitter password. At 5:00 they used iCloudâ€™s â€œFind Myâ€? tool to remotely wipe my iPhone. At 5:01 they remotely wiped my iPad. At 5:05 they remotely wiped my MacBook. Around this same time, they deleted my Google account. At 5:10, I placed the call to AppleCare. At 5:12 the attackers posted a message to my account on Twitter taking credit for the hack.By wiping my MacBook and deleting my Google account, they now not only had the ability to control my account, but were able to prevent me from regaining access. And crazily, in ways that I donâ€™t and never will understand, those deletions were just collateral damage. My MacBook data â€” including those irreplaceable pictures of my family, of my childâ€™s first year and relatives who have now passed from this life â€” werenâ€™t the target. Nor were the eight years of messages in my Gmail account. The target was always Twitter. My MacBook data was torched simply to prevent me from getting back in.I spent an hour and a half talking to AppleCare. One of the reasons it took me so long to get anything resolved with Apple during my initial phone call was because I couldnâ€™t answer the security questions it had on file for me. It turned out thereâ€™s a good reason for that. Perhaps an hour or so into the call, the Apple representative on the line said â€œMr. Herman, Iâ€¦.â€?â€œWait. What did you call me?â€?â€œMy name is Honan.â€?Apple had been looking at the wrong account all along. Because of that, I couldnâ€™t answer my security questions. And because of that, it asked me an alternate set of questions that it said would let tech support let me into my me.com account: a billing address and the last four digits of my credit card. (Of course, when I gave them those, it was no use, because tech support had misheard my last name.)It turns out, a billing address and the last four digits of a credit card number are the only two pieces of information anyone needs to get into your iCloud account. Once supplied, Apple will issue a temporary password, and that password grants access to iCloud.Apple tech support confirmed to me twice over the weekend that all you need to access someoneâ€™s AppleID is the associated e-mail address, a credit card number, the billing address, and the last four digits of a credit card on file. I was very clear about this. During my second tech support call to AppleCare, the representative confirmed this to me. â€œThatâ€™s really all you have to have to verify something with us,â€? he said.We talked to Apple directly about its security policy, and company spokesperson Natalie Kerris told Wired, â€œApple takes customer privacy seriously and requires multiple forms of verification before resetting an Apple ID password. In this particular case, the customerâ€™s data was compromised by a person who had acquired personal information about the customer. In addition, we found that our own internal policies were not followed completely. We are reviewing all of our processes for resetting account passwords to ensure our customersâ€™ data is protected.â€?On Monday, Wired tried to verify the hackersâ€™ access technique by performing it on a different account. We were successful. This means, ultimately, all you need in addition to someoneâ€™s e-mail address are those two easily acquired pieces of information: a billing address and the last four digits of a credit card on file. Hereâ€™s the story of how the hackers got them.On the night of the hack, I tried to make sense of the ruin that was my digital life. My Google account was nuked, my Twitter account was suspended, my phone was in a useless state of restore, and (for obvious reasons) I was highly paranoid about using my Apple email account for communication.I decided to set up a new Twitter account until my old one could be restored, just to let people know what was happening. I logged into Tumblr and posted an account of how I thought the takedown occurred. At this point, I was assuming that my seven-digit alphanumeric AppleID password had been hacked by brute force. In the comments (and, oh, the comments) others guessed that hackers had used some sort of keystroke logger. At the end of the post, I linked to my new Twitter account.And then, one of my hackers @ messaged me. He would later identify himself as Phobia. I followed him. He followed me back.We started a dialogue via Twitter direct messaging that later continued via e-mail and AIM. Phobia was able to reveal enough detail about the hack and my compromised accounts that it became clear he was, at the very least, a party to how it went down. I agreed not to press charges, and in return he laid out exactly how the hack worked. But first, he wanted to clear something up:â€œdidnt guess ur password or use bruteforce. i have my own guide on how to secure emails.â€?I asked him why. Was I targeted specifically? Was this just to get to Gizmodoâ€™s Twitter account? No, Phobia said they hadnâ€™t even been aware that my account was linked to Gizmodoâ€™s, that the Gizmodo linkage was just gravy. He said the hack was simply a grab for my three-character Twitter handle. Thatâ€™s all they wanted. They just wanted to take it, and fuck shit up, and watch it burn. It wasnâ€™t personal.â€œI honestly didnâ€™t have any heat towards you before this. i just liked your username like I said beforeâ€? he told me via Twitter Direct Message.After coming across my account, the hackers did some background research. My Twitter account linked to my personal website, where they found my Gmail address. Guessing that this was also the e-mail address I used for Twitter, Phobia went to Googleâ€™s account recovery page. He didnâ€™t even have to actually attempt a recovery. This was just a recon mission.Because I didnâ€™t have Googleâ€™s two-factor authentication turned on, when Phobia entered my Gmail address, he could view the alternate e-mail I had set up for account recovery. Google partially obscures that information, starring out many characters, but there were enough characters available, mâ€¢â€¢â€¢â€¢n@me.com. Jackpot.This was how the hack progressed. If I had some other account aside from an Apple e-mail address, or had used two-factor authentication for Gmail, everything would have stopped here. But using that Apple-run me.com e-mail account as a backup meant told the hacker I had an AppleID account, which meant I was vulnerable to being hacked.â€œYou honestly can get into any email associated with apple,â€? Phobia claimed in an e-mail. And while itâ€™s work, that seems to be largely true.Since he already had the e-mail, all he needed was my billing address and the last four digits of my credit card number to have Appleâ€™s tech support issue him the keys to my account.So how did he get this vital information? He began with the easy one. He got the billing address by doing a whois search on my personal web domain. If someone doesnâ€™t have a domain, you can also look up his or her information on Spokeo, WhitePages, and PeopleSmart.Getting a credit card number is tricker, but it also relies on taking advantage of a companyâ€™s back-end systems. Phobia says that a partner performed this part of the hack, but described the technique to us, which we were able to verify via our own tech support phone calls. Itâ€™s remarkably easy â€” so easy that Wired was able to duplicate the exploit twice in minutes.First you call Amazon and tell them you are the account holder, and want to add a credit card number to the account. All you need is the name on the account, an associated e-mail address, and the billing address. Amazon then allows you to input a new credit card. (Wired used a bogus credit card number from a website that generates fake card numbers that conform with the industryâ€™s published self-check algorithm.) Then you hang up.Next you call back, and tell Amazon that youâ€™ve lost access to your account. Upon providing a name, billing address, and the new credit card number you gave the company on the prior call, Amazon will allow you to add a new e-mail address to the account. From here, you go to the Amazon website, and send a password reset to the new e-mail account. This allows you to see all the credit cards on file for the account â€” not the complete numbers, just the last four digits. But, as we know, Apple only needs those last four digits. We asked Amazon to comment on its security policy, but didnâ€™t have anything to share by press time.And itâ€™s also worth noting that one wouldnâ€™t have to call Amazon to pull this off. Your pizza guy could do the same thing, for example. If you have an AppleID, every time you call Pizza Hut, youâ€™ve giving the 16-year-old on the other end of the line all he needs to take over your entire digital life.And so, with my name, address, and the last four digits of my credit card number in hand, Phobia called AppleCare, and my digital life was laid waste. Yet still I was actually quite fortunate.They could have used my e-mail accounts to gain access to my online banking, or financial services. They could have used them to contact other people, and socially engineer them as well. As Ed Bott pointed out on TWiT.tv, my years as a technology journalist have put some very influential people in my address book. They could have been victimized too.Instead, the hackers just wanted to embarrass me, have some fun at my expense, and enrage my followers on Twitter by trolling.I had done some pretty stupid things. Things you shouldnâ€™t do.I should have been regularly backing up my MacBook. Because I wasnâ€™t doing that, if all the photos from the first year and a half of my daughterâ€™s life are ultimately lost, I will have only myself to blame. I shouldnâ€™t have daisy-chained two such vital accounts â€” my Google and my iCloud account â€” together. I shouldnâ€™t have used the same e-mail prefix across multiple accounts â€” mhonan@gmail.com, mhonan@me.com, and mhonan@wired.com. And I should have had a recovery address thatâ€™s only used for recovery without being tied to core services.But, mostly, I shouldnâ€™t have used Find My Mac. Find My iPhone has been a brilliant Apple service. If you lose your iPhone, or have it stolen, the service lets you see where it is on a map. The New York Timesâ€™ David Pogue recovered his lost iPhone just last week thanks to the service. And so, when Apple introduced Find My Mac in the update to its Lion operating system last year, I added that to my iCloud options too.After all, as a reporter, often on the go, my laptop is my most important tool.But as a friend pointed out to me, while that service makes sense for phones (which are quite likely to be lost) it makes less sense for computers. You are almost certainly more likely to have your computer accessed remotely than physically. And even worse is the way Find My Mac is implemented.When you perform a remote hard drive wipe on Find my Mac, the system asks you to create a four-digit PIN so that the process can be reversed. But hereâ€™s the thing: If someone else performs that wipe â€” someone who gained access to your iCloud account through malicious means â€” thereâ€™s no way for you to enter that PIN.A better way to have this set up would be to require a second method of authentication when Find My Mac is initially set up. If this were the case, someone who was able to get into an iCloud account wouldnâ€™t be able to remotely wipe devices with malicious intent. It would also mean that you could potentially have a way to stop a remote wipe in progress.But thatâ€™s not how it works. And Apple would not comment as to whether stronger authentification is being considered.As of Monday, both of these exploits used by the hackers were still functioning. Wired was able to duplicate them. Apple says its internal tech support processes werenâ€™t followed, and this is how my account was compromised. However, this contradicts what AppleCare told me twice that weekend. If that is, in fact, the case â€” that I was the victim of Apple not following its own internal processes â€” then the problem is widespread.I asked Phobia why he did this to me. His answer wasnâ€™t satisfying. He says he likes to publicize security exploits, so companies will fix them. He says itâ€™s the same reason he told me how it was done. He claims his partner in the attack was the person who wiped my MacBook. Phobia expressed remorse for this, and says he would have stopped it had he known.â€œyea i really am a nice guy idk why i do some of the things i do,â€? he told me via AIM. â€œidk my goal is to get it out there to other people so eventually every1 can over come hackersâ€?I asked specifically about the photos of my little girl, which are, to me, the greatest tragedy in all this. Unless I can recover those photos via data recovery services, they are gone forever. On AIM, I asked him if he was sorry for doing that. Phobia replied, â€œeven though i wasnt the one that did it i feel sorry about that. Thats alot of memories im only 19 but if my parents lost and the footage of me and pics i would be beyond sad and im sure they would be too.â€?But letâ€™s say he did know, and failed to stop it. Hell, for the sake of argument, letâ€™s say he did it. Letâ€™s say he pulled the trigger. The weird thing is, Iâ€™m not even especially angry at Phobia, or his partner in the attack. Iâ€™m mostly mad at myself. Iâ€™m mad as hell for not backing up my data. Iâ€™m sad, and shocked, and feel that I am ultimately to blame for that loss.But Iâ€™m also upset that this ecosystem that Iâ€™ve placed so much of my trust in has let me down so thoroughly. Iâ€™m angry that Amazon makes it so remarkably easy to allow someone into your account, which has obvious financial consequences. And then thereâ€™s Apple. I bought into the Apple account system originally to buy songs at 99 cents a pop, and over the years that same ID has evolved into a single point of entry that controls my phones, tablets, computers and data-driven life. With this AppleID, someone can make thousands of dollars of purchases in an instant, or do damage at a cost that you canâ€™t put a price on.Additional reporting by Roberto Baldwin and Christina Bonnington. Portions of this story originally appeared on Mat Honanâ€™s Tumblr.Continued: How I Resurrected My Digital Life After an Epic Hacking.Subscribe to an NBR ONLINE Business Subscription today and get business news your staff can use.We now offer a flat rate for companies, unlimited access for all staff. Signup now for just $249 +GST per company, per quarter. With an NBR ONLINE Business Subscription all articles can easily be forwarded to anyone within your company or organisation. Free access is guaranteed, no login required. Register below or contact Todd Scott for more information tscott@nbr.co.nzEnvision this: you're at a Halloween party, a little drunk, a little bored. You don't recognize anyone's costumes around you except the third, fourth, and fifth Psy you've seen that night, all doing the Gangnam style dance together. Your eyes pass over a seemingly innocuous pumpkin decoration. But waitâ€”is that a Tetris matrix carved into its face? Is the stem a joystick? Are you in discreet gaming heaven?Nathan Pryor of Hahabird initially aspired to grow several pumpkins into the shape of Tetris blocks (Tetrominos). But when that didn't pan out, he simply used an Arduino to turn a carved pumpkin into a compact gaming cabinet. Behold: a Pumpktris.Initially Pryor planned to use a LoLShield LED matrix as the pumpkin's display, but each LED needed two wires to run to the Arduino board powering the game. The bundle would have been enormousâ€”and a mess. So to make the display, Pryor built and wired his own (appropriately orange) 8Ã—16 LED matrix and carved out 128 holes for each light on the face of an appropriately-shaped pumpkin. He also programmed the Arduino board true to the game's rules, with pieces that fall with increasing speed as the level goes up, as well as a scorekeeping element.Pryor told Ars the entire project cost about $100 altogether (including Arduino, LEDs, LED controllers, joystick assembly, and four pumpkinsâ€”three of which he had to reject due to suboptimal shape). In all it took twelve hours to build. That means there's still time before your Halloween celebration tomorrow to make a Pumpktris. Use it to impress your friends, or ignore themâ€”the Pumpktris does not judge.A key part of any cybersecurity plan is â€œcontinuous monitoringâ€?, or enabling auditing and monitoring throughout a network environment and configuring automated analysis of the resulting logs to identify anomalous behaviors that merit investigation. This is part of the new â€œassumed breachâ€? mentality that recognizes no system is 100% secure. Unfortunately, the company at the heart of this case didnâ€™t have a comprehensive monitoring system, so had been breached for some time before updated antimalware signatures cleaned their infection and brought the breach to their attention. Besides highlighting just how weak cybersecurity is at many companies, this case highlights the use of several Sysinternals Process Monitor features, including the Process Tree dialog and one feature many people arenâ€™t aware of, Process Monitorâ€™s ability to monitor network activity.The case opened when a network administrator at a South African company contacted Microsoft Services Premier Support and reported that their corporate Exchange server, running on Windows Server 2008 R2, appeared to be making outbound FTP connections. They noticed this only because the companyâ€™s installation of Microsoft Forefront Endpoint Protection (FEP) alerted them that it had cleaned a piece of malware it found on the server. Concerned that their network might still be compromised despite the fact that FEP claimed the system was malware-free, he examined the companyâ€™s perimeter firewall logs. To his horror, he discovered FTP connections that numbered in the hundreds per day and dated back several weeks. Instead of attempting a forensic examination on his own, he called on Microsoftâ€™s security consulting team, which specializes in helping customers clean up after an attack.The Microsoft support engineer assigned the case began by capturing a five-minute Process Monitor trace of the Exchange server. After stopping the trace he opened the Process Tree dialog (under the Tools menu), which shows the parent-child relationships of all the processes that existed at any point in the current trace. He quickly found that around 20 FTP processes had been launched during the collection, each of them short-lived, except for one, which was still active (process 7324 below):The engineer looked at the command lines for the FTP processes by selecting them in the tree so that their details appeared at the bottom of the Process Tree dialog. The command lines for the half of them bizarrely included just the â€œ-?â€? argument, which simply brings up FTP help:The other half were more interesting, including â€œ-iâ€? and â€œ-sâ€? switches:The â€“i switch has FTP turn off prompting for multiple file transfers, and â€“s directs FTP to execute the FTP commands listed in a file, in this case a file named â€œjâ€?.Â  Setting out to find out what file 'â€?jâ€? contained, he clicked on the â€œInclude Processâ€? button at the bottom of the Process Tree dialog so that he could find the processâ€™s file events:He searched the resulting filtered trace for â€œjâ€? and found the fileâ€™s location in several of the events:He navigated to the C:\Windows\System32\i4333 directory, but the â€œjâ€? file was gone. That being a dead end, he turned his attention to the FTP processâ€™s parent, Cmd.exe, and looked at its command line. The line was too long and convoluted to easily understand:He selected it, typed Ctrl+C to copy it to the clipboard, pasted it into Notepad, and decomposed it into its constituent components, each of which was separated by a â€œ&â€?. The result looked like this:The first instruction has the command prompt create a directory named i4333 and then start creating the contents of the â€œjâ€? file. The commands it writes into â€œjâ€? instruct FTP to connect to NUXZb.in.into4.info, login with the user name â€œNewâ€? and the password â€œ123â€?, then download all the files on the FTP server that end with â€œ.exeâ€?. After FTP has processed the file, the command prompt deletes â€œjâ€? and then creates a batch file that executes the downloaded files, first using the Shell to launch them (â€œstartâ€?) and then the Command Prompt.A quick detour to Whois showed the engineer that the NUXZb hostname was issued by Protected Name Services and didnâ€™t reveal any useful information. The engineer toggled off Process Monitorâ€™s network name resolution and found the outbound FTP connection in the trace to see the IP address the name had resolved to:An IP address location lookup on the Web pinpointed the IP address at an ISP in Chicago (the name now resolves to a different IP address), so he concluded the connection was to a server that was also compromised or one the attacker had hosted at the ISP. Finished analyzing the command line, he looked at the contents of the resulting script, D.bat, which was still in the directory and contained this single command:Not coincidentally, 134.exe was the executable Forefront had flagged as a remote access Trojan (RAT) in the alerts that the administrator first responded to. The script could therefore not find it, making it seem that the attack â€“ or at least this part of it - had been neutralized by FEP. It also implied that the attack was automated and stuck in a loop trying to activate.The engineer next set out to determine how the command-prompt processes were being launched. Looking at their parent processes in the process tree, he learned they were all launched from Sqlserver.exe:This obviously wasnâ€™t a good sign, but it wasnâ€™t the worst of it: examining SQL Serverâ€™s network activity in the trace, he saw many incoming connections:Lookups of the IP address locations placed them in China, Tunisia, Taiwan, and Morocco:The SQL Server was being used by an attacker or multiple attackers from around the world in countries known for being cybercriminal safe havens. It was clearly time to flatten the server, but before calling the administrator to give him the bad news and advise him to immediately disconnect the server from the network, he thought heâ€™d spend a few minutes examining the security of the SQL Server. Understanding what had led to the compromise could help the company avoid being compromised the same way again.He launched a Microsoft support batch file that checks various SQL Server security settings. The tool ran for a few seconds and then printed its discouraging results: the server had an administrator account with a blank password, was configured for mixed-mode authentication, and allowed stored procedures to launch command prompts via the enablement of the â€œxp_cmdshellâ€? feature:That meant that anyone on the Internet could logon to the server without a password and execute executables â€“ like FTP â€“ to infect the system with their own tools.With the help of Process Monitor and some discussion with the companyâ€™s administrator, the support engineer had a solid theory for what had happened: an administrator at the company had installed SQL Server on the companyâ€™s Exchange server several weeks prior to the incident. Not realizing the server was on the perimeter, they had opened the SQL Serverâ€™s port in the local firewall, left it with a blank admin account, and enabled xp_cmdshell. It goes without saying that even if the server wasnâ€™t on the Internet, that configuration leaves a server without any network security. Not long after, automated malware scanning the Internet for exposed targets had stumbled across the open SQL port, infected the server with malware, and likely enlisted it in a Botnet. FEP signatures for the new malware variant were delivered to the server some time later and removed the infection. The Botnet-enlisting malware was still trying to reintegrate the server when the case with Microsoft support was opened. While the company canâ€™t know how much â€“ if any â€“ of its corporate data was pilfered during the infection, this was a very loud and clear wakeup call.You can test your own cybersecurity knowledge by taking my Operation Desolation cybersecurity quiz.NEW YORK (CNNMoney) -- A number of popular websites went down late Monday after Superstorm Sandy took out a major Internet service provider.The Huffington Post, Gawker and many other sites were unreachable after Datagram, a New York-based provider of corporate Internet connections and servers, said it was battling flooding in its offices. The floods caused Datagram's fiber network to lose power, and the company said its backup generators were rendered useless because the diesel fuel pumps used to refuel generators were offline.Datagram is located on 33 Whitehall Street in Battery Park -- a large area of reclaimed land at the southern tip of Manhattan that was in an evacuation zone. It was among the worst-hit areas in the city.BuzzFeed, another Datagram customer, was able to get its site back up online and running Tuesday afternoon.On its Tumblr page, the company said Datagram told its staff that its basement was flooded with five feet of water. A Datagram representative was unreachable for comment.Many sites were updating their status on Twitter and publishing news stories on Tumblr accounts.Gawker was completely unreachable Tuesday morning."Gawker is temporarily down because the 57th Street Crane just flooded our servers with sea foam, or something," the company posted on Twitter. "Back with you shortly."The Huffington Post's site was down Tuesday morning, but it automatically redirected to a company blog. "We are working around the clock to get the site back to normal," the news organization, owned by AOL (AOL), noted. AOL's site was unaffected by the storm. The site came back online around noon ET.Cloud storage company Internap, located just four blocks away from Datagram, also flooded and was unable to refuel its generators. The company issued an emergency notification to customers suggesting they back up their data and make contingency plans.What do you get when you combine a pumpkin with the classic video game Tetris? Pumpktris! Fully playable, embedded in a pumpkin, and with the stem serving as a controller. Watch the video below to see it in action, then read on for the development story.One of my habits is to write down all the crazy, fleeting ideas I have, then go back to review later rather than judging right off the bat, or even worse, forgetting them. Â Earlier in the month I was looking through that idea notepad and found â€œMake Tetris Pumpkinsâ€? from sometime last year. My original plan had been to make forms to shape pumpkins into Tetris pieces as they grew, then stack them together for Halloween. Since Halloween was only a few weeks away and it was too late to start growing pumpkins, I thought â€œWhy not make a pumpkin you can play Tetris on instead?â€?I had a LOLShield I hadnâ€™t assembled yet, and I knew that someone had already written Tetris for it, so I figured it would be a simple matter to poke some holes in the pumpkin to match the LEDs, make a controller, and be done. But oh no, that would be too simple, and would look kind of lame. Little tiny LEDs, all stuck together on a 2Ã—3â€³ area? Nahhhh.Plan B: Still use the LOLshield, but instead of mounting LEDs in the shield I would wire them up externally so I could space them out more on the pumpkin. Luckily, I didnâ€™t get too far down that route before I realized that the bundle of wires between the LEDs and the shield would be as thick as my wrist and a nightmare to solder and organize.I was going to have to make my own LED matrix and program my own Tetris. With the decision made, I ordered 140 amber LEDs from Mouser and a pair of LED Matrix I2C â€œbackpacksâ€? from Adafruit. These little circuits come with a mini (.8â€³ square) LED matrix that I could use for programming instead of having to wire up my own LED matrix right from the start..The first step was to make the LED matrix, and for that Iâ€™m grateful to have found this guide on hackaday.com to making a 70 LED matrix. My construction steps were essentially the same (plus 58 more LEDs), but Iâ€™ll go through them here anyway. For more theory, check out their post. Mine leans toward â€œwhat I didâ€? rather than â€œwhy you should do it this way.â€?It started with cutting 112 pieces of 2.5â€³ wire and 16 pieces of 8â€³ wire. The short ones would go between each LED, and the long ones would run to the controller. A cutting mat made it easy to quickly and accurately measure out the lengths.Next I soldered seven short wires and one long one into a daisy chain. Then again 15 more timesâ€”one for each row and one for each column in the matrix.A jig was needed for assembly, and here I differed from Hackaday. Instead of drilling hardboard, I opted to poke holes into 1/4â€³ foam-core board with an awl. It was a lot quicker than a drill would be, and the foam-core board had a little bit of give so that I could make the holes small and theyâ€™d stretch out to hold the LED securely while I soldered.With a row of LEDS poked into holes, I tinned the base of each anode and clipped it short, then soldered the wire daisy-chain down the line. At each joint I slipped on a half-inch of heat-shrink tubing before soldering. Iâ€™m proud to say there were only a couple of times I forgot the heat-shrink and had to go back. What caused more trouble was being in a hurry and sliding the tubing down to the joint while it was still hot. It would start to shrink up and wouldnâ€™t fit over the connection on the LEDs.When eight rows of LEDs were finally strung together, it was time to mount them all into the jig and solder on the cathode columns. The procedure with the heat-shrink was the same. As each column was finished I would pull it out of the jig and fold it out of the way in order to reach the next column.But guess what? Thatâ€™s only one, and 8Ã—8 isnâ€™t enough room for a game of Tetris, so it all got done again! Iâ€™ll spare you a rerun on the pictures and description, but if you want to you can go back up and read it again to get the full experience.TheÂ Adafruit LED Matrix BackpackÂ is meant to have its LED matrix soldered right to the board, but instead I soldered on female headers that would permit me to plug in either the mini LED matrix for code testing or the large matrix for deployment. Someone will probably be along to tell me I need a resistor here or there or Iâ€™m going to blow some chip upâ€”and theyâ€™re likely rightâ€”but it seems to have worked so far as-is.To connect my own matrix to the I2C Backpack, I cut down a piece of prototyping board and soldered in the male headers, then connected the 8â€³ wires from the last row and last column of the matrix to the board.Would it work, though? I needed some code in order to find out.I did all coding with the hardware mounted on my bamboo prototyping board. The mini matrices in the I2C backpack sockets fit on the desk much better than the big, floppy matrices I built would have.There are seven Tetrominosâ€”yes, thatâ€™s what theyâ€™re calledâ€”in the game. Each has four points, as implied by the â€œtetraâ€? prefix. A three-dimensional array stores the location of every pixel of every shape, in each of four possible rotations. Storing each rotation is a lot easier (for my brain at least) than calculating it on the fly. As an example, hereâ€™s the T shape:To draw the active piece the program keeps an activePiece variable (the index of the shape in the array) and a rotation variable (the index of the rotation description of that shape), then offsets each pixel pair that it pulls out by a yOffset and xOffset of how far down the screen itâ€™s moved and how far left or right.It also keeps an array describing the status of each â€œfixedâ€? piece. With every move of the active piece, whether by gravity or by user control, it checks against that fixed-piece array to see if the requested move can be made without a collision. If the forbidden movement is left, right, or a rotation, it simply doesnâ€™t make the move. If the forbidden movement is vertical it considers the piece to have landed and writes the piece to the array of fixed pieces, then launches a new active piece. Along the way it keeps score, tracks the level, speeds up the drop of the active piece as the game goes on, etc.This project required the perfect arcade cabinetâ€”errr, I mean pumpkin. It had to be tall enough that the eight-inch tall matrix wouldnâ€™t wrap too far around the bottom or top, and it needed a nice straight stem. I bought 3 pumpkins in a row, thinking each was perfect until I got it home and realized one thing or another wouldnâ€™t work. Finally I found what I needed and the other pumpkins were relegated to prototyping duty for practice drilling holes and cutting.To get inside the pumpkin I cut a large opening on the back. It wouldnâ€™t work to cut from the top because I wanted the controller up there, and it would be easier to put the LEDs straight in from the back rather than the top.With a paper template taped on to the pumpkin, I poked guide holes through the orange flesh.Once the holes were marked I drilled through with a 13/64â€³ bit.And since round pixels just would not do for a proper Tetris game, I cut a square around each hole with an X-Acto blade. The ends of the holes on the inside of the pumpkin were left round.To turn the stem into a joystick I carefully sawed the it off at its base and drilled a 1-1/8â€³ hole right where the shaft would pass through.I squared off the inside of the pumpkin below the stem, cut down some drywall anchors so they wouldnâ€™t poke through the pumpkin, and screwed them in. Later I would attach the joystick with short screws into the drywall anchors.For a controller I used short handle joystick from SparkFun, with the red ball unscrewed and replaced with the stem of the pumpkin. I think Iâ€™m going to call this the Â â€?joystemâ€? from now on, as disgusting as that may sound.Â I drilled a hole in the detached stem and epoxied in a 6mm bolt, then screwed that into a coupling nut on the joystick shaft.One at a time, I started to poke each LED into its slimy place. It wasnâ€™t long before a problem became apparent: there were 16 rows of holes on the outside, but only 15 on the inside. The angle that the holes were drilled toward the top of the pumpkin had the two rows coming together into a single row. I was eventually able to squeeze the LEDs past each other and direct them into their appropriate shafts. Once the LEDs were in, IÂ attached the joystem.I plugged each matrix into the I2C backpack and then that into the Arduino. Usually Iâ€™ll build a standalone bare-bones controller board, but since this was definitely not a permanent piece I used the Arduino board. Power was provided by eight rechargeable AA batteries.It was time to play Pumpktris!Everything worked great, except for some occasional glitches in the top matrix as the night went on. Maybe a power supply issue, but itâ€™s also possible there might be some intermittent shorts that happen when you bury that many electrical connections inside a pumpkin. Itâ€™s also weird playing with the controller on the top and the display underneath, so if I were to do it again I would wire the joystem into a separate pumpkin, either wireless or with the wire made to look like a vine.Next up? Porting Halo to a watermelon.** No, not really.