Microsoft chief executive Steve Ballmer is expecting 2013 to be one of the company's busiest years, but he's not yet ready to start talking about Windows 8 and Surface sales.In an interview with The Wall Street Journal, Ballmer said that in terms of Windows 8 and Surface sales for the first few days, "there's not really much that's interesting to report."On any ordinary day, that probably would've plunged stock price by a good few percent. So, whether or not Ballmer is playing his cards close to his chest, preparing for some big reveal later, or sales haven't been all that interesting, it remains to be seen.Ballmer went on to say: "If you were to call the retailers, they would say, 'Hey, off to a very good start'." and that, "we're out of stock [in] a lot of places on touch-[screen] machines".Reading between the lines, and putting this together with what I've been hearing from the supply chain and the OEMs, I think that Microsoft has decided to play to safe with Surface and keep the initial order modest. It's better to sell out of tablets, and keep the customers wanting more, than it is to end up will millions gathering dust and have to have a frantic fire sale down the line -- such as the one that HP ended up having with the TouchPad.As for Windows 8, I have to say that this is the most subdued Windows launch that I can recall. The buzz doesn't seem to be there, and instead it's been replaced by confusion over pricing, hardware requirements, and the whole issue of touch. There also seems to be a great deal of confusion over the differences between Windows 8 and Windows RT, specifically nobody quite knows what the latter is even for.This much consumer confusion at the point of release seems to suggest that the industry -- specifically Microsoft and its hardware partners -- have not done a good enough job of educating the masses about Windows 8.We'll have to wait until Microsoft unveils financial details for this quarter to see if this had a negative effect on sales.San Francisco - The Electronic Frontier Foundation (EFF) won renewal of critical exemptions to the Digital Millennium Copyright Act (DMCA) in a ruling published today, including the upholding of jailbreaking rights for smartphones as well as new and expanded legal protections for video remixing."The DMCA creates a cloud of legal uncertainty over American consumers â€“ whether they are tinkerers, artists, or just looking to make their gadgets work better," said EFF Intellectual Property Director Corynne McSherry. "The ruling from the Copyright Office today goes a long way towards mitigating some of the DMCA's most grievous harms."Crucial support for the successful request on behalf of video remix artists â€“ carving out new legal protection for this important art form â€“ was provided by the Organization for Transformative Works (OTW). The OTW gathered evidence and presented testimony about the DMCA's adverse impact on several communities of remix creators, who use short clips from movies to build new creative works. The Copyright Office's decision broadens EFF's previously successful exemption request, which allows for taking short excerpts from DVDs in creating noncommercial works, by also protecting the use of clips from online streaming or downloading services."Remix videos are thriving on YouTube and other sites, offering dynamic criticism and commentary on popular movies as well as popular culture. It's a great example of how new technologies foster free expression, yet the anti-circumvention provisions of the DMCA endanger these important works," said McSherry. "We're thrilled that the Copyright Office broke new ground in protecting remix artists. We can't let misguided federal law block a new form of art and expression."The Copyright Office also renewed EFF's exemption request that protects smartphone jailbreaking, liberating phone owners to run operating systems and applications from any source, not just those approved by the manufacturer. However, the Copyright Office declined to expand that exemption to tablets and video game consoles, arguing that the category of "tablets" is not well defined and that jailbreaking video game consoles might lead to more copyright infringement."If you bought your gadget, you own it, and you should be able to install whatever software you please without facing potential legal threats," said EFF Senior Staff Attorney Marcia Hofmann. "We're pleased the Copyright Office renewed our smartphone jailbreaking exemption request, but we're disappointed that it couldn't see that consumers deserve the same rights for all the gadgets they own. We'll be back with more exemption requests in the next rulemaking, and we're hopeful the Copyright Office will keep moving in the right direction."The Copyright Office's rulemaking process is conducted every three years in order to mitigate the danger the DMCA poses to legitimate, non-infringing uses of copyrighted materials. The DMCA prohibits "circumventing" digital rights management (DRM) and "other technical protection measures" used to control access to copyrighted works. While the DMCA still chills competition, free speech, and fair use, today's exemptions help give consumers and artists protection from the law's extensive reach.EFF would like to acknowledge the invaluable assistance of the Samuelson Law, Technology & Public Policy Clinic at the University of California, Berkeley, in drafting the jailbreaking exemption requests.For the full ruling from the copyright office:https://www.eff.org/node/72131For more on our exemption requests:https://www.eff.org/cases/2012-dmca-rulemakingThe Advanced Research Projects Agency Network (ARPANET) was the world's first operational packet switching network and the progenitor of what was to become the global Internet. The network was initially funded by the Advanced Research Projects Agency (ARPA, later DARPA) within the U.S. Department of Defense for use by its projects at universities and research laboratories in the US. The packet switching of the ARPANET was based on designs by British scientist Donald Davies and Lawrence Roberts of the Lincoln Laboratory.Packet switching, today the dominant basis for data communications worldwide, was a new concept at the time of the conception of the ARPANET. Prior to the advent of packet switching, both voice and data communications had been based on the idea of circuit switching, as in the traditional telephone circuit, wherein each telephone call is allocated a dedicated, end to end, electronic connection between the two communicating stations. Such stations might be telephones or computers. The (temporarily) dedicated line is typically composed of many intermediary lines which are assembled into a chain that stretches all the way from the originating station to the destination station. With packet switching, a data system could use a single communications link to communicate with more than one machine by collecting data into datagrams and transmitting these as packets onto the attached network link, as soon as the link becomes idle. Thus, not only can the link be shared, much as a single post box can be used to post letters to different destinations, but each packet can be routed independently of other packets.The earliest ideas for a computer network intended to allow general communications among computer users were formulated by computer scientist J. C. R. Licklider, of Bolt, Beranek and Newman (BBN), in August 1962, in memoranda discussing his concept for an "Intergalactic Computer Network". Those ideas contained almost everything that composes the contemporary Internet. In October 1963, Licklider was appointed head of the Behavioral Sciences and Command and Control programs at the Defense Department's Advanced Research Projects Agency â€” ARPA (the initial ARPANET acronym). He then convinced Ivan Sutherland and Bob Taylor that this computer network concept was very important and merited development, although Licklider left ARPA before any contracts were let that worked on this concept.Ivan Sutherland and Bob Taylor continued their interest in creating such a computer communications network, in part, to allow ARPA-sponsored researchers at various corporate and academic locales to put to use the computers ARPA was providing them, and, in part, to make new software and other computer science results quickly and widely available. In his office, Taylor had three computer terminals, each connected to separate computers, which ARPA was funding: the first, for the System Development Corporation (SDC) Q-32, in Santa Monica; the second, for Project Genie, at the University of California, Berkeley; and the third, for Multics, at MIT. Taylor recalls the circumstance: "For each of these three terminals, I had three different sets of user commands. So, if I was talking online with someone at S.D.C., and I wanted to talk to someone I knew at Berkeley, or M.I.T., about this, I had to get up from the S.D.C. terminal, go over and log into the other terminal and get in touch with them. I said, "Oh Man!", it's obvious what to do: If you have these three terminals, there ought to be one terminal that goes anywhere you want to go. That idea is the ARPANET". Somewhat contemporaneously, several other people had (mostly independently) worked out the aspects of "packet switching", with the first public demonstration presented by the National Physical Laboratory (NPL), on 5 August 1968, in the United Kingdom.By mid-1968, Taylor had prepared a complete plan for a computer network, and, after ARPA's approval, a Request for Quotation (RFQ) was sent to 140 potential bidders. Most computer science companies regarded the ARPAâ€“Taylor proposal as outlandish, and only twelve submitted bids to build the network; of the twelve, ARPA regarded only four as top-rank contractors. At year's end, ARPA considered only two contractors, and awarded the contract to build the network to BBN Technologies on 7 April 1969. The initial, seven-man BBN team were much aided by the technical specificity of their response to the ARPA RFQ â€“ and thus quickly produced the first working computers. This team was led by Frank Heart. The BBN-proposed network closely followed Taylor's ARPA plan: a network composed of small computers called Interface Message Processors (IMPs), that functioned as gateways (today called routers) interconnecting local resources. At each site, the IMPs performed store-and-forward packet switching functions, and were interconnected with modems that were connected to leased lines, initially running at 50kbit/second. The host computers were connected to the IMPs via custom serial communication interfaces. The system, including the hardware and the packet switching software, was designed and installed in nine months.The first-generation IMPs were initially built by BBN Technologies using a rugged computer version of the Honeywell DDP-516 computer configured with 24kB of expandable core memory, and a 16-channel Direct Multiplex Control (DMC) direct memory access unit. The DMC established custom interfaces with each of the host computers and modems. In addition to the front-panel lamps, the DDP-516 computer also features a special set of 24 indicator-lamps showing the status of the IMP communication channels. Each IMP could support up to four local hosts, and could communicate with up to six remote IMPs via leased lines.Common ARPANET lore posits that the computer network was designed to survive a nuclear attack. In A Brief History of the Internet, the Internet Society describes the coalescing of the technical ideas that produced the ARPANET:Although the ARPANET was designed to survive subordinate-network losses, the principal reason was that the switching nodes and network links were unreliable, even without any nuclear attacks. About the resource scarcity that spurred the creation of the ARPANET, Charles Herzfeld, ARPA Director (1965â€“1967), said:Packet switching pioneer Paul Baran affirms this, explaining: "Bob Taylor had a couple of computer terminals speaking to different machines, and his idea was to have some way of having a terminal speak to any of them and have a network. That's really the origin of the ARPANET. The method used to connect things together was an open issue for a time."The initial ARPANET consisted of four IMPs:The first message on the ARPANET was sent by UCLA student programmer Charley Kline, at 10:30Â pm on 29 October 1969, from Boelter Hall 3420. Kline transmitted from the university's SDS Sigma 7 Host computer to the Stanford Research Institute's SDS 940 Host computer. The message text was the word login; the l and the o letters were transmitted, but the system then crashed. Hence, the literal first message over the ARPANET was lo. About an hour later, having recovered from the crash, the SDS Sigma 7 computer effected a full login. The first permanent ARPANET link was established on 21 November 1969, between the IMP at UCLA and the IMP at the Stanford Research Institute. By 5 December 1969, the entire four-node network was established.In March 1970, the ARPANET reached the East Coast of the United States, when an IMP at BBN in Cambridge, Massachusetts was connected to the network. Thereafter, the ARPANET grew: 9 IMPs by June 1970 and 13 IMPs by December 1970, then 18 by September 1971 (when the network included 23 university and government hosts); 29 IMPs by August 1972, and 40 by September 1973. By June 1974, there were 46 IMPs, and in July 1975, the network numbered 57 IMPs. By 1981, the number was 213 host computers, with another host connecting approximately every twenty days.In 1973 a transatlantic satellite link connected the Norwegian Seismic Array (NORSAR) to the ARPANET, making Norway the first country outside the US to be connected to the network. At about the same time a terrestrial circuit added a London IMP.In 1975, the ARPANET was declared "operational". The Defense Communications Agency took control since ARPA was intended to fund advanced research.In 1983, the ARPANET was split with U.S. military sites on their own Military Network (MILNET) for unclassified defense department communications. The combination was called the Defense Data Network (DDN). Separating the civil and military networks reduced the 113-node ARPANET by 68 nodes. Gateways relayed electronic mail between the two networks. MILNET later became the NIPRNet.Because of its government ties, certain forms of traffic were discouraged or prohibited. A 1982 handbook on computing at MIT's AI Lab stated regarding network etiquette:Support for inter-IMP circuits of up to 230.4 kbit/s was added in 1970, although considerations of cost and IMP processing power meant this capability was not actively used.1971 saw the start of the use of the non-ruggedized (and therefore significantly lighter) Honeywell 316 as an IMP. It could also be configured as a Terminal Interface Processor (TIP), which provided terminal server support for up to 63 ASCII serial terminals through a multi-line controller in place of one of the hosts. The 316 featured a greater degree of integration than the 516, which made it less expensive and easier to maintain. The 316 was configured with 40 kB of core memory for a TIP. The size of core memory was later increased, to 32 kB for the IMPs, and 56 kB for TIPs, in 1973.In 1975, BBN introduced IMP software running on the Pluribus multi-processor. These appeared in a small number of sites. In 1981, BBN introduced IMP software running on its own C/30 processor product.In 1983, TCP/IP protocols replaced NCP as the ARPANET's principal protocol, and the ARPANET then became one subnet of the early Internet.The original IMPs and TIPs were phased out as the ARPANET was shut down after the introduction of the NSFNet, but some IMPs remained in service as late as 1989.The ARPANET Completion Report, jointly published by BBN and ARPA, concludes that:In the wake of ARPANET being formally decommissioned on 28 February 1990, Vinton Cerf wrote the following lamentation, entitled "Requiem of the ARPANET":Senator Albert Gore, Jr. began to craft the High Performance Computing and Communication Act of 1991 (commonly referred to as "The Gore Bill") after hearing the 1988 report toward a National Research Network submitted to Congress by a group chaired by Leonard Kleinrock, professor of computer science at UCLA. The bill was passed on 9 December 1991 and led to the National Information Infrastructure (NII) which Al Gore called the "information superhighway". ARPANET was the subject of two IEEE Milestones, both dedicated in 2009.The starting point for host-to-host communication on the ARPANET in 1969 was the 1822 protocol, which defined the transmission of messages to an IMP. The message format was designed to work unambiguously with a broad range of computer architectures. An 1822 message essentially consisted of a message type, a numeric host address, and a data field. To send a data message to another host, the transmitting host formatted a data message containing the destination host's address and the data message being sent, and then transmitted the message through the 1822 hardware interface. The IMP then delivered the message to its destination address, either by delivering it to a locally connected host, or by delivering it to another IMP. When the message was ultimately delivered to the destination host, the receiving IMP would transmit a Ready for Next Message (RFNM) acknowledgement to the sending, host IMP.Unlike modern Internet datagrams, the ARPANET was designed to reliably transmit 1822 messages, and to inform the host computer when it loses a message; the contemporary IP is unreliable, whereas the TCP is reliable. Nonetheless, the 1822 protocol proved inadequate for handling multiple connections among different applications residing in a host computer. This problem was addressed with the Network Control Program (NCP), which provided a standard method to establish reliable, flow-controlled, bidirectional communications links among different processes in different host computers. The NCP interface allowed application software to connect across the ARPANET by implementing higher-level communication protocols, an early example of the protocol layering concept incorporated to the OSI model.In 1983, TCP/IP protocols replaced NCP as the ARPANET's principal protocol, and the ARPANET then became one component of the early Internet.NCP provided a standard set of network services that could be shared by several applications running on a single host computer. This led to the evolution of application protocols that operated, more or less, independently of the underlying network service. When the ARPANET migrated to the Internet protocols in 1983, the major application protocols migrated with it.Â­The Supreme Court is scheduled to hear arguments today in a case called Kirtsaeng v. Wiley, and their final decision could help shape the future of "first sale," a legal doctrine that underpins the right to sell, lend, or give away the things you buy, even if those things contain copyrighted elements.First sale provides the legal framework for marketplaces like used bookstores, flea markets, garage sales, and eBay. Itâ€™s crucial to making sure U.S. copyright holders canâ€™t dictate, for decades, what you do with the books, CDs, DVDs, games, etc., that you buy. But book publisher Wiley says it doesnâ€™t apply if the copyright holder is clever enough to ensure the product in question is manufactured outside of the United States.The Kirtsaeng case specifically deals with textbooks, but the Courtâ€™s decision is likely to affect a range of markets and consumers. First, many of the goods that people purchase every day are manufactured overseas and have some components or logos on the packaging that are subject to copyright law. In fact, the Swiss watchmaker Omega successfully sued Costco for copyright infringement because the retailer was reselling genuine Omega watches, purchased abroad, that happened to have the Omega logo on them. Second, if the Supreme Court rules in Wileyâ€™s favor, U.S. copyright holders will likely ensure that as many of their works as possible are manufactured outside the United States, so that they, too, can escape that pesky first sale doctrine.This dispute, however, is still just a skirmish in a larger battle to protect your right to actually own the things you buy. The first sale doctrine has long been a thorn in the side of many copyright holders, because it limits their ability to profit from and control secondary markets. In fact, attempts to lock down works after you purchase them extend back at least 100 years, when some publishers tried to set a minimum price at which you could resell their books. In more recent times, the problem has only gotten worse, with record labels attempting to restrict people's rights with "promotional" CDs to movie studios going after automated DVD rental services. Thankfully, Congress, the courts, and the market have repeatedly rejected those efforts.So big media has embraced an alternative approach: bypass the first sale doctrine by recasting every sale as a mere license agreement. That ebook you bought? Licensed. That MP3? Licensed. And these end-user license agreements, or EULAs, donâ€™t just prevent resale â€” they impose a variety of onerous terms of use as a condition of clicking the "buy" button for digital works sold online. It's an attempt to chip away at the rights consumers have long enjoyed in order to protect a legacy business model. That means the fight for first sale is also a fight against the proliferation of EULAs.It's good that the Supreme Court is hearing Kirtsaeng this term â€” in fact, we joined a brief encouraging them to â€” but the story isn't necessarily over once the decision comes down. The next step might be for Congress to respond with legislation. If so, they need to know what consumers think: if it looks like a sale and feels like a sale, it's a sale, with all the accompanying rights and privileges. We're joining our friends at Demand Progress in giving you tools to ask your Congressmembers to defend your rights in your digital goods.We know how vigorous the copyright industry lobby is about pushing for laws in their favor, even when they're against the public interest. It's important we let Congress know now that we want to see first sale alive and well and protecting our rights in the things we buy, even if they are digital goods and the sale is labeled a license.If the copyright industry has its way, you may have to seek permission or face penalties when you resell or tinker with the things you've bought. And if that comes to pass, then we've all been owned.EFF is teaming up with Demand Progress and Free Software Foundation to raise awareness about this issue and fight back. Please show your support by embedding this graphic into your website or replacing your social media avatar:It's easy! Just copy and paste this code into the HTML of your site:<a href="https://eff.org/r.a7pC"><img src="https://eff.org/files/owned.jpg" alt="You've Been Owned: Stand Up For Digital First Sale" /></a><br/>And visit our action center to tell Congress to defend your rights to do what you want with the digital goods you paid for.Doctors use different standards to judge scientific research depending on who funded it. They judge research funded by industry as less rigorous, have less confidence in the results, and are less likely to prescribe new drugs than when the funding source is either the NIH or unknown â€“ even when the apparent quality of the research is the same.Those were the results of a study published by Harvard researchers Dr. Aaron Kesselheim and colleagues in the New England Journal of Medicine last month. The story has received a fair amount of coverage since then, including being analyzed by theÂ Scientific AmericanGuest Blog, the Los Angeles Times, and the New York Times.Thereâ€™s a question of ethical and practical relevance embedded in this: is it justifiable to judge a paper by its author or funding source â€“ even when you cannot discern a difference in quality?The perspective from much of the medical side seems to be a definite yes. The divide between doctors and so-called â€œBig Pharmaâ€? is nothing new. Pharma has a bad reputation in the medical community, and there is history to back it. One of the most well-known scandals involved Vioxx being taken off the market in 2004 after Merck admitted it withheld information about known adverse risk of heart disease, resulting in tens of thousands of deaths. In 2008, physician and former Editor in Chief of the New England Journal of Medicine Marcia Angell wrote, â€œBias in the way industry-sponsored research is conducted and reported is not unusual and by no means limited to Merck.â€? In 2011, Harriet Washington published a piece inÂ The American Scholar highlighting some of the ways industry has misled and manipulated data, which include: comparing a new drug against a placebo rather than against another treatment option, comparing drugs to competitors in wrong dosages, pairing a drug with one known to work well, ending a trial prematurely when they see â€œclues that the trial is going south,â€? and cherry-picking only positive findings to report. This type of behavior can and should be called out as scientific misconduct, and those who commit it must be held accountable.But if thereâ€™s something just a bit unsavory about judging a paper solely by who wrote it, thereâ€™s good reason for it. The scientific world prides itself on judging content of ideas, not presumed integrity of authors. Itâ€™s the rationale behind the widespread practice of research journals blinding reviewers of authorsâ€™ names. Using any criteria other than quality in scientific evaluation is admittedly a kind of bias â€“ something we are usually quite wary of in science. As the authors of the study succinctly put it, â€œThe methodologic rigor of a trial, not its funding disclosure, should be a primary determinant of its credibility.â€? Moreover, if weâ€™re comfortable using authorship as a proxy for quality, itâ€™s not an absurd leap to start extending that approach to authors outside of industry. Itâ€™s not uncommon to hear accusations of industry bias because of self-interest in financial gain; but imagine if we started hearing sweeping accusations that young researchers, for example, should be trusted less because of their self-interest in trying to advance their careers. Industry is not alone in being capable of bias. The problem of publishing only positive results, for instance, is a recognized problem that has been discussed in the scientific community at large for years.There are also practical concerns of being overly dismissive of industry. Amidst the history of manipulation and fraud, there are medical contributions too. In the New York Times, surgeon and author Pauline Chen cited data showing thatÂ industry was responsible for nearly 60 percent of the more than $100 billion spent on research in 2007. Using authorship ties as a proxy for quality means possibly overlooking research of potential value for patients.So why not just use quality, removing the need to probe into researchersâ€™ background, affiliations, and motivations? Unfortunately, letting the data speak for themselves is not always possible. The low quality parts could be found in what does not make it to print. In the list of misconduct Washingtonâ€™s article described, ending a trial prematurely and failing to report negative results are forms of misconduct that would not be transparent from a paper alone. Similarly, failing to report side effects, as in the Vioxx scandal, is another way relevant data can be hidden. Thatâ€™s conscious and explicit manipulation, but thereâ€™s evidence for unconscious manipulation too. Numerous studies have found that the â€œfunding bias,â€? in which conclusions of research are more likely to agree with the sponsorâ€™s aims, is a real phenomenon. While unconscious bias is again not unique to industry, thereâ€™s something to be said for awareness of the trend where it has been clearly tracked.At the end of all this, we are left with two competing facts: 1) Industry sometimes produces valuable research that contributes to patient care. 2) There is also a significant history of manipulation. Is it possible to reconcile these two facts, in a way that is both vigilant against misconduct but also doesnâ€™t pass over potentially valuable findings?I think the last point about quality not always being transparent is the critical fact. Given that itâ€™s entirely scientifically feasible for a study that appears to be of good quality to actually be flawed, holding research conducted by authors with a dubious history seems justifiable. Should you dismiss industry across the board? Probably not. I think the authorsâ€™ caution against the dangers of excessive skepticism is sensible. I also agree that more â€œfundamental strategiesâ€? such as increased protocol and data transparency will make the whole process of determining quality easier. But as it stands, those doctors in the study voicing skepticism about the conclusions of industry sponsored research is understandable. As it goes, a critical eye and looking to others to replicate findings before you embrace new conclusions is probably a good approach to research in general, no matter who the initial authors are.With 100 million first-grade-aged children worldwide having no access to schooling, the One Laptop Per Child organization is trying something new in two remote Ethiopian villagesâ€”simply dropping off tablet computers with preloaded programs and seeing what happens.The goal: to see if illiterate kids with no previous exposure to written words can learn how to read all by themselves, by experimenting with the tablet and its preloaded alphabet-training games, e-books, movies, cartoons, paintings, and other programs.Early observations are encouraging, said Nicholas Negroponte, OLPCâ€™s founder, at MIT Technology Reviewâ€™s EmTech conference last week.The devices involved are Motorola Xoom tabletsâ€”used together with a solar charging system, which OLPC workers had taught adults in the village to use. Once a week, an OLPC worker visits the villages and swaps out memory cards so that researchers can study how the machines were actually used.After several months, the kids in both villages were still heavily engaged in using and recharging the machines, and had been observed reciting the â€œalphabet song,â€? and even spelling words. One boy, exposed to literacy games with animal pictures, opened up a paint program and wrote the word â€œLion.â€?The experiment is being done in two isolated rural villages with about 20 first-grade-aged children each, about 50 miles from Addis Ababa. One village is called Wonchi, on the rim of a volcanic crater at 11,000 feet; the other is called Wolonchete, in the Rift Valley. Children there had never previously seen printed materials, road signs, or even packaging that had words on them, Negroponte said.Earlier this year, OLPC workers dropped off closed boxes containing the tablets, taped shut, with no instruction. â€œI thought the kids would play with the boxes. Within four minutes, one kid not only opened the box, found the on-off switch â€¦ powered it up. Within five days, they were using 47 apps per child, per day. Within two weeks, they were singing ABC songs in the village, and within five months, they had hacked Android,â€? Negroponte said. â€œSome idiot in our organization or in the Media Lab had disabled the camera, and they figured out the camera, and had hacked Android.â€?Elaborating later on Negroponteâ€™s hacking comment, Ed McNierney, OLPCâ€™s chief technology officer, said that the kids had gotten around OLPCâ€™s effort to freeze desktop settings. â€œThe kids had completely customized the desktopâ€”so every kidsâ€™ tablet looked different. We had installed software to prevent them from doing that,â€? McNierney said. â€œAnd the fact they worked around it was clearly the kind of creativity, the kind of inquiry, the kind of discovery that we think is essential to learning.â€?â€œIf they can learn to read, then they can read to learn.â€?In an interview after his talk, Negroponte said that while the early results are promising, reaching conclusions about whether children could learn to read this way would require more time. â€œIf it gets funded, it would need to continue for another a year and a half to two years to come to a conclusion that the scientific community would accept,â€? Negroponte said. â€œWeâ€™d have to start with a new village and make a clean start.â€?The idea of dropping off tablets outside of the context of schools is a new paradigm for OLPC. Through the late 2000s, the company was focused on delivering a custom miniaturized and ruggedized laptop, the XO, of which about 3 million have been distributed to kids in 40 countries. Deployments went to schools including ones in Peru.Giving computers directly to poor kids without any instruction is even more ambitious than OLPCâ€™s earlier pushes. â€œWhat can we do for these 100 million kids around the world who donâ€™t go to school?â€? McNierney said. â€œCan we give them tool to read and learnâ€”without having to provide schools and teachers and textbooks and all that?â€?Vince "k|ngp|n" Lucido is one of the world's most well known Overclockers today. So in October 2012, EVGA put his skills to the test and challenged him to crush the competition and sweep the board for 3DMark 11 scores. Armed with an assortment of EVGA GeForce GTX 680 Classified, EVGA X79 Classified Motherboard, EVGA SuperNOVA NEX1500 Classified power supplies, and enough Liquid Nitrogen to turn Taipei into a deep freeze; Vince was able to smash three brand new 3DMark 11 World Records*. In fact, EVGA along with k|ngp|n were the first to reach over 17,000 points on a single graphics card!Also! Don't forget to sign up for the EVGA 3D Eclipse giveaway, download the exclusive EVGA Precision X skin, and maybe a chance to win some incredible OC prizes! http://www.evga.com/articles/00712/To learn more about extreme overclocking and stay up to date on the latest news, make sure to follow EVGA, Kingpin Cooling and GSkill on Facebook!https://www.facebook.com/TEAMEVGAhttps://www.facebook.com/kingpincoolinghttps://www.facebook.com/gskillofficial*World Records verified on October 23, 2012Back when Firefox 2 was released (six years ago this week!), the Internet Explorer team started a friendly tradition of sending Mozilla a cake as congratulations. This continued for Firefox 3 and Firefox 4. After Firefox switched from major releases once or twice a year to incremental updates every six weeks, they sent us a cupcake for the next few updates instead.I thought it would be fun to revive the tradition by ordering a cake for the IE team for the IE10 release today. Here it is right after I picked it up from Baked Custom Cakes, with a Firefox logo in painted fondant:Fellow Mozilla developer Eitan Isaacson drove with my wife Sarah and me to Microsoft Building 50 in Redmond, where program manager Jacob Rossi helped us deliver the cake to a group of IE team members:The IE team posted their thanks through their official Twitter account. (As you can see from their picture, the bottom border of the cake was slightly restyled in transit.) Just 30 minutes later, Michael Bolan tweeted that the cake was gone. I hear the sugary Firefox logo was eaten soon after.So congratulations to the Internet Explorer team on your latest release, and we hope you enjoyed the cake!Vince "k|ngp|n" Lucido is one of the world's most well known Overclockers today. So in October 2012, EVGA put his skills to the test and challenged him to crush the competition and sweep the board for 3DMark 11 scores. Armed with an assortment of EVGA GeForce GTX 680 Classified, EVGA X79 Classified Motherboard, EVGA SuperNOVA NEX1500 Classified power supplies, and enough Liquid Nitrogen to turn Taipei into a deep freeze; Vince was able to smash three brand new 3DMark 11 World Records*. In fact, EVGA along with k|ngp|n were the first to reach over 17,000 points on a single graphics card!Also! Don't forget to sign up for the EVGA 3D Eclipse giveaway, download the exclusive EVGA Precision X skin, and maybe a chance to win some incredible OC prizes! http://www.evga.com/articles/00712/To learn more about extreme overclocking and stay up to date on the latest news, make sure to follow EVGA, Kingpin Cooling and GSkill on Facebook!https://www.facebook.com/TEAMEVGAhttps://www.facebook.com/kingpincoolinghttps://www.facebook.com/gskillofficial*World Records verified on October 23, 2012Following the furor over the company's mapping service, the iOS software chief refused to sign a letter apologizing for its shortcomings and got the boot as a result, the Wall Street Journal reported.The exit of Apple iOS software chief Scott Forstall was apparently anything but quiet. Forstall was forced out after he refused to sign a letter apologizing for problems with Apple Maps, according to the Wall Street Journal.The New York Times confirmed the firing, along with the unrelated ouster of Apple's new retail chief, John Browett.The Journal reported that some within Apple considered Forstall a divisive figure who "never fit into the culture at Apple," and who had long rankled other company execs but enjoyed the confidence of Steve Jobs. As WSJ reporter Jessica Lessin wrote:In fact, Forstall recently sent an email to some of the folks on Apple's iOS software team saying that the group "wasn't working on enough big ideas in mobile software," according to the WSJ. That's effectively saying that Forstall thought the company was struggling to compete, so it's no surprise that tensions were mounting.Apple has said that Forstall will be replaced by Craig Federighi in 2013. Federighi will oversee both the iOS and OS X groups under one umbrella.A walkthrough and review of the just released Xbox SmartGlass app for Android, running on a Asus Google Nexus 7 through side-loading the app.While it's available - here's the APK you can sideload onto your device.https://www.dropbox.com/s/go8ufab7pd9emxs/com.microsoft.smartglass.apkThe company tells CNET that sales of its flagship Galaxy S III actually rose following the unveiling of the iPhone 5, the latest illustration of its run to the top.The Korean conglomerate's flagship Galaxy S III had four of its five best-selling weeks in the U.S. after the iPhone 5 was unveiled, Samsung told CNET.The spike after the iPhone 5 launch suggests that consumers hung around to see what Apple had to show off, weren't impressed, and went with a Galaxy S III instead."I was shocked by the numbers," Kevin Packingham, chief product officer of Samsung's U.S. mobile arm, said in an interview. "I thought: 'What the heck is going on here?'"It's just the latest bit of good news for a company that has enjoyed a remarkable run to the top of the smartphone business, allowing it to surpass Apple and dominate with a flagship brand that has virtually the same appeal as the iPhone.Samsung is poised to continue its run into the holidays as it drums up attention for its latest product, the extra-large Galaxy Note 2. In typical Samsung fashion, the company on Wednesday threw a splashy party for media, d-list celebrities, and select Samsung fans in Manhattan's old Post Office headquarters, capping off the night with a performance by Kanye West."It's the holiday season and they needed something to generate buzz around its products," said Avi Greengart, who covers consumer products for Current Analysis.Keep in mind that the event was being held for a product that has already been announced globally and in the U.S., with reviews of the Galaxy Note 2 already widely available.But that didn't stop Samsung from going big with the event, and partly illustrates why the company has been so successful in battling Apple and establishing its leadership in the mobile world. Few companies have the resources, recognition, and heft to compete with Apple; Samsung just happens to be one of them.The investment in mobile has clearly paid off. Samsung earlier today posted a record quarterly profit of $7.4 billion, thanks largely to its Galaxy line of smartphones. In this industry, only Apple can boast of better results, having posted an $8.2 billion profit yesterday.Given the strength and resources of both companies, Apple and Samsung are likely to continue dominating the handset industry, applying even more pressure to its smaller rivals and potentially forcing some out of the business altogether.Winning 'Phablet' fans Credit Samsung's persistence in creating a new segment for the success of the original Galaxy Note. The device, bigger than a phone, but smaller than a tablet, was initially mocked by critics who thought it looked silly. But Samsung said the company has slowly won over people despite the large size, and pressed the category even further with the larger Galaxy Note 2.Samsung said that it had sold 10 million units of the Galaxy Note in the first nine months of availability around the world, but it's unclear how well it actually did in the U.S. The first Galaxy Note debuted earlier this year with AT&T before later getting picked up by T-Mobile USA as well. But given that a majority of smartphone sales at AT&T are made up of iPhones, there's a question mark for how much share the Galaxy Note actually got.Packingham insisted that the Galaxy Note was "tremendously successful," and that its performance convinced other carriers to add it to their lineup. This time around, the Galaxy Note 2 will be sold by all four national carriers, as well as a few regional ones."It's impressive that they have all the carriers lined up," Greengart said.J.K. Shin, head of Samsung's mobile business, has high expectations for the Galaxy Note 2, and told reporters at a briefing that he expects it to sell three times more quickly than the previous version, hitting 3 million units in the first 90 days.Samsung's more bullish because the Galaxy Note 2 has the benefit of wider availability and higher awareness from consumers, Packingham said. He added that carriers like the device because it targets the kind of customers they want to go after: power users looking for more from their mobile devices and well-off enough to buy the product.Galaxy Note 2 vs. iPad Mini? At $299.99 with a two-year contract, the Galaxy Note 2 isn't for bargain seekers.In fact, it's only $30 less expensive than the recently released iPad Mini from Apple. (A cellular version starts at $459.) There are, of course, fundamental differences between the two devices, with the Galaxy Note 2 sold more as a phone with a smartphone plan and seen as more of a primary device, while the iPad Mini is more a complementary device. Still, they also aren't that far apart when it comes to size.Packingham doesn't believe that the Galaxy Note 2 will compete with the iPad Mini. Samsung has a lot of experience with 7-inch tablets, with its Galaxy Tab being one of the first such Android devices, and Packingham said that the customers who buy them are different than ones who would buy the Galaxy Note 2.While Samsung isn't the first to sell a 5-inch device, the company does take credit for creating this new category of tweener devices. (Internally, executives don't refer to them as "phablets.") The Galaxy Note has spawned follow-up attempts, including the Optimus Vu from LG, known as the Intuition at Verizon Wireless. Packingham, however, was fairly dismissive of other attempts."Clearly in this segment, the Note stands alone," he said.A walkthrough and review of the just released Xbox SmartGlass app for Android, running on a Asus Google Nexus 7 through side-loading the app.While it's available - here's the APK you can sideload onto your device.https://www.dropbox.com/s/go8ufab7pd9emxs/com.microsoft.smartglass.apkPeople increasingly have more than one device, and they switch between them many times a day. Nexusâ€”Googleâ€™s hardware line for Android devicesâ€”gets rid of the hassle. Just sign in with your Google Account and everything is there ready to go, whatever device youâ€™re using: photos, emails, contacts, bookmarks, even your entertainment on Google Play.Today, weâ€™re excited to announce three great new Nexus devices â€¦ in small, medium and large. And they all run Android 4.2, a new flavor of Jelly Beanâ€”which includes the latest version of Google Now and other great new features.Nexus 4 with Google Now and Photo Sphere Nexus 4 is our latest smartphone, developed together with LG. It has a quad-core processor which means it's super fast, a crisp 4.7" (320 ppi) display that's perfect for looking at photos and watching YouTube, and with wireless charging you just set the phone down on a charging surface to power it up, no wires needed. While Nexus 4 is incredibly powerful under the hood, it also features the latest version of Jelly Bean, Android 4.2â€”the simplest and smartest version of Android yet. Starting with the camera, we've reinvented the photo experience with Photo Sphere, which lets you capture images that are literally larger than life. Snap shots up, down and in every direction to create stunning 360-degree immersive experiences that you can share on Google+ with friends and familyâ€”or you can add your Photo Sphere to Google Maps for the world to see.Android 4.2 brings other great goodies like Gesture Typing, which lets you glide your finger over the letters you want to type on the keyboardâ€”it makes typing fast, fun and a whole lot simpler. Android 4.2 also adds support for wireless display so you can wirelessly watch movies, YouTube videos and play games right on your Miracast-compatible HDTV.Learn more about all of the new features of Android 4.2, Jelly Bean, here.Google Nowâ€”even more useful We designed Google Now to make life simpler by giving you the right information at just the right time in easy to read cards, before you even ask. And the feedback has been awesome. So today weâ€™re adding more cards that we hope youâ€™ll find useful. Flight information, restaurant reservations, hotel confirmations and shipping detailsâ€”how often have you found yourself wading through your email to get this information at the last moment? So next time you book a table for dinner, youâ€™ll get a reminder with all the details without ever having to lift a finger. Youâ€™ll also get cards for nearby attractions, interesting photo spots, movies times at nearby theaters or concerts by your favorite artists.Nexus 7: Thin, light and now even more portableNexus 7 brings you the best of Googleâ€“YouTube, Chrome, Gmail, Mapsâ€“and all the great content from Google Play in a slim, portable package that fits perfectly in your hand. To give you more room for all that great content you can now get Nexus 7 with 16GB ($199) or 32GB ($249) of storage. But we also wanted to make this highly portable tablet even more mobile. So we added HSPA+ mobile data. Nexus 7 is now also available with 32GB and HSPA+ mobile ($299), which can operate on more than 200 GSM providers worldwide, including AT&T and T-Mobile in the U.S. Nexus 10: Powerful and shareable Nexus 10 is the ultimate tablet for watching movies or reading magazines. We wanted to build a premium entertainment device, so we partnered with Samsung to do just that. Nexus 10 is the highest resolution tablet on the planet with a 10.055" display at 2560-by-1600 (300ppi), that's over 4 million pixels right in your hands. It comes with a powerful battery that will get you up to nine hours of video playback and more than 500 hours of standby time. With a set of front-facing stereo speakers, you can watch movies right from your Nexus 10 and they simply sound awesome. But what makes Nexus 10 unique is that it's the first truly shareable tablet. With Android 4.2, you can add multiple users and switch between them instantly right from the lockscreen. We believe that everyone should have quick and easy access to their own stuff -- email, apps, bookmarks, and more. That way, everyone can have their own home screens, their own music, and even their own high scores.Google Play: More entertainment, more countriesWeâ€™ve recently added a ton of great new entertainment to Google Play, such as movies and TV shows from Twentieth Century Fox. Earlier this year we expanded our service beyond movie rentals and now you can purchase movies and build a library of your favorites in Google Play. Today weâ€™re bringing movie purchasing to more countries - Canada, the U.K., France, Spain and Australia.Weâ€™re also excited to announce two new partnerships. Weâ€™re now working with Time, Inc. to bring you even more magazines like InStyle, PEOPLE, TIME and others. And weâ€™ve partnered with Warner Music Group who will be adding their full music catalog with new songs coming each day. Weâ€™re now working with all of the major record labels globally, and all the major U.S. magazine publishers, as well as many independent labels, artists and publishers.On November 13, we're bringing music on Google Play to Europe.  Those of you in the U.K, France, Germany, Italy and Spain will be able to purchase music from the Google Play store and add up to 20,000 songsâ€”for freeâ€”from your existing collection to the cloud for streaming to your Android devices or web browser. Weâ€™re also launching our new matching feature to streamline the process of uploading your personal music to Google Play. Weâ€™ll scan your music collection and any song we match against the Google Play catalog will be automatically added to your online library without needing to upload it, saving you time. This will be available in Europe at launch on November 13 and is coming to the U.S. soon after. This will all be for freeâ€”free storage of your music, free matching, free syncing across your devices and free listening.Great valueWeâ€™ve always focused on building great devices at great value.  And we think todayâ€™s devices offer the very best that money can buy. Here are more details on when and where you can pick up your next Nexus device:Nexus 4: 8GB for $299; 16GB for $349; available unlocked and without a contract on 11/13 on the Google Play store in the U.S., U.K., Australia, France, Germany, Spain and Canada. The 16GB version will also be available through T-Mobile for $199, with a 2-year contract (check here for more details).Nexus 7: 16GB for $199 and 32GB for $249; available in the U.S., U.K., Australia, France, Germany, Spain, Canada and Japan, and also through our retail partners Gamestop, Office Depot, Office Max, Staples and Walmart.Nexus 7 with 32GB and mobile data: $299 and unlocked, on sale 11/13 in the Google Play store in the U.S., U.K., Australia, France, Germany, Spain and  Canada.Nexus 10: 16GB for $399; 32GB for $499; available on 11/13 in the Google Play Store in the U.S., U.K., Australia, France, Germany, Spain, Canada and Japan. You'll also be able to purchase the 32GB version in more than 2,000 Walmart stores in the U.S.A Nexus device is much more than simply a phone or tablet. Itâ€™s your connection to the best of Googleâ€”all of your stuff and entertainment, everywhere you go with no hassle.  Now you have three new Nexus devices, a new improved version of Jelly Bean and more entertainment than ever beforeâ€”all available on Google Play. The playground is open.On the way to the Apple Store today to buy AppleCare+ for my wifeâ€™s new iPhone 5, we passed the new Microsoft Store, coincidentally in the middle of their Surface with Windows RT launch. (That is actually the productâ€™s name. â€œSurface with Windows RTâ€?.)They had set up a table and an Xbox demo in the hallway and were giving away â€œMicrosoft Surfaceâ€?-branded disposable rain ponchos (this entire mall is indoors, including the parking, and it didnâ€™t rain today) and muffin fragments (much like when you order a soda on a plane, they pour a third of it into a little plastic cup full of hollow ice cylinders, and they donâ€™t let you keep the rest of the can). An employee with a microphone in front of the Xbox kiosk was talking to the audience of nobody as if it were a dance party.The store is creepy: so many elements are embarrassingly similar to the Apple Store on the next floor. Microsoft even ripped off trivial elements that easily could have been different, such as the employee uniform. Thereâ€™s a huge elephant in the room, and we can all see it, but Microsoft still implicitly denies it.There were far more employees than customers, and I was curious, so I thought Iâ€™d stop in to take a look at Microsoftâ€™s new tablet. The employees in the store were overly enthusiastic, especially for 3:47 PM, and practically mobbed anyone who entered. â€œHEY! WELCOME TO THE MICROSOFT STORE! WOULD YOU LIKE TO TRY THE NEW SURFACE?â€?The salesman launched into an elaborate pitch. He wasnâ€™t a confident speaker, so the rote was obvious. I wanted to jump right in and start playing with the software, but the salesman kept butting in and driving â€œmyâ€? demo.The first thing he had me do was detach and reattach the keyboard cover. Click. He sold the keyboard cover hard. â€œNobody else has a cover like this.â€?The staff loved Adam so much that he later vomited in the Apple Store.The salesman then showed off the kickstand and started flipping through the applications himself. I wondered if this was how the press got to â€œuseâ€? the Surface before today.When we finally broke the salesmanâ€™s concentration so we could pick it up and start playing with it, Tiff and I both had the same first impression: itâ€™s heavy. On paper, itâ€™s 1.5 pounds (without the half-pound keyboard), like the iPad 1 and a bit heavier than the iPad 3. But itâ€™s not just heavy: it feels dense, like the iPhone 4 and 4S (and notably not like the iPhone 5).Like the Zune, the Surface might always be competing with the previous-generation iPad. Microsoft has approximately matched the weight of the already-too-heavy iPad 3 right as Apple is releasing the far lighter iPad Mini. (And Microsoft just launched this tablet at $500 as everyone else is moving to much lower pricing.)I tried rotating the Surface. There was a long enough delay that I thought rotation just wasnâ€™t supported, then it kicked in and the newly laid out screen just popped in. No transition, no animation. I switched to a different app and tried the same thing with the same results. Rotation was always slow and sloppy.My demo was interrupted as another employee walked through the store, shouting enthusiastically, â€œWE HAVE WORKSHOPS IN THE BACK!â€? Nobody followed him there.The diagonally-oriented camera is strange. In the one orientation itâ€™s optimized for, itâ€™s slightly annoying. In any other orientation, itâ€™s almost intolerable. If I brought home a Surface and didnâ€™t know this was a design decision, I might assume the camera was broken and return it.The maps app is very sluggish and doesnâ€™t use vector graphics, making it feel old.iOS is so responsive and so liberal with animations that it has a very tactile feel, and rather than thinking â€œtap this button to openâ€? or â€œswipe across this box to shareâ€?, conceptually, you just move the things on the screen with your fingers.The distinction seems subtle, but itâ€™s important. Every action on the Surface feels deliberate. It feels like youâ€™re using a computer.The standard gestures donâ€™t help, requiring many in-from-the-edge swipes that not only arenâ€™t discoverable but also frequently conflict with scrolling. My gestures often didnâ€™t work, and it wasnâ€™t clear whether there just wasnâ€™t a hidden context menu at that moment or I just screwed up the swipe.Most of the animations also arenâ€™t helpful, with minimal spatial consistency. Many animations seem arbitrary, not hinting at anything behaviorally useful. Microsoft has applied animations and gestures in Windows 8 about as effectively as they applied color in Windows XP and transparency in Windows Vista: they knew that Apple had been successful with these features, so they made a checklist and just applied them haphazardly. â€œApple does animations, so now we do animations! Apple does gestures, so now we have gestures!â€?An employee was stationed by these big letters on the floor to instruct people to exit to the left, rather than stepping over them. Iâ€™ve never been given instructions on how to exit â€œother storesâ€?.The keyboards are both decent but unmemorable. Every Surface had its own Touch Cover (no physical key movement), and the employees were frantically passing around a single Type Cover (traditional slim keys). Since everyone wanted to try the Type Cover, I only got a few seconds with it, but it was comparable to good iPad keyboards like Logitechâ€™s.The Touch Cover is one of the Surfaceâ€™s biggest innovations. I thought I would hate it, but I didnâ€™t. Itâ€™s not like typing on a completely flat surface: each â€œkeyâ€? is raised slightly, so while there isnâ€™t any mechanical feedback, it does feel a bit like a keyboard.But since it responds to touches rather than mechanical pressure, you canâ€™t rest your fingers on it without triggering key presses. Your fingers must hover over it, which makes it easy to get misaligned from your expected positions and type a bunch of wrong characters. I had a hard time keeping alignment when I needed to stretch for the boundary keys, including Shift. Every time I typed a capital letter, I mistyped the next few letters.I couldnâ€™t type on the Touch Cover significantly faster than with the on-screen keyboard, so I question its purpose. Moreover, since the Touch Cover and Type Cover are so close in price and nearly indistinguishable in size and weight, Iâ€™m not sure why the Touch Cover exists at all other than to be different from â€œother tabletsâ€?. I donâ€™t know why someone would get it instead of the Type Cover.I went to another Surface and was greeted by another salesman. He also aggressively demoed the tablet for me, not letting me take over for more than three seconds at a time. It was obvious that they had all had the same training and were instructed to hard-sell the same talking points. The pitches were aggressive, fast-paced, and competitively defensive: they often mentioned â€œother tabletsâ€? and didnâ€™t let me forget which features were â€œnot available on any other tabletâ€?.He kept showing me the home screen and how to rearrange my icons, even though I kept wanting to explore the apps.He showed me Office, which was almost unusable: it was extremely sluggish, and touch targets were tiny and difficult to hit. He said this was the only tablet that could run Office, and if you used Office at work, this was therefore the only tablet that you could use at work. I played dumb.He asked what kind of computer I had at home. I told him the truth: that I used to have PCs, but now I had an old Mac and wanted to see the newer options out there.He showed me the L-shaped magnetic power connector, which can be plugged in either way, and showed how the magnet safely disconnects when the cable is pulled. It was vaguely familiar, but I continued to play dumb.I asked about 3G options, which the Surface doesnâ€™t have. He said it would restrict me from being able to use it anywhere (?), so I pushed a little further, and he said nobody wants two bills and you can just use tethering and why mess with the pesky 3G connection?He started selling me on the screen quality, saying it had a better screen than any other tablet. I asked, â€œWhat do you mean? Which other tablets?â€?I couldnâ€™t get him to say â€œiPadâ€?, but he did say it was better than â€œRetina screensâ€?.I broke character slightly. â€œI donâ€™t know, I saw the Retina iPad upstairs and I canâ€™t see the pixels at all on it. On here, I can see the pixels clearly.â€?â€œNo you canâ€™t. Where can you see the individual pixels?â€?â€œRight there. See, the left stroke on that capital â€˜Dâ€™ has one solid pixel on the left and a half-shaded pixel on the right.â€?He scaled the icon up to â€œzoom inâ€?, which, of course, changes what the physical pixels display. â€œI canâ€™t see any pixels!â€?I gave up. It was like arguing with a Tea Partier. But I figured, now that I had broken character a little, Iâ€™d risk a bit more.An Apple Store employee had stopped by after his shift, with the original blue shirt over his shoulder, to check out the Surface across from us. We smiled at him. I asked my salesman, â€œDid you apply to work at the Apple Store upstairs first, or did you always want to work here?â€?â€œNo, I went right here. Always been a PC guy. I like being able to customize things, like upgrading my sound cardâ€”â€?I couldnâ€™t resist. â€œOh, can you upgrade the sound card in the Surface?â€?â€œNo, butâ€¦ I started working here before the Surface came out.â€? (This Microsoft Store opened 28 days ago.) â€œBut you can add more RAM to this, right over here, this is an SDXC slot, which means Extra Capacity.â€?Like John Moltz, Iâ€™m left to ask the question: why buy a Surface instead of an iPad? For the price, you can almost buy two baseline iPad Minis. Or you can buy a 32 GB iPad Mini with LTE and a Smart Cover.But I donâ€™t think many Surface buyers are going to comparison-shop with the iPad, or vice versa. Itâ€™s very clear who the Surface is for, and itâ€™s not us.The Surface is partially for Microsoftâ€™s world of denial: the world in which this store contains no elephants and Microsoft invented the silver store with the glass front and the glowing logo and blue shirts and white lanyards and these table layouts and the modern tablet and its magnetic power cable. In that world, this is a groundbreaking new tablet that you can finally use at work and leave your big creaky plastic Dell laptop behind when you go to the conference room to have a conference call on the starfish phone with all of the wires and dysfunctional communication.But itâ€™s also for people like that salesman who donâ€™t agree with Appleâ€™s choices: people who want to have more hardware options, more customization, more hackability, and fewer people saying â€œnoâ€? to what they can do on their devices.Appleâ€™s products say, â€œYou canâ€™t do that because we think it would suck.â€? Microsoftâ€™s products say, â€œWeâ€™ll let you try to do anything on anything if you really want to, even if it sucks.â€?People who dislike Appleâ€™s approach or whose requirements are incompatible with it will always exist in great numbers, and the Surface is for them. Itâ€™ll probably sell well, especially if Microsoft can expand their retail presence quickly.But itâ€™s not for me at all. Not even for testing, experimenting, or curiosity. It feels too much like using a Windows PC, which was exactly Microsoftâ€™s intention, and it will appeal to people who want that. But thatâ€™s a world I fled 8 years ago with no intention of returning.Apple's co-founder fears that freedom of information is under attack, with the internet controlled and regulated in unnecessary and harmful ways. RT talked to Steve Wozniak on a range of topics, from Wikileaks to Megaupload founder Kim Dotcom.RT LIVE http://rt.com/on-airSubscribe to RT! http://www.youtube.com/subscription_center?add_user=RussiaTodayLike us on Facebook http://www.facebook.com/RTnewsFollow us on Twitter http://twitter.com/RT_comFollow us on Google+ http://plus.google.com/b/102728491539958529040RT (Russia Today) is a global news network broadcasting from Moscow and Washington studios. RT is the first news channel to break the 500 million YouTube views benchmark.Hello from Advertising Week! You may remember a couple months ago at another industry event across the pond I shared how we were bringing in creative agency partners earlier than ever before to co-ideate on potential advertising opportunities with Windows 8 Ads in Apps. Bringing partners on board from the beginning is vital to the long-term success of the Windows 8 ecosystem. Working together in the co-ideation process demonstrates what can be gained from great collaboration when you involve creativity and technology. Itâ€™s exciting to see how weâ€™re driving innovation in this opportunity to create new industry standards.Weâ€™ve enjoyed digging in and getting creative with folks from the IAB creative board including Big Spaceship, Razorfish, Team Detroit, Universal McCann and Y&R Group on blue sky thinking for in-app ad concepts, as we are considering Windows 8 a brand new advertising canvas that offers endless opportunities. The connected user interface and unique, fluid design of Windows 8 will encourage people to explore and discover ads without disrupting their experience. Based on that, we set out not to just create new ad formats â€“ our goal was to rethink the entire experience.The results of our co-ideation sessions and work are the first five unique, custom advertising scenarios that feature major brand campaign concepts within marquee publisher apps â€“ including Delta Airlines in an NBC News app, Finish Line in an LA Times app, Ford Fusion in a Chicago Tribune app, Jeep in an AccuWeather app and Goldfish Crackers in a Slacker Radio app. Below is snapshot of each, which you can also see in a quick video with our partners here.Delta is launching a new advertising campaign called â€œUpâ€? that is all about upping the ante in travel with the airline. The Razorfish creative team leveraged the unique, creative campaign and content of â€œUpâ€? to conceptualize a Windows 8 Ads in Apps concept for Delta in the NBC News app that is an intuitive, contextually relevant and immersive experience, which is ideal for a tablet. When in the NBC News app, a user can initiate the ad by touching on the Delta tile so that it expands up the screen. The user can swipe â€˜upâ€™ to continue a visual journey of a travel experienceâ€”from checking in at the airport, to bags going up the ramp, until the plane is up in the skyâ€”that is simple and aspirational. Once the experience is closed, users are returned to the NBC News app content.Big Spaceship came up with a simple, yet compelling concept for Finish Line called, "Elements Change, Running's Eternal." The Big Spaceship team was excited about how Windows 8 encourages advertisers to create ads that deserve attention, rather than simply shouting messages, blinking repeatedly or interrupting people. As a result, the Windows 8 Ads in Apps concept for Finish Line is beautiful and fun to explore. In the sports section of the LA Times app, the Finish Line ad opens into a panoramic format that show a day in the life of a female athlete who loves to run. The concepts encourages people to follow her journey while showcasing Finish Line products through strategically placed â€œhot spotsâ€? on the runner that allows people to touch to learn more.Team Detroit created a Windows 8 Ads in Apps concept for Ford Fusionâ€™s new ad campaign that leveraged the consumer-first architecture of Windows 8 to tell a story and present content in a way that is non-intrusive and within the context of what the consumer wants and when. The team created an advertising concept with a dynamic background that is subtle and contextual, and empowers the user to control their brand experience. Shown within the Chicago Tribune app, as consumers scroll left to right, they see environmental changes in the background that are brought to life through dynamic layering of elements and timeline based animation with three advertisement spots highlighting various components of the Ford Fusion story.Universal McCann/Sapient created a dynamic Windows 8 Ads in Apps concept for Jeep within the AccuWeather app that speaks to how its new vehicle is ready for all weather. Once inside the AccuWeather app, the user scrolls through the content to the right until they come to the end and â€˜bumpâ€™ into the Jeep ad, which features engaging animation and a beautiful experience that encourages users to click. Once a user engages, the Jeep ad expands to a full-screen experience where the user can thumb through informative text, graphics and video elements.Pepperidge Farm is looking to expand beyond its typical moms audience to reach teens â€“ which is known as challenging to connect with in general. Y&R identified Slacker Radio as an ideal publishing partner to reach teens in their environment, and developed a Windows 8 Ads in Apps concept featuring a branded experience without having to leave the app. Y&R had to make it more than just awareness â€“ with teens itâ€™s all about selling indirectly to them to get them engaged. The team created the â€œMusic Visualizerâ€? with Goldfish Crackers that can play or work with any kind of music within the Slacker Radio app. The Goldfish crackers jump and literally dance to the music based on the beat/sound wave experience.The pairings were determined through ongoing conversations between the agencies, brands and publishers with the goal of matching like-minded audiences and creating organic, contextually relevant experiences. For instance, Jeep partnered with AccuWeather because weather is inherent to the driving experience and it mapped perfectly to their new all-weather, all-terrain Jeep vehicle.These concepts showcase how digital advertising can be more interactive and revolve around customer-initiated experiences that can be beautiful, relevant and useful. Our agency partners already agree that the potential for creative innovation is great â€“ just see what they had to say.â€œMicrosoft has over 1.3 billion customersâ€¦ if youâ€™re a global brand, Microsoft is the most relevant player in that ecosystem. Theyâ€™re ones that you really have to partner with. I think Windows 8 is going to be that next evolution.â€? Eric Baumgartner, Chief Innovation Officer, Y&R Groupâ€œWindows 8 allows us to tell stories â€¦over a long period of time. It doesn't have to be a single or a one-hit wonder. â€¦The ad formats are innovative, breakthrough, not too overt. Itâ€™s about connecting, and the ability to make an impact.â€? David Cohen, SVP, Universal McCann Interactiveâ€œThe way that Windows works is changing the very definition of an [agency] team today.â€? Margaret Cziesler, National Lead, Strategic Alliances, RazorfishHope everyone enjoys the rest of Advertising Week!Stephen Kim, General Manager of Yarn (formerly Global Creative Solutions) for Microsoft AdvertisingApple's co-founder fears that freedom of information is under attack, with the internet controlled and regulated in unnecessary and harmful ways. RT talked to Steve Wozniak on a range of topics, from Wikileaks to Megaupload founder Kim Dotcom.RT LIVE http://rt.com/on-airSubscribe to RT! http://www.youtube.com/subscription_center?add_user=RussiaTodayLike us on Facebook http://www.facebook.com/RTnewsFollow us on Twitter http://twitter.com/RT_comFollow us on Google+ http://plus.google.com/b/102728491539958529040RT (Russia Today) is a global news network broadcasting from Moscow and Washington studios. RT is the first news channel to break the 500 million YouTube views benchmark.Following the Amazon Web Services outage earlier this week, major sites and platforms are experiencing outages today, including at least Dropbox and Google App Engine. At the time of writing itâ€™s unclear how the two downtimes are related, but Tumblrâ€™s performance issues earlier today point to a clue.The blogging company told us in a statement: â€œTumblr is experiencing network problems following an issue with one of our uplink providers. Recovery is moving quickly and we will return to full service shortly.â€? Internet Traffic Report is reporting major packet loss in North America as well as issues in Asia (the problem is large enough that itâ€™s spilling into the rest of the world):At the time of writing, Dropbox is giving the following error (although it does seem to go back and forth every once in a while):Google App Engine is meanwhile timing out, and actually the Google Developers domain as a whole is having trouble loading. This is affecting Googleâ€™s own properties, such as Android Developers, as well as many other third-party Web sites that rely on App Engine. They are showing errors like this one (ironically, this is for BreakingNews.com):Even YouTube is experiencing issues; Downrightnow is calling it a â€œLikely Service Disruption,â€? although itâ€™s working fine for us:We have contacted both Dropbox and Google about these issues. We will update this article when we hear back.Update at 12:05PM EST: Dropbox appears to be coming back. Google App Engine is still down and out, and the search giant has classified the issue as an â€œAnomalyâ€? (talk about understatement) over at Google App Engineâ€™s System Status page. â€œApp Engine is currently experiencing serving issues. The team is actively working on restoring the service to full strength.â€? We are told to keep an eye on this Google Groups thread for more information.Update at 12:35PM EST: Cedexis has posted Google App Engine traffic details for today, which show things may be starting to return to normal:Update at 1:15PM EST: Google has posted an explanation.At approximately 7:30am Pacific time this morning, Google began experiencing slow performance and dropped connections from one of the components of App Engine. The symptoms that service users would experience include slow response and an inability to connect to services. We currently show that a majority of App Engine users and services are affected. Google engineering teams are investigating a number of options for restoring service as quickly as possible, and we will provide another update as information changes, or within 60 minutes.Update at 1:50PM EST: Google App Engine is starting to come back.Update at 2:10PM EST: Itâ€™s down again. Google has more.We are continuing work to correct the ongoing issues with App Engine. Operation has been restored for some services, while others continue to see slow response times and elevated error rates. The malfunction appears to be limited to a single component which routes requests from users to the application instance they are using, and does not affect the application instances themselves. Weâ€™ll post another status update as more information becomes available, and/or no later than one hour from now.Update at 3:45PM EST: All systems are go.At this point, we have stabilized service to App Engine applications. App Engine is now successfully serving at our normal daily traffic level, and we are closely monitoring the situation and working to prevent recurrence of this incident. This morning around 7:30AM US/Pacific time, a large percentage of App Engineâ€™s load balancing infrastructure began failing. As the system recovered, individual jobs became overloaded with backed-up traffic, resulting in cascading failures. Affected applications experienced increased latencies and error rates. Once we confirmed this cycle, we temporarily shut down all traffic and then slowly ramped it back up to avoid overloading the load balancing infrastructure as it recovered. This restored normal serving behavior for all applications. Weâ€™ll be posting a more detailed analysis of this incident once we have fully investigated and analyzed the root cause.Google has sent over an apologetic statement.Update at 4:15PM EST: Now itâ€™s Facebookâ€™s turn.Update at 9:00PM EST: Google has more information on the outage today over on its App Engine blog.Categories abpwatcher adblock adblock plus adblock plus chrome adblock plus kmeleon customizations development builds easylist elemhidehelper gecko jsdeobfuscator mozilla newsletter off-topic private progress releases security songbird textpattern tomtom weavesync website xulCommenting is closed for this article.Gauntlet is a one handed glove that serves as a wireless keyboard. Type by easily tapping your thumb on each segment of your fingers. Erase letters with just a swipe. Compatible today with iPhone, Android, and Bluetooth enabled tablets, laptops, and desktop computers.Four years after discovering that militants were tapping into drone video feeds, the U.S. military still hasnâ€™t secured the transmissions of more than half of its fleet of Predator and Reaper drones, Danger Room has learned.Â The majority of the aircraft still broadcast their classified video streams â€œin the clearâ€? â€” without encryption. With a minimal amount of equipment and know-how, militants can see what Americaâ€™s drones see.Unmanned aerial vehicles, or UAVs, have become the single most important weapon in Americaâ€™s far-flung pursuit of violent extremists. Hundreds of American Predators and Reapers fly above Libya, Yemen, Somalia, Pakistan, and Afghanistan â€” watching suspected enemies, and striking them when necessary.Â Nearly 3,000 people have been killedÂ in the decade-long drone campaign.â€œIf somebody could obtain reliable access to real-time Predator or Reaper video â€” without attribution or alerting U.S. military â€” that would Â a tremendous intel coup,â€? says Micah Zenko, a fellow at the Council on Foreign Relations. â€œThere is an insatiable demand from Predator and Reaper imagery in Afghanistan and elsewhere. Any reluctance to use those for spying or missile strikes places operations in Afghanistan, Pakistan, Yemen, and Somalia at some risk.â€?Military officials have known about â€” and mostly shrugged off â€” the vulnerability since the development of the Predator in the 1990s. But the problem drew increased attentionÂ in 2008, when drone video footage was found on the laptops of Shiâ€™ite militants in Iraq, who were able to intercept the feed using a piece of $26 software. The Pentagon and the defense industry assured the public that theyâ€™d close the hole by retrofitting the robotic aircraft with new communications protocols and encrypted transceivers that would keep the video from being intercepted again.Four years into the effort, however, only â€œ30 to 50 percentâ€? of Americaâ€™s Predators and Reapers are using fully encrypted transmissions, a source familiar with the retrofitting effort tells Danger Room. The total fleet wonâ€™t see its communications secured until 2014. This source and others who work closely with drone operations say that drones flying overseas are among the first to get the newly secured equipment. They also noted that they are unaware of any incidents of militants using Americaâ€™s unmanned eyes in the sky to their advantage. â€œBut Iâ€™m surprised I havenâ€™t,â€? the source adds. â€œAnd that doesnâ€™t mean itâ€™s not happening.â€?This isnâ€™t the only vulnerability in the drone fleet. In March of 2011, an unknown software glitch caused a PredatorÂ stationed at a U.S. base inÂ Africa toÂ start its engine without human direction.Â Last October, as Danger Room first reported, Air Force technicians discovered aÂ virus infecting the dronesâ€™ remote cockpitsÂ in Las Vegas. It tookÂ weeks of sustained effortÂ to clean up the machines. The aircraft, which rely on GPS to guide them through the air, can run into problems if GPS signals are jammed in a particular area â€” something that can be done with cheap, commercially available hardware.Â Iranian officials claimed they hacked the GPS control signal of an advanced drone, though itâ€™sÂ impossible to verify that lofty claim.No one who works with UAVs is questioning the fundamental integrity of the drone fleet at the moment; it would take an incredibly sophisticated hacker toÂ commandeerÂ a Predator, for example. Nor is anyone pretending that this premiere tool of the U.S.global Â counterterror campaign is flawless.Predators and the larger, better-armed Reapers transmit video and accept instructions in one of two ways. The first is via satellite, to remote pilots and sensor operators who are often on the other side of the planet; these satellite communications are encrypted, and are generally considered secure.The second is through a radio frequency signal called the Common Data Link, which is used to share the droneâ€™s video feed with troops on the ground. The CDLâ€™s carrier signal â€” its specific pattern of frequencies, in a given order and for a given length of time â€” tells both transmitter and receiver on how to function. The problem is that the Predatorsâ€™ version of the CDL carrier signal (also known as a â€œwaveformâ€?) didnâ€™t include an order to encrypt the signal. So neither the transmitter on the drone nor the receivers that troops used on the ground employed encryption, either.There were reasons for this.Â The original Predator, just 27 feet long, was little more than a scaled-up model plane with an 85-horsepower engine. It had a payload of just half a ton for all its fuel, cameras and radios. And encryption systems can be heavy. (Big crypto boxesÂ are a major reasonÂ the Armyâ€™s futuristic universal radio ended up being too bulky for combat, for example.) With the early Predator models, the Air Force made the conscious decision to leave off the crypto.The flying branch was well aware of the risk. â€œDepending on the theater of operation and hostile electronic combat systems present, the threat to the UAVs could range from negligible with only a potential of signal intercept for detection purpose, to an active jamming effort made against an operating, unencrypted UAV,â€?Â the Air Force reported in 1996.Â â€?The link characteristics of the baseline Predator system could be vulnerable to corruption of down links data or hostile data insertions.â€?The Predator models steadily grew in power and payload, and took a big leap in dimensions and capability with the 36-foot-long Reaper version introduced in 2007. The Reaper has a 950-horsepower engine and a nearly 4,000-pound payload â€” more than enough capacity for crypto-enabled systems which, like all electronics, had shrunk in size and weight.The problem was that, by then, the military had rushed to the battlefield hundreds ofÂ Remotely Operated Video Enhanced Receivers, orÂ RoversÂ â€“ rugged, laptop-sized receivers with screens for watching drone footage. And those early version of the Rovers were developed and distributed so fast, the military once again left the crypto off. â€œIt could be both intercepted (e.g., hacked into) and jammed,â€? e-mails an Air Force officer with knowledge of the program.Which mean the Pentagon was stuck, for a time. The military couldnâ€™t replace the old CDL waveform with something encryptable until the Rovers â€” and the radio transmitters aboard the Predators â€” could handle such a signal.Eventually, the Rovers began to be swapped out for newer models. The latest version, the â€œTactical Rover,â€? (.pdf) is about the size of an old-school mobile phone. It can use both the Advanced Encryption Standard an the triple-Data Encryption Standard to secure video feeds. There are now about a thousand of the units in the militaryâ€™s hands.And now, the Predators and Reapers are starting to get enhanced radios, too. â€œThe fleet-wide upgrade begins later this year and carries on for several years,â€? says Maj. Mary Danner-Jones, an Air Force spokesperson. The service is spending $12 million on crypto-enabled Vortex transceivers (.pdf).Thatâ€™s allowing a new, hardened waveform to be introduced throughout the Predator and Reaper fleet. The Air Force recently gave Predator-maker General Atomics Aeronautical SystemsÂ a $26 million contract to retrofit its drone cockpits to accept the carrier signal, among other enhancements.The question is why hasnâ€™t this happened sooner. After all,Â the Navy installed multiple layers of encryption inÂ theirÂ â€™bots some time ago. Navy spokesman Jamie Cosgrove tells Danger Room that â€œthe vast majorityâ€? of naval drones are encrypted â€“Â  â€œand have been since development.â€?One source who works on developing Navy UAVs, but is not authorized the speak on the record, explains why:Â â€?Standard unencrypted video is basically a broadcast to whoever can figure out the right carrier frequency, so essentially, we are simulcasting to battlefield commanders and the opposing force. If that opposing force knows we can see them and from where, they can take better evasive maneuvers.â€?Itâ€™s possible that none of the militants America is trying today are as sophisticated as the ones who intercepted that drone video in 2008. Itâ€™s possible that the value of such footage-from-above is so fleeting that extremists have never again bothered to grab it. But itâ€™s worth noting that Predator and Reaper video is considered by the U.S. military to be classified information. And when U.S. commanders on the ground get into a firefight, the first call they usually make is for a drone, so they can take a look at the battlefield through the eyes of a drone.Amsterdam, the Netherlands, â€“ Building on its innovation capabilities, today Philips unveils hue, the worldâ€™s smartest web-enabled LED home lighting system. Philips hue signals a new era in home lighting both in the way we think about and experience light in our homes. It allows you to create and control the light using your smartphone or tablet. Bringing endless possibilities to help you get creative and help you personalize your lighting to suit yours and your familyâ€™s lifestyle, Philips hue is available exclusively from Apple stores from 30th October. A starter pack includes three bulbs[1] that simply screw into your existing lamps, and a bridge that you plug into your home Wi-Fi router. Simply download the hue app to start experiencing light in a completely new way.Philips hue can be setup in minutes. The intuitive app allows you to remotely control your home lighting to help secure your home, personalize your home lighting experience with custom settings and program timers to help manage your daily schedules, all through the convenience of a smart device. An intuitive and seamless system, Philips hue is upgradeable and future-proof, with the potential for more features to be downloaded and enjoyed in the future.With its high quality energy-saving LED light, Philips hue allows you to tune shades of white light or create any color. In addition, Philips hue can:The app for Philipsâ€™ hue also features expert LightRecipes:Â  four pre-programmed lighting settings based on Philipsâ€™ research around the biological effects that lighting has on the body.Â  These scenarios adjust bulbs to the optimum shade and brightness of white light to help you relax, read, concentrate or energize.Jeroen de Waal, Head of Marketing & Strategy at Philips Lighting commented:Â  â€œPhilips hue is a game-changer in lighting â€“ a completely new way to experience and interact with light. In the way phones, media and entertainment have been revolutionized by digital technology, now we can also personalize light and enjoy limitless applications.Â  Philips continues to redefine the possibilities of LED technology, and hue pushes the boundaries even more, not only in offering great light quality, but in how lighting can be digitized and integrated with our world to further simplify and enhance our lives.â€?Â Â In home tests conducted in New York, Berlin and Shanghai, users highlighted hueâ€™s great quality light, programmable timers and the fact they could control their lighting from outside the home as features they most appreciated.Â  Moreover, consumers liked the ability to save personal light settings and recreate them at the touch of a button as well as the convenience of managing their lighting from their mobile device.Philips is opening up the hue app to the developer community and has created an open source platform at www.meethue.comÂ  inviting developers to explore the app and unleash even more possibilities to show what light can do to enhance your life. You can share light scenes or get inspired on the meethue.com community site. Philips hue uses the open ZigBee Light Link standard so that it can be integrated with other ZigBee certified systems.Building on the success of its AmbiLight experience, Philips is developing future product features, such as allowing hue to integrate with other media including sound and video.Â  Philips is also working on features such as geo-location services, allowing hue to sense when you are close to home and automatically turn on the lights, or turn them off when you leave.Â Â Â Philips hue is available only from Apple stores and Apple.com for $ 199 / â‚¬ 199 / Â£179. To find out more, visit www.meethue.com.Â For further information, please contact:Jeannet HarpePhilips LightingTel +31 6 53 722221Email: jeannet.harpe@philips.comAbout Royal Philips ElectronicsRoyal Philips Electronics of the Netherlands (NYSE: PHG, AEX: PHI) is a diversified health and well-being company, focused on improving peopleâ€™s lives through timely innovations. As a world leader in healthcare, lifestyle and lighting, Philips integrates technologies and design into people-centric solutions, based on fundamental customer insights and the brand promise of â€œsense and simplicity.â€? Headquartered in the Netherlands, Philips employs approximately 122,000 employees with sales and services in more than 100 countries worldwide. With sales of EUR 22.6 billion in 2011, the company is a market leader in cardiac care, acute care and home healthcare, energy efficient lighting solutions and new lighting applications, as well as lifestyle products for personal well-being and pleasure with strong leadership positions in male shaving and grooming, portable entertainment and oral healthcare. News from Philips is located at www.philips.com/newscenter.Â About ZigBee Light LinkZigBee Light Link gives the lighting industry a global standard for interoperable and very easy-to-use consumer lighting and control products. It allows consumers to gain wireless control over all their LED fixtures, light bulbs, timers, remotes and switches. Products using this standard will let consumers change lighting remotely to reflect ambiance, task or season, all while managing energy use and making their homes greener.Products built using this standard are as easy-to-use as a common dimmer switch. The standard does not require any special devices to coordinate with the lighting network, making it both easy and intuitive for consumers to use every day. Plus, it makes adding or even removing products to the lighting network a quick and easy. ZigBee Light Link products earning the ZigBee Certified seal are the industry's only networked consumer lighting products offering simplicity and interoperability.Since ZigBee Light Link is a ZigBee standard, lighting products will interoperate effortlessly with products using other ZigBee standards already in consumers' homes, including ZigBee Home Automation, ZigBee Input Device, ZigBee Remote Control and ZigBee Health Care.Leading home lighting solution manufacturers who contributed their expertise to the development of ZigBee Light Link, including GE, Greenwave, OSRAM Sylvania and Philips.Of all the images that have ever been made, would you be able to select just 100 to represent our species and human achievement? Trevor Paglenâ€™s Last Pictures is a project to do not only that, but also launch those images intoÂ geosynchronousÂ orbit around Earth â€“ all so that long after humans are gone, any space-wanderer will be able to fathom what humanity was all about.The project is based on the idea that after billions of years, all signs of human civilization will have eroded away on Earth, but its satellites will still spin around the planet, making them the best bet for an indefinite time capsule.â€œAny group of people would come up with 100 totally different images, but that is part of the fun. Itâ€™s an impossible project. Part of it was to engage peoplesâ€™ imaginations,â€?Â says artist Trevor Paglen, who conceived of the concept and collaborated with scientists, anthropologists, curators and corporations to get the images into space.Writer and artistÂ Anya VenturaÂ coordinated the work of five researchers who whittled down the image selection fromÂ 10,000 to 500 to 100. With every choice open to debate, it was a mindful experience.â€œWeâ€™re inundated with images, but we donâ€™t stop to look at them,â€? says Ventura.Â â€?The Last Pictures necessitates the act of looking. Itâ€™s a project that sticks with me because of our discussions about what makes a good photograph.Â We were tackling issues of representation and decoding images.â€?But choosing the images was only the beginning â€“ two more giant problems loomed. Firstly, how does one fabricate those 100 images to survive billions of years in space? Secondly, how does one get them into orbit?Brian Wardle, associate professor at MITâ€™s Department of Aeronautics and Astronautics and director of theÂ Nano-Engineered Composite aerospace StructuresÂ (NECST) Consortium, consulted on design and fabricated the vessel for the images. He andÂ Professor Karl Berggren, a quantumÂ nano-structuresÂ expert, were mostly concerned with preventing diffusion â€“ the incredibly slow movement of molecules which over millions of years could potentially degrade the sharpness of the image.â€œBy using a single material, Silicon, and etching physical features in that material, the Artifact will maximally resist diffusion. Usually the â€˜sands of timeâ€™ erase writings through erosion, but in this case we used sand/Silicon against time to resist its effect,â€? says Wardle with a poetic flourish.To that end, theÂ Last PicturesÂ are nano-etched onto a silicon disc â€“ referred to within the project as â€œthe Artifactâ€? â€“ and secured within a gold-plated aluminum clamshell.Paglen now knew the images could survive, but how to get them up there?Creative Time, a stalwart New York arts organization andÂ Last Pictures partner, was on board to help with the logistics, but even when the project mangerÂ telephoned every company that put hardware into space they drew a blank.Short on options,Â Anne Pasternak, Executive Director ofÂ Creative Time, began making pleas to audience members at her numerous public speaking events for contacts within theÂ satelliteÂ industry. Two connections and a few phone calls later,Â Last PicturesÂ had an agreement withÂ EchoStar Corporation, a Colorado-basedÂ telecommunicationsÂ company responsible for maintaining Dish Networkâ€™s satellite fleet. (EchoStar also owns SlingBox.)Once the deal was done, Paglen waited for a window. It came in December 2011 when Palo Alto-basedÂ Space Systems Loral were in the final stages of manufacturing the next EchoStar satellite.â€œEchostar gave us a month to get the disc tested and flight ready,â€? says Paglen.Â â€?Many engineers stepped up over the Christmas holidays.â€?After two delayed launch attempts, the 6,600 kilograms EchoStar XVI is set for launchÂ on November 20th from the Baikonur CosmodromeÂ inÂ Kazakhstan, on the back of an ILS Proton Breeze M Rocket. EchoStarâ€™s main cargo is 32 Ku-band transponders which will deliver direct-broadcast satellite (DBS) signals back to earth for suped-up local HD channels among other things.Last Picturesâ€˜ efforts have reminded many of Â Carl Saganâ€™sÂ Voyager Golden RecordÂ which includedÂ 116 images of animals, food, architecture, portraits and daily human life, as well as sounds.Â Ventura says the Last Pictures team were a bit sniffy about the appropriateness of Saganâ€™s images to farily represent unified humanity but when they took on a similar selection process, â€œweÂ realizedÂ how difficult it was,â€? says Ventura.â€œAt the beginning we imagined the images as an archive, but later we started to think of them as a silent film, like poetry. We made aesthetic decisions,â€? says Paglen who in the book arranges many images in pairs based on formal relationships.Â â€?I guess thatâ€™s where my artistic influence came in.â€?Paglen and his team deliberately included images to challenge viewers.â€œWeâ€™re making cave paintings for the future,â€? he says. â€œA lot of images are enigmatic.Â Thereâ€™s stories outside of the images. Enough to keep the aliens on their toes!â€?One curve ball is an installation shot of Malevichâ€™s work at the Last Futurist Exhibition in St Petersburg, 1915.Â It is Paglenâ€™s nod to the convergence of art, philosophy and science and to the definitive differences between the American and the Russian space programs.â€œThe U.S. space program has mythologies attached to pioneering and conquering, but the Russian tradition is very different,â€? says Paglen. â€œIn the Russian tradition, the ultimate goal of humanity was to resurrect all humans. In the late 19th centuryÂ Russian CosmistsÂ such asÂ Nikolai FyodorovÂ believed we need to go to space to collect all the particles of all the people who had ever lived.Â Cosmism says going into space is going into the past.â€?The majority of the images, which are published in the Last Pictures book, carry layers of narrative. Percival Lowellâ€™s 19th century maps of â€œcanalsâ€? on Mars surface are typical of the tension between reality and perception. Lowell wasnâ€™t out to fool anyone but the conflagration of tiny aperture and a eye condition he wasnâ€™t aware of had him seeing things.â€œHe thought he was mapping canals on Mars, but he was really seeing blemishes in his own eye,â€? says Anya Ventura.No one on the team is pompous about the selection. Rather Last Pictures is an interstellar version of the question, â€œIf your house was burning down, which photos would you save?â€? Itâ€™s about questions, not necessarily answers.â€œItâ€™s a paradoxical project. It is about time and space, but also ambivalent,â€? says Paglen. â€œLast Pictures questions material circumstances. What does it mean that we make machines that exist as long as the sun?â€?For those who are uncurious about the answers to these questions, fear not. Ultimately the project taxed only a relatively small amount of resources.â€œThe Artifact hitched a ride on a satellite that was going up anyway, and the delta in payload was absolutely negligible relative to typical mass budgets and this one specifically,â€? saysÂ BrianÂ Wardle of MIT.The hostÂ satellite will onlyÂ broadcast signal andÂ orbit Earth for 15 years. Scheduled for 2027, the mission profile of Echostar XVI includes an end-of-life maneuver into a spacecraft junkyard just beyond the Clarke Belt.â€œCreative projects are rarely the result of a single personâ€™s efforts,â€? says Paglen.Â â€?Technologically, it is not hard to launch anÂ objectÂ into space. Emotionally, it has been difficult.â€?Last Pictures, the book, is published by University of California Press. The project is to be presented as an travelling exhibition in 2013.Nexus 7 comes with all of Googleâ€™s best in class Apps - like Maps, Gmail, Chrome, Google+ and YouTube - all in the palm of your hand. With tons of free cloud storage, easy to use apps stay in sync automatically across your tablet, phone and PC. Google Now brings you just the right information, at just the right time. It shows you how much traffic to expect on your way to work, lets you know if your flight is delayed, and brings you live scores from your favorite sports teams. All automatically.On Thursday, 25 October, hundreds of Internet Archive supporters, volunteers, and staff celebrated addition of the 10,000,000,000,000,000th byte to the Archiveâ€™s massive collections.The only thing missing was electricity; the building lost all power just as the presentation was to begin. Thanks to the creativity of the Archiveâ€™s engineers and a couple of ridiculously long extension cords that reached a nearby house, the show went on.Vid The big launch of Microsoftâ€™s Surface slab got off to an inauspicious start in Beijing after an elderly couple invaded the stage in an attempt to halt proceedings.Redmond launched the Windows RT tablet-cum-laptop device at a series of events starting at midnight across the country in partnership with retail giant Suning.However, the Thursday night outdoor launch in the capital attracted two rather irascible Chinese attendees among the hundreds of Microsoft fans keen to be the first in the world to get their hands on the tablet.The inevitable YouTube clip - see below - shows an old dear mount the stage in an attempt to kill the noise because it was apparently stopping her grandchildren from getting to sleep before school the next day.Her brave attempt ends in failure, though, as sheâ€™s unceremoniously bundled off the stage by two guards, followed by her husband, while the glamorous sparkly dancers try to complete their routine.Not quite the impression Microsoft wanted to make in China.Things went from bad to worse for the software giant in Asia after reports emerged that a high-profile live public demonstration of Windows 8 in downtown Taipei fell flat when the OS cocked up on some devices. Microsoft staff apparently had trouble closing apps on several all-in-one PCs and instead were forced to demo the new OS on tablets.â€œIt was pretty rushed to the launch date, and the user experience will improve,â€? marketing manager Yi-Fang Chu told the Wall Street Journal.â€œIt is a hardware issue, rather than a software one. Itâ€™s partly because of the large screen size of the all-in-ones.â€? Â®Google has officially announced the Nexus 4, the latest phone in its Nexus line of flagship Android devices. Built by LG, the phone features a 4.7-inch 1280 x 768 IPS display, a 1.5GHz quad-core Snapdragon S4 Pro processor â€” which Google claims is the fastest on the market â€” an 8 megapixel camera and a 1.3 megapixel front-facing camera, and up to 16GB of storage. Oh, and the back is made of glass â€” etched, layered glass that sparkles with a strange, almost holographic depth.The executive vibe is balanced nicely by the playfulness of the backNot much of that should be surprising, as the phone had been thoroughly leaked around the web in the past few weeks. What is surprising is how much better it all looks in person. Compared to the LG Optimus G, which shares many of the same components, it's no contest â€” the Nexus 4 is a far nicer piece of hardware. It feels weighty and high-end, and the tight construction combined with the soft-touch plastic on the sides and chrome edging give it a solidly executive vibe â€” a vibe that's balanced nicely by the playfulness of Disco City on the back.The device will sell for $299 with 8GB of storage, or $349 with 16GB. A T-Mobile version will sell unlocked for $199 on a two-year contract. Alongside the improved screen and faster CPU, the Nexus 4 has 2GB of RAM, Wi-Fi 802.11b/g/n, NFC, Bluetooth, and built-in compatibility with Google's latest accessory, the Wireless Charging Orb â€” an inductive charging dock. The phone also houses a sizable 2100 mAh battery, which the company claims will get you about 10 hours of talk time.There's no LTE hereAll that battery life would be great if the device was sporting LTE radios â€” but it is not. Google has decided to forgo stricter carrier partnerships in the US, which for now means that the company will only offer the device as an unlocked HSPA+ phone. That's a bit of a crushing blow to many, who expected Google's next flagship phone to go toe-to-toe with the iPhone 5 and the latest crop of Windows Phone devices.On the bright side, the 320 ppi IPS+ LCD screen is terrific â€” a massive upgrade over the so-so Galaxy Nexus display and competitive with the iPhone's 326 ppi Retina Display. And it's not just competitive in pixel density; the screen looks stunning. It's also laminated and uses LG's new "G2" technology which integrates the touch sensor into the Gorilla Glass 2 outer layer, making everything thinner as well as bringing the actual pixels closer to the surface of the display. (Apple uses a similar technique called "in-cell touch" on the iPhone 5, which integrates the touch sensor into the display panel.) The screen is also curved slightly at the edges, like it's been melted over the phone; Google says it's meant to improve swiping in from the sides of the device.Performance on the phone was snappy. Google execs we spoke with pointed out just how fast the new Snapdragon CPU is, and in our short time testing the phone, it seemed to rip through just about anything we threw at it with little or no hesitation.The screen is curved slightly at the edges, like it's been melted over the phoneFor those disappointed with the camera performance of the Galaxy Nexus, there's also a bright spot here. Literally. Photos taken with the Nexus 4 seem greatly improved over the last generation, and Google reps say that a lot of attention has been paid to the low-light performance of the camera. We won't know for sure just how much better it is than previous phones until we put the device through its full paces, but first impressions suggest a big improvement.On the software front, Google is launching Android 4.2 along with the Nexus 4 (and the Nexus 10 tablet), and it's got some killer new features. We have a full look at the software here, not to mention an exclusive feature on the inside story of the Android team here, but there are a few standout components of the OS update that are worth mentioning.For starters, Google has added widget functionality to the lock screen, meaning you can quickly glance at information without having to get into the phone. The camera has also been improved with a completely redesigned UI focused on single-handed input, and Google has added a Street View-like mode called Photo Sphere which makes panorama shots seem tiny by comparison. The company has also improved Google Now significantly (we have a big feature story on that too).Android now has a typing mode called Gesture Typing, which mimics the functionality of Swype in conjunction with standard tap typing. The company has also added a new quick settings menu to the notifications window, tweaked Gmail with much-needed features like swipe to archive and scale-to-fit messages (like the iPhone), and added new accessibility options that make Android easier than ever â€” for all users.We'll have a full review of the Nexus 4 soon; until then, be sure to check into all of the in-depth news on Google's announcements today.You can also watch this video on YouTube.The system is powered by Nvidia GPUs and thought to be one of the two fastest supercomputers in the world. It's capable of making 20,000 trillion calculations each second.Forecasting for weather like this week's "Frankenstorm" may become a lot more accurate with the help of the Department of Energy's Titan supercomputer, a system that launched this month for open research development.The computer, an update to the Jaguar system, is operated in Tennessee by Oak Ridge National Laboratory, part of the DOE's network of research labs. Researchers from academia, government labs, and various industries will be able to use Titan -- believed to be one of the two most powerful machines in the world -- to research things such as climate change and alternative fuels."Why care about these big computers? It's really because society's got big problems," Steve Scott, chief technology officer of Nvidia's GPU accelerated computing business, said in a recent interview. "There are healthcare issues, lots of diseases across the board, an aging population. Energy is a huge problem facing the world and our country. ... Increasingly computers are used to solve these problems."As part of this month's launch of Titan, the DOE has awarded 4.7 billion supercomputing hours at Oak Ridge and another facility to 61 science and engineering projects with "high potential for accelerating discovery and innovation" through its Innovative and Novel Computational Impact on Theory and Experiment (INCITE) program.While the areas of research vary, there are six main areas targeted for Titan, according to Nvidia's Scott:Â• Material science code. This is basically looking at material at the atom level, to understand its properties. It also involves figuring out how to construct new materials to have superior properties of strength, weight, and other characteristics.Â• Climate change. Researchers want to answer questions about what's going on, how to change it, how to adapt to it, etc.Â• Biofuels. This involves looking at certain plants -- like switchgrass -- and converting them into ethanol using an enzymatic process.Â• Nuclear energy. The technology can be used to simulate neutron flux in fusion and fission. It includes looking at a new form of fusion energy that would be safer and cleaner, as well as new fuels that would burn longer and cleaner.Â• Combustion. Titan can allow the simulation of combustion for researchers trying to optimize the fuel, process, and engine design to get a cleaner burning fuel."All of these areas have tremendous real world societal benefits," Scott said. "And they need high performance computing to drive them forward."None of the research would be possible without the massive computing abilities provided by Titan. The system is believed to be more powerful than the world's current top supercomputers from Japan and China, and it rivals the Top500's No. 1 machine from June, the DOE's Sequoia machine at Lawrence Livermore National Laboratory.Titan is one of the new types of systems that combine discrete graphics chips, or GPUs, commonly used for videogames, along with standard microprocessors. In this case, Nvidia is providing the GPUs while the CPUs come from Advanced Micro Devices. Graphics chips are used to accelerate the number-crunching functions of supercomputers by allowing many tasks to be completed at once, and they require less power than CPUs alone.Titan is 10-times more powerful and five-times more energy efficient than Oak Ridge's last system, dubbed Jaguar. Oak Ridge says the use of GPUs combined with CPUs allows Titan to take up the same physical space as Jaguar while using only "marginally" more electricity (9 megawatts for Titan versus 7 megawatts for Jaguar).If Oak Ridge upgraded Jaguar by simply expanding the CPUs, the system would be more than four-times its current size and would consume more than 30 megawatts of power.Jaguar became the world's most powerful supercomputer in late 2009, and it held onto that title for a year before being passed by a Chinese system. The DOE's Sequoia system, meanwhile, nabbed the top spot in June with a performance of 16.32 petaflops. That system is powered by IBM chips and is used for classified national defense research.Titan may prove to be the most powerful system when the list is again released early next month, Scott said.It's almost mindboggling how fast Titan operates. The system is capable of churning through more than 20,000 trillion calculations each second -- or 20 petaflops -- by using GPUs.The system, developed by Cray, contains 18,688 nodes, with each containing a 16-core AMD Opteron processor and an Nvidia Tesla GPU based on the graphics chipmaker's Kepler architecture. Titan also has more than 700 terabytes of memory.Bill Blake, chief technology officer at Cray, said the industry is at an inflection point where GPUs become necessary to reach higher performance in supercomputers."For the foreseeable future, for sure the next 10 years plus, the industry will be on this inflection point of change because of accelerated computing," he said in a recent interview.A smart road design that features glow in the dark tarmac and illuminated weather indicators will be installed in the Netherlands from mid-2013."One day I was sitting in my car in the Netherlands, and I was amazed by these roads we spend millions on but no one seems to care what they look like and how they behave," the designer behind the concept, Daan Roosegaarde, told Wired.co.uk. "I started imagining this Route 66 of the future where technology jumps out of the computer screen and becomes part of us."The Smart Highway by Studio Roosegaarde and infrastructure management group Heijmans won Best Future Concept at the Dutch Design Awards, and has already gone beyond pure concept. The studio has developed a photo-luminising powder that will replace road markings -- it charges up in sunlight, giving it up to ten hours of glow-in-the-dark time come nightfall. "It's like the glow in the dark paint you and I had when we were children," designer Roosegaarde explained, "but we teamed up with a paint manufacture and pushed the development. Now, it's almost radioactive".Special paint will also be used to paint markers like snowflakes across the road's surface -- when temperatures fall to a certain point, these images will become visible, indicating that the surface will likely be slippery. Roosegaarde says this technology has been around for years, on things like baby food -- the studio has just upscaled it.The first few hundred metres of glow in the dark, weather-indicating road will be installed in the province of Brabant in mid-2013, followed by priority induction lanes for electric vehicles, interactive lights that switch on as cars pass and wind-powered lights within the next five years.The idea is to not only use more sustainable methods of illuminating major roads, thus making them safer and more efficient, but to rethink the design of highways at the same time as we continue to rethink vehicle design. As Studio Roosegaarde sees it, connected cars and internal navigation systems linked up to the traffic news represent just one half of our future road management systems -- roads need to fill their end of the bargain and become intelligent, useful drivers of information too."Research on smart transportation systems and smart roads has existed for over 30 years -- call any transportation and infrastructure specialist and you'll find out yourself," Studio Roosegaarde comunications partner Emina Sendijarevic told Wired.co.uk. "What's lacking is the implementation of those innovations and making those innovations intuitive and valuable to the end-consumers -- drivers. For this, a mentality change needs to take place within a country and its people, but also within a company such as Heijmans."This is a story that goes beyond the 'Smart Highway' as such -- it's about the fact that Heijmans and Roosegaarde are not going to wait any longer for innovations to find their way through the political system, but will start building this highway now."All together, the studio has around 20 ideas that will eventually be rolled out and it has had inquiries from countries across the globe -- "India is really keen on it; they have a lot of blackouts there, it would be hallelujah to them".Roosegaarde also hopes to take his designs to the US west coast, where companies like Google already have autonomous vehicles driving round their campuses: "It amazes me that most innovation in the west coast is screen based -- I always imagined that technology jumping out of our screens and becoming part of our environment. It's incredibly important we keep imagining what our reality is going to look. A lot of people have told me along the way that what I wanted could not be done, and it's my job to prove them wrong."The Roosegaarde design promise comes as UK authorities announce that lights on motorways, residential streets and footpaths will be turned off or dimmed from as early as 9pm to save money (hundreds of thousands of pounds, in some cases) and to meet green targets.Some councils are, however, taking on the burden of installing new lights with dimmers, the cost of which will mean they will need to wait four to five years before they recoup the money -- by which time, they could have conserved cash for more efficient and safer ways to save on lighting costs. A Sunday Telegraph report has also revealed that nearly 5,000km of motorways and trunk roads in England are already unlit, 75km have their lights switched off between midnight and 5am and 73 percent of 134 councils surveyed switch off or dim lights, or plan to. Fully switching the lights off on major roads saved the Highways Agency just Â£400,000 in 2011.Paul Watters, head of roads policy at the AA, told the Telegraph: "We do know that most accidents happen in the dark. It's also comforting for people, especially if they arrive back from somewhere in the night, when they have got a late train. There are also suggestions that it increases crime. So it may save money in terms of energy but then you have to look at the cost in terms of security, safety and accidents, it may actually be more."According to a report by car insurance company Zurich Connect, there is an 11 percent increase in claims immediately following the winter clock change in the UK, when nights get darker earlier.A slide taken from an online slideshow by a political targeting firm.Connect with Facebook to share articles you read on ProPublica. Learn more Â»If you're a registered voter and surf the web, one of the sites you visit has almost certainly placed a tiny piece of data on your computer flagging your political preferences. That piece of data, called a cookie, marks you as a Democrat or Republican, when you last voted, and what contributions you've made. It also can include factors like your estimated income, what you do for a living, and what you've bought at the local mall.Across the country, companies are using cookies to tailor the political ads you see online. One of the firms is CampaignGrid, which boasted in a recent slideshow, "Internet Users are No Longer Anonymous."Â The slideshow includes an image of the famous New Yorker cartoon from 1993: "On the Internet, nobody knows you're a dog." Next to it, CampaignGrid lists what it can now know about an Internet user: "Lives in Pennsylvania's 13th Congressional District, 19002 zip code, Registered primary voting Republican, High net worth household, Age 50-54, Teenagers in the home, Technology professional, Interested in politics, Shopping for a car, Planning a vacation in Puerto Rico."The slideshow was online until last week, when the company removed it after we asked for comment. (Here is the full slideshow.) Rich Masterson, CampaignGrid's chairman, wrote in an email that the slideshow was posted in error: "It was an unapproved version of a sales deck that was posted by an intern who no longer works for the company."CampaignGrid does indeed collect 18 different "attributes" for every voter, Masterson told ProPublica, including age, gender, political donations, and more. Campaigns use this data to tailor the online ads you see.Online targeting has taken off this campaign season. ProPublica has identified seven companies that advertise the ability to help campaigns target specific voters online. Among them is Experian, the credit reporting company. Datalogix, a company that works with Facebook to track users' buying patterns, is also involved. (Here are marketing materials and comment from the seven companies). CampaignGrid and a few, similar firms have been profiled for their innovative approaches. Yet the scale of the targeting and the number of companies involved has received little notice.Few of the companies involved in the targeting talk about it publicly. But CampaignGrid, which works with Republicans, and a similar, Democratic firm, Precision Network, told ProPublica they have political information on 150 million American Internet users, or roughly 80 percent of the nation's registered voters.The information â€” stripped of your name or address â€” is connected to your computer via a cookie. Targeting firms say replacing your name with an ID number keeps the process anonymous and protects users' privacy.But privacy experts say that assembling information about Internet users' political behavior can be problematic even if voters' names aren't attached."A lot of people would consider their political identity more private than lots of information," said William McGeveran, a data privacy expert at the University of Minnesota Law School. "We make more rules about medical privacy. We make more rules about financial privacy. So if you think private political beliefs are in that category, maybe you're concerned about having them treated like your favorite brand of toothpaste."Google has stayed away from this kind of targeting. It classifies political beliefs as "sensitive personal information," in the same category as medical information and religious beliefs.But other big players have embraced the "political cookie," as one company branded it.As we reported in June, Yahoo and Microsoft sell access to your registration information for political targeting. That's one way CampaignGrid and other companies find you online. Political targeting firms say they also work with other websites, but would not name them.While campaigns and the firms working with them can buy reams of data about voters, voters have been left mostly in the dark.Many online ad companies mark targeted ads with a small blue triangle symbol, or the phrase "Ad Choices," and offer surfers a chance to opt out. But even if web users know what the triangle means, they get no information about how or why they were targeted."Consumers don't really understand what's going on and haven't given their permission," says Joseph Turow, a digital marketing and privacy expert at the University of Pennsylvania's Annenberg School for Communication.There are few legal regulations governing how online targeting works, or what notification consumers must receive.Online advertising experts point out that individual voting records are public information and have long been used to target voters through direct mail. And targeting companies say they are offering a valuable service. Instead of seeing random ads, users get to see ads from candidates they might actually want to support."We empower voters," Jeff Dittus, co-founder of Campaign Grid and now head of Audience Partners, wrote in an email. "We give voters information that is meaningful to them and helps them make choices."Stuart Ingis, a lawyer for the Digital Advertising Alliance, an industry group, said that voter file targeting is a First Amendment issue, and that targeting should be protected as part of political speech."These technologies provide a method for politicians inexpensively to improve our democracy," he said. "I would say that the founding fathers firmly believed in the ability â€” I think our society very much values the ability â€” to efficiently reach a desired audience with a political message."Not everyone seems to agree. A recent study from the University of Pennsylvania's Annenberg School found that 86 percent of surveyed adults did not want "political advertising tailored to your interests," and that 77 percent would not return to a website if they knew it "was sharing information about me with political advertisers."While targeting firms promise a wealth of individual detail, it's hard to know how much information most campaigns are actually using."The more third-party data providers you use, the smaller the universe of people who you can reach becomes," CampaignGrid's Masterson said. "Republican women 25-34 who drive SUVs and have American Express cards, and go to the theater once a month â€” that might be four people."One place online voter targeting has been used successfully is in the state senate primary race of Morgan McGarvey, a Kentucky Democrat who faced off against three other Democratic candidates this May.With four liberal candidates competing for a liberal district, McGarvey told ProPublica, he needed to convince the small number of voters who would turn out in the primary that they should vote for him.His campaign worked with Precision Network to show online McGarvey ads to local voters under 35, and to female Democrats who had voted in at least three of the past five primary elections. (Two of his challengers were women.)"When every dollar counts, when literally every vote counts, you have to be more targeted," he said."I do think it helped us win."McGarvey is now running unopposed in the November election.Have you seen a targeted political ad?Help us find out how politicians are targeting you online.1. If you spot a small blue triangle icon on any online political ad, or the words "Ad Choices," take a screenshot of the ad.2. Then click on the blue triangle or the words "Ad Choices" to find out which company showed you the ad. Take a screenshot of that, too.3. Email the screenshots to us at targeting2012@propublica.org. Please include the full URL of the page where you saw the ad.If the ad asks you to "learn more," visit a website, donate, or sign a petition, please send us a screenshot of that site or petition, as well. (The page where the ad sends you may also be targeted to what advertisers know about you.)Not sure how to take a screenshot? Here are the instructions if you're using a PC, using a Mac, or using a smartphone.On 9th July 2012 the High Court of Justice of England and Wales ruled that Samsung Electronic (UK) Limited's Galaxy Tablet Computer, namely the Galaxy Tab 10.1, Tab 8.9 and Tab 7.7 do not infringe Apple's registered design No. 0000181607-0001. A copy of the full judgment of the High court is available on the following link www.bailii.org/ew/cases/EWHC/Patents/2012/1882.html.In the ruling, the judge made several important points comparing the designs of the Apple and Samsung products:"The extreme simplicity of the Apple design is striking. Overall it has undecorated flat surfaces with a plate of glass on the front all the way out to a very thin rim and a blank back. There is a crisp edge around the rim and a combination of curves, both at the corners and the sides. The design looks like an object the informed user would want to pick up and hold. It is an understated, smooth and simple product. It is a cool design.""The informed user's overall impression of each of the Samsung Galaxy Tablets is the following. From the front they belong to the family which includes the Apple design; but the Samsung products are very thin, almost insubstantial members of that family with unusual details on the back. They do not have the same understated and extreme simplicity which is possessed by the Apple design. They are not as cool."That Judgment has effect throughout the European Union and was upheld by the Court of Appeal on 18 October 2012. A copy of the Court of Appeal's judgment is available on the following link www.bailii.org/ew/cases/EWCA/Civ/2012/1339.html. There is no injunction in respect of the registered design in force anywhere in Europe.However, in a case tried in Germany regarding the same patent, the court found that Samsung engaged in unfair competition by copying the iPad design. A U.S. jury also found Samsung guilty of infringing on Apple's design and utility patents, awarding over one billion U.S. dollars in damages to Apple Inc. So while the U.K. court did not find Samsung guilty of infringement, other courts have recognized that in the course of creating its Galaxy tablet, Samsung willfully copied Apple's far more popular iPad.The land in West Oakland where Eric Maundu is trying to farm is covered with freeways, roads, light rail and parking lots so there's not much arable land and the soil is contaminated. So Maundu doesn't use soil. Instead he's growing plants using fish and circulating water.It's called aquaponics- a gardening system that combines hydroponics (water-based planting) and aquaculture (fish farming). It's been hailed as the future of farming: it uses less water (up to 90% less than traditional gardening), doesn't attract soil-based bugs and produces two types of produce (both plants and fish).Aquaponics has become popular in recent years among urban gardeners and DIY tinkerers, but Maundu- who is trained in industrial robotics- has taken the agricultural craft one step further and made his gardens smart. Using sensors (to detect water level, pH and temperature), microprocessors (mostly the open-source Arduino microcontroller), relay cards, clouds and social media networks (Twitter and Facebook), Maundu has programmed his gardens to tweet when there's a problem (e.g. not enough water) or when there's news (e.g. an over-abundance of food to share).Maundu himself ran from agriculture in his native Kenya- where he saw it as a struggle for land, water and resources. This changed when he realized he could farm without soil and with little water via aquaponics and that he could apply his robotics background to farming. Today he runs Kijani Grows ("Kijani" is Swahili for green), a small startup that designs and sells custom aquaponics systems for growing food and attempts to explore new frontiers of computer-controlled gardening. Maundu believes that by putting gardens online, especially in places like West Oakland (where his solar-powered gardens are totally off the grid), it's the only way to make sure that farming remains viable to the next generation of urban youth.More info on original story: http://faircompanies.com/videos/view/internet-food-arduino-based-urban-aquapo...TorrentFreak broke an unsurprising, but amazing, story this week in uncovering that Stroz Friedberg, the supposedly "independent and impartial tech expert" that was brought on to assist the Center for Copyright Information (CCI) in making sure that the new "six strikes" program BitTorrent monitoring is accurate, used to lobby for the RIAA. Apparently this bit of news took folks at CCI completely by surprise, since the RIAA failed to mention that tidbit of info. Now, CCI is apparently scrambling to make things right -- either by finding someone new, or by "opening up" the review that Stroz Friedberg does for the public to review. Either way, it's pretty incredible that the RIAA thought that no one would notice that the "impartial and independent" expert just happened to be a biased party that lobbied directly for them in the past.The land in West Oakland where Eric Maundu is trying to farm is covered with freeways, roads, light rail and parking lots so there's not much arable land and the soil is contaminated. So Maundu doesn't use soil. Instead he's growing plants using fish and circulating water.It's called aquaponics- a gardening system that combines hydroponics (water-based planting) and aquaculture (fish farming). It's been hailed as the future of farming: it uses less water (up to 90% less than traditional gardening), doesn't attract soil-based bugs and produces two types of produce (both plants and fish).Aquaponics has become popular in recent years among urban gardeners and DIY tinkerers, but Maundu- who is trained in industrial robotics- has taken the agricultural craft one step further and made his gardens smart. Using sensors (to detect water level, pH and temperature), microprocessors (mostly the open-source Arduino microcontroller), relay cards, clouds and social media networks (Twitter and Facebook), Maundu has programmed his gardens to tweet when there's a problem (e.g. not enough water) or when there's news (e.g. an over-abundance of food to share).Maundu himself ran from agriculture in his native Kenya- where he saw it as a struggle for land, water and resources. This changed when he realized he could farm without soil and with little water via aquaponics and that he could apply his robotics background to farming. Today he runs Kijani Grows ("Kijani" is Swahili for green), a small startup that designs and sells custom aquaponics systems for growing food and attempts to explore new frontiers of computer-controlled gardening. Maundu believes that by putting gardens online, especially in places like West Oakland (where his solar-powered gardens are totally off the grid), it's the only way to make sure that farming remains viable to the next generation of urban youth.More info on original story: http://faircompanies.com/videos/view/internet-food-arduino-based-urban-aquapo...The search and software giant says it has hit the new milestone for programs available for Android. By comparison, Microsoft has 120,000.Google has hit another milestone for Android apps, and this one is pretty big news for Apple too.The number of apps available for Android now totals about 700,000, a Google spokesman confirmed to CNET. That's up from the 675,000the company said it had a month ago.And it equals the figure Apple most recently touted. The Cupertino, Calif., company first revealed it had about 700,000 apps available in its store last month, and Apple reiterated that amount during the iPad Mini launch last week.The number of apps offered for an operating system is an important factor for driving user adoption. Apple had long led the rest of the market, but Google had been quickly catch up. By comparison, Microsoft said yesterday that it now has 120,000 apps for it Windows Phone OS. That's a pretty big figure for the company but it significantly lags Android and iOS.There may be an app for almost everything, but there still isnâ€™t one for controlling Mother Nature.Google this morning officially canceled the Android event that was scheduled to occur on Monday, October 29 in New York City due to Hurricane Sandy, which is expected to hit the city on Sunday evening.In an email sent to reporters signed up to attend the event first picked up by Marketing Landâ€™s Danny Sullivan, Google issued a terse explanation:â€œWe are canceling our Monday morning event in New York due to Hurricane Sandy. We will let you know our plans as soon as we know more.â€?Weâ€™ve reached out to Google PR for more detail on when the event may be rescheduled, and will be sure to update this with anything we hear.The Android event was expected to compete for press attention with Microsoftâ€™s Windows Phone 8 launch also planned for Monday October 29th. That event is still on, though, as itâ€™s taking place in sunny San Francisco.Over 170,000 people are part of the Sophos community on Facebook. Why not join us on Facebook to find out about the latest security threats. Don't show me this againHi fellow Twitter user! Follow our team of security experts on Twitter for the latest news about internet security threats. Don't show me this againDon't forget you can subscribe to the SophosLabs YouTube channel to find all our latest videos. Don't show me this againHi there! If you're new here, you might want to subscribe to our RSS feed for updates. Don't show me this againAlready using Google+? Find us on Google+ for the latest security news. Don't show me this againOn LinkedIn? Join the Naked Security discussion group and connect with your peers in the security industry. Don't show me this againSorry, something happened and we couldn't sign you up. Please come back later and try again.Congratulations, you've successfully signed up for our daily news! Check your inbox soon, we've sent you an email.Sorry, that email doesn't look right to us so we haven't added it to our list.Join thousands of others, and sign up for Naked Security's newsletterA little more than a month ago Apache went head to head with Microsoft over the choice of do not track (DNT) in Internet Explorer 10. Apache has now backed down and provides the code to ignore DNT as a commented option in its config files.On Friday Yahoo! decided it was time to take over the resistance to DNT by announcing it would now ignore Internet Explorer 10 users' choices to not be tracked on grounds that it believes its users' experience is "better when it is personalized."There are several problems with their argument.The crux of the matter is whether Internet Explorer 10 is requiring users to choose a tracking preference. Considering the options presented during installation, this should be obvious.Yahoo! and other organizations that depend upon advertising revenue need to find a balance between targeted ads and respect for user privacy. If I log into their services I expect personalized weather, sports, stock and targeted advertising.If I simply click a link that leads to a Yahoo! asset, they should respect my choice, do not track, and present ads that may not be tailored, but still support Yahoo's valuable services.Every day I receive non-targeted ads in my physical mailbox. Pizzas, manicures and concerts from the latest bands. Clearly this generates revenue and costs significantly more than delivering a banner ad.I am not a piece of meat to be sent to market. Respect my choices and adapt your business model. I am happy to buy products and happy to pay for the services I receive.Proof? Follow me on App.Net. If you care about your privacy, insist that companies honor your preferences and don't patronize those who don't.And to Yahoo!: If you want to talk big about privacy, put your money where your mouth is. I don't begrudge you your methods, but respect my choices. Microsoft fairly presents a choice and you need to honor it or become irrelevant.What theyâ€™re doing on Marsden Farm isnâ€™t organic. Itâ€™s not industrial, either. Itâ€™s a hybrid of the two, an alternative version of agriculture for the 21st century: smart, green and powerful.On this farm in Boone County, Iowa, in the heart of corn country, researchers have borrowed from both approaches, using traditional techniques and modern chemicals to get industrial yields â€” but without industrial consequences.If the approach works at commercial scales, and thereâ€™s good reason to think it will, it might just be an answer to modern farmingâ€™s considerable problems.â€œWe wanted to show that small amounts of synthetic inputs are very powerful tools, but theyâ€™re tools with which you tune the system, not drive it,â€? said Adam Davis, a researcher with the United States Department of Agriculture.The Marsden Farm experiment, which is described in a study published Oct. 10 in Public Library of Science One, started in 2003, when Davis was a graduate student under agronomist Matt Liebman of Iowa State University. Liebmanâ€™s specialty is integrated pest management, or strategies that use nature to accomplish whatâ€™s typically done with pesticides, herbicides and synthetic fertilizer.Itâ€™s not a new idea, but itâ€™s one thatâ€™s been generally neglected for the last several decades, as large-scale farming came to rely on simplified, chemically intensive and ultimately unsustainable approaches. For a while, these worked, but with high yields came big problems: the threat of catastrophic disease outbreaks in monocultures, an insatiable demand for nitrogen fertilizer, pesticide-resistant bugs and herbicide-resistant superweeds, and a new generation of crops designed to be drenched in toxic chemicals.â€œWe have two choices now,â€? said Liebman. â€œWe can double down, load more chemicals into the system, and get another decade of increasingly ineffective control â€” or we can choose the path towards integrated management.â€?Liebman, inspired in part by a pioneering Iowa farmer named Dick Thompson, wanted to bring integrated pest management back, but augmented with technologyâ€™s new tools. On 22 acres at Marsden Farm, his team planted three plots with different rotations of crops. The first followed a two-year rotation, alternating between corn and soybeans, as is customary in the region. It was managed the usual way, with lots of chemicals.For the second plot, the researchers rotated over three years between corn, soy and oats, with red clover planted in winter. The clover, which absorbs atmospheric nitrogen, was planted between crop rows and plowed under as soil-replenishing â€œgreen manureâ€? in spring. On another plot, instead of red clover the researchers planted a fourth-year crop of alfalfa, which can be used to feed livestock. The animalsâ€™ manure came back as fertilizer.On these fields, the researchers still used herbicides and pesticides, but not the usual way. Rather than spraying them routinely over large areas, Liebmanâ€™s team applied them only when necessary. â€œWe use low-dose products in the smallest quantities possible,â€? he said. â€œWeâ€™re not against their use. What weâ€™re arguing for is using them as carefully deployed tactical options.â€?Liebman called these applications â€œtherapeutic measures.â€? Therapy wasnâ€™t often needed. Having different crops with different life cycles made it harder for weeds to grow. What might flourish among corn and soy, for example, was disrupted by oats. When red clover and alfalfa were mowed, weeds were chewed up before they flowered. As for insect problems, low pesticide use, along with habitat provided by cover crops, allowed pest-eating bugs and birds to flourish.After eight years, Liebman and Davis used eight times less herbicide in the three- and four-year rotations than in the conventional plot, they report in the new study. Ecotoxicity in surrounding water was two orders of magnitude lower. Thanks to clover and alfalfa, the experimental plots also used 86 percent less synthetic fertilizer.Most important of all, the experimental plots were as productive as the conventional. They produced just as much total crop biomass. When the researchers calculated the value of their environmentally friendly harvest, it was every bit as profitable.â€œWe exceeded those goals â€” not by pumping chemicals in, but by maximizing ecosystem services,â€? Davis said. â€œWeâ€™re not throwing away those tools. Theyâ€™re very important. But you use a strong cropping system as the foundation for your agriculture. Then, when you need it, you tweak it a little bit with the inputs.â€?Liebman and Davis said the system can be scaled up and applied to other crops. While the new studyâ€™s details were local, the essential underlying principle, of building a crop system around the ecological services it provides, is universal.â€œThis is a great study,â€? said John Reganold, a soil scientist at Washington State University who was not involved in the research. â€œWeâ€™ve been pushing the envelope on yields, and not paying as much attention to the environmental and social and economic consequences. This shows that these integrated systems can be profitable, produce high yields, and offer more environmental benefit.â€?In a paper published last year in Science, Reganold called for a transformation of U.S. agriculture along the lines seen at Marsden Farm. â€œTheyâ€™re almost like a blend of conventional and organic, using the best of both worlds,â€? he said. â€œItâ€™s these kinds of systems we need.â€?â€œTheir ideas point to the way that agriculture has to be in the future,â€? said agronomist Nicholas Jordan of the University of Minnesota. â€œThereâ€™s wide consensus that we have to figure out this fusion of â€˜organicâ€™ and â€˜industrial.â€™ Theyâ€™ve illustrated what that fusion looks like. Itâ€™s power and efficiency.â€?Jordan stressed that the Marsden Farm data was sound: No fudged numbers, no apples-and-oranges comparisons or subtle statistical slip-ups. Asked if the methods could scale commercially, Jordan said â€œthe answer is a resounding yes.â€?His enthusiasm was, however, tempered with caveats about challenges. Integrated pest management is much more complicated than industrial farming, requiring more day-to-day decisions and local knowledge. â€œWeâ€™ve become very, very used to a system thatâ€™s straightforward,â€? said crop scientist GermÃ¡n Bollero of the University of Illinois. â€œImplementing this at a large scale is not going to be easy.â€?Integrated pest management also requires more work. In the new study, the conventional method demanded one-third less labor than Liebman and Davisâ€™s fusion. â€œIt takes an energetic farmer, someone whoâ€™s investing a lot more of their own time, or potentially hiring added labor,â€? said agricultural economist Greg Graff of Colorado State University.These challenges should not be insurmountable. Locale-specific research will help with complexity. As for the additional labor, money that would have gone to chemicals can be used to hire workers. â€œI would argue that needing more labor in these systems means more jobs,â€? Reganold said. â€œIt will be good for the well-being of rural communities.â€?There are other advantages to the Marsden Farm method. As corn and soy production intensified in the midwest, field farmers often stopped raising livestock. These are now grown in concentrated animal feeding operations, which both incubate new disease and generate immense amounts of waste. If livestock again became part of local farming, as was required to consume the Marsden Farmâ€™s alfalfa, that waste would be fertilizer.Diverse, year-round crop rotations are also more resilient to climate stress. Weather patterns in the the midwestern United States are becoming more extreme, veering between the catastrophic floods of 2008 and 2010 and this summerâ€™s epic drought. Complex root systems prevent soil from washing away during spring rains, and store extra water against dry spells.â€œThese more diversified systems, the three- and four-year systems in the study, are less vulnerable to resource scarcities, climate change and market volatility,â€? said Reganold. â€œThese systems use less fertilizer and pesticides than the typical conventional system. Yes, this is environmentally beneficial, but it also has economic benefits because the price of fertilizers and pesticides will likely increase in the future.â€?If transforming agriculture seems an imposing task, Liebman said it can start small, with something as simple as weaving conservation strips into fields. It also doesnâ€™t need to happen immediately, in one radical step.â€œThe concept could be introduced by encouraging farmers to continue farming in the traditional way, but little by little introduce diversity. There could be tax benefit or subsidy for introducing things like cover crops,â€? Bollero said. â€œIf those signals are there, youâ€™ll see a lot of farmers adopting this.â€?Graff noted that farm subsidies currently favor intensive soy and corn production, and that industry lobbying groups have actively resisted subsidy reform that rewards other types of crop production. Ultimately, however, this is an issue that citizens can decide.â€œA very large amount of taxpayer money is channeled through the federal government into the farming sector. In Iowa, itâ€™s something like $1 billion of your money,â€? Liebman said. â€œIf you can get cleaner water, less exposure to pesticide, and more wildlife habitat, if farmers can maintain their revenue streams and work in a healthier world â€” why wouldnâ€™t you do that?â€?NEW YORK (CNNMoney) -- It's gadget season, and Google wants in on all the fun that Microsoft and Apple have been having.Google (GOOG, Fortune 500) unveiled a new "Nexus" phone, tablet and Android operating system on Monday. Its goal is wrest back some of the attention that Windows 8, Surface, the iPad, iPad miniand iPhone 5 have gotten over the past several weeks.The Nexus 4 is the fourth annual "Google phone," designed by the search giant and manufactured by one of its Android partners -- this time, LG. Google didn't say much about the device, other than that it has the latest quad-core mobile processor (that's fast), and a 4.7-inch screen (really big).Google's Nexus phones have never sold particularly well, but this time around Google is trying something bold. For $299, customers can buy a Nexus 4 without a two-year contract. That's quite cheap for an "unlocked" high-end smartphone. An unlocked iPhone 5, by comparison, costs $650.The base model Nexus 4 comes with 8 gigabytes of storage, half the typical amount for a smartphone. A 16 GB phone is available for $349. Both will go on sale on Nov. 13 online at the Google Play store. T-Mobile customers can also get a 16 GB version with a two-year contract for $199.The Nexus also works on AT&T (T, Fortune 500), which uses a similar network technology, but it isn't compatible with Verizon's network or Sprint's, according to a Google spokesman.The search leader also announced a new 10-inch tablet, dubbed the Nexus 10. With 300 pixels per inch, the Samsung device has the highest-resolution screen for any tablet, Google claims, including the iPad with Apple's Retina display. Apple (AAPL, Fortune 500) says the iPad sports a 264-pixels-per-inch screen.The Nexus 10 allows for multiple user accounts, so that a family can share the device and keep separate apps and settings for each user. It also has stereo speakers and a standard tablet battery that lasts for nine hours.The price tag is competitive: The 16 GB version will go on sale on the Google Play store Nov. 13 for $399, and a 32 GB version will be available for $499. Comparable iPads are each $100 more expensive.Google also unveiled an update to its Nexus 7 tablet, which the company unveiled in June. A new 32 GB version of the seven-inch Asus device is now available with AT&T's 3G-HSPA+ service -- which AT&T brands as "4G" -- for $299."We think today's devices offer the very best that money can buy," Android chief Andy Rubin said in a blog post.The Android software that runs Google's devices also got a minor update on Monday. New features include Photo Sphere, a 360-degree photo-taking app and wireless streaming support for Qualcomm's (QCOM, Fortune 500) Miracast wireless displays. It also offers a keyboard that doesn't require typing: "Gesture Typing" lets users glide their fingers over the letters they want to type.Google Now, an app that surfaces important information from e-mail, calendars and social networks, added support for flight information notifications, restaurant reservations, hotel confirmations and shipping details, in addition to nearby attractions like movies times at local theaters.A launch event had been planned in New York, but it was canceled due to Hurricane Sandy. Google announced the devices in a blog post instead.Microsoft (MSFT, Fortune 500) will be holding a Windows Phone 8 launch event in San Francisco on Monday.The European Union will spend approximately $900 million on a project to build the world's most intense, powerful laser beam in order to eviscerate nuclear waste and possibly provide new cancer treatments as well.TheÂ EXTREME LIGHT INFRASTRUCTURE project (ELI)Â involves nearly 40 research and academic institutions from 13 different states within the European Unioin.ELI's coordinator at its Romanian facility, Nicolae-Victor Zamfir, told Bloomberg that the lasers are "10 times more powerful than any yet built and will be strong enough to create subatomic particles in a vacuum, similar to conditions that may have followed the start of the universe."Â "Eventually," according to Zamfir, "the power of the light beams could be used to deteriorate the radioactivity of nuclear waste in just a few seconds and target cancerous tumors."The cancer treatment would be similar to a current experiential process known as hadron therapy.Â The therapy is particularlyÂ effective in targeting cancers located in areas "which are inaccessible to the surgeon's instruments or which are hard to treat by radiotherapy," like brain tumors, those in areas close to the spinal cord, or inside the eye.There will be four separate sites throughout Europe that make up the facility when it is completed: the one in Romania, another in Hungary, a third in the Czech Republic, and a fourth in a location that has yet to be named (but will be by the end of 2012).The laser is expected to become operational in 2017.See the most energetic laser beam ever created >MENLO PARK, Calif. â€” Many people cite Albert Einsteinâ€™s aphorism â€œEverything should be made as simple as possible, but no simpler.â€? Only a handful, however, have had the opportunity to discuss the concept with the physicist over breakfast.One of those is Peter G. Neumann, now an 80-year-old computer scientist at SRI International, a pioneering engineering research laboratory here.As an applied-mathematics student at Harvard, Dr. Neumann had a two-hour breakfast with Einstein on Nov. 8, 1952. What the young math student took away was a deeply held philosophy of design that has remained with him for six decades and has been his governing principle of computing and computer security.For many of those years, Dr. Neumann (pronounced NOY-man) has remained a voice in the wilderness, tirelessly pointing out that the computer industry has a penchant for repeating the mistakes of the past. He has long been one of the nationâ€™s leading specialists in computer security, and early on he predicted that the security flaws that have accompanied the pell-mell explosion of the computer and Internet industries would have disastrous consequences.â€œHis biggest contribution is to stress the â€˜systemsâ€™ nature of the security and reliability problems,â€? said Steven M. Bellovin, chief technology officer of the Federal Trade Commission. â€œThat is, trouble occurs not because of one failure, but because of the way many different pieces interact.â€?Dr. Bellovin said that it was Dr. Neumann who originally gave him the insight that â€œcomplex systems break in complex waysâ€? â€” that the increasing complexity of modern hardware and software has made it virtually impossible to identify the flaws and vulnerabilities in computer systems and ensure that they are secure and trustworthy.The consequence has come to pass in the form of an epidemic of computer malware and rising concerns about cyberwarfare as a threat to global security, voiced alarmingly this month by the defense secretary, Leon E. Panetta, who warned of a possible â€œcyber-Pearl Harborâ€? attack on the United States.It is remarkable, then, that years after most of his contemporaries have retired, Dr. Neumann is still at it and has seized the opportunity to start over and redesign computers and software from a â€œclean slate.â€?He is leading a team of researchers in an effort to completely rethink how to make computers and networks secure, in a five-year project financed by the Pentagonâ€™s Defense Advanced Research Projects Agency, or Darpa, with Robert N. Watson, a computer security researcher at Cambridge Universityâ€™s Computer Laboratory.â€œIâ€™ve been tilting at the same windmills for basically 40 years,â€? said Dr. Neumann recently during a lunchtime interview at a Chinese restaurant near his art-filled home in Palo Alto, Calif. â€œAnd I get the impression that most of the folks who are responsible donâ€™t want to hear about complexity. They are interested in quick and dirty solutions.â€?Dr. Neumann, who left Bell Labs and moved to California as a single father with three young children in 1970, has occupied the same office at SRI for four decades. Until the building was recently modified to make it earthquake-resistant, the office had attained notoriety for the towering stacks of computer science literature that filled every cranny. Legend has it that colleagues who visited the office after the 1989 earthquake were stunned to discover that while other offices were in disarray from the 7.1-magnitude quake, nothing in Dr. Neumannâ€™s office appeared to have been disturbed.A trim and agile man, with piercing eyes and a salt-and-pepper beard, Dr. Neumann has practiced tai chi for decades. But his passion, besides computer security, is music. He plays a variety of instruments, including bassoon, French horn, trombone and piano, and is active in a variety of musical groups. At computer security conferences it has become a tradition for Dr. Neumann to lead his colleagues in song, playing tunes from Gilbert and Sullivan and Tom Lehrer.Until recently, security was a backwater in the world of computing. Today it is a multibillion-dollar industry, though one of dubious competence, and safeguarding the nationâ€™s computerized critical infrastructure has taken on added urgency. President Obama cited it in the third debate of the presidential campaign, focusing on foreign policy, as something â€œwe need to be thinking aboutâ€? as part of the nationâ€™s military strategy.Dan joins the BGR team as the Android Editor, covering all things relating to GoogleÃ¢â‚¬â„¢s premiere operating system. When he isnÃ¢â‚¬â„¢t testing the latest devices or apps, he can be found enjoying the New York City nightlife.The iPad mini has been rumored for nearly as long as the original iPad has existed, but it wasn't clear early on how many of those rumors were based on fact and how many were based on hope. Hope, that was, for a smaller, more portable tablet that would bring access to all the Apple ecosystem had to offer, in a package you could easily hold in one hand. Specifically, a package more affordable than the 10-incher.That's this, the 7.9-inch, $329 iPad mini that sports a screen with the same resolution as the iPad 2 -- only smaller. As we put this one through its paces it quickly became clear that this is far more than a cheaper, smaller iPad. This is a thinner, lighter device that deserves independent consideration. In many ways, it's actually better than the 10-inch slate from which it was born. But is it better for you? Join us after the break as we find out.Apple wanted to be very clear at its product-packed iPad mini launch event that this isn't just a shrunken-down iPad. And, indeed, that starts with a very different case design. While the second, third and fourth generations of iPads have all been more or less indistinguishable, the iPad mini's anodized aluminum back looks entirely different. In fact, the whole thing looks a lot more like a blown-up fifth-generation iPod touch than a shrunken-down fourth-generation iPad.The profile itself is more rounded than the full-size iPad, lacking the sharp taper at the edges. This, we presume, gives a little more room for the battery inside, but it also makes this a more comfortable slate to carry around. The edges on the 10-inch iPad can cut into your hand if you're the sort who carries yours wherever you go. Not so with the mini.Of course, that's helped greatly by the decrease in weight here. The WiFi-only iPad mini weighs just 0.68 pounds (308 grams), which is less than half the weight of the fourth-generation iPad. It's far thinner, too, at 7.2mm (vs. 9.4) and measures 7.87 x 5.3 inches (200 x 135mm) on the other dimensions. Inside that plane is a 7.9-inch, 1,024 x 768 IPS LCD which has significantly smaller bezels than those found in other iPads. It's thanks to those bezels that a display this size can be housed in a slate this size, but still that 5.3-inch horizontal span may be a bit of a problem for some.To us, the joy of a 7-inch tablet is walking across the office or the airport, holding the slate in one hand while tapping away at it with the other. The Nexus 7, with its 16:9 aspect ratio, is relatively narrow and easy to carry securely one-handed -- even by those whose mittens are size S. With the iPad mini, holding the slate in the same way can be a bit of a reach. This editor, who wears XL gloves, had no problem palming the littler iPad, but when we handed it to other, dainty-fingered people they sometimes struggled to hold it securely.The scrawny bezels on either side actually exacerbate this issue to some degree, as those who must loop a thumb around the front of the device when holding it are forced to put that thumb right on the display. Thankfully, every app we tried handled this situation without issue, Kindle and iBooks turning pages and acting normally even with that stray opposable member making square contact on the digitizer.Overall, the tablet is very comfortable to hold; its thinness and lightness are both attributes that must be perceived first-hand. That 7.2mm depth is exactly the same as the fourth-generation iPod touch, which even today is an impressively svelte device. We reviewed the black model, which features a dark bezel and anodized back to match. It's cool and matte to the touch, which we find very appealing, but time will tell just how durable this black version will prove. Those who are scratch-averse may want to think about the white and silver variety, which will likely hide those markings a bit better.The layout of the buttons is familiar, but different. The volume rocker and orientation lock switches are on the upper portion of the right side, but here up and down are distinct buttons, not like the integrated rocker on the full-size iPad. It's also not like the three-way rocker found on the latest iPod nano, which features an integrated play/pause button. That's a bit unfortunate, as we'd like to see that find its way across the product line, but perhaps it will in future revisions. (Yes, we're expecting more.)The power button is up top, looking and feeling very much like those on older iPads. There's a small slit for a microphone up there as well, and on the other side, the 3.5mm headphone jack, which bucks the trend of bottom-placement found on nearly every other Apple mobile device. On the left side of the device nothing, and on the bottom is where the Lightning connector lives. Like the iPhone 5, that connector is flanked by two sets of two rows of holes, drilled to let the device's sound out. It's reasonably loud and, since it's on the bottom not the back, the sound is closer to traveling in the right direction to meet your ears, but it's still a less than ideal listening experience. You'll want a set of headphones -- which, as with other iPads, are not included.The only other button is on the front, a smaller version of the same Home button found on the iPad. Curiously, it's even smaller than the button on the iPhone, making it very petite indeed. Around back, there's just one detail to concern yourself with: the lens assembly for the 5-megapixel iSight camera stuffed in the upper-left. That's paired with a 1.2-megapixel FaceTime HD center-cut in the bezel atop the LCD.No, this isn't Retina, but maintaining the same resolution as a 10-inch display shrunken down to 7.9 means a necessary boost in pixel density: 163ppi. That's a nice increase over the iPad 2's 132ppi, but it still falls short of the 264ppi of the fourth-generation iPad -- not to mention, the iPhone 5's 326dpi. Naturally, this means that text isn't anywhere near as sharp as on the newer iPads, but this is still a very nice-looking display.In fact we found the brightness and color reproduction to be improved over the iPad 2, comparable to the latest Retina displays. Colors are very pleasing to the eye and viewing angles, as ever with an Apple display, do not disappoint. You can line up as many friends as you like and sit them shoulder-to-shoulder, they'll all have a bright, clear picture. Yes, mini owners may have to make do with some resolution envy, but they at least won't be lacking in any other regard.The iPad mini is running a dual-core 1GHz CPU with 512MB of RAM, same as in the iPad 2 and as such it throws down the same benchmark scores and overall performance figures. Geekbench averages out at 751 and GLBench shows 24fps on the 2.5 Egypt HD benchmark. The SunSpider JavaScript benchmark completes in 1,426ms.These numbers pale in comparison to the new, fourth-gen iPad but we think that in day-to-day usage the relative lack of performance won't be as noticeable. Apps do load more slowly but most are still up and running within a second or two and when it comes to general web surfing tasks the iPad mini easily kept up with our taps and swipes. So, perhaps not the greatest performance in the Apple lineup, but there is one place where it bests the rest: battery life.In our standard battery run-down test, which entails looping a video with WiFi enabled and a fixed display brightness, the iPad mini managed an astounding 12 hours and 43 minutes. This gives it the longest battery life of any tablet we've ever tested, besting even the Samsung Galaxy Tab 7.7 by 42 minutes. Indeed during the course of our testing the battery on the iPad mini exceeded our expectations, expectations that were already high thanks to the consistently great battery life offered by the iPad family.The iPad 2 never saw HDR nor the Panorama mode that wowed us so on the iPhone 5, and neither does the iPad mini. It does, however, have a better camera than the iPad 2, a 5-megapixel shooter with an f/2.4 lens, and a 1.2-megapixel Facetime HD camera up front. The one 'round back appears to be the same camera module used on the iPhone 4 and as such, it takes good quality images. No, they don't quite pop like the 8-megapixel shooter on the iPhone 5, nor does this tablet manage low-light shooting as well as Apple's latest round of CPUs, but in our opinion tablets should only be used to take pictures in a pinch, and as such the iPad mini does just fine.It also takes reasonably good video, shooting at 1080p like all the latest Apple devices. But again, the combination of a lower-res sensor and the lack of a newer image processing chip means image stabilization isn't nearly as good here as on the iPhone 5. So, you'll want to hold steady while shooting, but remember to do so in a place with enough ambient light; do that and you'll get yourself some quality footage.You can't tally up any iPad's chances in the market without comparing it against all the other iPads in the market, and so we'll start by comparing the mini to its siblings, of which there are two at present. First is the iPad 2, available only in 16GB sizes either WiFi-only or a 3G model, each priced $70 more than the same-sized mini. For that $70 more you get a bigger screen and lower-resolution cameras front and back. For us, this is a no-brainer. Get the mini. Unless you suffer from ailing eyesight and need a larger portal into the iOS world, the smaller device is far and away the better one.The choice between this and the new fourth-generation iPad is a bit more challenging. It's a considerably more expensive device, starting at $499, and of course a bigger and heavier one, too. Still, battery life on that guy is impressively good (over 11 hours) and the performance is stellar -- living up to and exceeding Apple's "2x faster" claims. Still, speed isn't everything and while we love that big, Retina display we're not entirely sure that we prefer it to the tiny, lightweight form factor of the mini. In fact, we found ourselves enjoying the portability of the mini so much that we'd probably give that one the nod, but this decision will almost certainly come down to personal preference. So, if you can, head to an Apple Store and try out both.Moving outside of the ecosystem, most people are comparing the iPad mini to the Nexus 7. To some degree that's a natural comparison, as this is Apple's cheapest tablet compared to Google's low-cost device. In practice, these are very different devices, starting with the cost: $199 for a 16GB Nexus 7 vs. $329 for the iPad. The designs are strikingly different, too, with the Nexus having a high-quality but somewhat discount feel versus the overwhelmingly high-end iPad mini. In no way does Apple's latest feel like a tablet that was made to a budget. It simply feels like an Apple device.And, of course, it gives access to Apple's ecosystem of hundreds of thousands of tablet-friendly apps -- plus all the media iTunes has to offer. We can't help you decide which ecosystem, Apple or Google's, is better-suited to your interests, but we do imagine that will be the deciding factor for most. When it comes down to hardware, it's almost no contest between the two, with the iPad mini clearly winning out -- except in one area. That's the display. The Nexus 7 has a higher-resolution panel that's also 16:9, making it better for movie watching. It's also narrower, and thus easier to hold in your hand.We'd also be remiss if we didn't at least mention the $199 Kindle Fire HD. Amazon's latest also offers a higher-resolution, IPS LCD and has the extra selling point of stereo speakers. It also has a strong suite of content, courtesy of Amazon's many partnerships, but overall we have a hard time comparing these two. Amazon's device is clearly a cut-rate slate designed to push as much digital buying power into the hands of consumers as possible, while Apple's is simply a legitimately nice tablet. It's a legitimately nice tablet that Apple certainly would love for you to fill with premium content downloaded through iTunes, but it never feels like a shopping portal. The Kindle does.Surely, the most popular accessory for the iPad mini will be the new Smart Cover that, despite being both smaller and of considerably simpler construction, still costs the same $39 as the bigger, 10-inch version. That's a little unfortunate, especially because we don't think this version works as well. There is one positive change: the smaller Smart Cover moves away from the aluminum hinge on the bigger version, a good thing because we've seen plenty of scratches caused by that metal-on-metal contact.It's still attached magnetically, but where the 10-inch model will immediately snap into the perfect placement every time, we found the mini cover just as eager to attach either too high or too low. It requires a little more precision. Hardly a deal-breaker (how often are you removing your Smart Cover?) but a bit of an annoyance.The other accessories, and there are plenty of them, all make use of the device's Lightning connector, many existing only to add a little more life to your various iPod docks and chargers. The stubby 30-pin to Lightning adapter is $29, the same cost as the two camera adapters: one USB and one SD. (This is a change from the 30-pin Camera Connection Kit, which included both for $29.) The Lightning to 30-pin adapter (which includes a 0.2 meter cable in the middle) costs $39 and, finally, both the VGA and digital AV adapters are $49. Like the previous Digital AV adapter (which was $39), this one includes HDMI output and has an input so that you can still charge the tablet while it's in use. Handy for those digital signage applications -- or getting in one final, epic Lord of the Rings marathon before December.This isn't just an Apple tablet made to a budget. This isn't just a shrunken-down iPad. This is, in many ways, Apple's best tablet yet, an incredibly thin, remarkably light, obviously well-constructed device that offers phenomenal battery life. No, the performance doesn't match Apple's latest and yes, that display is a little lacking in resolution, but nothing else here will leave you wanting. At $329, this has a lot to offer over even Apple's more expensive tablets.Those comparing this to the Kindle Fire HD will have a hard time, as that's a tablet manufactured to a fixed cost and designed to sell you content. This is very much more. Similarly, the hardware here -- the materials, the lightness, the build quality, the overall package as it sits in your hand -- is much nicer than the Nexus 7 and it offers access to the comprehensively more tablet-friendly App Store, but whether that's worth the extra cost depends entirely on the size of your budget -- and your proclivity toward Android.Regardless, the iPad mini is well worth considering for anybody currently in the market for a tablet. Its cost is compelling, its design superb and it of course gives access to the best selection of tablet-optimized apps on the market. To consider it just a cheap, tiny iPad is a disservice. This is, simply, a great tablet.Update: This review originally stated (as does Apple's spec page) that the iPad mini has a mono speaker. It is, in fact, a stereo device.[Last photo by Will Lipman]When you buy a USB charger, how do you know if you're getting a safe, high-quality charger for your money? You can't tell from the outside if a charger provides silky-smooth power or if it is a dangerous charger that emits noisy power that cause touchscreen malfunctions[1] and could self-destruct. In this article, I carefully measure the performance of a dozen different chargers, rate their performance in multiple categories, and determine the winners and losers.Inside a chargerThese chargers cram a lot of complex circuitry into a small package, as you can see from the iPhone charger below. (See my iPhone charger teardown for more details.) The small size makes it challenging to make an efficient, high-quality charger, while the commoditization of chargers and the demand for low prices pressure manufacturers to make the circuit as simple as possible and exclude expensive components, even if the power quality is worse. The result is a wide variation in the quality of the chargers, most of which is invisible to the user, who may believe "a charger is a charger".Internally a charger is an amazingly compact switching power supply that efficiently converts line AC into 5 volt DC output. The input AC is first converted to high-voltage DC. The DC is chopped up tens of thousands of times a second and fed into a tiny flyback transformer. The output of the transformer is converted to low-voltage DC, filtered, and provided as the 5 volt output through the USB port. A feedback mechanism regulates the chopping frequency to keep the output voltage stable. Name-brand chargers use a specialized control IC to run the charger, while cheap chargers cut corners by replacing the IC with a cheap, low-quality feedback circuit.[4]A poor design can suffer several problems. If the output voltage is not filtered well, there will be noise and spikes due to the high-frequency switching. At extreme levels this could damage your phone, but the most common symptom is the touchscreen doesn't work while the charger is plugged in.[1] A second problem is the output voltage can be affected by the AC input, causing 120 Hz "ripple".[5] Third, the charger is supposed to provide a constant voltage. A poor design can cause the voltage to sag as the load increases. Your phone will take longer to charge if the charger doesn't provide enough power. Finally, USB chargers are not all interchangeable; the wrong type of charger may not work with your device.[6]CounterfeitsCounterfeit chargers pose a safety hazard as well as a hazard to your phone. You can buy a charger that looks just like an Apple charger for about $2, but the charger is nothing like an Apple charger internally. The power is extremely bad quality (as I will show below). But more importantly, these chargers ignore safety standards. Since chargers have hundreds of volts internally, there's a big risk if a charger doesn't have proper insulation. You're putting your phone, and more importantly yourself, at risk if you use one of these chargers. I did a teardown of a counterfeit charger, which shows the differences in detail.I've taken apart several counterfeit chargers and readers have sent me photos of others. Surprisingly, the counterfeit chargers I've examined all use different circuitry internally. If you get a counterfeit, it could be worse or better than what I've seen.How do you tell if a charger is counterfeit? The fakes are very similar; it's hard for me to tell, even after studying many chargers. There's a video on how to distinguish real and fake chargers through subtle differences. You can also weigh the charger (if you have an accurate scale), and compare with the weights I give above. The easiest way to get a genuine Apple charger is fork over $29 to an Apple store. If you buy a $2 "Original Genuine Apple" charger on eBay shipped from China, I can guarantee it's counterfeit. On the other hand, I've succeeded in buying genuine used chargers from US resellers for a moderate price on eBay, but you're taking a chance.The following picture shows a counterfeit charger that burned up. The safety issues with counterfeits are not just theoretical; when hundreds of volts short out, the results can be spectacular.A device being charged can detect what type of charger is being used through specific voltages on the USB data pins.[6] Because of this, some devices only work with their own special chargers. For instance, an "incorrect" charger may be rejected by an iPhone 3GS or later with the message "Charging is not supported with this accessory".[7]There are many different charger types, but only a few are used in the chargers I examined. A USB charger that follows the standard is known as a "dedicated USB charger". However, some manufacturers (such as Apple, Sony, and HP) don't follow the USB standard but implement their own proprietary charger types. Apple has separate charger types for 1 amp (iPhone) and 2 amp (iPad) chargers. HP has a special type for the HP TouchPad.The point is that USB chargers are not interchangeable, and devices may not work if the charger type doesn't match what the device expects. The table below shows the type of charger, the current that the label claims the charger provides, the current it actually provides, and the charger type it indicates to the device.The types of the counterfeit chargers are a mess, as they advertise one power level, actually supply a different power level, and have the charger type for a third level. For example, the counterfeit iPhone charger is advertised as supplying 1 amp, but has the 2A charger type, so an iPad will expect 2 amps but not obtain enough power. On the other hand, the counterfeit iPad charger claims to supply 2 amps, but really only supplies 1 amp and has a 1A type.People often wonder how much power their charger is wasting while it's idle, and if they should unplug their charger when not in use. I measured this "vampire" power usage and found the chargers varied by more than a factor of 20 in their idle power usage. The Samsung oblong charger came in best, using just 19 mW; this was so low compared to the other chargers that I measured it again a different way to make sure I hadn't made an error. On the other extreme, the fake iPhone charger used 375 mW. The Apple iPhone charger performed surprisingly badly at 195 mW. If plugged in for a year, this would cost you about 21 cents in electricity, so it's probably not worth worrying about.[8] In the following table, I use the official charger Star Rating System (yes, there actually is such a thing).[9][10]I also measured efficiency of the chargers under load.[11] One of the benefits of switching power supplies over simpler linear supplies is they are much more efficient at converting the input power to output. The chargers I measured all did pretty well, with 63% to 80% efficiency. The HP charger was the winner here.I'm proud to announce an upcoming private beta of sex.ly! sex.ly is a new web and mobile app aimed at bringing Social to Sex. It's based around the idea that sexual intercourse itself should be more social, more open, and more fun.To that end, sex.ly will feature the following:â€” Check-in to sexual encounters. You'll now never forget a night. Describe positions, durations, sounds.â€” If (and only if) your partner(s) agrees, you can rate and review them. If they don't, you still can review them as anonymous partners.â€” Give a heads-up (pun intended) warning to other potential mates. Make sure dysfunction is kept out of your life.â€” Earn sex-cred for number of check-ins, which can be used at sex stores and other selected merchants.â€” Geo-tag sexual encounters! Support for in-airplane geo-tags is coming soon.sex.ly is of course not real. And yet, each day, I become more and more convinced that we really are not that far from it.You were repulsed by the above description of this imaginary site. But not because of some prudish reasons, not even because it had to do with sex. No. You were repulsed because sex.ly violates something very deep and fundamental about humanity. But what, in particular?I doubt that it's some old-fashioned 'don't kiss and tell' shit. After all, we have plenty of sex writers in the world, all describing their sex lives in detail, and we don't hate that. Nor do I think it is even the egoism of the whole thing.No. What is truly horrifying about sex.ly is that it so utterly and absolutely cheapens the experience of something very important. It bundles it all up into some packaged product of check-ins and ratings and de-humanizing rankings. It turns us into commercial broadcasters of the meaningful parts of our lives.And yet one can almost already hear it: "It's not really sex until it's on sex.ly."Now my description of sex.ly is obviously an intuition pump. I want you to hate it â€” because, with only slight exaggeration, this is how I feel about almost all life-casting.We have begun to pollute and desecrate and cheapen all of our experiences. We are creating neat little life-boxes for everything, all tied up with a geo-tag, a photo, a check-in; our daily existence transformed into database entries in some NoSQL database on some spinning disk in some rack in suburban Virginia.The end-game is this. Slowly, gradually, without realizing: we stop participating in our own lives. We become spectators, checking off life achievements for reasons we do not know. At some point, everything we do is done soley to broadcast these things to casual friends, stalkers, and sycophants.Philip Larkin, writing about the destruction of the English countryside, once said that most things are never meant. That may be true here too. Maybe things won't get so bad.But as I watch us fall further and further into packaged lives, I can't escape hearing Larkin's conclusion to that poem: I just think it will happen, soon.New York - The Electronic Frontier Foundation (EFF) urged a federal appeals court Friday not to shut down Aereo, a startup that lets customers send local broadcast television to Internet-connected devices, arguing that consumers have the right to watch free broadcast TV with the technology of their choice.Broadcasters and TV networks â€“ including ABC, Fox, Univision, Disney, CBS, NBC, and PBS â€“ sued Aereo for copyright infringement in March, claiming that Aereo should be paying them license fees. The trial court declined to shut Aereo down during the lawsuit, and the broadcasters appealed. Now, the appeals court will decide whether Aereo can stay open while the case goes forward. EFF, along with Public Knowledge and the Consumer Electronics Association (CEA), filed a friend of the court brief Friday, asking the appeals court to reject the networks' bogus copyright claims and protect the rights of consumers."Just because Aereo's system sends TV signals to customers doesn't mean that Aereo needs permission from the broadcasters," said EFF Staff Attorney Mitch Stoltz. "Personal TV transmissions don't violate copyright â€“ it's a private use that copyright law doesn't reach. This is just a craven attempt by TV executives to profit from technology that they didn't think of first."Aereo's system works with thousands of dime-sized antennas installed on a Brooklyn rooftop. Each customer is assigned a single antenna that he or she can control, and the signal from that antenna travels over the Internet to the customer's devices. Aereo has explained in court that it simply takes the place of "rabbit ears" or a rooftop antenna, but the networks argued that Aereo should be treated like a cable system that must get permission from and pay fees to broadcasters.In deciding not to shut Aereo down pending trial, Judge Alison Nathan of the Southern District of New York said that Aereo's system was similar to another technology that survived a court challenge: Cablevision's "remote DVR" system, which in 2008 was found not to infringe copyright law. Like Aereo, Cablevision took equipment that customers traditionally put in their homes â€“ in that case, digital video recorders â€“ and moved them to the company's offices. Judge Nathan ruled that the appeals court's decision in the Cablevision case also applied to Aereo."Broadcasters have exclusive use of a scarce public resource â€“ the airwaves â€“ and that privilege carries with it a responsibility to serve the public. Obviously, the public benefits by having alternative ways to enjoy TV content," said EFF Intellectual Property Director Corynne McSherry. "Judge Nathan reached the right result and we hope the appeals court does too."EFF co-wrote its brief with John Bergmayer and Sherwin Siy of Public Knowledge.We've written before about Google's investments in a wide range of green energy companies, including wind, solar, and geothermal plants. At this week's annual shareholder's meeting, CEO Larry Page announced a new R&D team charged with capitalizing on those investments and Google's own cleantech intellectual property. These moves suggest the search and software giant is ramping up its efforts to develop its own clean technology in conjunction with its partners to bring that energy to market at efficiency and scale.Google's energy investments have always been complicated, spread between philanthropy and business, trying to be responsible to both shareholders and the planet. On one hand, Google wants to take the long view, identifying genuinely transformative possibilities in energy generation and transmission and securing its own high-energy-needs future. On the other hand, the company is looking for places where it can make an immediate technological impact and generate a solid return on its investment."We spend most of our time on search and advertising," Page said, but "to people outside the company, what's more interesting is 'what is the latest crazy thing that Google did?'""For us, those things are interesting, too, but it tends to be three people somewhere in the company," he noted. "We're not betting the farm on any of those things." In the case of renewable energy, Google's new hires seem to indicate it will be five people somewhere in the company, but their work is more serious than just engineers fiddling in a lab looking for "the latest crazy thing." In other words, it isn't like a driverless car that may or may not appear in the indefinite future, but a serious industry that Google's approaching with urgency.The ultimate goal is eminently practical: "RE < C," Google's long-established project to make renewable energy cheaper than coal. The urgency comes in the addendum to that formula: "Within a few years."To that end, Google has advertised five new positions in its Renewable Energy Engineering wing in Mountain View. One will be charged with managing Google's own energy usage to help keep the company cost-efficient and carbon-neutral. The other four spots are much more mechanical-engineering heavy than the typical Google hires. These are more interesting.The three-person renewable energy engineering team will be responsible for both evaluating and recommending investments for the company and in developing new technologies. There's a head of renewable energy engineering to lead the team, an engineer specializing in early-stage technology and prototyping, and a mechanical engineer who heads up design and manufacturing.The key phrase throughout the advertised positions is "utility-scale." The language of the mechanical engineer advertisement is especially revealing: "You will not be designing laboratory experiments; you will be designing useful systems that must deliver cost-effective results in the real world." This isn't pie-in-the-sky R&D. This is about products.I asked Google spokesperson Parag Chokshi if it would be fair to say that Google may soon be playing a more active role with its clean energy partners than just capital support. "We haven't changed our strategy," Chokshi said, while noting that Google doesn't typically comment on the specifics of its hiring strategy. "In fact, we have and continue to work closely with our partners... [both] the renewable energy projects in which we have invested, and with the co-investors who have joined us in investing in those projects."In April, Rick Needham, Google's Director of Green Business Operations and Strategy, toldFast Companythat Google's energy approach was both investment- and technology-driven: "We want to have an impact on the scale of the project, and an impact because of the technology being deployed." Large-scale projects are "the proof point of technology on a scale that allows those technologies to be financed and deployed at other locations."As new CEO, Larry Page is under pressure to deliver something big. Recently, Malcolm Gladwell argued (in his typically contrarian fashion) that the Internet "search solves problems that aren't really problems":Can we make a better Google or Bing? Yeah; sure we can. But it solves a problem that isn't really a problem. You cannot point to any area of intellectual activity or innovation that is today being compromised or hamstrung by their lack of access to search technology. Can we honestly go to some scientist to say that the reason you haven't cured cancer is because you don't have access to some information about cancer research? No!There isn't a problem that's any bigger or more real than generating renewable energy and bringing it to market. If Google can find big ways in just the next few years to solve only a part of that puzzle, turning Google's energy wing into a business remotely as robust as its search and software core, then Page will have delivered something big indeed.Go ahead, jailbreak your cellphone. But just know that tablet computer of yours is off limits.The U.S. Copyright Office published a document on Oct. 26, specifying that while jailbreaking a smartphone is deemed legal, the same rules do not apply to gaming consoles or tablets like Apple's iPad or the Microsoft Surface.According to CNET, the Copyright Office accepts requests every three years from "digital rights proponents and opponents" to alter laws under the Digital Millennium Copyright Act. This legislation was passed in 1998 and, fittingly, was put into effect in 2000. The American Library Associationdefines the act as a way for "U.S. copyright law to meet the demands of the Digital Age." In short, amendments to this act change the legality of practices like jailbreaking, or unlocking, your gadgets.The updated document (seen here) states the following:So which organizations wanted consumers to legally be allowed to jailbreak their devices? The legal papers show that the Electronic Frontier Foundation (EFF), New America Foundationâ€™s Open Technology Initiative, New Media Rights, Mozilla Corporation and the Free Software Foundation (FSF) were all proponents.The Copyright Office cites several reasons as to why cellphones can legally undergo the process of jailbreaking, while other devices are excluded from this freedom. Explanations are provided below:Still, how long will many of these laws be applicable? For example, the idea that smartphones are more widely adapted than tablets could be an outdated concept by 2015. Either way, the updated copyright laws will be implemented on Oct. 28, 2012 and remain in effect for three years.What are your thoughts on the Copyright Office's amendments? What makes sense and what seems completely ridiculous? Tell us your opinions in the comments section, or tweet us your response to this article at [@HuffPostTech]. Then read more about the latest anti-piracy rules (here), or flip through the slideshow below of the top nine countries downloading the most illegal music.Apple (AAPL) customers are famed for their loyalty, but it looks as though some of them may not be as fanatical as theyâ€™ve been in the past. New data from Strategy Analytics shows that 75% of iPhone owners in Western Europe said they would buy an Apple device for their next smartphone, versus 88% who said theyâ€™d buy an iPhone for their next device last year. iPhone user loyalty also dipped slightly in the United States, with 88% of iPhone owners saying theyâ€™d buy an Apple smartphone in the future, down from 93% last year. Paul Brown, the director at Strategy Analyticsâ€™ User Experience Practice, said that Appleâ€™s loyalty numbers may have taken a hit because of â€œnegative press prompted by a perceived lack of recent innovation.â€? Strategy Analyticsâ€™ press release is posted below.Boston, MA â€“ October 30, 2012 â€“ For the first time since the Apple iPhone was released in 2007, the number of iPhone owners who say they definitely will or probably will purchase their next phone from the same brand has declined.The recent Strategy Analytics Wireless Device Lab Report, iPhone Owner Loyalty Declines: Is Apple Losing its Innovation Edge?, found that only 75 percent of iPhone owners in Western Europe say they are likely to buy their next phone from Apple, down from 88 percent in 2011. US repeat purchase intentions have also seen a slight decline, down from 93 percent in 2011 to 88 percent in 2012.â€œThere is no doubt that Apple is continuing its success in retaining existing user base while attracting new customers,â€? commented Paul Brown, Director at Strategy Analyticsâ€™ User Experience Practice. â€œHowever, negative press prompted by a perceived lack of recent innovation by Apple has meant we are starting to see some growth in the number of previously highly loyal consumers who are now reconsidering whether or not they will purchase a new iPhone for their next device.â€?Taryn Tulay, Analyst at Strategy Analyticsâ€™ Wireless Device Lab added, â€œRespondents who say they probably will or definitely will not buy their next phone from Apple is low. However, it is the shift in the number of those who are unsure whether they will remain with the same brand for their next phone that Apple should be concerned about.â€?Microsoft CEO Steve Ballmer cites the strong debut as a selling point to convince developers to create more apps for the company's platforms, primarily Windows 8 and Windows Phone 8.REDMOND, Wash. -- Microsoft CEO Steve Ballmer said the company has sold 4 million copies of Windows 8 to consumers since the operating system debuted on Friday.Ballmer made the announcement today at the start of the Build conference, a show Microsoft is hosting on its campus for more than 2,000 developers. Microsoft is hoping to convince developers to create applications for its new operating system and the Windows Phone 8 operating system that debuted yesterday."In a sense, what these launches really do is the kick off the golden age of opportunity for you as developers," Ballmer said.Right now, the Windows Store, the application marketplace on Windows 8, has about 5,000 apps in stock for U.S. customers. ESPN said it will have an app for the store by the end of the year. Dropbox as well as enterprise software maker SAP are also working on apps that will be available soon. And Ballmer said that Twitter is working on a Windows 8 app that will be available "in the months ahead.""It will be the most important in terms of highlighting and showcasing some of these capabilities we're talking about today," Ballmer said.Toward the end of his speech, Ballmer became animated, raising his voice to exhort developers to build new applications for the various Microsoft platforms."Windows 8 is the best opportunity for software development today," Ballmer said. "Hundreds of millions of people are aching to use your apps, just dying to use your application."The centerpiece of Ballmer's pitch to developers: Microsoft's huge footprint. Ballmer said that there are currently 670 million PCs running Windows 7, all of which can be upgraded to Windows 8. What's more, analysts expect computer makers to sell 400 million PCs next year, most of which will run Windows."I think we're going to see a lot of growth and vitality and explosion in the PC market," Ballmer said. "This is a market in which you can do your best work, your most innovative work.... This is a market in which you can make money."Ballmer gave a demo of a variety of products running Windows 8, everything from an 82-inch touch screen monitor from Perceptive Pixel, a company Microsoft recently purchased, to Microsoft's new lightweight Surface tablet. He also showed Windows 8 running on Acer's new Aspire S7-191, a trim laptop with a touch-enabled screen."You say, 'Do people really want to us touch laptops?'" Ballmer said. "Touch laptops really are cool."Microsoft also released a new software development kit for Windows Phone 8, giving developers new tools to create application for the company's mobile phone platform. It's a business that's tiny, relative to rivals Google and Apple. But Microsoft believes that it will benefit from from the push behind Windows 8."The opportunity there is also excellent," Ballmer said.To spark more interest, developers were given a few freebies for attending the conference. Each one got a Microsoft Surface RT, 100 gigabytes of storage on Microsoft's SkyDrive Web service, and a Nokia Lumia 920 mobile phone.Updated at 10:50 a.m. PT with more details and analysis.Updated to clarify that ESPN's app will be available by the end of the year.On Monday, the US Supreme Court will hear arguments in a case that pits a major textbook publisher against Supap Kirtsaeng, a student-entrepreneur who built a small business importing and selling textbooks.Like many Supreme Court cases, though, there's more than meets the eye. It's not merely a question of whether the Thai-born Kirtsaeng will have to cough up his profits as a copyright infringer; the case is a long-awaited rematch between content companies seeking to knock out the "first sale" doctrine on goods made abroad (not to mention their many opponents). That makes Wiley v. Kirtsaeng the highest-stakes intellectual property case of the year, if not the decade. It's not an exaggeration to say the outcome could affect the very notion of property ownership in the United States. Since most consumer electronics are manufactured outside the US and include copyrighted software in it, a loss for Kirtsaeng would mean copyright owners could tax, or even shut down, resales of everything from books to DVDs to cellphones."First sale" is the rule that allows owners to resell, lend out, or give away copyrighted goods without interference. Along with fair use, it's the most important limitation on copyright. So Kirtsaeng's cause has drawn a wide array of allies to his side. These include the biggest online marketplaces like eBay, brick-and-mortar music and game retailers, and Goodwillâ€”all concerned they may lose their right to freely sell used goods. Even libraries are concerned their right to lend out books bought abroad could be inhibited.John Wiley and Sons, the textbook publisher suing Kirtsaeng, has its share of backers as well, including the movie and music industries, software companies, and other book publishers. Those companies argue differential pricing schemes are vital to their success, and should be enforced by US courts. Nearly 30 amicus briefs have been filed in all.Supporters of Kirtsaeng are mobilized, following an alarmingâ€”but not precedentialâ€”loss in an earlier case, Omega v. Costco. On a call with reporters this week, librarians and lawyers for pro-Kirtsaeng companies painted a stark picture of what might happen should he lose the case. If the appellate court ruling against Kirtsaeng is allowed to stand, they suggest copyright owners could start to chip away at the basic idea of "you bought it, you own it.""This case is an attempt by some brands and manufacturers to manipulate copyright law, to control the distribution and pricing of legitimate, authentic goods," said eBay's top policy lawyer, Hillary Brill. "When an American purchases an authentic item, he shouldn't have to ask permission from the manufacturer to do with it what he wants."Without "first sale" doctrine in place, content companies would be allowed to control use of their goods forever. They could withhold permission for resale and possibly even library lendingâ€”or they could allow it, but only for an extra fee. It would have the wild effect of actually encouraging copyrighted goods to be manufactured offshore, since that would lead to much further-reaching powers."When we purchase something, we assume it's ours," said Overstock.com general counsel Mark Griffin. "What is proposed by [the content companies] is that we change the fundamental notion of ownership rights."Book publishers and their content-industry allies say those concerns are overblown. No assault on libraries and garage sales is forthcoming, they argue. These organizations simply have a right to set different prices abroad, without being undermined in the US by importation they say is illegal.The road to the Kirtsaeng clash has been a long one. Ultimately, this confrontation has been brewing since the rise of Internet marketplaces like eBay and Amazon in the mid-1990s. It became easier to get price information about goods being sold overseas, and consumers could see that identical or good-enough products were often being offered for prices much lower than the products being hawked in the US. At the same time, the big shopping sites made it simple for anyone to become their own business, selling and shipping around the globe.The textbook market was an obvious place to look for arbitrage. Students have been complaining about the high cost of books for many years; they also became the first group to enthusiastically embrace life online, and naturally looked for ways to cut costs.Foreign-born students, exposed to the lower-priced textbooks on trips home, became some of the first to see the opportunity. The same textbooks they were using to study medicine, engineering, and mathematics in the US were being sold in their home countries for a fraction of the cost. Often a Chinese, Thai, or Indian edition of a textbook had a more cheaply bound cover, sometimes with the local lettering on the front, and perhaps cheaper paper. The internal contents, however, were often the exact same English words being read by their classmates buying high-priced US editions.By 2003, the secret was out. Students' Internet-age solution to the problem of costly textbooks hit the front page of the New York Times. For some students, it was as simple as logging on to Amazon's UK site to comparison-shop.Â  A biochemistry text was $146.15 on the American Amazon site, but sold on the UK site for a mere $63.48, plus $8.05 shipping, one student found. A math textbook cost $110 in the US, but sold for $41.76 plus shipping in Britain.Even cheaper prices were found in Asia on English textbooks. The local college bookstore at Purdue University began buying overseas after it had to start competing with student-resellersâ€”the Indian Association at Purdue bought hundreds of books on their own.Neither the students nor the bookstores quoted by the Times in 2003 thought they were doing anything illegal. It was thought to be settled law; in a 1998 Supreme Court case called Quality King, the high court found that copyright owners couldn't control the re-importation of goods. They were limited by the "first sale" doctrine, which meant the rights held in a particular copy of a work expired once it was sold or given away.Years passed, and copyright owners found a wrinkle in that ruling. The shampoo bottles in Quality King had been made in the US but then shipped abroad, and re-imported. In cases where goods were actually produced abroadâ€”as foreign textbooks generally wereâ€”copyright owners argued unauthorized importers were guilty of infringement. Because imported foreign textbooks were not "made legally under this title [the Copyright Act]," they weren't subject to first sale at all. Or so the thinking went.It seems like an audacious argument, but sure enough, student book-sellers were hit with copyright lawsuits. They fought back hardâ€”but, for the most part, they have lost.Supap Kirtsaeng lost first and lost hardest. He came to the US from Thailand in 1997 to study at Cornell University, and later went on to get a PhD in mathematics from the University of Southern California. From 2007 to 2008, he financed his educationâ€”and made extra money, doubtlessâ€”by importing textbooks from Thailand and selling them under his eBay handle, bluechristine99.The book publisher, John Wiley and Sons, didn't want to see those books in the USâ€”and it had said so. Each book was marked: "[A]uthorized for sale in Europe, Asia, Africa and the Middle East Only... The Publisher may recover damages including but not limited to lost profits and attorney's fees, in the event legal action is required."Kirtsaeng didn't abide by those warnings. He talked to some Thai friends; he consulted "Google Answers;" and he went ahead and sold books.The warning in the books was not an idle one. Wiley and Sons followed through on their threat and sued Kirtsaeng in 2008. Kirtsaeng's lawyer was unable to get the case thrown out on "first sale" grounds. By the end of 2009 Kirtsaeng was in court, justifying his importation business to a jury.Lawyers portrayed Kirtsaeng to the jury as a Thai "gray market" mogul who had gone far beyond financing his own college educationâ€”a portrayal that US publishers continue toÂ push. Working with friends and family who packaged and shipped his books, he made plenty of money selling extra books on eBay. Publishers' lawyers tallied up his receipts for the jury: $1.2 million in a few short years.The jury found Kirtsaeng guilty of infringing copyrights in eight books he had sold, and he was ordered to pay $600,000 in damagesâ€”$75,000 per book. He appealed, but a panel of judges ruled 2-1 in the publishers' favor.KirtsaengÂ returnedÂ to Thailand in 2010 after earning his doctorate from USC, but his court case continues.Microsoft has just announced that developers at its Build 2012 conference will receive 100GB of SkyDrive storage, and a free 32GB Surface RT. Speaking enthusiastically about the developer opportunity ahead, Microsoft CEO Steve Ballmer guaranteed developers in the crowd that "this will be the best opportunity software developers will see.""Hundreds of millions of people are just aching to use your applications," said Ballmer, before announcing the giveaway for Build attendees. The crowd was understandably excited, and Ballmer promised developers that Microsoft would do more marketing and "better marketing" for Windows 8.Update: Nokia's Richard Kerris joined Microsoft on stage at Build today and also announced a free Lumia 920 for attendees.Microsoft Windows 8 is shipped without the "Start" menu.We put the "Start" menu back in Windows 8. We accurately recreated the most used desktop feature billions of users depend on every day and packed it with additional functionality.Computerworld - Intel researchers are working on a 48-core processor for smartphones and tablets, but it could be five to 10 years before it hits the market."If we're going to have this technology in five to 10 years, we could finally do things that take way too much processing power today," said Patrick Moorhead, an analyst with Moor Insights and Strategy. "This could really open up our concept of what is a computer... The phone would be smart enough to not just be a computer but it could be my computer."Enric Herrero, a research scientist at Intel Labs in Barcelona, said the lab is working on finding new ways to use and manage many cores in mobile devices.Today, some small mobile devices use multi-core chips. However, those multi-cores might be dual- or quad-core CPUs working with a few GPUs. Having a 48-core chip in a small mobile device would open up a whole new world of possibilities.At this point, researchers are working to see how to best use so many cores for one device."Typically a processor with one core would do jobs one after another," Herrero told Computerworld. "With multiple cores, they can divide the work among them."He explained that with many cores, someone could, for instance, be encrypting an email while also working on other power-intensive apps at the same time. It could be done today, but the operations might drag because they'd have to share resources.Tanausu Ramirez, another Intel research scientist working on the 48-core chip, said that if someone was, for example, watching a high-definition video, a 48-core chip would be able to use different cores to decode different video frames at the same time, giving the user a more seamless video experience.Ramirez also said that instead of one core working at near top capacity and using a lot of energy, many cores could run in parallel on different projects and use less energy."The chip also can take the energy and split it up and distribute it between different applications," he added.Justin Rattner, Intel's CTO, told Computerworld that a 48-core chip for small mobile devices could hit the market "much sooner" than the researchers' 10-year prediction."I think the desire to move to more natural interfaces to make the interaction much more human-like is really going to drive the computational requirements," he said. "Having large numbers of cores to generate very high performance levels is the most energy efficient way to deliver those performance levels."Rattner said functions such as speech recognition and augmented reality will push the need for more computational power."If it's doing speech recognition or computer vision... that's very computational intensive," he added. "It's just not practical to just take sound and pictures and send it up to the cloud and expect that some server is going to perform those tasks. So a lot of that will be pushed out to the client devices."Rob Enderle, an analyst with the Enderle Group, said being able to have different device functions, as well as apps all running on their own cores would be a great advance.When you tweet with a location, Twitter stores that location. You can switch location on/off before each Tweet and always have the option to delete your location history. Learn moreWhile working on desktops or laptops, itâ€™s useful to have a second display handy. Another monitor can easily be plugged in, but why not use the screens you already have instead of going off and purchasing another one? With a little bit of effort, the iPad, iPhone, and iPod Touch can be turned into a second screen for your Mac or Windows computer. This can be used in two ways: using the iOS device as a true second display, or mirroring the content of your main display. In this post, youâ€™ll learn how to accomplish both.Air Display is actually two separate applications: one running in Windows or OS X, and an app running in iOS. First off, download and install the client on your computer. Next, youâ€™ll need to buy the iOS app for $9.99 on the App Store. Once both are running, connect both to the same WiFi network, and then follow the on-screen instructions to make sure they are talking to each other.Once theyâ€™re connected on OS X, you can configure them even further. Launch System Preferences, and select the Displays section. On the iOS device, youâ€™ll be able to configure your resolution. Specifically, devices with Retina displays can enable High Dots Per Inch (HiDPI) mode that draws windows as if the resolution was a quarter the size, but with the full detail that your screen allows. Sadly, the Windows version doesnâ€™t support the high resolution mode properly just yet, but the developer promises this will be added in a future update.On your main display in Mac OS X, you can now adjust where the second screen sits in relation to your main screen by switching to the â€œArrangementâ€? tab. In Windows, you need to open the system tray icon and select â€œDisplay Arrangement.â€? In OS X, this screen also displays a toggle called â€œMirror Displays.â€? This will turn your iOS device into a duplicate of your main screen. This is useful if youâ€™re trying to show someone a website or a photo, and you donâ€™t want to huddle in front of your computer. If you want to enable mirroring on Windows, simple click the system tray icon, and navigate to â€œOptions,â€? and click â€œEnable Mirror Mode.â€?If all youâ€™re looking for is display mirroring and control of your main screen on your iOS device, Virtual Network Computing (VNC) might be the best option for you. This is built right into Mac OS X, but Windows users will need something like TightVNC which is available for free. Not only will VNC mirror your screen, but it also allows you to control the computer remotely. Seeing whatâ€™s on your screen is nice, but being able to manipulate your computer when youâ€™re not at your desk is even better.To turn it on in OS X, go into System Preferences under the Sharing section, and check the Screen Sharing toggle. Whichever way you plan on enabling VNC on your computer, make note of your local IP or Bonjour address displayed by your software.Next, youâ€™re going to need a VNC client for your iOS device. Some clients are available for free like Mocha VNC Lite, but apps like iTeleport ($4.99) and Mocha VNC ($5.99) are more feature-rich. Once you have one installed, input your computerâ€™s IP or Bonjour address into the configuration, and youâ€™re good to go.These require a bit of effort to set up, but it certainly worth the hassle. Youâ€™ll be glad to have went jumped through these hoops when you need that display at your desk, or if you want to turn off that download without getting out of bed.PURDUE (US) â€” Objects created with 3D printing often fall apart or lose their shape, but new software anticipates weak spots and increases durability.â€œI have an entire zoo of broken 3D printed objects in my office,â€? says Bedrich Benes, an associate professor of computer graphics at Purdue University.The printed fabrications often fail at points of high stress.â€œYou can go online, create something using a 3D printer and pay $300, only to find that it isnâ€™t strong enough to survive shipping and arrives in more than one piece,â€? says Radomir Mech, senior research manager from Adobeâ€™s Advanced Technology Labs.The 3D printers create shapes layer-by-layer out of various materials, including metals and plastic polymers. Whereas industry has used 3D printing in rapid prototyping for about 15 years, recent innovations have made the technology practical for broader applications, he says.â€œNow 3D printing is everywhere,â€? Benes says. â€œImagine you are a hobbyist and you have a vintage train model. Parts are no longer being manufactured, but their specifications can be downloaded from the Internet and you can generate them using a 3D printer.â€?The recent rise in 3D printing popularity has been fueled by a boom in computer graphics and a dramatic reduction of the cost of 3D printers, Benes says.Researchers at Purdue University and Adobeâ€™s Advanced Technology Labs have jointly developed a program that automatically imparts strength to objects before they are printed.â€œIt runs a structural analysis, finds the problematic part and then automatically picks one of the three possible solutions,â€? Benes says.The researchers detailed their findings in a paper presented during the SIGGRAPH 2012 conference in August.Former Purdue doctoral student Ondrej Stava created the software application, which automatically strengthens objects either by increasing the thickness of key structural elements or by adding struts. The tool also uses a third option, reducing the stress on structural elements by hollowing out overweight elements.â€œWe not only make the objects structurally better, but we also make them much more inexpensive,â€? Mech says. â€œWe have demonstrated a weight and cost savings of 80 percent.â€?The new tool automatically identifies â€œgrip positionsâ€? where a person is likely to grasp the object. A â€œlightweight structural analysis solverâ€? analyzes the object using a mesh-based simulation. It requires less computing power than traditional finite-element modeling tools, which are used in high-precision work such as designing jet engine turbine blades.â€œThe 3D printing doesnâ€™t have to be so precise, so we developed our own structural analysis program that doesnâ€™t pay significant attention to really high precision,â€? Benes says.The paper was authored by Stava, now a computer scientist at Adobe, doctoral student Juraj Vanek; Benes; Mech; and Nathan Carr, a principal scientist at Adobeâ€™s Advanced Technology Labs.Future research may focus on better understanding how structural strength is influenced by the layered nature of 3D-printed objects. The researchers may also expand their algorithms to include printed models that have moving parts.It's a big storm, moving slowly. A gigantic span of ferocious swirl meets a front of chilly resistance. The effect of that collision is amplified by powerful tidal influence. Upheavals and surges swamp the landscape. Many people are displaced; countless others stay with the familiar.Also, in the real world, some nasty weather is happening. But I'm talking about the tech industry of the last five business days, which has aligned and concentrated its forces in a crystal-clear demonstration, if one were needed, that mobile is where the bets are placed and futures will be won and lost.Apple is at the eye of the storm, where its devoted legions expect it, but no longer as a pioneer. Defending its territory rather than breaking new ground, the post-Jobs company did something its late and fabled leader scorned, split hairs to justify it, engaged in implicit combat with four competitors, ticked off some of its best customers and was squeezed by inexorable pressure of a quickly evolving industry.As I noted a week ago, it has been a perfect storm of product announcements and earnings releases. The two are always entwined. Though we like to imagine that companies are solely dedicated to the happiness of consumers at the end of the chain, the drumbeat of quarterly reports is what drives most decisions around product timing and the release of feature sets.This umbilical connection was etched in bold relief last week when Apple announced a new mini-maxi-Mac product lineup just two days before its Q4 earnings call. The mysteries of one were explained by the other.Though the accumulated import of last week's events had a tectonic rumble, there was really only one surprise -- the launch of a fourth-generation iPad, an upgrade that left disciples slack-jawed, and not entirely euphoric. Christina Warren spoke on behalf of incensed iPad owners in a 1,500-word rampage that explored the thesaurus entry for "angry" and invited rugged push-back of the #firstworldproblem type. The disaffected have a point, which is that a seven-month dev cycle (between the third- and fourth-gen iPads) is shorter than usual for Apple, and therefore, arguably, deceptive to third-gen buyers.The argument loses steam when you splash cold water on your throbbing veins and remember that Apple is a down-to-business corporation like any other, its steely eyes focused on managing its public stakeholders. That can be hard to remember during the live event, which is about shiny new features and end-use scenarios.In the earnings call two days later, CEO Tim Cook and CFO Peter Oppenheimer laid out past and future performance metrics like snapshots in a mosaic. Sales of iPads missed projections; iPod sales likewise below expectation. Mac down. Revenue flat against guidance, but earnings-per-share down. Most important to analysts: gross profit margin just below expectation, and projected to dip further. In fact, gross margins have skidded the last two quarters, from 47 percent to 40 percent, and the fiscal Q1 projection (that's the current quarter) is 36 percent, which harks back to fiscal 2008. Against all of this is a backdrop of plunging AAPL stock.When margins slump, volume must make up the difference. In a voracious market of technology adopters, sales come from new and refreshed products. Hence, the mini and the fourth-gen iPad.The post-PC company more clearly entered the post-Jobs epoch as Apple repudiated its previous scorn for small tablets. The mini is not a 7-incher! Tim Cook wants us to be clear on that point. It is a 7.9-incher. That's 35 percent bigger than a 7-inch screen! Put down the Red Bull, Tim, we get the point. But Cook also weirdly and defensively compared the iPad mini to the iPad 2 ("...equal to or better than the iPad 2 in every way"), and a portion of the commentariat complained that the specs were weak, barely competitive with the Google Nexus.The $329 starting price isn't earning many compliments either. This is how Apple works the offense and defense in the same play. Defensively, the company was forced to plug its portfolio gap with an intermediate slate. Forbes divined from Amazon's earnings call (also last week) that the Kindle Fire, with its succulent price point, is eating into iPad's share. Impossible to know for sure, since Amazon doesn't break out Kindle sales.But we know as a corollary that Samsung whipped Apple in smartphone share and units shipped in calendar Q3 by two to one. (56M vs. 27M phones sold; 31 percent vs. 15 percent share.) In a barbed announcement, Samsung noted that its Galaxy S III experienced a sales spike immediately after the iPhone 5 release.Google is another share-stealing tormentor. Sadly, Google scheduled its New York event in conflict with the latest storm of the century, and tiptoed out of the city when the weather forecast firmed up. But the new products came out today anyway: a 10-inch Nexus, plus a memory upgrade and price reduction of the 7-inch tablet line. In Apple's perspective: more pressure. The $329 iPad mini will soon be fighting for holiday gift status with a $200, 16GB 7-inch Nexus.For its offensive game, Apple relies on the concept and reality of premium. "Premium" means different things to different people, and its specifications are always changing. Apple's bankable status as a premium merchant has relied on build quality (still current), brand reputation (ephemeral, but earned and lasting for now), screen display quality (soon to be bettered by a new Nexus), and a safe, curated, huge app ecosystem (hanging onto leadership there for the time being).More than any other quality, though, Apple has accrued premium credibility through innovation leadership. Its destiny as a business titan depends on whether the company has invention left in the gas tank. Without the innovation, Apple is in an assembly-line business of iterating its products, synchronizing release cycles with finance milestones, managing its pipeline and massaging margins. Naturally, any company must do all these things. But last week we didn't see freshness from Apple; we saw a company loading up the pipeline for an earnings assault in Q1 with a barrage of products. In the live event, Tim Cook bragged about "...a truly prolific year for innovation for Apple." Prolific is not breakthrough. Apple did not become the world's most valuable company by making screens thinner, tablets smaller or phones longer. It got there by persuading society to adopt new categories.The dark-horse innovator last week was Microsoft, an aging legacy ruler facing entropic decay in a changing world of unmoored devices. There were no surprises; Microsoft held back no secrets about the radically different Windows 8 and the new Surface tablet. Windows Phone 8 was announced earlier today as the smartphone leg of Microsoft's stool. The boldness and commitment of Redmond's bet is breathtaking; that is universally recognized. But it's uphill for Microsoft's under-developed ecosystem: according to an Associated Press poll, most people haven't even heard of Windows 8.So it's Apple vs. Microsoft on daring, Apple vs. Samsung on smartphone market share and patent conflicts, Apple vs. Google on specifications and price, Apple vs. Amazon on willingness to cut margin, Apple vs. its customers on betrayed expectations, Apple vs. itself on the insurmountable challenge of remaining a true innovator forever. Interesting times. Fortunately for manufacturers and consumers both, it's not a winner-take-all industry. Get out the pie cutters.Brad Hill is a former Vice President at AOL, and the former Director and General Manager of Weblogs, Inc.I had a great idea this morning. I figured Iâ€™d head to the Microsoft Store in Scottsdale around 10am, waltz in, buy a Microsoft Surface, and then be out in 10 minutes. I assumed the store would be empty. I mean, come on, this is a Microsoft tablet weâ€™re talking about, and who goes to the Microsoft Store anyway?I was completely wrong.Â Microsoftâ€™s new tablet, the Surface RT, may not do everything an iPad can, but itâ€™s drawing some pretty big lines to Microsoft retail stores across the country for its launch this morning.Once I got to the Microsoft Store I was shocked to see a line of about 125 people waiting to buy the Surface and was told itâ€™d be a two hour wait before I could get in. The story is the same at other Microsoft Stores across the country with people lining up to purchase Microsoftâ€™s hyped tablet thatâ€™s supposed to compete with the iPad.The line at the Seattle stores have been reported to be the largest, but many people in those lines are associated with Microsoft. Microsoft isnâ€™t used to dealing with long launch lines though. A lot of people on Twitter have complained that itâ€™s taking Microsoft retail employees an hour to to get 15 people or so through the line. Apple usually churns through about one hundred or so customers on launch day every hour.Whether clinging to the inside of a bell jar, or outstretched from floor to ceiling, San Francisco-based artist Dan Grayberâ€™s mechanisms have but one purpose: to stay upright. Combining pulleys, bike brake cables, counterweights, and steel framing, Dan writes,Many of my pieces are small, spring loaded, mechanical objects. They are intricately designed and fabricated to accomplish one of the most simple, yet most essential tasks that an autonomous object can. This task, this need, is that of holding itself up. In most cases, my pieces accomplish this by actively attaching themselves to specific architectural features and individual objects.Some of Danâ€™s mechanisms self-install on walls, creating holes like industrial tracks. Others cling to corners or specific architectural features. More artworks can be seen in Grayberâ€™s online portfolio.One year ago, EFF rang alarm bells about SOPA and PIPA â€” Internet censorship bills threatening online freedom and the very structure of the Internet. Not long after, our members and the Internet community stood up to misguided politicians and deep-pocketed lobbyists and won, sinking SOPA and PIPA forever. It was revolutionary.You have the power to shape this world, and EFF stands with you. For 22 years, donating members have enabled EFF to bring legal and technological expertise into crucial battles about online rights, from defending free speech online to challenging unconstitutional surveillance.Your participation makes a difference, and weâ€™re proud to be a member-supported organization. Please consider becoming an EFF member today â€” every donation, no matter the size, guarantees that we who value freedom online will always have a voice and a formidable advocate.Help protect the free and open Internet. Join or renew your membership with the Electronic Frontier Foundation today!The prospect of growing crops in vertical farms directly inside of cities has been on the collective wish-list of environmentalists, sustainable developers, and futurists for quite some time now. And now it looks like it's finally starting to happen. Land-strapped Singapore has opened its first vertical farm â€” an innovation that will increase the variety of foods it has available and decrease its dependance on foreign imports.And indeed, a major problem facing Singapore (and many other cities) today is land scarcity. Located at the tip of the Malay Peninsula, it is an island country that consists of a mere 710 square kilometers (271 square miles) â€” and most of it is developed and urbanized. Today, only 7% of Singapore's vegetables are grown locally. But by virtue of the new facility, it's looking to change the situation.Developed by Sky Greens Farms, the vertical farm consists of 120 aluminum towers that extend over 9 meters (30 feet) in height. In total, the vertical farm is able to produce vegetables at a rate of 0.5 tonnes per day. The company is hoping to attract investors so that it can devote another USD$21M dollars for upgrades. Ideally, they'd like to construct as many as 300 towers â€” enough to produce two tonnes of vegetables per day.Currently, the farm is able to grow three kinds of vegetables, and they can only be found at the local FairPrice Finest supermarkets, but at a price that's 10 to 20 cents more than vegetables from other sources. But according to Channel News Asia, customers are enthusiastic about the new products and the supermarkets are struggling to keep the vegetables in stock. Moreover, Sky Greens expects the price to drop as the farm ramps up supply.The FSF has fought for years against the threat of Digital Restrictions Management (DRM). Users should have the right to modify, share and learn from the software on their devices, and technical measures put in place in the name of DRM offer a substantial roadblock. It's even worse when those measures have the force of criminal law behind them, threatening people who simply want to change the software on their computers with jail time. The FSF wants to create a world in which there is no DRM. Until then, at the very least, users shouldn't have to worry about legal consequences for disabling these malfeatures on their own devices.The Digital Millennium Copyright Act (DMCA) of course circumvents the rights of users by making it illegal to modify your devices in ways that would give you actual access to them, or to share tools to help others do this. Congress did create one small carve-out from this belligerence; that once every three years the Library of Congress (via the Copyright Office), would consider making exceptions to this broad rule. In 2010, the Office recommended exempting the freeing of cellphones. They did not, however, make clear that this exemption extended to people who distributed tools for freeing these devices. In 2012, we had hoped to expand the exempted class of uses, and encouraged the Copyright Office to extend exemptions to tablets, gaming consoles, and computers running restricted boot. We were on the side of organizations like the EFF, and the Mozilla Foundation as well as hundreds of other individuals calling for the protection of those who simply want to be able to use their own devices in freedom.But we were not the only ones to send recommendations to the Copyright Office. Large corporations like Sony, and corporate-backed groups like "Joint Creators and Copyright Holders" also sent comments opposing these reasonable exemptions. And the Copyright Office fell for their FUD. The Copyright Office has announced that while freeing your phone in order to install your own software is still permitted, unlocking the phone in order to switch carriers will be phased out. And even that minimal remaining protection has not been extended to tablets. Offering the duplicitous explanation that they weren't sure what a tablet was, the office completely abdicated its responsibility to protect users' rights to run their own software on their devices, as well as their rights to works locked down on those tablets. They similarly rejected exemptions for users wanting to install their own operating system on game consoles, and even worse, failed to extend protection to users who want to install their own operating system on computers with restricted boot.This means no longer being able to switch your own cell phone carrier without permission. This means no modifying tablet operating systems without legal threat. It means that trying to install a different operating system on your game console could result in the FBI breaking down your door. It means that you cannot even be sure of your right to remove proprietary software from devices encumbered with restricted boot.The Copyright Office picked Sony over you. They had an opportunity to protect users, but instead chose to protect corporate interests. This is a terrible outcome for users everywhere, and just proves that we need wholesale elimination of the anti-circumvention laws.We need to band together. Here is what you can do to help:South Carolinaâ€™s Department of Revenueâ€™s computer system was hacked, resulting in the compromise of some 3.6 million Social Security numbers on top of nearly 400,000 credit and debit card numbers exposed. The actual breaches occurred in September and October.Adding insult to injury, none of the Social Security numbers were encrypted; nor were 16,000 credit card numbers. The South Carolina Division of Information Technology apparently informed the Department of Revenue of the breach Oct. 10, according to local news reports. Anyone who filed a tax return in South Carolina after 1998 is urged to call 866-578-5422.â€œThis is not a good day for South Carolina,â€? governor Nikki Haley told an Oct. 26 press conference, according to WACH Fox News Center, adding about the hacker responsible: â€œI want this person slammed against the wall.â€?On Oct. 26, Haley filed an executive order to beef up the stateâ€™s security. â€œI hereby direct all cabinet agencies to immediately designate an information technology officer,â€? it read, â€œto cooperate with the State Inspector General who is authorized to make recommendations to improve information security policies and procedures in state agencies.â€?The order also stipulates cooperation with national cyber-security sources such as the Sharing Analysis Center, collaboration with in-state agencies to identify vulnerable points in cyber-security systems, and improvement in the training of government employees in information security measures.In the meantime, the current breach is under intense investigation by state authorities. Various local news sources are reporting that the attack came from a â€œforeign country.â€?According to Census.gov, the population estimate for the state of South Carolina is a bit over 4.67 million souls, meaning that roughly three-quarters of its citizensâ€™ Social Security numbers are in the hands of hackers.â€œFrom the first moment we learned of this, our top priority has been to protect the taxpayers and the citizens of South Carolina, and every action weâ€™ve taken has been consistent with that priority,â€? South Carolina DOR director James Etter wrote in an Oct. 26 statement. â€œWe have an obligation to protect the personal information entrusted to us, and we are redoubling our efforts to meet that obligation.â€?To reduce online piracy, Google has implemented several changes to its search engine in recent years. Among other things, Google has blacklisted dozens of piracy related terms from appearing in its autocomplete and instant services. Megaupload is one of these search terms, and nine months after the last infringement took place the name of Kim Dotcomâ€™s file-hosting service is still being censored. This begs the question, what other terms are needlessly censored by Googleâ€™s blacklist?Since January 2011, Google has been filtering â€œpiracy-relatedâ€? terms from its â€˜Autocompleteâ€˜ and â€˜Instantâ€˜ services.Google users searching for terms like â€œtorrentâ€?, â€œBitTorrentâ€? and â€œMegauploadâ€? will notice that no suggestions and search results appear before they type the full word. While no search results are removed from Googleâ€™s index, there is sharp decrease in searches for these terms.What triggers a keyword to be included in the blacklist is not clear, but a Google spokesperson previously told TorrentFreak that they remove terms that are â€œclosely associated with infringing results.â€?â€œItâ€™s not easy and the list will undoubtedly change over time. When evaluating terms for inclusion, we examine several factors, including correlation between the term and results that have been subject to valid DMCA takedown notices,â€? Google told us.Sounds deliberate, and as weâ€™ve documented in the past the list has indeed been changed. Many new terms have been added since the start, most recently to include several of The Pirate Bayâ€™s domain names.However, these changes appear to go only one way.Megaupload, for example, is still among the censored terms even though the site has been offline for more than nine months. There are simply no accurate â€œcopyright infringementâ€? grounds to keep it blacklisted, one would think.Nevertheless, searching for â€œMegauploaâ€? today still shows no Autocomplete and Instant results at all.Funnily enough, Googleâ€™s search algorithm bypasses the filter to some extent, suggesting â€œMegauplauploadâ€? when typing â€œMegauplâ€? and displaying instant results for a â€œMegauploadâ€? search because thatâ€™s a far more popular search term.That said, the concern remains that once a term is placed on Google piracy blacklist itâ€™s not so easy to get it taken off.At this point itâ€™s still unclear what factors dictate a term being placed on Googleâ€™s piracy blacklist. Itâ€™s also unknown how many piracy related terms are censored as the list is not made public.To get a better understanding of Megauploadâ€™s continued presence in the blacklist and what the update policy is, TorrentFreak asked Google for a comment, but we have yet to receive a reply.In the meantime we decided to compile our own list of terms that are currently blocked from Instant and Autocomplete. Most terms are related to torrent sites and cyberlockers. In many cases the full url is not blocked, which then simply takes over as an Autocomplete suggestion.Readers are welcome to add more censored keywords in the comment so we can add to the list.Status Symbols are devices that transcend their specs and features, and become something beautiful and luxurious in their own right. They're things that live on after the megapixel and megahertz wars move past them, beacons of timeless design and innovation.2005 was a good year for Nintendo handhelds. The original DS was on its way to becoming the most successful portable device of all time, while the Game Boy Advance SP let you play your entire Game Boy library â€” dating back to the monochromatic original â€” on one, handy machine. So it was a bit curious, then, when the company decided to release the $99 Game Boy Micro, a small, streamlined version of the handheld that could only play GBA games. It improved form at the expense of functionality, creating a device that wasn't strictly necessary, but was amazing anyways.The most important thing about the Micro was its size â€” it was downright miniscule. The screen was only two inches across and the entire thing weighed just 0.18 pounds. That's less than half the weight of the original Game Boy (0.49 pounds) and a drop even from the ultralight iPhone 5's 0.25 pounds. It was so small and light you could leave it in a bag â€” or even your pocket! â€” and forget it was there. But it wasn't just that the Micro was small, it was also stylish in a way no Nintendo device had ever been. Unlike the clunky DS or any version of the Game Boy or GBA, the Micro wasn't something you'd be embarrassed to pull out in public. It felt like a gadget, not a toy. The 20th anniversary edition was particularly lovely, with a gold and red color scheme reminiscent of the original Famicom controller (the Japanese version of the NES).It was stylish in a way no Nintendo device had ever beenWhile its size made it an ideal companion for just about any trip â€” I particularly enjoyed using it for grinding through Final Fantasy V levels in between, and occasionally during, university classes â€” the screen is what made the Micro a great game system. It was small, but it was beautiful. Shrinking down games made them appear crisper, and the brilliant backlight made older games pop with new life and color. You haven't played The Legend of Zelda: The Minish Cap until you've played it on a Micro with the brightness cranked up to 11. And if you wanted to feel extra cool, the Micro was ideal for playing the Japan-exclusive Bit Generations line of GBA games â€” sleek, minimalist games in sleek, minimalist packaging, just begging to be played on a sleek, minimalist Game Boy.Like many beautiful devices, the Micro also had its share of problems. The smaller screen wasn't ideal for text-heavy games, the faceplate was prone to scratches, and the ergonomics could feel a tad cramped after lengthy sessions. But sometimes you have to make sacrifices, and with the Micro it was more than worth it. The combination of its size, style, and screen made it the first machine from Nintendo that looked as good as it played. And unlike later releases, like the iPod-influenced DS Lite, the Micro had a look all its own, and one that has yet to be duplicated. It was the last device to feature the Game Boy name, and though it was far from the most popular, it was definitely the coolest.Do not buy a Microsoft Surface RT yet.Iâ€™m typing this with gritted teeth.Â  My 24 hours with the half-baked Surface have been a frustrating challenge, a mix of love and hate.Â  I want want want this to work, but one problem after another have led me to come to the conclusion â€“ a temporary one at least â€“ that this thing just isnâ€™t ready to ship.Every time Apple unveils a new gadget or laptop, my jaw drops and I wonder how they pulled off executing their industrial designs.Â  Their v1 designs look so beautifully put together, not a mishmash of plastic parts and lids like the PC counterparts.Â  Every now and then, a PC maker will bring out something similar, but itâ€™s the very rare exception rather than the rule.The Surface RT is Microsoft shoving their hardware partners aside and saying, â€œLemme show you how this should be done. Pay attention, kids.â€?This tablet hardware doesnâ€™t just compete with the iPad â€“ it bypasses the iPad in many ways that are significant and valuable for me.I plugged in my USB presentation remote and it just worked.I plugged in a 64GB micro SD card with all my presentations and files and it just worked.I popped out the kickstand and started typing and it just worked.Â  Well, almost â€“ if thereâ€™s one significant compromise in the Surface RT, itâ€™s the kickstand.Â  You get two and only two positions for the kickstand: open and closed.Â  Thereâ€™s no adjustments.Â  I think the kickstand angle was designed for airplane use by short people, because the screen hardly goes back at all.Â  Itâ€™s probably perfect for Danny DeVito when he puts it on the seat back tray in coach class, but for me on a desk, itâ€™s too steep.The built-in front-facing camera for Skype is angled so that itâ€™ll work great when the kickstand is open, but again, only for Danny DeVito, or maybe for people who want to show off their chests in Skype.There are other hardware compromises, but theyâ€™re pretty small.Â  The speakers are laughably quiet; I fired up one of my favorite movies, Once Upon a Time in Mexico, and I couldnâ€™t even hear the actorsâ€™ dialog in the opening scenes.Â  Not couldnâ€™t understand â€“ couldnâ€™t even hear it.Â  The magnetic power cord doesnâ€™t snap in with authority, but rather requires careful positioning.Â  The volume up/down buttons are exactly opposite the USB port, so when I plug in USB devices I often push the volume up/down by accident.But who cares? I HAVE A USB PORT! Oh, Steve Jobs, I understand that you were a design deity, but I really needed that USB port, and I didnâ€™t want a stupid dongle to get it.Â  The iPad has a USB dongle available, but it was useless to me because I needed it for my presentation clicker at the same time I also needed video out, but I couldnâ€™t use both simultaneously.The Type Cover (the one with real keys) just works.Â  Iâ€™ve got big hands that often struggle on undersized keyboards, but I can type very quickly on the Type Cover.Â  So quickly, in fact, that I can outrun Microsoft Word on the Surface.Â  I get the feeling that the Surface RTâ€™s CPU or Word code just canâ€™t keep up with my typing.Â  Hereâ€™s an example video:But thatâ€™s not a hardware problem â€“ and itâ€™s time for us to talk about the ugly problem with the Surface RT.The hardware makes promises that the software canâ€™t deliver â€“ and the ability to type faster than Word can digest is a great example of that.Â  Sure, I understand that the shipped version is â€œMicrosoft Word Preview,â€? but you canâ€™t deliver software like this.Â  Itâ€™s a recipe for returned products â€“ and frankly, thatâ€™s exactly what Iâ€™m going to do with the Surface RT, return it.Wordâ€™s problems arenâ€™t limited to slow typing.Â  Once youâ€™ve banged out a document, saving your work is another adventure:I can understand problems with Word because itâ€™s a new piece of software that Microsoft has never released bef â€“ wait, hold on. Iâ€™m being told by my staff that Word is not a new program, and has been out since the 1980s.Â  If I want to see a v1 program, theyâ€™re telling me to look at the Mail app.Â  Alright, letâ€™s give that a shot:After waiting over a minute for the machine to boot and launch the mail app, I got a blank gradient screen. User interface 101: if the app needs to be set up on the first launch, offer to do that, please.Â  Folks from Twitter suggested that I swipe out from the right side and click Accounts, Add, and I did, but the Surface just sat there as shown in the video.Â  Eventually, after setting the unit aside and going on with my day, I noticed several minutes later that it popped up and said it couldnâ€™t detect the email servers for brento@brentozar.com.Â  User interface 102: when youâ€™re doing something, say something.The Surface Pro comes out in a few months.Â  The hardware design is very similar, but heavier, thicker, and with a â€œrealâ€? processor that requires a fan.Â  Yes, those are drawbacks, but they come with a very, very powerful advantage: the Surface Pro will run real Windows 8.Â  This means (hopefully) none of the buggy Windows RT problems, and perhaps more importantly, a full stable of applications.See, the Surface RT only runs Metro (whatever) apps, of which there are woefully few.Â  I didnâ€™t even get to the point of testing the very few that I found â€“ forget it, because the built-in stuff is so incredibly bad.Â  The lack of apps wasnâ€™t a problem for me â€“ I explained why I preordered a Surface RT â€“ but the quality of the built-in apps was.The whole point of the Surface RT was supposed to be a tablet thatâ€™s ready for work.Â  Itâ€™s not.Â  Donâ€™t touch it.After getting linked from HN and Reddit, Iâ€™ve gotten a bazillion comments that boil down to â€œYou should have updated Office.â€?Â  Yes, if only I could have figured out how.Â  Since this post went live, Microsoft has explained how to get it:For Windows RT Surface users, the update can be had by:Emphasis mine.Â  I had no idea that there were multiple places for Windows Update on the same tablet.Â  One tablet, but multiple places to get Microsoft updates?Â  And weâ€™re not even counting the Windows Store here.Â  This just isnâ€™t realistic to expect end users to find this buried treasure.Other commenters have suggested that the Office updates apply automatically overnight â€“ they do not.Â  Iâ€™d left my Surface RT plugged in overnight, but even so, that only lets automatic updates apply, not optional ones like this Office update.And of course, keep in mind that I still donâ€™t know if these updates fix the problem â€“ they certainly donâ€™t fix the camera or mail problems, both of which were already updated through Windows Update.Yesterday this got posted to a bunch of news sites. I was out shopping with Erika when I got a tweet saying Iâ€™d hit the front page of HackerNews, LoopInsight, and Reddit, plus getting linked to from comments at CNet and Techmeme.Hereâ€™s what that looks like in Google Analytics:Yesterday was supposed to be a fun shopping day, just Erika and I out looking at furniture and clothes before my trip out to DevConnections and the PASS Summit. Increasingly, though, I kept turning to my phone and typing frantically, trying to explain things to commenters. My stress level went through the roof, and eventually I realized that being out and about was probably the best thing that could happen. I stopped trying to keep up, and just went back to my life â€“ taking Ernie for a long walk, going out for dinner, reading the paper.Yesterday was frustrating as all hell.Iâ€™m a geek. Iâ€™ve been using computers since my first Commodore 64, then writing code in Topspeed Clarion, VBscript, Java, and .NET before switching over to Microsoft SQL Server database administration. I know bugs. Iâ€™ve coded bugs. (Thatâ€™s probably all Iâ€™ve ever coded, come to think of it.) Iâ€™m used to poking around to discover workarounds to get things to work. Iâ€™m very used to doing updates to devices before I start working with â€˜em, and I repeatedly did updates on the Surface RT trying to get it to work.Iâ€™m not a zealot. I use both Microsoft and Apple gear, and while a lot of my SQL Server friends rant against cloud-based and NoSQL databases, I like those too. Iâ€™m all about using whatever works best â€“ or to be more specific, whatever sucks the least. No software or hardware is perfect, although Iâ€™ll be the first to tell you that the Surface RTâ€™s hardware comes pretty darned close to being perfect for 2012 tablets. The iPad isnâ€™t. I hate that Apple continues to burden their products with wacko connectors, and now theyâ€™re even changing the connectors. Give me a freakinâ€™ USB port, memory card port, and video out port, and letâ€™s call it a day.I really, really wanted the Surface RT to work. I need a lightweight backup PowerPoint device when Iâ€™m on the road presenting at conferences. That device needs to show PowerPoint presenter view while driving an external projector, while being plugged in for electricity (some of my sessions are 8-9 hours long), and take a presentation clicker. Keynote Remote doesnâ€™t cut it because it loses reception in noisy radio areas like big conference rooms. The iPad only has one miserable dock connector or Lightning port, so it can either drive video OR be plugged in, but not both. The Surface RT looked like a great answer to this problem.Iâ€™m fair. If Iâ€™m going to complain about something, I want to have proof. I canâ€™t just say, â€œSurface RT suxxorzâ€? if I get frustrated. Rather than just return it and call it a day, I restored the device from scratch and tried the setup experience again. (Remember, Iâ€™m a former developer, so Iâ€™m used to trying to reproduce bugs.) I recorded videos of it in action to prove what was going on.But none of these mattered yesterday. Even with the restores, even with recording video of the problems, I got hammered. Hundreds of commenters on all kinds of sites said it was my fault.Last night, I went to bed with a plan. Iâ€™d drive down to the Microsoft store, buy another Surface RT, film the unboxing process, show how hard it is to find the behind-the-scenes desktop update panel on your own, and find out if it fixes the Skydrive and keyboard problems. (I already know the Mail updates donâ€™t fix the login/freeze problem, because Iâ€™d done those before filming the videos.)This morning, I woke up with a better plan. Iâ€™m moving on. I donâ€™t think thereâ€™s anything I could do to convince the hard-core fanboys out there that the Surface RT has problems â€“ because I realized that most of the commenters donâ€™t even own Surfaces. So many of the comments were flat out wrong, like saying thereâ€™s only one place for Surface updates and that Windows RT doesnâ€™t have a desktop mode. I think Iâ€™ve done a fair job of documenting the problems I ran into, and Iâ€™ve burned enough of my weekend time on it.And no, Iâ€™m not heading down to the Apple store to buy a new iPad, either. Iâ€™m still using a first-generation iPad 1, and believe me, itâ€™s just as flaky as the Surface RT is. Thereâ€™s no good presentation solution, the keyboards pale in comparison to the Surfaceâ€™s, and many apps are crashtastic.I donâ€™t have a single right answer for my gadget needs yet, but the fun part about being a geek in 2012 is that the options are nearly endless. The journey of finding the right gadget is just as much fun as the destination, and Iâ€™m looking forward to giving the next gadget a shot.Got a solution thatâ€™s available to buy today? Tell me in the comments.Itâ€™s not completely official yet, but it appears that Steven Sinofsky, Microsoftâ€™s President of Windows Division, agrees that the Word typing problem is a known issue and another update is forthcoming.Everybody who called me incompetent, please take your time in apologizing. Iâ€™m sure my blog would fall over immediately if all of you apologized at once.The real-world reviews are coming in, and theyâ€™re not good. Â Hereâ€™s a very long and detailed review from Chris Pirillo:The drones and other military aircraft have crowded the skies over the Horn of Africa so much that the risk of an aviation disaster has soared.Since January 2011, Air Force records show, five Predators armed with Hellfire missiles crashed after taking off from Lemonnier, including one drone that plummeted to the ground in a residential area of Djibouti City. No injuries were reported but four of the drones were destroyed.Predator drones in particular are more prone to mishaps than manned aircraft, Air Force statistics show. But the accidents rarely draw public attention because there are no pilots or passengers.As the pace of drone operations has intensified in Djibouti, Air Force mechanics have reported mysterious incidents in which the airborne robots went haywire.In March 2011, a Predator parked at the camp started its engine without any human direction, even though the ignition had been turned off and the fuel lines closed. Technicians concluded that a software bug had infected the â€œbrainsâ€? of the drone, but never pinpointed the problem.â€œAfter that whole starting-itself incident, we were fairly wary of the aircraft and watched it pretty closely,â€? an unnamed Air Force squadron commander testified to an investigative board, according to a transcript. â€œRight now, I still think the software is not good.â€?Djibouti is an impoverished former French colony with fewer than 1Â million people, scarce natural resources and miserably hot weather.But as far as the U.S. military is concerned, the country's strategic value is unparalleled. Sandwiched between East Africa and the Arabian Peninsula, Camp Lemonnier enables U.S. aircraft to reach hot spots such as Yemen or Somalia in minutes. Djiboutiâ€™s port also offers easy access to the Indian Ocean and the Red Sea.â€œThis is not an outpost in the middle of nowhere that is of marginal interest,â€? said Amanda J. Dory, the Pentagonâ€™s deputy assistant secretary for Africa. â€œThis is a very important location in terms of U.S. interests, in terms of freedom of navigation, when it comes to power projection.â€?The U.S. military pays $38Â million a year to lease Camp Lemonnier from the Djiboutian government. The base rolls across flat, sandy terrain on the edge of Djibouti City, a somnolent capital with eerily empty streets. During the day, many people stay indoors to avoid the heat and to chew khat, a mildly intoxicating plant that is popular in the region.Hemmed in by the sea and residential areas, Camp Lemonnierâ€™s primary shortcoming is that it has no space to expand. It is forced to share a single runway with Djiboutiâ€™s only international airport, as well as an adjoining French military base and the tiny Djiboutian armed forces.Apple has just announced a major executive shake-up: Senior VP of iOS software Scott Forstall is leaving Apple at the end of the year â€” he'll be serving in an advisory role to CEO Tim Cook until his departure. Additional executive changes include the departure of retail head John Browett, with Jony Ive, Bob Mansfield, Eddy Cue and Craig Federighi being tapped for additional responsibilities.To make up for the departure of Forstall, Jony Ive will now provide leadership and direction for human interface across the entire company â€” it sounds like Ive will be getting a major opportunity to bring his famed hardware design sensibility to Apple's software. Eddy Cue, who has been responsible for Apple's digital storefronts, will get increased responsibility in the form of Maps and Siri. Obviously, that's a major challenge for Cue to take on, and it isn't unreasonable to think that the failure of iOS 6 Maps at launch may have directly led to his removal as iOS VP.Craig Federighi, who previously served as VP of Mac software, will now be in charge of both iOS and OS X. Apple says this move will help unify software strategy across the two platforms; it sounds like he'll be the one most responsible for assuming Forstall's duties. Finally, VP Bob Mansfield â€” whose retirement was announced earlier this year before he announced his intentions to stay on in a less defined role â€” will head up a group known as Technologies, with a focus on semiconductor and wireless hardware.As for John Browett, Apple's Senior VP of retail is out after less than a year on the job. There's no word as to why he left (or was dismissed), but Apple says that a search for a replacement is underway. In the meantime, the company's retail team will report directly to Cook. All told, removing Browett and Forstall from Apple is a significant shake-up, as Forstall was a huge component behind the rapid rise and success of the iOS platform. Adam Lashinsky, author of Inside Apple, theorized on Twitter that Forstall was the "DRI" â€” directly responsible individual â€” for Maps and Siri, and thus "paid the price" for Apple's troubles with those two key iOS features. The DRI model was one that Steve Jobs believed strongly in during his role as Apple's CEO, and it looks like the concept lives on under Tim Cook's direction.CUPERTINO, Calif.--(BUSINESS WIRE)--AppleÂ® today announced executive management changes that will encourage even more collaboration between the Company's world-class hardware, software and services teams. As part of these changes, Jony Ive, Bob Mansfield, Eddy Cue and Craig Federighi will add more responsibilities to their roles. Apple also announced that Scott Forstall will be leaving Apple next year and will serve as an advisor to CEO Tim Cook in the interim. "We are in one of the most prolific periods of innovation and new products in Apple's history," said Tim Cook, Apple's CEO. "The amazing products that we've introduced in September and October, iPhone 5, iOS 6, iPad mini, iPad, iMac, MacBook Pro, iPod touch, iPod nano and many of our applications, could only have been created at Apple and are the direct result of our relentless focus on tightly integrating world-class hardware, software and services." Jony Ive will provide leadership and direction for Human Interface (HI) across the company in addition to his role as the leader of Industrial Design. His incredible design aesthetic has been the driving force behind the look and feel of Apple's products for more than a decade. Eddy Cue will take on the additional responsibility of SiriÂ® and Maps, placing all of our online services in one group. This organization has overseen major successes such as the iTunes StoreÂ®, the App Storeâ„ , the iBookstoreâ„  and iCloudÂ®. This group has an excellent track record of building and strengthening Apple's online services to meet and exceed the high expectations of our customers. Craig Federighi will lead both iOS and OS XÂ®. Apple has the most advanced mobile and desktop operating systems, and this move brings together the OS teams to make it even easier to deliver the best technology and user experience innovations to both platforms. Bob Mansfield will lead a new group, Technologies, which combines all of Apple's wireless teams across the company in one organization, fostering innovation in this area at an even higher level. This organization will also include the semiconductor teams, who have ambitious plans for the future. Additionally, John Browett is leaving Apple. A search for a new head of Retail is underway and in the interim, the Retail team will report directly to Tim Cook. Apple's Retail organization has an incredibly strong network of leaders at the store and regional level who will continue the excellent work that has been done over the past decade to revolutionize retailing with unique, innovative services for customers.Update: 9to5Mac has posted a team-wide email from Tim Cook thanking Forstall for his "many contributions to Apple over his career" and explaining that Mansfield will remain with the company for an additional two years. The full text is below.We are in one of the most prolific periods of innovation and new products in Appleâ€™s history. The amazing products that weâ€™ve introduced in September and October â€“ iPhone 5, iOS6, iPad mini, iPad, iMac, MacBook Pro, iPod touch, iPod nano and many of our applications â€“ could only have been created at Apple, and are the direct result of our relentless focus on tightly integrating world-class hardware, software and services. Today, I am announcing changes that will encourage even more collaboration between our world-class hardware, software and services teams at all levels of our company. As part of these changes, Jony Ive, Bob Mansfield, Eddy Cue, and Craig Federighi will be taking on more responsibilities. I am also announcing that Scott Forstall will be leaving Apple next year and will serve as an advisor to me during the interim. I want to thank Scott for all of his many contributions to Apple over his career. Jony Ive will provide leadership and direction for Human Interface (HI) across the company in addition to his longtime role as the leader of Industrial Design. Jony has an incredible design aesthetic and has been the driving force behind the look and feel of our products for more than a decade. The face of many of our products is our software and the extension of Jonyâ€™s skills into this area will widen the gap between Apple and our competition. Eddy Cue will take on the additional responsibility of Siri and Maps. This places all of our online services in one group. Eddy and his organization have overseen major successes such as the iTunes Store, the App Store, the iBookstore and iCloud. They have an excellent track record of building and strengthening our online services to meet and exceed the high expectations of our customers. Craig Federighi will lead both iOS and OS X. We have the most advanced mobile and desktop operating systems on the planet, and bringing together our OS teams will make it even easier to deliver our best technology and user experience innovations to both platforms. Craig recently led the very successful release of Mountain Lion. Bob Mansfield will lead a new group, Technologies, which combines all of our wireless teams across the company in one organization, allowing us to innovate in this area at an even higher level. This organization will also include all of our semiconductor teams, who have some very ambitious plans. As part of this, I am thrilled to tell you that Bob will remain with Apple for an additional two years. Bob has led some of our most challenging engineering projects for many years. Additionally, John Browett is leaving Apple. Our search for a new head of Retail is already underway. In the meantime, the Retail team will report directly to me. Retail has an incredibly strong network of leaders at the store and regional level, and they will continue the excellent work theyâ€™ve done over the past decade to revolutionize retailing with unique, innovative services and a focus on the customer that is second to none. This phenomenal team of talented and dedicated people works their hearts out making our customers happy. They have our respect, our admiration and our undying support. Please join me in congratulating everyone on their new roles. Iâ€™d like to thank everyone for working so hard so that Apple can continue to make the worldâ€™s best products and delight our customers. I continue to believe that Apple has the most talented and most innovative people on the planet, and I feel privileged and inspired to be able to work with all of you.Update: In response to the impact of Hurricane Sandy, Comcast is opening its XFINITY WiFi hotspots to non-Comcast subscribers in PA, NJ, DE, MD, DC, VA, WV, MA, NH and ME until Nov. 7. Users should search for the network "xfinitywifi" and click on "Not a Comcast subscriber?" at the bottom of the sign-in page. Users should select the "Complimentary Trial Session" option from the drop down list. The Open Wireless Movement thanks Comcast for helping out!In troubled times, it's important to help each other out. Right now, we're witnessing an unprecedented hurricane hitting the Eastern Seaboard of the United States, and the ensuing damage and power outages are crippling rescue efforts, businesses large and small, and personal communications.Communication is critical in time of crisis, and the Internet allows for the most effective way of getting information in and out. With readily available networks, governmentÂ officials could use tools like Twitter to quickly spread information, citizen reports could help focus assistance where it is needed most, and social media updates could help reassure friends and loved onesâ€”keeping mobile phone lines open for emergencies.To take advantage of the Internet, people should not have to attempt to skirt restrictive Terms of Service to attempt to tether their smartphones. And tethering would not be necessary if there were ubiquitous open wireless, so that anyone with a connection and power can share their networkÂ with the neigborhood.Last year, we wrote a post titled "Why We Need An Open Wireless Movement." Today,Â EFF is proud to announce the launch of the Open Wireless Movementâ€”located at openwireless.orgâ€”a coalition effort put forth in conjunction with nine other organizations: Fight for the Future, Free Press, Internet Archive, NYCwireless, the Open Garden Foundation, OpenITP, the Open Spectrum Alliance, the Open Technology Institute, and the Personal Telco Project.Aimed at residences, businesses, Internet service providers (ISPs), and developers, the Open Wireless Movement helps foster a world where the dozens of wireless networks that criss-cross any urban area are now open for us and our devices to use.The Open Wireless Movement envisions a world where people readily have access to open wireless Internet connectionsâ€”a world where sharing one's network in a way that ensures security yet preserves quality is the norm. Much of this vision is attainable now. In fact, many people have routers that already feature "guest networking" capabilities. To make this even easier, we are working with a coalition of volunteer engineers to build technologies that would make it simple for Internet subscribers to portion off their wireless networks for guests and the public while maintaining security, protecting privacy, and preserving quality of access. And we're working with advocates to help change the way people and businesses think about Internet service.We're also teaching the world about the many benefits of open wireless in order to help society move away from closed networks and to a world in which open access is the default. We are working to debunk myths (and confront truths) about open wireless while creating technologies and legal precedent to ensure it is safe, private, and legal to open your network.We believe there are many benefits to having a world of open wireless. Two of the big ones for us have to do with privacy and innovation.Open wireless protects privacy. By using multiple IP addresses as one shifts from wireless network to wireless network, you can make it more difficult for advertisers and marketing companies to track you without cookies. Activists can better protect their anonymous communication by using open wireless (though TorÂ is still recommended).Innovations would also thrive: Smarter tablets, watches, clothing, carsâ€”the possibilities are endless.Â In a future with ubiquitous open Internet, smartphones can take advantage of persistent, higher quality connections to run apps more efficiently without reporting your whereabouts or communications. Inventors and creators would not have to ask permission of cell phone companies to utilize their networks, both freeing up radio spectrum and reducing unnecessary barriers to entry.This movement is just beginning, but in a sense it has always been around. People, businesses, and communities have already been opening up their wireless networks, sharing with their neighbors, and providing an important public good. We want this movement to grow without unnecessary legal fears or technical restraints.Join the Open Wireless Movement. Whether you're a household or small business, a technologist or a student, we need your support. Check out openwireless.org for more information, and spread the word.A backlash among Reddit users has seen BitTorrent Inc. criticized over the way revenue-generating addons were presented in parallel with uTorrent client downloads. The company informs TorrentFreak that it always considers feedback, aims to provide a good customer experience, and will introduce changes soon. But whatever they are, is it really possible to please all of the people all of the time, especially ones whose requirements are â€œno-strings freeâ€? at all times?Apparently everything is available for free on the web these days. Music, movies, TV shows, games â€“ you name it â€“ itâ€™s all just a click away.New business models must be found, the tide is way too strong to hold back, the genie is out of the bottle. Itâ€™s reportedly get real or get out time, or so the sound bites go.BitTorrent users, in one form or another, have been held to blame for much of the above scenario, along with their main weapon of choice, uTorrent. But market forces are interesting beasts and ones that donâ€™t exist in a vacuum.BitTorrent Inc., the company behind the completely legal uTorrent, has worked hard to develop both itself and its software, but as it grows so do its costs. Somehow revenue has to be generated and these days, when youâ€™re a company employing around 80 staff, that has to be a significant amount.So, just like the entertainment companies who struggle to make money against free, BitTorrent Inc. has to employ techniques to give away their free product, in this instance uTorrent, and bring in the bucks at the same time.In part this is achieved by selling uTorrent Plus, which is essentially the regular uTorrent with anti-virus, media playing and conversion functions built in. Revenue is also generated by bundling optional addons, such as a toolbar, with the free uTorrent, but a new method of offering these extras has managed to irritate a bunch of Reddit users.The complaint centers around a single but very important button on the uTorrent site â€“ the â€œFree Downloadâ€? button, as illustrated below.The problem is that the button isnâ€™t a simple one-click download. Once a user hovers over it ready to click, the button and surrounding areas quickly change to include extra information.The very eager user will simply see â€œDownloadâ€? directly under their mouse pointer and will just click away, but the more cautious will notice that there are three options â€“ all preselected â€“ which relate to extra features and bundled revenue-generating software. You can test for yourself here.Obviously BitTorrent Inc. need to make money, but the main complaints seem to center around the way this download page has been configured to encourage a skipping over the details (and therefore the installation of potentially unwanted software) in order to obtain a quick download.While critics might argue that people should read what theyâ€™re agreeing to before clicking, BitTorrent Inc. say that the changes are recent and were implemented to streamline the uTorrent installation experience.â€œWeâ€™ve been offering the toolbar for years as a way to support the development of our software so users can get it free,â€? a spokesman told TorrentFreak.â€œWe recently moved the toolbar to the download page so we could have more flexibility in how we describe the toolbarâ€™s torrent-specific features and also shorten and clean up our installer, an ongoing process.â€?But what is clear from the posts on Reddit and elsewhere is that the changes arenâ€™t popular. With that in mind, BitTorrent Inc., which has a record of listening to its users, says it will do some restructuring.â€œWe have read feedback including the Reddit posts, and are planning adjustments to improve the experience,â€? their spokesperson concludes.While we wait for the changes to be confirmed (they will apparently arrive tomorrow), what is interesting to observe is how relatively easily some BitTorrent users, despite getting a free product in return, are upset by tactics they perceive as being less than upfront.The Reddit thread is full of threats to switch to different clients and as always there is a tendency to suggest clients with less intrusive revenue generating mechanisms, fewer adverts, then ultimately ones that offer a plain client with nothing added at all.It seems that having to compete with free is a reality even for BitTorrent clients these days. How times change.We first posted about the situation at our data center 8:57 am on Tuesday. 60 hours later, it has stabilized. What does that mean? Mostly, it means that the methods being used to power our services are unremarkable. Data centers throughout New York City and the surrounding area are using the same types of generators to keep countless hosted services running.It also means that we will spare you the hourly status reports on the nuts and bolts of maintaining power at our data center. Barring a completely new problem, the only further post here will be to let you know that our data center is back on the grid.The total actual downtime during this incident was approximately three hours, from about 10:45am to about 2pm on Tuesday. This was self-imposed, to protect our customers against data corruption. If this has materially impacted your ability to do business, please let us know.As is our policy with any unplanned downtime, we are planning a full postmortem, which will appear on this site. Though you will see no new evidence of it, the entire Fog Creek team continues to work full steam on contingency plans. If something unforeseen happens in the near future, or when the next natural disaster strikes, we will be able to respond quickly and effectively.The Bulgarian blogger and digital rights activist who made headlinesÂ on Tuesday when he reported acquiring more than one million Facebook data entries for just $5, said Friday he is cooperating with Facebook as it conducts an internal investigation, but won't comply with the company's request to remove blog posts or not talk about the investigation.In an interview with ReadWrite, Bogomil Shopov said he had been contacted by Facebook's Platform Policy Team after revealing on his blog that he had acquired the list, which included email addresses of active Facebook users who were primarily located in the U.S., Canada and Europe. Shopov said officials with the company were upset because they feared his public revelation would upend an internal investigation.(Read Shopov's new blog post: Mixed Feelings After Conversation With Facebook.)Â Facebook declined elaborate on the details of its investigation.â€œFacebook is vigilant about protecting our users from those who would try to expose any form of user information. In this case, it appears someone has attempted to scrape information from our site," Facebook spokesman Chris Kraeuter said in an email statement. "We have dedicated security engineers and teams that look into and take aggressive action on reports just like these. We continue to investigate this specific individual.â€?Â In addition to requesting that he keep conversations with Facebook private, the company also requested that Shopov destroy the data after sending a copy to Facebook. Shopov said he complied with the request to destroy the data but was continuing to speak with news outlets to make Facebook users aware of the breach.That didnâ€™t sit well with Facebook, according to Shopov.Â â€œTheir version is [they are conducting] an â€˜internal investigationâ€™ and one of the reasons they are angry about my blog posts is that the seller can â€˜go deepâ€™,â€? Shopov said, explaining Facebook is concerned the seller will disappear before the investigation can figure out how the data was obtained.Shopov provided ReadWrite with a cached link to the site where he purchased the data. The offer was removed within two days after his initial blog postÂ on Tuesday, October 23, but the cached version shows that the seller obtained the data through an unidentified, third-party application. This raises the question of whether there's an international black market where anyone can buy supposedly secret Facebook user data.Â Shopov verified that some of the addresses were legitimate and had planned to notify people on the list that he had purchased the data. Facebook asked him to not notify people included on the list, Shopov said.â€œWe agreed with Facebook not to do that,â€? he said. â€œThat was actually my first reaction, to tell them and to teach them about their rights.â€?Who says that Android tablets arenâ€™t cool? Research firm Strategy Analytics says that shipments of Android tablets surged to a new high in the third quarter of 2012, accounting for 41% of all tablets shipped.Â Neil Mawston, Strategy Analyticsâ€™ executive director, says that thereâ€™s no one Android tablet responsible for the surge, which is more due to a large influx of devices from a wide variety of vendors including â€œASUS (2357), Samsung (005930) and Nook.â€? Shipments of Appleâ€™s (AAPL) iPad lineup, meanwhile, shrank to 57% of the market as â€œdemand for tablets slowed due to ongoing economic uncertainty and consumers holding off purchases in anticipation of multiple new models, like the iPad Mini, during the upcoming Q4 holiday season.â€? Strategy Analyticsâ€™ full press release is posted below.BOSTONâ€“(BUSINESS WIRE)â€“According to the latest research from Strategy Analytics, global tablet shipments reached 25 million units in the third quarter of 2012. Apple iOS slipped to 57 percent global market share, allowing Android to capture a record 41 percent share.Peter King, Director at Strategy Analytics, said, â€œGlobal tablet shipments reached 24.7 million units in Q3 2012, rising a sluggish 43 percent from 17.2 million in Q3 2011. Demand for tablets slowed due to ongoing economic uncertainty and consumers holding off purchases in anticipation of multiple new models, like the iPad Mini, during the upcoming Q4 holiday season. Apple shipped a disappointing 14.0 million iPads worldwide and captured 57 percent share in the third quarter of 2012, dipping from 64 percent a year ago. Appleâ€™s slowdown allowed the Android community to make gains and Androidâ€™s global share of the tablet market now stands at a record 41 percent.â€?Neil Mawston, Executive Director at Strategy Analytics, added, â€œAndroid captured a record 41 percent share of global tablet shipments in Q3 2012, jumping from 29 percent a year earlier. Global Android tablet shipments doubled annually to 10.2 million units. No single Android vendor comes close to Apple in volume terms at the moment, but the collective weight of dozens of hardware partners, such as Asus, Samsung and Nook, is helping Googleâ€™s Android platform to register a growing presence in tablets.â€?Other findings from the research include:* Global tablet shipments grew just 43 percent annually in Q3 2012, compared with 289 percent annually in Q2 2011. This was the weakest growth rate since the modern tablet industry began in Q2 2010;* Microsoft captured a niche 2 percent global tablet share in Q3 2012. The imminent release of the new Windows 8 operating system will likely drive Microsoft tablet volumes higher during the Q4 2012 holiday season.The full report, Global Tablet OS Market Share: Q3 2012, is published by the Strategy Analytics Tablet & Touchscreen (TTS) service, details of which can be found here: http://tinyurl.com/bpqpnbs.Last night, a transformer exploded at a Con Edison plant in lower Manhattan, sparking a flurry of tweets, texts and Facebook posts from residents who witnessed or caught the event on camera. Power failed from 39th Street all the way to the southern tip of Manhattan, and the affected area likely will not regain power for up to a week. So far, authorities donâ€™t know whether the explosion was directly related to the storm since it happened just as Con EdÂ intentionallyÂ cut power to 65,000 customers in an effort to protect equipment, CBS News writes.Although we donâ€™t yet know what happened at this particular plant, we do know several general problems that can cause transformers to explode. Popular Mechanics explains:When flooded with too much electricity, the sudden surge can cause a transformer explosion. As transformers detect an energy spike, theyâ€™re programmed to turn off, but it can take up to 60 milliseconds for the shutdown. However fast those milliseconds may seem, they still may be too slow to stop the electrical overload. A chamber full of several gallons of mineral oil keeps the circuits cool, but given too much electricity, the circuits fry and melt, failing in a shower of sparks and setting the mineral oil aflame. Mineral oil, in turn, combusts explosively and rockets transformer scything into the air. All it takes is a trigger, a corroded or faulty wire, and the circuits surge will get ahead of the breaker.Salt from sea water, for example, can create hazardousÂ conditionsÂ for underground electrical systems since it acts as a corrosive agent. Old transformers can explode when their insulating materials begin to fail, too.We should have a more specific answer about what happened during Hurricane Sandy to trigger the transformer explosion soon, but hopefully the thousands without electricity will have their power restored even sooner.An Unholy Alliance of Unusual Weather and Scarce Coal Nuked Indiaâ€™s Power GridÂ  How Smart Can a City Get?Â Since ACTA was decisively beaten on 4th July 2012, the first time a free trade agreement had been scuppered by the people of EU member nations, the big business lobbyists have taken heed and resolved to change in order to be more successful. Hence the secrecy. CETA and the EU-India trade agreement are the next big battles. We need your help.The term â€œFree Trade Agreementâ€? is a misnomer. The idea is to remove barriers, taxes, and tariffs, but since people can end up being shackled to a multinational corporationâ€™s agenda, the only freedom is in the ability of the corporations to operate in ways that often end up utterly destroying local economies or harnessing law enforcement agencies to protect their interests. The worst part is that we the taxpayers have to foot the bill for our losses of national sovereignty and civil rights. We saw ACTA off in July, but there are two more major agreements to deal with and we need to be ready to contact our M.E.P.s when the time comes.CETA is the Canada-Europe Treaty Agreement. Itâ€™s so bad, Canadian cities and local authorities want to be able to opt out of it. The issues theyâ€™re having centre on the onerous procurement rules that would favor European corporations over local suppliers but there are implications for the internet, too, in the form of the ACTA-style intellectual property chapter, which Dr. Michael Geist published on his blog. Itâ€™s only an old leaked draft, but getting hold of the actual documents has been an exercise in frustration. However, it seems that Bilaterals.org has been able to preserve a copy of the Draft Consolidated Text. Despite the lack of information available, tech blogs such as Techdirt and Computerworld are picking up the story.The European Union has been secretly negotiating a free trade agreement with India since 2007 that is worryingly similar to ACTA. Intellectual property rights enforcement would include border detention and seizure measures of goods being imported by India, exported by India or in transit via Indiaâ€™s ports or airports. This could affect the generic drugs that India produces for its people. Needless to say, intellectual property rights are on the menu, mostly for pharmaceuticals, it has to be said, but since we have no access to the documents involved itâ€™s fair to say itâ€™s likely to include internet provisions, too. David Martin MEP, rapporteur for the European Unionâ€™s International Trade Committee, whose recommendations helped to pull ACTA down in July, is joining unions and international NGOs to oppose the treaty and the secrecy that goes with it. Indian business groups agree, fearing that European imports will jeopardize local production.It is essential that we mobilize opposition to these free trade agreements, not just because they are unjust, but because, if they are ratified, they will bring back the spectre of ACTA, just as E.U. Trade Commissioner Karel De Gucht assured us back in July.Microsoft has just announced that developers at its Build 2012 conference will receive 100GB of SkyDrive storage, and a free 32GB Surface RT. Speaking enthusiastically about the developer opportunity ahead, Microsoft CEO Steve Ballmer guaranteed developers in the crowd that "this will be the best opportunity software developers will see.""Hundreds of millions of people are just aching to use your applications," said Ballmer, before announcing the giveaway for Build attendees. The crowd was understandably excited, and Ballmer promised developers that Microsoft would do more marketing and "better marketing" for Windows 8.Update: Nokia's Richard Kerris joined Microsoft on stage at Build today and also announced a free Lumia 920 for attendees.Last week Glassdoor published its most recent software engineering salary report. Short version: it pays to code. Google and Facebook employees earn a base salary of ~$125K, not counting benefits, 401k matching, stock options/grants, etc., and even Yahoo! developers pull in six figures. Everyone knows why: ask anyone in the Valley, or NYC, or, well, practically anywhere, and theyâ€™ll tell you that good engineers are awfully hard to find. Demand has skyrocketed, supply has stagnated, prices have risen. Basic economics.But why has the supply of good engineers remained so strained? Weâ€™re talking about work that can, in principle, be performed by anyone anywhere with a half-decent computer and a decent Internet connection. Development tools have never been more accessible than in this era of $100 Android phones, free-tier web services, and industry-standard open-source platforms. Distributed companies with employees scattered all around the world are increasingly normal and acceptable. (I work for one. Weâ€™re hiring.) And everyone knows that software experts make big bucks, because software is eating the world. Whatâ€™s more, technology may well be destroying jobs faster than it creates them. Basic economics would seem to dictate that an exponentially larger number of people will flood into the field, bringing salaries back down to earth despite the ever-increasing demand.But reality has stubbornly refused to follow that dictation. Even way back during the first dot-com boom people were already predicting that American and European coders would soon be driven into the poorhouse by a flood of competition from low-cost nations like India and Brazil. But thereâ€™s still no sign of that happening. Why not? And when will it happen, if ever?Well. I have a theory. Iâ€™ve spend the last couple of days chilling out in Chiang Mai, northern Thailand, a city where you could live like royalty and save money while making merely half of Googleâ€™s average developer salary. Which doesnâ€™t tempt me â€“ I prefer Where Things Happen to Away From It All â€“ but has tempted thousands of expats who now live here. And their presence has sparked a possible explanation for this apparent paradox.To be clear, Iâ€™m only talking about very-good-to-excellent developers. Everyone claims to only hire â€œA-listers,â€? and that may even be true of a select few companies, including Facebook and Google. (Though even B-listers and C-listers are in relative demand.) Think of such skilled engineers as emerging from the end of a pipeline which draws from the entire population of the world. Economic incentives act like gravity, pulling almost everyone down that pipe â€“ so what are the stages that filter people out of it nonetheless?First, you have to grow up wealthy enough to have a decent education, some exposure to technology, and the ability to choose between options in your life, which immediately rules out most of the planet. Then you have to have both an interest in and a talent for development, and thereâ€™s evidence that that talent is rare: â€œbetween 30% and 60% of every university computer science departmentâ€™s intake fail the first programming course.â€œ. Then you either have to get a good professional education â€“ eg at a good university like Indiaâ€™s IIT campuses â€“ or supplement a crappy one with home hacking or on-the-job training.(Or maybe, maybe, learn-coding-at-home sites like Codecademy and the likeâ€“but Iâ€™m pretty skeptical about those. Iâ€™ve said before that I think think such services are like learning French from books, and then going to France and finding out that you canâ€™t actually communicate and it would take you years to be become fluent. Programming is like English: itâ€™s fairly easy to learn the rudimentary basics, but very hard to master.)Regardless, all of those filters should be allowing many more people through every year. The world as a whole is much wealthier than it was twelve years ago. (Thatâ€™s when I was last in Thailand. This time around itâ€™s a different and far more prosperous place.) A fixed proportion of people may have the programming gene â€” though Iâ€™ll be watching Estoniaâ€™s experiments with interest â€” but thereâ€™s little doubt that interest has erupted. Top-notch university courses are available online worldwide, and industry-standard development tools are within reach of all.But itâ€™s the very last stage that matters most. Even after youâ€™ve gotten your basic programming education, you still have to put in your thousands of hours to achieve mastery. That doesnâ€™t mean doing the same thing again and again for thousands of hours; it means challenging yourself with new tools, new languages, new objectives. Otherwise you get people writing code of the sort I see all too often these days, when HappyFunCorp (my employer) is brought on to clean up someone elseâ€™s hot mess:My theory that if itâ€™s sheer economics, the lure of a better paycheck, that initially draws you into software engineering, then youâ€™re much less likely to master it. Instead youâ€™ll advance to the point at which youâ€™re reasonably happy with your paycheck, which studies indicate is about $70,000/year in America. (But much less in Chiang Mai or Bangalore.) So my theory is that there are many more software engineers out there â€” but the ones drawn in by economic forces are content to compete with each other for mediocre (but happy-making) jobs, rather than put in the thousands of hours of mentally gruelling work required to become really good at what they do.(Donâ€™t get me wrong: that work is fun, too. But undeniably gruelling.)So why arenâ€™t there more people drawn into the field out of sheer interest? Because when youâ€™re poor, which most of the world is, money is more important than passion. Itâ€™s not until you reach a near First-World level of development that pursuing your passions rather than escaping poverty seems like a reasonable and/or admirable thing to do. So if my theory is correct, the shortage of excellent engineers will eventually alleviate or even end, as the world grows wealthier everywhere â€¦ but not for another decade or more.When you have a question, finding the answer should be effortlessâ€”wherever you are and whatever device youâ€™re using. The new Google Search app for iPhone and iPad helps you to do just that with enhanced voice search that answers any question with the comprehensive Google search results you know and love.Fast and accurate voice recognition technology enables Google to understand exactly what youâ€™re saying. Getting an answer is as simple as tapping on the microphone icon and asking a question like, â€œIs United Airlines flight 318 on time?â€? Your words appear as you speak, you get your answer immediately andâ€”if itâ€™s short and quick, like the status and departure time of your flightâ€”Google tells you the answer aloud.You can get answers to an increasingly wide variety of questions thanks to Knowledge Graph, which gives our search technology an understanding of people, places and things in the real world. Here are a few of the questions that Google can answer:â€œWhat does Yankee Stadium look like?â€? Google will show you hundreds of pictures instantly.â€œPlay me a trailer of the upcoming James Bond movie.â€? The trailer starts playing immediately right within Google Search. â€œWhen does daylight savings time end?â€? The answer will appear above the search results, so you can set your clock without having to click on a link.  â€œWhoâ€™s in the cast of The Office?â€? See a complete cast list and find out who made you crack up last night. Hue is a series of light-emitting-diode bulbs controlled from a handheld Apple device through a household Wi-Fi network. At the Apple end, users can control the lights using a free app on their iPhone, iPod or iPad.The bulbs offer a variable white light, mimic incandescent lights and will produce more than 16 million colours. While LED lighting has been praised for its extreme power-saving attributes, the harsh whiteness of the light has taken longer for technology to control."I was able to change the colours of the light bulbs in different rooms, adjust the brightness level or turn the lights off and on with one touch from my iPad," wrote Mashable reviewer Andrea Smith, who tested the system for several days.As well, the system can memorize lighting combinations for people to reuse in the future and can operate on a timed on-off basis. Lighting combinations and programs can be shared through social media."I pressed a button on the bridge which immediately identifies all three lights," Smith wrote."Using the app on my iPad, I was able to rename the lights, calling them living room, family room and office. I had fun sliding the bar from left to right, which changes the intensity of the bulb's colour; it was like having a dimmer switch built into my mobile device."The system offers flexibility and control that was once limited to lighting systems worth thousands of dollars in commercial applications.For all that, however, it isn't cheap. The introductory kit â€” three bulbs and a ZigBee bridge that attaches to a Wi-Fi router â€” costs $199 in Canada. Additional bulbs cost $59 each. As many as 50 bulbs can be operated on one system.In terms of power, the bulbs are rated at up to 8.5 watts, and each produces light of 600 lumens â€” roughly equivalent to a 50-watt incandescent bulb.Dear Lord: Please make my words sweet and tender, for tomorrow I may have to eat them.Connection woes hit popular services across the Internet. So far, though, it's unclear if they are related.A mysterious rash of outages struck the Internet today, crippling major services for hours at a time. It isn't clear whether they're related.Google Apps Engine. Google said that at about 7:30 a.m., an unnamed component of App Engine "began experiencing slow performance and dropped connections." Users began seeing slow response times and had trouble connecting to services. At the moment, most App Engine users and services are being affected. "Google engineering teams are investigating a number of options for restoring service as quickly as possible, and we will provide another update as information changes, or within 60 minutes," Google's Max Ross said.Tumblr. Around the same time Google Apps Engine began having problems, Tumblr tweeted it was having problems of its own.Dropbox. The Next Web and other sites also reported having issues with Dropbox, though the service was working fine when we checked.Meanwhile, there's evidence that the outages have affected the wider Web. The Internet Traffic Report showed a sharp decline in traffic today:It also showed an increase in packet loss, which is a measurement of a connection's reliability.Update, 1:10 p.m. Tumblr and Google App Engine have been restored.Napier & Son was the most successful British manufacturer of aircraft engines in the 1920s and 30s with their 12-cylinder Napier Lion powering 163 different types of aircraft between 1918 and 1935. Over that 17 year period the Lion grew from 450 to 1350 horsepower and was, for awhile, the most powerful aircraft, boat, and car engine in the world, holding world speed records in all three venues at the same time. And then the Napier Lion was suddenly gone â€” a lesson from which Microsoftâ€™s Steve Ballmer could benefit if he and his company donâ€™t repeat it.Napier perfected their Lion engine over those 17 years, improving it in every way until it was the best and most efficient engine of its class in the world. Then, seemingly overnight, the class changed as air forces and record setters alike suddenly needed more than the 1,350 horsepower a finely-tuned Lion could deliver. Napierâ€™s Lion gave way to Rolls-Royceâ€™s larger and innately more powerful Merlin and Griffon engines and Napier, for all intents and purposes, was gone.Napier milked its technical and market advantages for a little too long.What does this have to do with Steve Ballmer and Microsoft? They are Napier, circa 1935 and their Lion is called Windows.Windows 8 shipped last week to mixed reviews. Ballmer himself called it â€œa bold re-imaginingâ€? of Windows. Itâ€™s bold alright, but not bold enough. Windows is doomed.We can argue all day about whether Windows 8 is better or worse than Windows 7 or even Windows 9, but the real issue here isnâ€™t the software at all but the platform, by which I mean the desktop PC. Companies, governments, families, schools, and individuals are all buying fewer desktop PCs than they used to. Desktop growth has reversed and international desktop expansion is slowing as even that market matures. This year will probably mark Microsoftâ€™s highest desktop sales ever in dollar volume, which sounds good, except that next year sales will be less as they will again the year after and every year past that.Six years from now (four hardware generations) Windows will be dead. Or free.And for all his bold re-imagining in New York last week, Steve Ballmer knows this, and thatâ€™s his dilemma.Desktops are fading now, notebooks will be fading soon, both to be replaced by tablets and smart phones where Microsoft not only doesnâ€™t dominate, they arenâ€™t even among the major players.Death of the desktop is clear not because Windows desktop sales are declining but because Macintosh desktop sales are declining. When Mercedes (Apple) begins to suffer declining unit sales, what does it mean for GM (Microsoft)? Not good.The only option is to invent the future, which Ballmer and Microsoft are attempting to do by entering the tablet hardware business (again emulating Apple) and cutting bold smart phone deals with outfits like Nokia. But Microsoft, for all its posturing and $1 billion marketing budgets, isnâ€™t any good at inventing the future and knows it. Ballmer lacks confidence that Redmond can invent itâ€™s way out of the current hole. And because he lacks confidence, as does nearly everyone else at Microsoft, of course it wonâ€™t happen.Microsoft didnâ€™t invent the PC but benefited from its invention. Microsoft didnâ€™t invent BASIC, they didnâ€™t invent the PC operating system, they didnâ€™t invent word processor, spreadsheet, or presentation applications, they didnâ€™t invent PC games, they didnâ€™t invent the graphical user interface, they didnâ€™t invent the notebook or the tablet, they didnâ€™t invent the Internet, they didnâ€™t invent the music player or the video game, but they benefited from all these things.Like Blanche DuBois, Microsoft has relied on the kindness of strangers.Microsoft may have invented the smart phone. More on that below.Having not invented any of the products it is known for, why should we expect Microsoft to invent its way out of declining markets? We shouldnâ€™t.Even video games are in decline and we now see Microsoft trying to turn its 30 million-strong xBox installed base into something like a cable TV network in order to milk that franchise beyond what would otherwise be its death.Ballmer knows all this. And like Napier, he can keep building his old product line with a twist or two until the market drops out from under him or he can do some real re-imagining and turn Microsoft into a completely different company.I donâ€™t think he will do it, though, because I donâ€™t think he can do it. Even if Steve Ballmer could envision a better future for Microsoft built on true technical leadership, I donâ€™t think he or his company could follow-through. They are just making too much money doing the old stuff to truly embrace anything new.Until itâ€™s too late.This does not mean Microsoft is going away. Their smart phone patents score them $15 for every new Android license of which there are 1.3 million every day. Thatâ€™s $20 million per day ($7.3 billionÂ per year) to Microsoft for doing, well, nothing.What Steve Ballmer and Microsoft need to do is clean up their act, quietly trim expenses, maybe even sell a few product lines, and start to seriously stash away cash toward the post-Windows, post-Office world of 2018.Yes, post-Office. What else can be meant by bundling Office with Windows RT than its value is headed to zero?If Microsoft can continue to pretend it is big while actually becoming small, they might end up in 2018 with a small residual product line sitting atop $100 billion in cash. Then Ballmer can hand that money to Warren Buffett or to Buffettâ€™s successor and let them manage Microsoft as a mutual fund rather than a technology company.This is the only future I see for Microsoft because I think Steve Ballmer is a rational man, he understands this, and he sees himself as the only plausible steward for such a sneaky transition. Otherwise, simply as a huge Microsoft shareholder he would have long ago fired himself.I think this is exactly what has been happening at Microsoft for at least the last 2-3 years, ever since the plan to buy Yahoo cratered.Ballmer isnâ€™t stupid and he isnâ€™t deluded, heâ€™s a man with a plan â€” a plan weâ€™re just not supposed to know about yet.Nothing else makes sense to me.This entry was posted on Sunday, October 28th, 2012 at 12:15 am and is filed under 2012, Business, Companies, Computing, Internet, Predictions, Software, Tablets, Technology. You can follow any responses to this entry through the RSS 2.0 feed. You can leave a response, or trackback from your own site.Sitting U.S. President Ford was visiting San Francisco in 1975 when a woman attempted to shoot him. A former marine named Oliver Sipple grabbed the gun, preventing the assassination attempt. When the press began contacting him, he asked that his sexuality not be discussed. While Sipple was very active in the gay menâ€™s scene in the Castro, he was not out to family or work. But Harvey Milk, a famous gay rights activist, chose to out him so the public could see that gay men could be heroes, too.The cost to Sipple was devastating. The White House distanced itself from him, his family rejected him, and he sunk into a dark depression. He gained massive amounts of weight, began drinking profusely, and died at the ripe young age of 47. Many around Sipple reported that he regretted his act of heroism and the attention resulting from it. But for Harvey Milk, the potential social good from using Sippleâ€™s story far outweighed what he perceived as the costs of outing him.This is a hard moral conundrum, in part because Sipple was clearly a â€œgoodâ€? guy who had done a good deed. But what if he wasnâ€™t? What are the moral and ethical costs of outing people and focusing unwanted attention on them?Two weeks ago, Gawker journalist Adrian Chen decided to unmask the infamous Reddit troll â€œViolentacrezâ€? as Michael Brutsch. When Chen contacted him, Brutsch did not attempt to deny the things he had done. He simply begged Chen not to publish his name, citing the costs that publicity would have on his disabled wife. Chen chose to publish the piece â€“ including Brutschâ€™s pleas and promises to do anything that Chen asked in return for not ruining his life. As expected, Brutsch lost his job and the health insurance that paid for his wifeâ€™s care; Chen reported this outcome three days later. Many celebrated this public shaming, ecstatic to see a notorious troll grovel.Although none of his actions appeared to be illegal, itâ€™s hard to call Brutsch a â€œgoodâ€? guy. He had created settings where people could share deeply disturbing content. He enticed people to reveal their ugliest sides. In many ways, Brutsch was a classic troll, abusing technology and manipulating the boundaries of free speech to provoke systematic prejudices and harassment for his own entertainment. He got joy from making others miserable.There are many different reasons to unmask people, out them, or make them much more visible than they previously were. Sometimes, the goal is to celebrate someoneâ€™s goodness. At other times, people are made visible to use them as an example â€¦ or to set an example. People are outed to reveal hypocrisy and their practices are made visible to shame them.In identifying Butsch and shining a spotlight on his insidious practices, Chenâ€™s article condemns Butschâ€™s choice of using the mask of pseudonymity to hide behind actions that have societal consequences. Public shaming is one way in which social norms are regulated. Another is censorship, as evidenced by the Reddit communityâ€™s response to Gawker.Yet, how do we as a society weigh the moral costs of shining a spotlight on someone, however â€œbadâ€? their actions are? What happens when, as a result of social media, vigilantism takes on a new form?Â How do we guarantee justice and punishment that fits the crime when we can use visibility as a tool for massive public shaming? Is it always a good idea to regulate what different arbiters consider bad behavior through increasing someoneâ€™s notoriety â€“ or censoring their links?As the Gawker/Reddit story was unfolding, another seemingly disconnected case was playing out. In a town outside of Vancouver, a young woman named Amanda Todd committed suicide a few weeks after posting a harrowing YouTube video describing an anonymous stalker she felt ruined her life. The amorphous hacktivist collective known as â€œAnonymousâ€? decided to make a spectacle of the situation by publishing personally identifiable information on â€“ â€œdoxxingâ€? â€“Â Toddâ€™s stalker. They identified a 32-year-old man, enabling outraged people to harass him. Yet it appears they got the wrong person. Earlier this week, Canadian police reported that Toddâ€™s stalker was someone else: reportedly a 19-year-old.Needless to say, this shift in information doesnâ€™t relieve the original target of the public shame he felt from Anonymousâ€™ pointed finger. It doesnâ€™t wipe his digital record clean. He has to deal with being outed â€“ in this case, wrongly â€“ going forward.By enabling the rapid flow of information, technology offers us a unique tool to publicly out people or collectively tar and feather them. Well-meaning people may hope to spread their messages far and wide using Twitter or Facebook, but the fast-spreading messages tend to be sexual, horrific, or humiliating.Gossip is social currency. And in a networked world, trafficking in gossip is far easier than ever before.When someoneâ€™s been wronged â€“ or the opportunity arises to use someone to make a statement â€“ it is relatively easy to leverage social media to incite the hive mind to draw attention to an individual.Â The same tactic that trolls use to target people is the same tactic that people use to out trolls.More often than not, those who use these tools do so when they feel theyâ€™re on the right side of justice. Theyâ€™re either shining a spotlight to make a point or to shame someone into what they perceive to be socially acceptable behavior. But each act of outing has consequences for the people being outed, even if we do not like them or what theyâ€™ve done.This raises serious moral and ethical concerns:Â In a networked society, who among us gets to decide where the moral boundaries lie?This isnâ€™t an easy question and itâ€™s at the root of how we, as a society, conceptualize justice.Governance and the construction of a society is not a fact of life; itâ€™s a public project that we must continuously make and remake. Networked technologies are going to increasingly put pressure on our regulatory structures as conflicting social values crash into one another. In order to benefit from innovation, we must also suffer the destabilizing aspects of new technology.Yet â€¦ that destabilization and suffering allow us, as a society, to interrogate our collective commitments. The hard moral conundrums are just beginning.After falling behind Asia and Europe in the great race, where success is measured in FLOPS (floating-point operations per second), the US has struck back at the new high-tech Olympians with Titan: quite possibly the fastest supercomputer in the world.When Tennesseans hear the word Titan, their first thought is going to be gains on the gridiron, rather than leaps and bounds on the field of science.All of that might now change, as a new supercomputing giant hailing from the Smokey Mountains was unveiled by the US Department of Energyâ€™s (DOE) on Monday.More than 10 times faster and five times more energy efficient than its predecessor Jaguar, Titan is the brainchild of the DOEâ€™s Oak Ridge National Laboratory (ORNL), nestled in the Tennessee highlands.Titanâ€™s theoretical peak is 20 petaflops â€“ 20 quadrillion calculations per second â€“ with 299,008 CPUs (central processing units) and 18,688 graphics processing units (GPUs) spinning at breakneck speeds to make to make scientific breakthroughs in record times.Titan's blistering computation speed will be the equivalent of â€œthe worldâ€™s 7 billion people being able to carry out 3 million calculations per second,â€? ORNL says.Titanâ€™s precursor Jaguar â€“ which was developed by the Seattle-based Cray Inc. â€“ was the fastest supercomputer in the world in June 2010, though it was later outclassed by the Chinese Tianhe-1A several months later.The fastest computer to date is currently the California-based IBM Sequoia, which whirred to the 16.32 petaflops mark in June. Titan also boosts more than 700 terabytes of memory, and will be manage higher energy efficiency than Jaguar by innovatively combining CPUs and the more recent GPUs to synergistic effect.Power limits have long served to trammel those looking to break world records in the great computational race. Jaguarâ€™s 2.3 petaflops needed 7 megawatts of energy â€“ enough to power a small town.At $7 million dollars a year, Jaguarâ€™s electric bill was nothing to scoff at. Titan â€“ essentially an upgraded version of Jaguar housed in the same 200 cabinets arranged very much like a locker room â€“ will hit nearly 10 times the speed while consuming roughly nine megawatts. That makes Titan approximately five times more energy efficient than its previous incarnation.The race to outclass the Chinese and other international competitors has driven Titanâ€™s development forward, though as an open-science system, its benefits will be global."American competitiveness is very important from a global security and national security perspective," Jeffrey Nichols, associate laboratory director for the computing and computational sciences directorate at ORNL, told PCWorld in an interview."It's absolutely important that we are competitive in this high-tech field so the science solutions we are solving are competitive and put us on the leading edge of where we need to be in solving these problems,"he continued.With Titan poised to help the US conduct research in areas like biosciences, climate change, nuclear energy and space, Nichols believes Oak Ridge has â€œdevelopers that can use these machines at scale,â€? while Chinaâ€™s economic development model precludes it from reaching its research potential.But researchers, academics, government labs and a large swath of industries seeking to expedite the scientific method via Titan's ability to use a powerful computational model of varied natural systems are welcome to give it a spin.ORNL has opened its doors to all comers, and 40 projects a year will continue to be given access to the labâ€™s massive computational facilities based on their scientific merits. With Titan, that will mean hundreds of millions CPU hours per project at their disposal.With the never-ending pace of technological development, Titan will inevitably be overthrown by a race of younger computing gods. The Department of Energy already plans on making Titanâ€™s successor operate at 10 times its speed by 2016, meaning Americaâ€™s drive to maintain this golden age of supercomputing excellence might be far from seeing its last day.With its cryptic â€œthe playground is openâ€? tagline, the impending Google Android event has many pundits speculating on what will be introduced. So, we thought weâ€™d once again ask the real experts â€“ consumers â€“ for their take on the Android platform on the eve of what may be the next big thing â€“ or big bust. After all, the nearly 9,000 consumers BIGinsight talks to each month correctly gauged the room temperature reception of Septemberâ€™s iPhone 5 announcement from Apple.As it turns out, a look at the latest results from our â€œHot or Notâ€? feature reveals that the Google Android OS may be becoming quite the pressure cooker for Appleâ€™s iOS. While the majority of adults deemed both the Google Android platform and Apple iOS as pretty popular in October, Android maintained a slight lead on the pairing with 53.0% voting it â€œhotâ€? to Appleâ€™s 51.4%.These insights become really interesting, though, when divvied up by generation. While more than three out of five of the must-have Millennial demographic concurred that both platforms were â€œhot,â€? it was Android again (with 64.0%) that held the edge over Apple (61.9%). The operating system disparity was greatest among Gen X-ers, who were 10% more likely to side with Android (58.6%) versus Apple (53.4%). Boomers were on the fence for this debate, while Apple finally found some support among the Silent generation. Nearly half (46.8%) of those born before 1946 judged Apple to be â€œhot,â€? four points higher than those who felt the same way about Android (41.4%).Bottom Line: While both platforms are undoubtedly popular, it seems that the children of our future â€“ Millenials and Gen X-ers â€“ are positioning Google Android as the mobile future, at least for the time being. As I recall, playground popularity contests could be pretty competitive.Pam Goodfellow (@BIGinsight_Pam) is Consumer Insights Director forBIGinsight. For additional insights, check out this monthâ€™sConsumer Snapshotand theBIG Consumer Blog. And, access complimentary, on-demand insights through one or more of ourInsightCentersâ„¢.The U.S. Department of Energyâ€™s (DOE) Oak Ridge National Laboratory (ORNL)unveiled their new flagship computer, Titan, on Monday. The Department also announced its latest round of Innovative and Novel Computational Impact on Theory and Experiment (INCITE) award recipients.Titan, according to Oak Ridgeâ€™s announcement, is 10 times more powerful than its predecessor, Jaguar, with a theoretical peak performance of 20 petaflops, or 20,000 trillion calculations per second. The current fastest computer, according to the Top 500 list, is Sequoia, which clocked in at 16.32 petaflops in June.The first phase of Titanâ€™s installation was completed earlier this year, and final updates were completed this fall. Titan consumes slightly more energy than Jaguar, but when its significantly faster processing speed is taken into account, it is five times more energy efficient, according to the national laboratoryâ€™s team. The combination of faster speed and only slightly more energy consumption is critical, since the roughly seven megawatts Jaguar consumed â€” enough to power roughly 7,000 homes â€” cost millions. Titan is estimated to consume roughly nine megawatts.â€œThis power problem is changing everything,â€? said Steve Scott, chief technology officer of NVIDIAâ€™s Tesla business unit. â€œThe fact that the energy isnâ€™t dropping as fast as the transistor budget is increasing is just making us more and more power-constrained. And thatâ€™s really whatâ€™s driving us to reinvent how we make processors.â€?In addition to being faster and more efficient, Titan is the same size as its predecessor. Titan, like Jaguar, occupies a space roughly the size of a basketball court, with each stack approximately the size of a household kitchen refrigerator. Thatâ€™s due to the nature of the upgrade, which primarily involved the incorporation of graphic processing unit (GPU) accelerators. GPUs are primarily used for computer games, but can be used to accelerate central processing units, or CPUs.Titan is a Cray-XK7 system and is the first machine to use NVIDIAâ€™s latest GPU accelerator, the Tesla K20, with each of Titanâ€™s 18,688 nodes holding one CPU and GPU accelerator, according to Oak Ridge and NVIDIA. The GPU used in Titan is no different, said Scott, than the one made for high-end gaming units.â€œThe technology for gaming is the disruptive technology thatâ€™s now impacting computing broadly,â€? said Jeff Nichols, associate director of Oak Ridge National Laboratory.Pairing GPUs and CPUs in and of itself is not novel, but â€œthere were a lot of skepticsâ€? at Oak Ridge, said Scott. It had never been done on this scale before, and Titan had to be more than, in Scottâ€™s words, a â€œstunt.â€? The machine had to be able to run six predetermined applications to Oak Ridgeâ€™s specifications. The programs are in the areas of material science, climate change, biofuels, astrophysics, combustion and nuclear energy.Discovers using Titan could have an impact by leading to cleaner, more efficient engines, faster and cheaper drug testing, climate modeling and even the development of future high-performance computers.â€œThis opens up new vistas of calculations we couldnâ€™t conceive of doing before,â€? said Jeremy Smith, Governorâ€™s Chair at the University of Tennessee and also director of the Center for Molecular Biophysics at Oak Ridge National Laboratory. Smith is likely to be one of the most frequent users of Titan, as he was with Jaguar. But Smith emphasized that Titan is merely one step in high-performance computer evolution. Smith is among many who await the arrival of exascale computing, which, in theory, would allow for, among other things, the simulation of a living cell in atomic detail.â€œItâ€™s really what comes afterwards that will provide the bulk of the discoveries,â€? said Smith. â€œWhat Titan will have done is to set the standard in computer power, identify the challenges in using such a machine, and it will make a couple of useful discoveries that couldnâ€™t be made on any other machine.â€?Smith will not be alone in leveraging Titanâ€™s processing power. Recipients of the 2013 INCITE awards will also have access to Titan. The Department of Energyâ€™s Leadership Computing Facilities (LCFs) awarded a total of 4.7 billion hours to 61 projects in science and engineering â€” 1.84 billion hours on Titan and 2.83 billion hours on two of Argonne National Laboratoryâ€™s supercomputers, Mira and Intrepid. Projects ranged from research around nuclear reactors and electric engines to the development of a unified theory for physical forces.Titanâ€™s public unveiling comes weeks before the release of the latest Top500 supercomputer rankings. The Top500 list, which dates back to 1993, is released twice a year â€” once in June and again in November. The Titan team anticipates their machine will be ranked in the top two, which would make it the fastest high-performance computer open to non-classified projects. Thatâ€™s assuming Sequoia comes in first or second. Sequoia is housed at Lawrence Livermore National Laboratory (LLNL) and is used exclusively by the National Nuclear Security Administration (NNSA) to manage the United Statesâ€™ nuclear weapons stockpile. Jaguar ranked sixth in the latest list.When asked what he would use Titan for, Nichols said he thought there was â€œfascinatingâ€? research to be done in chemical physics, specifically simulating the breaking of chemical bonds. But given his focus in materials science, he said he would most likely use Titan to figure out how to design better photovoltaics.NVIDIAâ€™s Scott, on the other hand, said he would use the supercomputer to help him find Titanâ€™s successor. But a few moments later, added, â€œYou could also maybe use the machine for a really giant multi-user game.â€?Read more news and ideas on Innovations:New database grades lawmakers on their tech-friendlinessâ€˜Iron Manâ€™-style exoskeleton could help in space and here on EarthThe network made it official today that production on the long-running shows is shutting down at the end of the year. Attack Of The Show and X-Play helped define G4â€˜s gamer-culture focus and launched careers for the likes of Olivia Munn and Chris Hardwick, amassing close to 3000 episodes to date. They also provided wall-to-wall coverage of Comic-Con and E3 â€” two events right in the networkâ€™s young-male demo wheelhouse. X-Play launched in 2003 on what was then known as TechTV; Attack followed in 2005. Hereâ€™s the networkâ€™s release about farewell plans for the shows, which will air original episodes through 2012:Los Angeles, CA, October 26, 2012 â€“ Attack of the Show! and X-Play are the longest-running and defining series for G4 through its first decade. With the shows ending production at the end of 2012, G4 is getting set to showcase the landmark series as they wind down their long runs on the network.With upwards of 1,700 and 1,300 episodes, respectively, Attack of the Show! and X-Play defined the gamer culture for a generation of young men, and served as the launch pad for prominent personalities including Kevin Pereira, Olivia Munn, Chris Hardwick and Adam Sessler. Guests James Cameron, Ryan Reynolds, Jimmy Fallon, William Shatner, Sasha Baron Cohen and Joseph Gordon-Levitt are among the notables who got their geek on. The shows also pioneered live-from-the-floor coverage of the two most important conventions in the game culture universe: San Diego Comic-Con and E3.Leading up to their final episodes, Attack of the Show! and X-Play will look back at their most memorable moments, important scoops, entertaining programming and appealing hosts. A rotating lineup of guest co-hosts like John Barrowman, Michael Ian Black, Josh Myers, Paul Scheer, Rob Huebel and Horatio Sanz will join AOTS hosts Candace Bailey and Sara Underwood, and X-Play hosts Morgan Webb and Blair Herter as part of the farewell shows.â€œAttack of the Show! and X-Play have been important for G4, and we want to acknowledge the creative people who have helped inspire and showcase the phenomenon of gamer culture,â€? G4 Media General Manager Adam Stotsky said. â€œWith more than 3,000 episodes aired between them, we have more than enough great material to honor these innovators and their amazing contributions as we bring both shows to a close.â€?Attack of the Show! debuted March 28, 2005 and from the start was the ultimate male guide to everything cool and new in the world of technology, web culture, gaming and pop culture. For the next few months, AOTS will mix new segments with audience favorites, such as the iPhone extravaganza on June 29, 2007, on the eve of the debut of the first generation of Appleâ€™s market-changing smartphone. The July 2006 premiere of the first live-from-the-floor coverage from San Diego Comic-Con will be celebrated as well. Old friends will return to join the celebration, and the showâ€™s signature cheeky attitude and feel-for-the zeitgeist will be very much in evidence.X-Play made its debut almost two years earlier, on April 28, 2003 (on G4â€™s previous incarnation: TechTV), and immediately became the go-to destination for young men seeking the latest video game news, honest reviews, hands-on demos and exclusive video game trailers and footage. The year-end celebration will take viewers back through highlights of this landmark showâ€™s history, including its exclusive live-from-the-floor coverage of the E3 convention in Los Angeles, the most important annual gathering for the gaming community. X-Play has also established a franchise of doing an annual year-end round-up of the best in a wide range of video games, and you can be sure those will be revisited before the show signs-off for good. As with AOTS, expect old friends to return too.Attack of the Show! and X-Play will air original episodes through the end of the year.A core goal for Ubuntu 13.04 is to get Ubuntu running on a Nexus 7 tablet. To be clear, this is not going to be a tablet Unity interface running on the 8/16GB Nexus 7, but instead will focus on getting the current Ubuntu Desktop running on the Nexus so that we can ensure pieces such as the kernel, power management and other related areas are working effectively on a tablet device.Topics such as battery life, memory footprint, and support for sensors are all areas in which needs and expectations vary widely between a PC and a mobile devices. The 13.04 cycle will very much be focused on this exploration and learning and this is why we want to focus our efforts on getting the existing Ubuntu Desktop running on the Nexus 7. This will mean that some user-facing parts of the experience wonâ€™t make a lot of sense on the tablet, but we want to get the foundations optimized before we focus on these higher level challenges.Naturally we want our community to be involved throughout this exploration and I want to talk more about how you can get involved both as a tester and as a developer.To help with testing you will need an 8/16GB Nexus 7 tablet and be willing to replace the Android Operating System with Ubuntu (as such, please be sure to back up any valuable data on your tablet).You can follow instructions of how to install Ubuntu on your device by reading the instructions at https://wiki.ubuntu.com/Nexus7.If you have any questions about the installation and setup, please post on Ask Ubuntu; we will use the mobile tag to track these questions. The Mobile development team will be regularly monitoring the questions, and we would like you folks to help answer the list of questions too if you have the answers.When you find bugs, please use to file the bug (more details about using can be found here). Please also tag the bug with so we can find them more easily.You can also get in touch with our wider testing community in #ubuntu-testing on the Freenode IRC network.If you are interested in contributing to making Ubuntu work flawlessly and optimizing the Ubuntu Desktop core for the Nexus 7, we would love to have you participate in this work.You can find details of many of the areas that we would like to focus on over at Victorâ€™s blog; this provides some great food for thought for performance and functionality goals.Much of this work will be discussed at the upcoming Ubuntu Developer Summit taking place in Copenhagen from 29th Oct â€“ 1st Nov 2012.If you are unable to participate in person you can join the sessions remotely. For instructions of how to participate remote, see this page for instructions. You are also encouraged to join #ubuntu-arm on Freenode to discuss this work.The following sessions are scheduled. Please note times may change, so be sure to click the link below to ensure the date/time is up to date. You can also find the appropriate blueprints linked from the links below too:Made in IBM Labs: Researchers Demonstrate Initial Steps toward Commercial Fabrication of Carbon Nanotubes as a Successor to Silicon ï‚· For the first time, scientists precisely place and test more than ten thousand carbon nanotube devices in a single chip using mainstream manufacturing processes ï‚· Novel processing method helps pave the way for carbon technology as a viable alternative to silicon in future computingYORKTOWN HEIGHTS, NY â€“ 28 Oct 2012: IBM (NYSE: IBM) scientists have demonstrated a new approach to carbon nanotechnology that opens up the path for commercial fabrication of dramatically smaller, faster and more powerful computer chips. For the first time, more than ten thousand working transistors made of nano-sized tubes of carbon have been precisely placed and tested in a single chip using standard semiconductor processes. These carbon devices are poised to replace and outperform silicon technology allowing further miniaturization of computing components and leading the way for future microelectronics.Aided by rapid innovation over four decades, silicon microprocessor technology has continually shrunk in size and improved in performance, thereby driving the information technology revolution. Silicon transistors, tiny switches that carry information on a chip, have been made smaller year after year, but they are approaching a point of physical limitation. Their increasingly small dimensions, now reaching the nanoscale, will prohibit any gains in performance due to the nature of silicon and the laws of physics. Within a few more generations, classical scaling and shrinkage will no longer yield the sizable benefits of lower power, lower cost and higher speed processors that the industry has become accustomed to.Carbon nanotubes represent a new class of semiconductor materials whose electrical properties are more attractive than silicon, particularly for building nanoscale transistor devices that are a few tens of atoms across. Electrons in carbon transistors can move easier than in silicon-based devices allowing for quicker transport of data. The nanotubes are also ideally shaped for transistors at the atomic scale, an advantage over silicon. These qualities are among the reasons to replace the traditional silicon transistor with carbon â€“ and coupled with new chip design architectures â€“ will allow computing innovation on a miniature scale for the future.The approach developed at IBM labs paves the way for circuit fabrication with large numbers of carbon nanotube transistors at predetermined substrate positions. The ability to isolate semiconducting nanotubes and place a high density of carbon devices on a wafer is crucial to assess their suitability for a technology â€“ eventually more than one billion transistors will be needed for future integration into commercial chips. Until now, scientists have been able to place at most a few hundred carbon nanotube devices at a time, not nearly enough to address key issues for commercial applications."Carbon nanotubes, borne out of chemistry, have largely been laboratory curiosities as far as microelectronic applications are concerned. We are attempting the first steps towards a technology by fabricating carbon nanotube transistors within a conventional wafer fabrication infrastructure," said Supratik Guha, Director of Physical Sciences at IBM Research. "The motivation to work on carbon nanotube transistors is that at extremely small nanoscale dimensions, they outperform transistors made from any other material. However, there are challenges to address such as ultra high purity of the carbon nanotubes and deliberate placement at the nanoscale. We have been making significant strides in both."Originally studied for the physics that arises from their atomic dimensions and shapes, carbon nanotubes are being explored by scientists worldwide in applications that span integrated circuits, energy storage and conversion, biomedical sensing and DNA sequencing.This achievement was published today in the peer-reviewed journal Nature Nanotechnology.Carbon, a readily available basic element from which crystals as hard as diamonds and as soft as the "lead" in a pencil are made, has wide-ranging IT applications.Carbon nanotubes are single atomic sheets of carbon rolled up into a tube. The carbon nanotube forms the core of a transistor device that will work in a fashion similar to the current silicon transistor, but will be better performing. They could be used to replace the transistors in chips that power our data-crunching servers, high performing computers and ultra fast smart phones.Earlier this year, IBM researchers demonstrated carbon nanotube transistors can operate as excellent switches at molecular dimensions of less than ten nanometers â€“ the equivalent to 10,000 times thinner than a strand of human hair and less than half the size of the leading silicon technology. Comprehensive modeling of the electronic circuits suggests that about a five to ten times improvement in performance compared to silicon circuits is possible.There are practical challenges for carbon nanotubes to become a commercial technology notably, as mentioned earlier, due to the purity and placement of the devices. Carbon nanotubes naturally come as a mix of metallic and semiconducting species and need to be placed perfectly on the wafer surface to make electronic circuits. For device operation, only the semiconducting kind of tubes is useful which requires essentially complete removal of the metallic ones to prevent errors in circuits. Also, for large scale integration to happen, it is critical to be able to control the alignment and the location of carbon nanotube devices on a substrate.To overcome these barriers, IBM researchers developed a novel method based on ion-exchange chemistry that allows precise and controlled placement of aligned carbon nanotubes on a substrate at a high density â€“ two orders of magnitude greater than previous experiments, enabling the controlled placement of individual nanotubes with a density of about a billion per square centimeter.The process starts with carbon nanotubes mixed with a surfactant, a kind of soap that makes them soluble in water. A substrate is comprised of two oxides with trenches made of chemically-modified hafnium oxide (HfO2) and the rest of silicon oxide (SiO2). The substrate gets immersed in the carbon nanotube solution and the carbon nanotubes attach via a chemical bond to the HfO2 regions while the rest of the surface remains clean.By combining chemistry, processing and engineering expertise, IBM researchers are able to fabricate more than ten thousand transistors on a single chip. Furthermore, rapid testing of thousands of devices is possible using high volume characterization tools due to compatibility to standard commercial processes.As this new placement technique can be readily implemented, involving common chemicals and existing semiconductor fabrication, it will allow the industry to work with carbon nanotubes at a greater scale and deliver further innovation for carbon electronics.A memory leak and a failed monitoring system caused theÂ Amazon Web Services outage on Monday that took out Reddit and other major services.According to a postFriday night, AWS explained that the problem arose after a simple replacement of a data collection server. After installation, the server did not propagate its DNS address correctly and so a fraction of servers did not get the message. Those servers kept trying to reach the server, which led to a memory leak that then went out of control due to the failure of an internal monitoring alarm. Eventually the system groundÂ to a virtual stop and millions of customers felt the pain.The failure in its North Virginia region eventually interrupted Reddit, Foursquare, Minecraft, Heroku, GitHub, imgur, Pocket, HipChat, Coursera and a number of others.In the past, Amazonâ€™s Elastic Block Storage (EBS) servers have proved troublesome. This outage proved not much different. The EBS servers, feeling the memory leak, began losing the ability to process customer requests, causingÂ the number of stuck volumes to increase quickly. The server degradation came all at once, causing a tax on the system as not enough healthy servers could be found to replace them all.The outage started at 10 a.m. PST. Five hours later, AWS discovered the root of the problem. An hour later things got back to normal.AWS says it is taking a number of steps to prevent similar issues going forward. The group plans to deploy monitoring that will sound the alarm if this specific memory leak problem arises again in any of its production EBS servers. Next week it will begin deploying a fix for the memory leak issue.AWS has had its share of outages over the past several months. Its problems are magnified by an increasingly competitive market that is seeking to slow AWSâ€™ momentum by casting doubt on its infrastructure.I get the competitive issues in play here. But customers should not overlook AWSâ€™ uniqueness in providing a service that allows startups to use elastic computing, network and storage to compete on the world stage. It may have outages, but no other service comes even close to what AWS offers its customers.In the final phase of its first operational flight, the commercial cargo ship returns safely to Earth, carrying nearly a ton of supplies and experiment samples.In a major milestone for the space station program, a commercial cargo capsule loaded with nearly a ton of long-awaited experiment samples, broken components, and other gear returned to Earth on Sunday, plunging back through the atmosphere to a Pacific Ocean splashdown and wrapping up the spacecraft's first operational flight.The SpaceX Dragon capsule is the first space station cargo ship since the shuttle capable of carrying large amounts of equipment both to and from the lab complex. As such, it restores a critical capability for NASA -- the return of experiment samples from the station -- along with failed components that require troubleshooting and analysis."We see her moving aft and away from us out of the keep-out sphere," Expedition 33 Commander Sunita Williams radioed from the station as the Dragon capsule departed early today. "It was nice while she was on board. We tamed her, took her (on board), and literally and figuratively, there's a piece of us on that spacecraft going home to Earth."She was referring to urine and other biological samples packed aboard the cargo ship that had been awaiting a ride back to researchers on the ground."Not only is it going to give us a consistent supply chain up, but very critical, particularly to biological research, is the return mass, to be able to have frozen samples returned home," space station Program Manager Mike Suffredini said earlier. "This really is the keystone to what is going to allow the space station to do what it was built to do. It's critical to the success of the station."Designed, built, and operated by Space Exploration Technologies -- SpaceX -- under a $1.6 billion contract with NASA, the Dragon capsule was launched from Cape Canaveral, Fla., on October 7, loaded with nearly a half ton of supplies and equipment. It was captured by the station's robot arm three days later and attached to the Earth-facing port of the forward Harmony module.After unloading its cargo, the station crew repacked the capsule with nearly a ton of experiment samples, station components, and other gear awaiting return to Earth. Williams and Japanese astronaut Akihiko Hoshide, operating the space station's robot arm, detached Dragon from its berthing port at 7:19 a.m. ET today. The astronauts then released the capsule at 9:29 a.m. as the two spacecraft sailed 255 miles above Burma.At that point, SpaceX flight controllers in Hawthorne, Calif., took over active control, using thruster firings to move the capsule away from the space station. At 2:28 p.m., the capsule's braking rockets fired for 9 minutes and 50 seconds, dropping the far side of its orbit deep into the atmosphere over the Pacific Ocean.After enduring the heat of re-entry, the capsule's two drogue parachutes deployed at an altitude of about 45,000 feet, slowing the craft enough to permit the release of three large main parachutes at an altitude of around 10,000 feet. A SpaceX team was standing by in the landing zone 250 miles off the coast of Baja California to recover the spacecraft."The SpaceX recovery boat sees the vehicle with three main chutes out," NASA mission control radioed the station crew at 3:16 p.m."Good news," Williams replied from orbit. "Thanks for the update."A few moments later, at 3:22 p.m., the spacecraft splashed into the Pacific Ocean to complete the return to Earth."Station, Houston on two, Dragon is in the Pacific," mission control advised."Awesome," Williams said. "She made it home to Earth."The SpaceX commercial resupply contract requires the company to deliver 44,000 pounds of equipment and supplies over 12 flights. To pave the way for operational resupply missions, SpaceX carried out two successful test flights, one that tested the capsule's systems in a solo flight and another that included a berthing at the station last May.The Dragon capsule measures 14.4 feet tall and 12 feet wide, with a trunk section, jettisoned just before re-entry, that extends another 9.2 feet below the capsule's heat shield and houses two solar arrays and an unpressurized cargo bay. The spacecraft can carry up to 7,297 pounds of cargo split between the pressurized and unpressurized sections.Under a separate $440 million contract with NASA, SpaceX engineers are working on upgrades to convert the Dragon capsule into a manned spacecraft that can ferry crews to and from the station. SpaceX managers believe they will be ready for initial manned test flights in the 2015 timeframe, assuming continued NASA funding. Two other companies, Boeing and Sierra Nevada, are developing their own spacecraft designs under similar contracts.For Dragon's first Commercial Resupply Service mission -- CRS-1 -- the SpaceX cargo capsule delivered 882 pounds of hardware, supplies, and equipment to the space station, including 260 pounds of crew food and supplies, 390 pounds of science gear, and 225 pounds of spare parts and other station hardware.For its return to Earth, the Dragon was packed with about 1,673 pounds of experiment samples and hardware, including 163 pounds of crew supplies; 518 pounds of station hardware; 123 pounds of computer gear and Russian equipment; and 866 pounds of science gear and experiment samples.Update: This story was originally published at 8:06 a.m. PT after the Dragon left the space station. It was updated at 12:50 p.m. PT with information and quotations regarding re-entry and splashdown.Microsoft's biggest desire is to get you using Windows 8, and fast. Here's how to use that $40 upgrade to flip older versions of Windows to Windows 8.The Windows 8 eagle has landed, which means that Microsoft's $39.99 in-place upgrade is now available. They've made it extremely easy to upgrade your computer from a Windows 7, Vista, or XP computer to Windows 8. Here's how it's done.First, check out our CNET guide on how to prepare your computer for Windows 8. There's also instructions on how to restore your old system, which is important in case something unexpectedly goes awry, or you decide you don't like Windows 8, you can restore what you had before.If you're upgrading a laptop, you must take note of your Wi-Fi passwords. Windows 8 will keep your settings, personal files, and programs if you upgrade from Windows 7. Vista and XP upgraders will have to re-install programs and reconfigure settings.Next, go to Microsoft's Windows 8 site. Scroll down to the offer and click "Get the details." It's $39.99 for the downloadable installer, or $69.99 to have them mail you a disc.When you click on the Download Pro link, it will give to your computer a small "stub" installer. It's a 5 MB file that will run a compatibility check on your computer, tell you which programs will and won't work in Windows 8, and let you know if you have to uninstall any of them.Until Windows 8 begins its installation, there's some babysitting required. After running the stub, it'll tell you how much of your current computer is compatible, and if there's anything you'll have to review. On the Toshiba Satellite running Windows 7 that I tested this on, I learned that Windows 8 is about as fond of bloatware as the rest of us: the upgrade process requested that I uninstall several Toshiba-branded programs.You don't have to stop everything to take care of them, though, because the Windows 8 installer will walk you through that process. After letting you know whether there are details that will require your attention, it asks Windows 7 upgraders what they'd like to keep of their settings, apps, and personal files.After that, it asks you to buy the upgrade. The ordering process happens in the installer, too. Once you've paid by either credit card or PayPal, it will start downloading the 2 GB installer. You get a choice of installing immediately, installing later, or creating a USB key or disc from which to run the installer.After that, it prompts you to remove any programs that cause conflicts on Windows 8, such as the aforementioned Toshiba-built software. It's clearly a nuanced process, though, as I wasn't required to uninstall all of it -- just four programs out of 11 conflicts. If you have to restart your computer, just double-click on the Windows 8 installation icon on your desktop and it will quickly find where it left off.Once any conflicts are eliminated, Windows 8 will install. It's a surprisingly fast process, as long as you remember to babysit it at the beginning.SAN FRANCISCO â€” I.B.M. scientists are reporting progress in a chip-making technology that is likely to ensure that the basic digital switch at the heart of modern microchips will continue to shrink for more than a decade.The advance, first described in the journal Nature Nanotechnology on Sunday, is based on carbon nanotubes â€” exotic molecules that have long held out promise as an alternative to silicon from which to create the tiny logic gates now used by the billions to create microprocessors and memory chips.The I.B.M. scientists at the T.J. Watson Research Center in Yorktown Heights, N.Y., have been able to pattern an array of carbon nanotubes on the surface of a silicon wafer and use them to build hybrid chips with more than 10,000 working transistors.Against all expectations, silicon-based chips have continued to improve in speed and capacity for the last five decades. In recent years, however, there has been growing uncertainty about whether the technology would continue to improve.A failure to increase performance would inevitably stall a growing array of industries that have fed off the falling cost of computer chips.Chip makers have routinely doubled the number of transistors that can be etched on the surface of silicon wafers by shrinking the size of the tiny switches that store and route the ones and zeros that are processed by digital computers.The switches are rapidly approaching dimensions that can be measured in terms of the widths of just a few atoms.The process known as Mooreâ€™s Law was named after Gordon Moore, a co-founder of Intel, who in 1965 noted that the industry was doubling the number of transistors it could build on a single chip at routine intervals of about two years.To maintain that rate of progress, semiconductor engineers have had to consistently perfect a range of related manufacturing systems and materials that continue to perform at evermore Lilliputian scale.The I.B.M. advance is significant, scientists said, because the chip-making industry has not yet found a way forward beyond the next two or three generations of silicon.â€œThis is terrific. Iâ€™m really excited about this,â€? said Subhasish Mitra, an electrical engineering professor at Stanford who specializes in carbon nanotube materials.The promise of the new materials is twofold, he said: carbon nanotubes will allow chip makers to build smaller transistors while also probably increasing the speed at which they can be turned on and off.In recent years, while chip makers have continued to double the number of transistors on chips, their performance, measured as â€œclock speed,â€? has largely stalled.This has required the computer industry to change its designs and begin building more so-called parallel computers. Today, even smartphone microprocessors come with as many as four processors, or â€œcores,â€? which are used to break up tasks so they can be processed simultaneously.I.B.M. scientists say they believe that once they have perfected the use of carbon nanotubes â€” sometime after the end of this decade â€” it will be possible to sharply increase the speed of chips while continuing to sharply increase the number of transistors.This year, I.B.M. researchers published a separate paper describing the speedup made possible by carbon nanotubes.â€œThese devices outperformed any other switches made from any other material,â€? said Supratik Guha, director of physical sciences at I.B.M.â€™s Yorktown Heights research center. â€œWe had suspected this all along, and our device physicists had simulated this, and they showed that we would see a factor of five or more performance improvement over conventional silicon devices.â€?Carbon nanotubes are one of three promising technologies engineers hope will be perfected in time to keep the industry on its Mooreâ€™s Law pace. Graphene is another promising material that is being explored, as well as a variant of the standard silicon transistor known as a tunneling field-effect transistor.Dr. Guha, however, said carbon nanotube materials had more promising performance characteristics and that I.B.M. physicists and chemists had perfected a range of â€œtricksâ€? to ease the manufacturing process.Carbon nanotubes are essentially single sheets of carbon rolled into tubes. In the Nature Nanotechnology paper, the I.B.M. researchers described how they were able to place ultrasmall rectangles of the material in regular arrays by placing them in a soapy mixture to make them soluble in water. They used a process they described as â€œchemical self-assemblyâ€? to create patterned arrays in which nanotubes stick in some areas of the surface while leaving other areas untouched.Perfecting the process will require a more highly purified form of the carbon nanotube material, Dr. Guha said, explaining that less pure forms are metallic and are not good semiconductors.Dr. Guha said that in the 1940s scientists at Bell Labs had discovered ways to purify germanium, a metal in the carbon group that is chemically similar to silicon, to make the first transistors. He said he was confident that I.B.M. scientists would be able to make 99.99 percent pure carbon nanotubes in the future.This post has been revised to reflect the following correction:Because of an editing error, an article on Monday about an I.B.M. breakthrough on chip design defined incorrectly Mooreâ€™s Law, an observation on technology advances named for Gordon Moore, a co-founder of Intel. Mooreâ€™s Law holds that the chip industry doubles the number of transistors it can build on a single chip at routine intervals of about two years â€” not intervals of about 12 to 18 months.Freemium app revenue is now dominating premium for developers on both iOS and Android, said App Annie. The analytics firm said that freemium apps generate 69 percent of the worldwide iOS app revenue and 75 percent of global Android app revenues.The mobile app world took to the freemium model with a passion last year, as revenue from freemium iOS appseclipsed 50 percent mark in the US about a year ago. But in the last year, the momentum behind freemium apps has only grown stronger, according to new data from app analytics firm App Annie.App Annie Intelligence, which tracks more than 700,000 apps, found that global revenues for freemium apps on iOS have quadrupled over the last 24 months. And for Google Play, worldwide freemium revenues have grown 3.5x in 2012. Now, freemium apps generate 69 percent of the worldwide iOS app revenue and 75 percent of global Android app revenues.Â Meanwhile, premium app revenue from paid download apps have remained relatively flat over the same periods.The numbers confirm the trend weâ€™ve been noticing but the fact that thereâ€™s been no let up shows just how app developers continue to embrace the freemium model and how those apps continue to bring in more money. WeÂ reported two years agoÂ that the 1/3 of the top grossing apps on iOS in the US had moved to the freemium model. By the end of 2011,Â Distimo reportedÂ that about half of the revenue from the 200 top grossing iPhone apps came from freemium app while 65 percent of the revenue from top apps in the Android Market came from freemium apps. Hereâ€™s a look at some of the charts worked up by App Annie Intelligence:Â In January,Â IHS saidÂ that in-app purchase in freemium apps brought in $970 million in worldwide sale last year, or 39 percent compared to paid downloads. And freemium app revenue was expected to grow to $5.6 billion by 2015, representing 64 percent of the total market. The App Annie data, which is limited to iOS and Android, suggests we may be on a faster pace than IHS predicted.Itâ€™s not just in the US, where the figures generally mirror the world stats. App Annie said countries like China and Japan have rapidly adopted the freemium model in the last year. Japanese freemium revenues grew by 24x in the last year on Google Play and Chinese freemium revenue grew by nearly 25x on iOS since January 2011.Not every app needs to go freemium. AsÂ Flurry recently pointed out, some apps are better suited to that model. For example, apps with high intensity of usage in a short window creates an opportunity for developers to make money though in-app purchases that users can binge on. And for users who come back repeatedly over a long period of time, thereâ€™s also a chance to keep selling them on more content and add-on functions. Apps that donâ€™t necessarily hold on to users over a long period of time might monetize better through one-time paid downloads, said Flurry.I suspect weâ€™ll see paid downloads remain as a viable option for some developers. Instapaperâ€™s success, for example, has shown thatÂ consumers will pay up front for a good product. But increasingly, the bigger money seems to be found in letting people in for free and then monetizing a smaller group of users over time through in-app purchases, subscriptions and other added features.Streaming video may be the epitome of instant gratification, but that's only after you actually find the content you're looking for. You may know you want to watch "True Grit," but it's not easy to remember whether it's available on Netflix, Amazon Instant, or any of the other countless services available.That's exactly the problem the newly announced Roku Search is designed to fix.The feature upgrade will allow owners of Roku boxes to search for TV and movies available on Netflix, Amazon Instant, Vudu, Hulu Plus, Crackle, and HBO Go via one simple interface. The Roku Search channel will be rolling out to supported players (Roku LT, Roku HD and Roku 2 boxes) over the week and sits right next to the settings menu on Roku's home screen.I had the opportunity to try out the new feature over the weekend and it works well. Search for a movie and Roku will show you which services it's available for, plus whether it's free for subscribers or requires a pay-per-view fee. After you select your service, Roku launches the appropriate channel, bringing you right to the content you selected. The most tedious part is entering text, although you can use Roku's smartphone app (available for iOS and Android) to speed up the process. It's also possible to search for actors and directors and browse their available content.There are a few quirks. While you can use the Roku smartphone app to enter in text, response time is slightly delayed. I found I had to purposefully type slower than usual, otherwise letters would occasionally be left out, despite typing correctly. I also noticed that Roku Search would only specifically note that certain Amazon Instant movies are available to stream free for Prime members; TV shows didn't have the same "free for Prime" designation.Overall, it's definitely a handy feature, albeit one that only helps if you know what you want to watch. Competing platforms like the Xbox 360 and Google TV offers cross-platform browsing, in addition to search, which can help you find content you don't already know you want to watch. But in the back-and-forth battle between Roku and the Apple TV, it's another win for Roku, as Apple's box doesn't offer any cross-platform searching capabilities.Weâ€™ve seen some absurd trademark threats in recent years, but this one sets the bar at a new low: The Village Voice is suing Yelp for trademark infringement based on Yelpâ€™s creation of various â€œBest ofâ€? lists.  Yes, that's correct, the publisher behind the paper (as well as several other weeklies around the U.S.) has managed to register trademarks in the term â€œBest of â€? in connection with several cities, including San Francisco, Miami, St. Louis and Phoenix.   And it now claims that Yelpâ€™s use of those terms infringes those trademarks and deceives consumers.Right.First, a practical question: deceives consumers about what?  Trademark law is supposed to ensure that consumers can trust that the goods and services they buy come from the sources they expect, e.g., that the Pepsi you just bought really was manufactured by Pepsi.  That helps consumers, because it gives mark-owners an incentive to maintain the expected level of quality. And it helps mark-owners, because they can build customer loyalty and good will.   But you donâ€™t need a survey or even a lawyer to figure out that no one actually thinks the Village Voice is associated with Yelp because both publish â€œbest ofâ€? lists â€“ not least because no one associates the term â€œBest ofâ€? with any particular news source. Second, the more important question: What is going on at the Patent and Trademark Office?  For decades, folks have been complaining (with good reason) that the patent examiners need to do a better job of screening out bogus patent applications.  Itâ€™s clear that the problem extends to the trademark side as well. The PTO has allowed companies and individuals to register marks in any number of obviously generic and/or descriptive terms, such as â€œurban homesteadâ€? (to refer to urban farms), â€œgaymerâ€? (to refer to gay gamers), and â€œB-24â€? (to refer to model B-24 bombers).Once a mark is registered, it is all too easy for the owner to become a trademark bully.  And while companies like Yelp have the resources to fight back (as we expect it will), small companies and individuals may not. Just as dangerous, the trademark owner may go upstream, to intermediaries like Facebook who have little incentive to do anything other than take down an account or site thatâ€™s accused of infringement. "Good enough for government work" isn't good enough for free speech. Itâ€™s time the PTO did its part to stop trademark bullies and tightened up the trademark application process. Fewer bogus registrations means fewer bogus threats, and more online creativity and competition.  That's a win for everyone.In case you havenâ€™t seen the news yet, earlier today, AMD made an announcement that represents a new era in the compute landscape and builds on our rich tradition of bringing disruptive technology to the data center. By announcing our intent to build 64-bit ARM technology-based server CPUs, AMD has embarked on a path that will effectively end the one size fits all compute era that has dominated the data center for the past two decades.With the explosion of new devices and business models that touch the internet, the data center has now become the center of the universe.Â  New workloads are placing tremendous demands on the server infrastructure which is forcing the need for accelerating the pace of innovation.Â  The largest data centers in the world are adding compute at an extremely fast pace, and the market is looking for disruptive ways to improve the efficiency and reduce the total cost of ownership in the data center.Small and efficient CPU, like ARM CPUs, bring a very unique capability to the data center.Â  Â Â The compute/$$ and compute/watt is substantially improved in ARM CPUs over large-core CPUs, thus making them ideal for highly parallelizable tasks.Â  However, the challenge with efficient CPUs is that they need to be linked to the network.Â Â  If each individual efficient CPU is linked to the network, it becomes a very inefficient way to operate.This is where AMD can come in and can offer a unique advantage to drive the industry forward. Â Â AMD, through our SeaMicro acquisition, has the industryâ€™s premier fabric, the AMD SeaMicro Freedomâ„¢ fabric.Â  By using Freedom fabric to link ARM-based CPUs into a cluster, and then linking the clusters to the network, AMD can effectively solve the bottleneck of leveraging small, efficient CPUs in the mega data centers of tomorrow.There are a number companies that have talked about 64-bit ARM in the server space but only AMD comes in with the background and expertise to drive and accelerate the ARM 64-bit ecosystem. We start with a deep knowledge of what it takes to be successful in servers; industry-leading 64-bit microprocessor technology, a broad portfolio of IP and the experience of working with OEMs, ODMs and ISVs to really deliver an enterprise-class portfolio of features. In fact, at our press event in San Francisco earlier today, we pulled together a panel of industry leaders from Facebook, Dell, Red Hat, Amazon and ARM to talk about this movement to more flexible and energy-efficient compute solutions and what was required to further drive this data center inflection point.The best part of it is that we provide customers choice.Â  In addition to ARM-based CPUs, AMD will continue to offer x86 CPUs and APUs so that customers can use the right processor for the right workload.We are extremely excited to be driving the industry at this key inflection point in the data center.Â  This is an exciting time to be in our industry and we look forward to partnering with the entire ecosystem to drive this disruptive change.Take a look at the video here for highlights of todayâ€™s panel and event.Lisa Su is senior vice president and general manager of AMDâ€™s Global Business Units.Her postings are her own opinions and may not represent AMDâ€™s positions, strategies or opinions. Links to third party sites, and references to third party trademarks, are provided for convenience and illustrative purposes only. Unless explicitly stated, AMD is not responsible for the contents of such links, and no third party endorsement of AMD or any of its products is implied.OAK RIDGE, Tenn., Oct. 29, 2012 Â— The U.S. Department of Energy's (DOE) Oak Ridge National Laboratory launched a new era of scientific supercomputing today with Titan, a system capable of churning through more than 20,000 trillion calculations each secondâ€”or 20 petaflopsâ€”by employing a family of processors called graphic processing units first created for computer gaming. Titan will be 10 times more powerful than ORNL's last world-leading system, Jaguar, while overcoming power and space limitations inherent in the previous generation of high-performance computers.Titan, which is supported by the Department of Energy, will provide unprecedented computing power for research in energy, climate change, efficient engines, materials and other disciplines and pave the way for a wide range of achievements in science and technology.The Cray XK7 system contains 18,688 nodes, with each holding a 16-core AMD Opteron 6274 processor and an NVIDIA Tesla K20 graphics processing unit (GPU) accelerator. Titan also has more than 700 terabytes of memory. The combination of central processing units, the traditional foundation of high-performance computers, and more recent GPUs will allow Titan to occupy the same space as its Jaguar predecessor while using only marginally more electricity."One challenge in supercomputers today is power consumption," said Jeff Nichols, associate laboratory director for computing and computational sciences. "Combining GPUs and CPUs in a single system requires less power than CPUs alone and is a responsible move toward lowering our carbon footprint. Titan will provide unprecedented computing power for research in energy, climate change, materials and other disciplines to enable scientific leadership."Because they handle hundreds of calculations simultaneously, GPUs can go through many more than CPUs in a given time. By relying on its 299,008 CPU cores to guide simulations and allowing its new NVIDIA GPUs to do the heavy lifting, Titan will enable researchers to run scientific calculations with greater speed and accuracy."Titan will allow scientists to simulate physical systems more realistically and in far greater detail," said James Hack, director of ORNL's National Center for Computational Sciences. "The improvements in simulation fidelity will accelerate progress in a wide range of research areas such as alternative energy and energy efficiency, the identification and development of novel and useful materials and the opportunity for more advanced climate projections."Titan will be open to select projects while ORNL and Cray work through the process for final system acceptance. The lion's share of access to Titan in the coming year will come from the Department of Energy's Innovative and Novel Computational Impact on Theory and Experiment program, better known as INCITE.Researchers have been preparing for Titan and its hybrid architecture for the past two years, with many ready to make the most of the system on day one. Among the flagship scientific applications on Titan:Materials Science The magnetic properties of materials hold the key to major advances in technology. The application WL-LSMS provides a nanoscale analysis of important materials such as steels, iron-nickel alloys and advanced permanent magnets that will help drive future electric motors and generators. Titan will allow researchers to improve the calculations of a material's magnetic states as they vary by temperature."The order-of-magnitude increase in computational power available with Titan will allow us to investigate even more realistic models with better accuracy," noted ORNL researcher and WL-LSMS developer Markus Eisenbach.Combustion The S3D application models the underlying turbulent combustion of fuels in an internal combustion engine. This line of research is critical to the American energy economy, given that three-quarters of the fossil fuel used in the United States goes to powering cars and trucks, which produce one-quarter of the country's greenhouse gases.Titan will allow researchers to model large-molecule hydrocarbon fuels such as the gasoline surrogate isooctane; commercially important oxygenated alcohols such as ethanol and butanol; and biofuel surrogates that blend methyl butanoate, methyl decanoate and n-heptane."In particular, these simulations will enable us to understand the complexities associated with strong coupling between fuel chemistry and turbulence at low preignition temperatures," noted team member Jacqueline Chen of Sandia National Laboratories. "These complexities pose challenges, but also opportunities, as the strong sensitivities to both the fuel chemistry and to the fluid flows provide multiple control options which may lead to the design of a high-efficiency, low-emission, optimally combined engine-fuel system."Nuclear Energy Nuclear researchers use the Denovo application to, among other things, model the behavior of neutrons in a nuclear power reactor. America's aging nuclear power plants provide about a fifth of the country's electricity, and Denovo will help them extend their operating lives while ensuring safety. Titan will allow Denovo to simulate a fuel rod through one round of use in a reactor core in 13 hours; this job took 60 hours on the Jaguar system.Climate Change The Community Atmosphere Model-Spectral Element simulates long-term global climate. Improved atmospheric modeling under Titan will help researchers better understand future air quality as well as the effect of particles suspended in the air.Using a grid of 14-kilometer cells, the new system will be able to simulate from one to five years per day of computing time, up from the three months or so that Jaguar was able to churn through in a day."As scientists are asked to answer not only whether the climate is changing but where and how, the workload for global climate models must grow dramatically," noted CAM-SE team member Kate Evans of ORNL. "Titan will help us address the complexity that will be required in such models."ORNL is managed by UT-Battelle for the Department of Energy. The Department of Energy is the single largest supporter of basic research in the physical sciences in the United States, and is working to address some of the most pressing challenges of our time. For more information, please visit http://science.energy.gov/.For more information, including Titan images and videos, please visit http://www.olcf.ornl.gov/titan/.This video demonstrates how a Barrett WAM arm uses our mixture of motor primitives (MoMP) algorithm to learn successful hitting movements in table tennis using imitation and reinforcement Learning.Anthony here. Just wanted to share a personal update now that I have a moment. Â At around 9:00 this morning upon hearing about the fuel situation at Peer1, I decided to head out and see if I could lend a hand. The streets of Manhattan near where I live (Soho â€“ not in the evacuation zones) are in not-so-bad shape right now, but the damage left from the flooding in the evacuation zones is significant and real.Iâ€™m sitting in our datacenter NOC at 75 Broad St. Not that itâ€™s been pointed out to me, but there are beds set up on the tiled floor here from the great team at Peer1 who stayed to monitor the situation overnight. These guys have incredible commitment to keeping everything running, and itâ€™s great to see.Normally, power loss would not be a major problem for our datacenter â€“ Peer1 stayed online during the major Manhattan power outage in 2003 that lasted for days, and we preemptively shifted to backup power around 4:00pm yesterday predicting that Con Edison would be shutting off power in evacuation zones. Â Given the nature of the flooding, this situation escalated greatly, submerging our reserve fuel in the basement, shutting off the elevators, and damaging the pumps required to get this fuel to the generator on the 17th floor.My reasons for coming to the datacenter were twofold: one was simply to help and do whatever I could to help us (and the whole building) stay online. The other was to send our systems team the absolute final signal to perform a clean shutdown of our infrastructure should we be moments away from total power loss. Generally, clean shutdowns are preferable to abrupt halts, since code halting in a known state is better than code halting in an unknown state.We had an initial warning that 10:45am was going to be the clean shutdown time. To determine how much time we have remaining, engineers are taking readings at particular time intervals to attempt to determine how quickly we are depleting. The tank readings are behaving somewhatÂ erratically, as there is another mechanism replenishing it from a separate fuel header. Some of our recent readings seem more optimistic, but it is impossible to predict how much fuel remains in this header at this time. As of this writing, we have at least 45 minutes left.Bridges to the island are open right now, and we currently have a fuel truck en route. We have approval from the building to manually carry fuel up in plastic water bottles, and we have a number of our team on-site to carry fuel up the stairs as needed. I do not know if the manual plan will be successful, but we will certainly try.Unfortunately, I do not have more information on a final resolution to this issue. You should still expect Squarespace to go offline at some point because of the hurricaneâ€™s aftermath, but we will do our best to keep that downtime to a minimum. Once we have a reliable stream of fuel to the building, it will go online independently of any other grid issues related to ConEdison and lower Manhattan in general.Weâ€™ll continue to keep you posted. Thank you for your patience.This video demonstrates how a Barrett WAM arm uses our mixture of motor primitives (MoMP) algorithm to learn successful hitting movements in table tennis using imitation and reinforcement Learning.MENLO PARK, Calif. â€” Many people cite Albert Einsteinâ€™s aphorism â€œEverything should be made as simple as possible, but no simpler.â€? Only a handful, however, have had the opportunity to discuss the concept with the physicist over breakfast.One of those is Peter G. Neumann, now an 80-year-old computer scientist at SRI International, a pioneering engineering research laboratory here.As an applied-mathematics student at Harvard, Dr. Neumann had a two-hour breakfast with Einstein on Nov. 8, 1952. What the young math student took away was a deeply held philosophy of design that has remained with him for six decades and has been his governing principle of computing and computer security.For many of those years, Dr. Neumann (pronounced NOY-man) has remained a voice in the wilderness, tirelessly pointing out that the computer industry has a penchant for repeating the mistakes of the past. He has long been one of the nationâ€™s leading specialists in computer security, and early on he predicted that the security flaws that have accompanied the pell-mell explosion of the computer and Internet industries would have disastrous consequences.â€œHis biggest contribution is to stress the â€˜systemsâ€™ nature of the security and reliability problems,â€? said Steven M. Bellovin, chief technology officer of the Federal Trade Commission. â€œThat is, trouble occurs not because of one failure, but because of the way many different pieces interact.â€?Dr. Bellovin said that it was Dr. Neumann who originally gave him the insight that â€œcomplex systems break in complex waysâ€? â€” that the increasing complexity of modern hardware and software has made it virtually impossible to identify the flaws and vulnerabilities in computer systems and ensure that they are secure and trustworthy.The consequence has come to pass in the form of an epidemic of computer malware and rising concerns about cyberwarfare as a threat to global security, voiced alarmingly this month by the defense secretary, Leon E. Panetta, who warned of a possible â€œcyber-Pearl Harborâ€? attack on the United States.It is remarkable, then, that years after most of his contemporaries have retired, Dr. Neumann is still at it and has seized the opportunity to start over and redesign computers and software from a â€œclean slate.â€?He is leading a team of researchers in an effort to completely rethink how to make computers and networks secure, in a five-year project financed by the Pentagonâ€™s Defense Advanced Research Projects Agency, or Darpa, with Robert N. Watson, a computer security researcher at Cambridge Universityâ€™s Computer Laboratory.â€œIâ€™ve been tilting at the same windmills for basically 40 years,â€? said Dr. Neumann recently during a lunchtime interview at a Chinese restaurant near his art-filled home in Palo Alto, Calif. â€œAnd I get the impression that most of the folks who are responsible donâ€™t want to hear about complexity. They are interested in quick and dirty solutions.â€?Dr. Neumann, who left Bell Labs and moved to California as a single father with three young children in 1970, has occupied the same office at SRI for four decades. Until the building was recently modified to make it earthquake-resistant, the office had attained notoriety for the towering stacks of computer science literature that filled every cranny. Legend has it that colleagues who visited the office after the 1989 earthquake were stunned to discover that while other offices were in disarray from the 7.1-magnitude quake, nothing in Dr. Neumannâ€™s office appeared to have been disturbed.A trim and agile man, with piercing eyes and a salt-and-pepper beard, Dr. Neumann has practiced tai chi for decades. But his passion, besides computer security, is music. He plays a variety of instruments, including bassoon, French horn, trombone and piano, and is active in a variety of musical groups. At computer security conferences it has become a tradition for Dr. Neumann to lead his colleagues in song, playing tunes from Gilbert and Sullivan and Tom Lehrer.Until recently, security was a backwater in the world of computing. Today it is a multibillion-dollar industry, though one of dubious competence, and safeguarding the nationâ€™s computerized critical infrastructure has taken on added urgency. President Obama cited it in the third debate of the presidential campaign, focusing on foreign policy, as something â€œwe need to be thinking aboutâ€? as part of the nationâ€™s military strategy.Dow Jones Reprints: This copy is for your personal, non-commercial use only. To order presentation-ready copies for distribution to your colleagues, clients or customers, use the Order Reprints tool at the bottom of any article or visit www.djreprints.comApple Inc. executive Scott Forstall was asked to leave the company after he refused to sign his name to a letter apologizing for shortcomings in Apple's new mapping service, according to people familiar with the matter.The incident was the latest clash between Mr. Forstall, who oversaw Apple's mobile software unit, and other executives at the company. It led to one of the most significant management shake-ups in Apple's recent history and its most sweeping changes under Chief Executive Tim Cook.Apple announced the departure of Mr. Forstall on Monday along with the unrelated departure of its new retail chief, ...Google announced a handful of new Nexus-branded products Monday, including the Nexus 4 smartphone, and the Nexus 7 and Nexus 10 tablets. With its new lineup of Nexus gear, Google is prepared to battle Apple for consumers' holiday dollars over the coming months.The Nexus 4 is in fact a rebadged version of LG's Optimus G. It's a fine smartphone, and perhaps the best ever made by LG. Its best features are the incredible 1280 x 768 HD, 4.7-inch display; quad-core Snapdragon processor; and killer 8-megapixel camera. It is going to be sold unlocked, without carrier contracts for the extremely low price of $299. It can be purchased directly from Google starting November 13.The Nexus 7 is a new version of the Asus-made Nexus 7 that's been available since June. Really the only thing that's different is the amount of storage available and the price. Google upped the possible max storage to 32 GB. The 16-GB Wi-Fi version costs $199, the 32-GB Wi-Fi version costs $249 and the 32-GB Wi-Fi and HSPA+ costs $299.The Nexus 10 is a brand new tablet manufactured from Apple-foe Samsung. There should be no doubt in anyone's mind that Samsung is hoping to appeal to consumers who lust after the Retina Display on Apple's iPad. The iPad 3 and 4 have 9.7-inch displays with 2048 x 1536 pixels and 264 pixels per inch. The Nexus 10 has a 10.05-inch display that has a 2560 x 1600 pixel resolution, making for 300 pixels per inch. Neither Google nor Samsung said what kind of technology is behind the display. Samsung typically favors AMOLEDs, while Apple favors LCDs.[ Smartphones and tablets are little without apps. Check out the 10 Best Apps For Samsung Galaxy Notes. ]In addition to the Retina Display-killing screen, the Nexus 10 boasts a dual-core A15 processor, and Mali T604 graphics processor with 2 GB of RAM; 5-megapixel main camera and 1.9-megapixel user-facing camera; 802.11b/g/n Wi-Fi, Bluetooth and NFC; and microUSB and HDMI ports.The Nexus 10 is priced fairly aggressively. The 16-GB version costs $399 and the 32-GB version costs $499. Neither offers 3G or 4G cellular data, though.It will be interesting to see how Samsung and Google market the Nexus 10. If there's one feature of the iPad 3 and iPad 4 that Apple likes to brag about, it's the Retina Display. Now that Samsung has a tablet with a higher-resolution display than the iPad, the mudslinging between the two competitors is probably going to get worse.All of the new Nexus devices run Android 4.2 Jelly Bean. This minor update to Android includes some pretty cool features, such as Photo Sphere. Photo Sphere lets people take 360-degree panoramas to create really wild images. It also adds a Swype-like keyboard and new powers for Google Now.The Nexus 7 and Nexus 10 can also be ordered directly from Google beginning November 13.Time to patch your security policy to address people bringing their own mobile devices to work. Also in the new Holes In BYOD issue of Dark Reading: Metasploit creator HD Moore has five practical security tips for business travelers. (Free registration required.)Google has officially announced the Nexus 4, the latest phone in its Nexus line of flagship Android devices. Built by LG, the phone features a 4.7-inch 1280 x 768 IPS display, a 1.5GHz quad-core Snapdragon S4 Pro processor â€” which Google claims is the fastest on the market â€” an 8 megapixel camera and a 1.3 megapixel front-facing camera, and up to 16GB of storage. Oh, and the back is made of glass â€” etched, layered glass that sparkles with a strange, almost holographic depth.The executive vibe is balanced nicely by the playfulness of the backNot much of that should be surprising, as the phone had been thoroughly leaked around the web in the past few weeks. What is surprising is how much better it all looks in person. Compared to the LG Optimus G, which shares many of the same components, it's no contest â€” the Nexus 4 is a far nicer piece of hardware. It feels weighty and high-end, and the tight construction combined with the soft-touch plastic on the sides and chrome edging give it a solidly executive vibe â€” a vibe that's balanced nicely by the playfulness of Disco City on the back.The device will sell for $299 with 8GB of storage, or $349 with 16GB. A T-Mobile version will sell unlocked for $199 on a two-year contract. Alongside the improved screen and faster CPU, the Nexus 4 has 2GB of RAM, Wi-Fi 802.11b/g/n, NFC, Bluetooth, and built-in compatibility with Google's latest accessory, the Wireless Charging Orb â€” an inductive charging dock. The phone also houses a sizable 2100 mAh battery, which the company claims will get you about 10 hours of talk time.There's no LTE hereAll that battery life would be great if the device was sporting LTE radios â€” but it is not. Google has decided to forgo stricter carrier partnerships in the US, which for now means that the company will only offer the device as an unlocked HSPA+ phone. That's a bit of a crushing blow to many, who expected Google's next flagship phone to go toe-to-toe with the iPhone 5 and the latest crop of Windows Phone devices.On the bright side, the 320 ppi IPS+ LCD screen is terrific â€” a massive upgrade over the so-so Galaxy Nexus display and competitive with the iPhone's 326 ppi Retina Display. And it's not just competitive in pixel density; the screen looks stunning. It's also laminated and uses LG's new "G2" technology which integrates the touch sensor into the Gorilla Glass 2 outer layer, making everything thinner as well as bringing the actual pixels closer to the surface of the display. (Apple uses a similar technique called "in-cell touch" on the iPhone 5, which integrates the touch sensor into the display panel.) The screen is also curved slightly at the edges, like it's been melted over the phone; Google says it's meant to improve swiping in from the sides of the device.Performance on the phone was snappy. Google execs we spoke with pointed out just how fast the new Snapdragon CPU is, and in our short time testing the phone, it seemed to rip through just about anything we threw at it with little or no hesitation.The screen is curved slightly at the edges, like it's been melted over the phoneFor those disappointed with the camera performance of the Galaxy Nexus, there's also a bright spot here. Literally. Photos taken with the Nexus 4 seem greatly improved over the last generation, and Google reps say that a lot of attention has been paid to the low-light performance of the camera. We won't know for sure just how much better it is than previous phones until we put the device through its full paces, but first impressions suggest a big improvement.On the software front, Google is launching Android 4.2 along with the Nexus 4 (and the Nexus 10 tablet), and it's got some killer new features. We have a full look at the software here, not to mention an exclusive feature on the inside story of the Android team here, but there are a few standout components of the OS update that are worth mentioning.For starters, Google has added widget functionality to the lock screen, meaning you can quickly glance at information without having to get into the phone. The camera has also been improved with a completely redesigned UI focused on single-handed input, and Google has added a Street View-like mode called Photo Sphere which makes panorama shots seem tiny by comparison. The company has also improved Google Now significantly (we have a big feature story on that too).Android now has a typing mode called Gesture Typing, which mimics the functionality of Swype in conjunction with standard tap typing. The company has also added a new quick settings menu to the notifications window, tweaked Gmail with much-needed features like swipe to archive and scale-to-fit messages (like the iPhone), and added new accessibility options that make Android easier than ever â€” for all users.We'll have a full review of the Nexus 4 soon; until then, be sure to check into all of the in-depth news on Google's announcements today.You can also watch this video on YouTube.Supercomputer combines gaming and traditional computing technologies to provide unprecedented power for researchOAK RIDGE, Tenn. â€“ The U.S. Department of Energy's (DOE) Oak Ridge National Laboratory launched a new era of scientific supercomputing today with Titan, a system capable of churning through more than 20,000 trillion calculations each second-or 20 petaflops-by employing a family of processors called graphic processing units first created for computer gaming. Titan will be 10 times more powerful than ORNL's last world-leading system, Jaguar, while overcoming power and space limitations inherent in the previous generation of high-performance computers.Titan, which is supported by the Department of Energy, will provide unprecedented computing power for research in energy, climate change, efficient engines, materials and other disciplines and pave the way for a wide range of achievements in science and technology.The Cray XK7 system contains 18,688 nodes, with each holding a 16-core AMD Opteron 6274 processor and an NVIDIA Tesla K20 graphics processing unit (GPU) accelerator. Titan also has more than 700 terabytes of memory. The combination of central processing units, the traditional foundation of high- performance computers, and more recent GPUs will allow Titan to occupy the same space as its Jaguar predecessor while using only marginally more electricity."One challenge in supercomputers today is power consumption," said Jeff Nichols, associate laboratory director for computing and computational sciences. "Combining GPUs and CPUs in a single system requires less power than CPUs alone and is a responsible move toward lowering our carbon footprint. Titan will provide unprecedented computing power for research in energy, climate change, materials and other disciplines to enable scientific leadership."Because they handle hundreds of calculations simultaneously, GPUs can go through many more than CPUs in a given time. By relying on its 299,008 CPU cores to guide simulations and allowing its new NVIDIA GPUs to do the heavy lifting, Titan will enable researchers to run scientific calculations with greater speed and accuracy."Titan will allow scientists to simulate physical systems more realistically and in far greater detail," said James Hack, director of ORNL's National Center for Computational Sciences. "The improvements in simulation fidelity will accelerate progress in a wide range of research areas such as alternative energy and energy efficiency, the identification and development of novel and useful materials and the opportunity for more advanced climate projections"Titan will be open to select projects while ORNL and Cray work through the process for final system acceptance. The lion's share of access to Titan in the coming year will come from the Department of Energy's Innovative and Novel Computational Impact on Theory and Experiment program, better known as INCITE.Researchers have been preparing for Titan and its hybrid architecture for the past two years, with many ready to make the most of the system on day one. Among the flagship scientific applications on Titan:Materials Science The magnetic properties of materials hold the key to major advances in technology. The application WL- LSMS provides a nanoscale analysis of important materials such as steels, iron-nickel alloys and advanced permanent magnets that will help drive future electric motors and generators. Titan will allow researchers to improve the calculations of a material's magnetic states as they vary by temperature."The order-of-magnitude increase in computational power available with Titan will allow us to investigate even more realistic models with better accuracy" noted ORNL researcher and WL-LSMS developer Markus Eisenbach. CombustionThe S3D application models the underlying turbulent combustion of fuels in an internal combustion engine. This line of research is critical to the American energy economy, given that three-quarters of the fossil fuel used in the United States goes to powering cars and trucks, which produce one-quarter of the country's greenhouse gases.Titan will allow researchers to model large-molecule hydrocarbon fuels such as the gasoline surrogate isooctane; commercially important oxygenated alcohols such as ethanol and butanol; and biofuel surrogates that blend methyl butanoate, methyl decanoate and n-heptane."In particular, these simulations will enable us to understand the complexities associated with strong coupling between fuel chemistry and turbulence at low preignition temperatures," noted team member Jacqueline Chen of Sandia National Laboratories. "These complexities pose challenges, but also opportunities, as the strong sensitivities to both the fuel chemistry and to the fluid flows provide multiple control options which may lead to the design of a high-efficiency, low-emission, optimally combined engine-fuel system"Nuclear Energy Nuclear researchers use the Denovo application to, among other things, model the behavior of neutrons in a nuclear power reactor. America's aging nuclear power plants provide about a fifth of the country's electricity, and Denovo will help them extend their operating lives while ensuring safety. Titan will allow Denovo to simulate a fuel rod through one round of use in a reactor core in 13 hours; this job took 60 hours on the Jaguar system.Climate Change The Community Atmosphere Modelâ€“Spectral Element simulates long-term global climate. Improved atmospheric modeling under Titan will help researchers better understand future air quality as well as the effect of particles suspended in the air.Using a grid of 14-kilometer cells, the new system will be able to simulate from one to five years per day of computing time, up from the three months or so that Jaguar was able to churn through in a day."As scientists are asked to answer not only whether the climate is changing but where and how, the workload for global climate models must grow dramatically," noted CAM-SE team member Kate Evans of ORNL. "Titan will help us address the complexity that will be required in such models."ORNL is managed by UT-Battelle for the Department of Energy. The Department of Energy is the single largest supporter of basic research in the physical sciences in the United States, and is working to address some of the most pressing challenges of our time. For more information, please visit http://science.energy.gov.Look out, silicon. IBM has managed to create a computer chip based on newer carbon-nanotube technology with more than 10,000 transistors. While thatâ€™s still a drop in the bucket compared to the billions of transistors on todayâ€™s state-of-the-art silicon microprocessors, itâ€™s an important step in proving the viability of the new tech.You may have heard of Mooreâ€™s Law, which says that the number of transistors that can be put in a computer chip doubles every 18 months. That â€œlawâ€? has held true for four decades, successfully predicting the rapid evolution of computers and smartphones.However, itâ€™s not a law like, say, Boyleâ€™s Law, which is an inviolable tenet of physics. Mooreâ€™s Law is just a prediction, and itâ€™s about to collide with those real physical laws in the next few years as transistors approach the limit of how small they can get. What then?IBM has an answer in the form of a relatively new technology: carbon nanotubes. Each tube is an atom thick, rolled up in a cylinder (one is shown above). Carbon nanotubes actually conduct electricity better than silicon, have the perfect shape to act as a transistor and, most importantly, can scale smaller.However, theyâ€™re also much harder to work with, which is why no oneâ€™s pursued the tech until recently. They have to be aligned perfectly and metallic impurities, which naturally occur, must be completely removed.IBM has met those challenges, however, not only creating a 10,000-transistor-strong processor based on carbon nanotubes, but doing it with standard semiconductor techniques. That means, should todayâ€™s chipmakers end up switching to the technology, they wouldnâ€™t have to spend billions creating new tools and production facilities.It would also mean Mooreâ€™s Law could get a new lease on life, just through a different technology. And the gadget market, which has been reliant on introducing newer and more powerful gadgets year after year, should be safe for another decade at least.Hackers penetrated the computer defenses of South Carolina's Department of Revenue and accessed 3.6 million social security numbers and account data for 387,000 payment cards, officials said. The Associated Press reported the intrusion also exposed citizens' tax returns, which typically contain much more sensitive personal information, but that couldn't immediately be confirmed.The breach, which occurred in mid-September, followed a series of attempted intrusions beginning in August, according to a press release. State officials have known of the data breach since October 16, and suspected an intrusion as early as October 10, but didn't disclose it until Friday, just hours before the start of the weekend. The underlying vulnerability that attackers exploited to access the state network was fixed on October 20.Officials have retained security firm Mandiant to assist in the investigation of the breach and to help secure the system. The state is also offering one year of credit-monitoring and identity-theft protection from Experian."The number of records breached requires an unprecedented, large-scale response by the Department of Revenue, the State of South Carolina and all our citizens," Governor Nikki Haley was quoted as saying in the press release. "We are taking immediate steps to protect the taxpayers of South Carolina, including providing one year of credit monitoring of identity protection to those affected."Of the 387,000 payment cards exposed, all but 16,000 were encrypted using measures "deemed sufficient" under credit card industry standards, presumably a reference to the Payment Card Industry Data Security Standard, which critics say doesn't go far enough in protecting account data. With a state population of about 4.6 million, the exposure could affect as many as much as three-fourths of South Carolina citizens.Malware samples use increasingly refined trickery to avoid being detected by automated threat analysis systems. Anti-virus company Symantec reports that it has found a trojan which attaches its malicious code to the routines for handling mouse events. Since nobody moves the mouse in an automated threat analysis system, the code will remain inactive, and the malware undetected.In view of the exploding numbers of new malware variants â€“ Symantec mentions about 1Â million a day â€“ fully automated threat detection systems must do most of the initial work for creating virus signatures. This includes systems on which a potential malware sample is executed and its behaviour monitored. Evaluating the results is also a largely automated process; only particularly suspicious cases will be investigated further by an actual person.The simplest method of avoiding this form of detection is to allow time to pass, because such analyses are typically aborted after a certain period of time. If, however, as observed by Symantec, a suspicious program only unpacks its malicious code after 5 minutes, then waits another 20 minutes before it inserts itself into the registry, and finally begins its network activities another 20 minutes later, it stands a good chance of remaining undetected.An even cleverer malware variant uses the Windows API function to inject itself into the message handling functions that process mouse events. On a normal Windows system, a user will sooner or later click on something and activate the malware unwittingly; but on a threat analysis system, the trojan stands a good chance of remaining undetected. AV companies will probably need to introduce virtual mouse nudgers now.Around a 100 million first-grade-aged children lack access to schools. A foundation is testing whether poor children who are given computers and learning software can teach themselves.With 100 million first-grade-aged children worldwide having no access to schooling, the One Laptop Per Child organization is trying something new in two remote Ethiopian villagesâ€”simply dropping off tablet computers with preloaded programs and seeing what happens.Â The goal: to see if illiterate kids with no previous exposure to written words can learn how to read all by themselves, by experimenting with the tablet and its preloaded alphabet-training games, e-books, movies, cartoons, paintings, and other programs.Early observations are encouraging, said Nicholas Negroponte, OLPCâ€™s founder, at MIT Technology Reviewâ€™s EmTech conference last week.The devices involved are Motorola Xoom tabletsâ€”used together with a solar charging system, which Ethiopian technicians had taught adults in the village to use.Â  Once a week, a technician visits the villages and swaps out memory cards so that researchers can study how the machines were actually used.Â After several months, the kids in both villages were still heavily engaged in using and recharging the machines, and had been observed reciting the â€œalphabet song,â€? and even spelling words. One boy, exposed to literacy games with animal pictures, opened up a paint program and wrote the word â€œLion.â€?The experiment is being done in two isolated rural villages with about 20 first-grade-aged children each, about 50 miles from Addis Ababa. One village is called Wonchi, on the rim of a volcanic crater at 11,000 feet; the other is called Wolonchete, in the Great Rift Valley. Children there had never previously seen printed materials, road signs, or even packaging that had words on them, Negroponte said.Earlier this year, OLPC workers dropped off closed boxes containing the tablets, taped shut, with no instruction. â€œI thought the kids would play with the boxes. Within four minutes, one kid not only opened the box, found the on-off switch â€¦ powered it up. Within five days, they were using 47 apps per child, per day. Within two weeks, they were singing ABC songs in the village, and within five months, they had hacked Android,â€? Negroponte said. â€œSome idiot in our organization or in the Media Lab had disabled the camera, and they figured out the camera, and had hacked Android.â€?Elaborating later on Negroponteâ€™s hacking comment, Ed McNierney, OLPCâ€™s chief technology officer, said that the kids had gotten around OLPCâ€™s effort to freeze desktop settings. â€œThe kids had completely customized the desktopâ€”so every kidsâ€™ tablet looked different.Â  We had installed software to prevent them from doing that,â€? McNierney said. â€œAnd the fact they worked around it was clearly the kind of creativity, the kind of inquiry, the kind of discovery that we think is essential to learning.â€?â€œIf they can learn to read, then they can read to learn,â€? Negroponte said (see â€œEmtech Preview: Another Way to Think About Learningâ€?).In an interview after his talk, Negroponte said that while the early results are promising, reaching conclusions about whether children could learn to read this way would require more time. â€œIf it gets funded, it would need to continue for another a year and a half to two years to come to a conclusion that the scientific community would accept,â€? Negroponte said. â€œWeâ€™d have to start with a new village and make a clean start.â€?The idea of dropping off tablets outside of the context of schools is a new paradigm for OLPC. Through the late 2000s, the company was focused on delivering a custom miniaturized and ruggedized laptop, the XO, of which about 3 million have been distributed to kids in 40 countries. Deployments went to schools including ones in Peru (see â€œUna Laptop por Ninoâ€?).Giving computers directly to poor kids without any instruction is even more ambitious than OLPCâ€™s earlier pushes. â€œWhat can we do for these 100 million kids around the world who donâ€™t go to school?â€? McNierney said. â€œCan we give them tool to read and learnâ€”without having to provide schools and teachers and textbooks and all that?â€?It appears that you have JavaScript disabled or have an old version of the Adobe Flash Player. Download the latest Flash player to view this video.If you are on a mobile device, you may be able to directly download the video to play.If your browser allows only "trusted sites" to execute Javascript, you should add the "googleapis.com" domain to your whitelist to allow our Flash detection to work properly.On Monday, the US Supreme Court will hear arguments in a case that pits a major textbook publisher against Supap Kirtsaeng, a student-entrepreneur who built a small business importing and selling textbooks.Like many Supreme Court cases, though, there's more than meets the eye. It's not merely a question of whether the Thai-born Kirtsaeng will have to cough up his profits as a copyright infringer; the case is a long-awaited rematch between content companies seeking to knock out the "first sale" doctrine on goods made abroad (not to mention their many opponents). That makes Wiley v. Kirtsaeng the highest-stakes intellectual property case of the year, if not the decade. It's not an exaggeration to say the outcome could affect the very notion of property ownership in the United States. Since most consumer electronics are manufactured outside the US and include copyrighted software in it, a loss for Kirtsaeng would mean copyright owners could tax, or even shut down, resales of everything from books to DVDs to cellphones."First sale" is the rule that allows owners to resell, lend out, or give away copyrighted goods without interference. Along with fair use, it's the most important limitation on copyright. So Kirtsaeng's cause has drawn a wide array of allies to his side. These include the biggest online marketplaces like eBay, brick-and-mortar music and game retailers, and Goodwillâ€”all concerned they may lose their right to freely sell used goods. Even libraries are concerned their right to lend out books bought abroad could be inhibited.John Wiley and Sons, the textbook publisher suing Kirtsaeng, has its share of backers as well, including the movie and music industries, software companies, and other book publishers. Those companies argue differential pricing schemes are vital to their success, and should be enforced by US courts. Nearly 30 amicus briefs have been filed in all.Supporters of Kirtsaeng are mobilized, following an alarmingâ€”but not precedentialâ€”loss in an earlier case, Omega v. Costco. On a call with reporters this week, librarians and lawyers for pro-Kirtsaeng companies painted a stark picture of what might happen should he lose the case. If the appellate court ruling against Kirtsaeng is allowed to stand, they suggest copyright owners could start to chip away at the basic idea of "you bought it, you own it.""This case is an attempt by some brands and manufacturers to manipulate copyright law, to control the distribution and pricing of legitimate, authentic goods," said eBay's top policy lawyer, Hillary Brill. "When an American purchases an authentic item, he shouldn't have to ask permission from the manufacturer to do with it what he wants."Without "first sale" doctrine in place, content companies would be allowed to control use of their goods forever. They could withhold permission for resale and possibly even library lendingâ€”or they could allow it, but only for an extra fee. It would have the wild effect of actually encouraging copyrighted goods to be manufactured offshore, since that would lead to much further-reaching powers."When we purchase something, we assume it's ours," said Overstock.com general counsel Mark Griffin. "What is proposed by [the content companies] is that we change the fundamental notion of ownership rights."Book publishers and their content-industry allies say those concerns are overblown. No assault on libraries and garage sales is forthcoming, they argue. These organizations simply have a right to set different prices abroad, without being undermined in the US by importation they say is illegal.The road to the Kirtsaeng clash has been a long one. Ultimately, this confrontation has been brewing since the rise of Internet marketplaces like eBay and Amazon in the mid-1990s. It became easier to get price information about goods being sold overseas, and consumers could see that identical or good-enough products were often being offered for prices much lower than the products being hawked in the US. At the same time, the big shopping sites made it simple for anyone to become their own business, selling and shipping around the globe.The textbook market was an obvious place to look for arbitrage. Students have been complaining about the high cost of books for many years; they also became the first group to enthusiastically embrace life online, and naturally looked for ways to cut costs.Foreign-born students, exposed to the lower-priced textbooks on trips home, became some of the first to see the opportunity. The same textbooks they were using to study medicine, engineering, and mathematics in the US were being sold in their home countries for a fraction of the cost. Often a Chinese, Thai, or Indian edition of a textbook had a more cheaply bound cover, sometimes with the local lettering on the front, and perhaps cheaper paper. The internal contents, however, were often the exact same English words being read by their classmates buying high-priced US editions.By 2003, the secret was out. Students' Internet-age solution to the problem of costly textbooks hit the front page of the New York Times. For some students, it was as simple as logging on to Amazon's UK site to comparison-shop.Â  A biochemistry text was $146.15 on the American Amazon site, but sold on the UK site for a mere $63.48, plus $8.05 shipping, one student found. A math textbook cost $110 in the US, but sold for $41.76 plus shipping in Britain.Even cheaper prices were found in Asia on English textbooks. The local college bookstore at Purdue University began buying overseas after it had to start competing with student-resellersâ€”the Indian Association at Purdue bought hundreds of books on their own.Neither the students nor the bookstores quoted by the Times in 2003 thought they were doing anything illegal. It was thought to be settled law; in a 1998 Supreme Court case called Quality King, the high court found that copyright owners couldn't control the re-importation of goods. They were limited by the "first sale" doctrine, which meant the rights held in a particular copy of a work expired once it was sold or given away.Years passed, and copyright owners found a wrinkle in that ruling. The shampoo bottles in Quality King had been made in the US but then shipped abroad, and re-imported. In cases where goods were actually produced abroadâ€”as foreign textbooks generally wereâ€”copyright owners argued unauthorized importers were guilty of infringement. Because imported foreign textbooks were not "made legally under this title [the Copyright Act]," they weren't subject to first sale at all. Or so the thinking went.It seems like an audacious argument, but sure enough, student book-sellers were hit with copyright lawsuits. They fought back hardâ€”but, for the most part, they have lost.Supap Kirtsaeng lost first and lost hardest. He came to the US from Thailand in 1997 to study at Cornell University, and later went on to get a PhD in mathematics from the University of Southern California. From 2007 to 2008, he financed his educationâ€”and made extra money, doubtlessâ€”by importing textbooks from Thailand and selling them under his eBay handle, bluechristine99.The book publisher, John Wiley and Sons, didn't want to see those books in the USâ€”and it had said so. Each book was marked: "[A]uthorized for sale in Europe, Asia, Africa and the Middle East Only... The Publisher may recover damages including but not limited to lost profits and attorney's fees, in the event legal action is required."Kirtsaeng didn't abide by those warnings. He talked to some Thai friends; he consulted "Google Answers;" and he went ahead and sold books.The warning in the books was not an idle one. Wiley and Sons followed through on their threat and sued Kirtsaeng in 2008. Kirtsaeng's lawyer was unable to get the case thrown out on "first sale" grounds. By the end of 2009 Kirtsaeng was in court, justifying his importation business to a jury.Lawyers portrayed Kirtsaeng to the jury as a Thai "gray market" mogul who had gone far beyond financing his own college educationâ€”a portrayal that US publishers continue toÂ push. Working with friends and family who packaged and shipped his books, he made plenty of money selling extra books on eBay. Publishers' lawyers tallied up his receipts for the jury: $1.2 million in a few short years.The jury found Kirtsaeng guilty of infringing copyrights in eight books he had sold, and he was ordered to pay $600,000 in damagesâ€”$75,000 per book. He appealed, but a panel of judges ruled 2-1 in the publishers' favor.KirtsaengÂ returnedÂ to Thailand in 2010 after earning his doctorate from USC, but his court case continues.Editor/Authors are : Brian Wang, Director of Research. Sander Olson, Interviews and other articles Phil Wolff, Communications and social technologist. Alvin Wang. Computer, technology, social networking, and social media expert. Contact: blwang at gmail dot com Â© Copyright all rights reserved by Nextbigfuture and Z1 Consulting Inc 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012Zach Epstein has worked in and around the telecommunications industry for 10 years, first in marketing and business development with two private Telcos, then as a writer and editor covering business, technology and telecommunications. As a writer, Zachâ€™s work has been quoted by countless top news organizations, and he was named one of the top 10 â€œpower mobile influencersâ€? in the world by Forbes in January 2012. Zach is now Executive Editor at BGR, where he guides the editorial team and contributes reports and analyses with an unbiased viewpoint and a widely respected voice.As Hurricane Sandy churns its way through the Atlantic, those in its path are turning to their smartphones, and specifically Instagram, to document and share their experiences. Their output runs the gamut, from shocking to silly.People are posting shots of deserted city centers, waterlogged streets, self-portraits in scuba gear and images borrowed from the apocalyptic film â€œThe Day After Tomorrow.â€?The easiest way to see many of the storm-related photos is through a site called Instacane that is pulling together all images that are tagged with terms like â€œSandyâ€? and â€œhurricane.â€?The site, according to Instagram, was originally created by two developers named Peter Ng and Chris Ackermann. It was first set up in August 2011 as a way to collect images related to Hurricane Irene.Last winter, people used Instagram to capture the blizzard that blanketed parts of the country, revealing a kaleidoscoped view of the storm, parsed into thousands of vantage points. But the service has grown tremendously over the last year, pushing past 100 million users and billions of photographs.Kevin Systrom, the founder and chief executive of Instagram, said via e-mail that there were 10 pictures a second tagged with â€œsandyâ€? flowing through the service. In total, more than 230,000 images are using that hashtag â€” but there could be more related to the storm.â€œMost are images of people prepping for the storm and images of scenes outdoors,â€? Mr. Systrom said. â€œI think this demonstrates how Instagram is quickly becoming a useful tool to see the world as it happens â€“ especially for important world events like this.â€?Instagram has played a role in other news events lately. Last month, an Instagram user saw, and photographed, an attempted suicide on the Brooklyn Bridge. And during the shooting at the Empire State Building in August, some of the first photographs from the scene appeared on Instagram. Although both instances prompted controversy online, Instagram and services like it feel especially valuable in an era when news is not always delivered first by the television but through social networks and the people on them.What are you really agreeing to when you click that fateful â€œagree button?Â Terms & ConditionsÂ cuts out the legal lingo to spell it out in plain English.First launched by Ohio University student Alan Schaaf in 2009, Imgur has become the de-facto picture hosting site for Reddit (and thus, tens of millions of reddit users). And for good reason: Itâ€™s simple, easy to use, and makes sharing links a breeze. Due to Facebookâ€™s nasty habit of swiping usersâ€™ photos for its own purposes, Iâ€™ve come to use Imgur as my go-to online photo storage bin. And so have many others â€” more than 55 million photos have been uploaded to Imgur over the past 30 days â€” a popularity that could increase thanks to a recent, social-centric update. Given Imgurâ€™s booming popularity, itâ€™s high time we put the photo-sharing site under some good olâ€™ T&C scrutiny. Here, a quick rundown of Imgurâ€™s terms of service and privacy policy.Because Imgur was made by a real Internet user (as opposed to some disconnected corporation), the terms of service are thankfully summed up at the beginning of the document, colored by language like, â€œDonâ€™t be a troll or a jerk.â€? Summing up terms in this way is wise, and I hope to see more companies following suit.That said, it is extremely doubtful that many Imgur users have ever clicked on the tiny â€œtermsâ€? link at the bottom of every Imgur page. So hereâ€™s the rest of what you need to know.What you canâ€™t doJust like every other service weâ€™ve covered here at T&C, Imgur forbids users to do a number of things. They are:If you do any of these things, or use Imgur to break the law in some other way, Imgur â€œwill ban you along with the site youâ€™re hotlinking from, delete all your images, report you to the authorities if necessary, and prevent you from viewing any images hosted on Imgur.com.â€?All that talk of â€œno copyrighted imagesâ€? sounds good. But of course, itâ€™s mostly just there for show â€” Imgur is packed full of copyrighted images that were almost certainly not uploaded by whomever owns the intellectual property rights.That said, a good number of the most popular images uploaded to the site come directly from users. Which is why itâ€™s important to note that, by making an image publicly viewable on Imgur (you can set images and galleries to private if you wish), you are giving Imgur the right to do almost whatever it likes with that image. If you delete the image, or make it private, then Imgur immediately loses its rights to your image.Make sure to keep a backup of any photos you upload to Imgur â€” the company is not responsible, and cannot be held liable, if your pictures are somehow deleted from the companyâ€™s servers.Anytime you visit Imgur, the siteâ€™s servers collect various data about your computer. This includes:All of this data is with any comment you leave on a Imgur-hosted photo.Furthermore, like most other websites, Imgur makes money through advertising. And that means your activities on Imgur are, by default, being tracked by cookies, Web beacons, and other forms of traffic monitoring. This means some vague personal information is transferred to third-party advertisers. To block these cookies, Imgur recommends installing a tracker blocker plugin like PrivacyFix.And thatâ€™s pretty much it. Compared to most other Web legal documents, Imgurâ€™s terms and privacy policy are short, sweet, and without a lick of double-speak purposefully included to confuse users. Well done, Imgur. Well done.The Department of Energy's Oak Ridge National Labs today powered up Titan, a new supercomputer with 299,008 CPU cores, 18,688 GPUs, and more than 700 terabytes of memory. Titan is capable of a peak speed of 27 quadrillion calculations per second (petaflops)â€”ten times the processing power of its predecessor at Oak Ridgeâ€”and will likely unseat DOE's Sequoia supercomputer (an IBM BlueGene/Q system at Lawrence Livermore National Laboratory) as the fastest in the world.Based on the Cray XK7 system, Titan consists of 18,688 computing nodes, each with an AMD Opteron 6274 processor and an NVIDIA Tesla K20 GPU accelerator. The NVIDIA GPUs provide most of the computing horsepower for simulations, with the Opteron cores managing them. True to its name, Titan is bigâ€”it takes up 4,352Â square feet of floorspace in ORNL's National Center for Computational Sciences.The combination of GPUs and CPUs dramatically reduces the electrical power consumption required to generate the computing power required. "Combining GPUs and CPUs in a single system requires less power than CPUs alone," said Jeff Nichols, ORNL's Associate Laboratory Director for computing and computational sciences. In his written statement on the launch, heÂ called Titan a "responsible move toward lowering our carbon footprint."Titan is an upgrade to Jaguar, a Cray XK6 system which as of June was the sixth fastest supercomputer in the world, drawing seven megawatts at its 2.3-petaflop peak performance. Titan will provide about 10 times that performance at nine megawatts. To achieve the same performance using solely Opteron CPUs, according to NVIDIA officials, Titan would have had to have been four times larger and would have consumed over 30 megawatts of power. The move to a hybrid CPU/GPU architecture is another step down the road toward "exascale" computing systemsâ€”with a goal of achieving 1,000 quadrillion (or 1 quintillion) computations per second.ORNL researchers have been preparing for the shift to Titan's hybrid architecture for the past two years as the upgrade from Jaguar was planned, and several projects are already set to run on the new architecture. James Hack, Director of ORNL's National Center for Computational Sciences, said "Titan will allow scientists to simulate physical systems more realistically and in far greater detail. The improvements in simulation fidelity will accelerate progress in a wide range of research areas such as alternative energy and energy efficiency, the identification and development of novel and useful materials and the opportunity for more advanced climate projections."Musician-turned-activist wants new SOPA-like law preventing search engines like Google from linking to Web sites where pirated music might be found.John Mellencamp, the rock musician turned political activist who jointly launched the Farm Aid concert series, has found a new cause: attacking Internet copyright law.Mellencamp says that U.S. copyright law should be rewritten to compel Google and other search engines to police Web pages they index -- that number in the billions -- and delete links to infringing Web sites.The musician, once known as John Cougar Mellencamp, wrote in an op-ed yesterday that:Mellencamp's Huffington Post op-ed calls for revising the 1998 Digital Millennium Copyright Act (DMCA), saying "the law needs to be changed" to squash sites like "the brazen thieves" at The Pirate Bay: "We need to write a new law that should declare, something to the effect, that if you own and operate a search engine, you cannot allow criminal activity to take place in your virtual town."It echoes the same argument that the Recording Industry Association of America and the Motion Picture Association of America used last year when arguing that the DMCA was outdated and copyright law must be expanded. Their legislative effort, the Stop Online Piracy Act, was designed to make allegedly piratical Web sites virtually disappear from the Internet.But the MPAA and RIAA's lobbying efforts spectacularly failed in January when major Web sites went dark, millions of Internet users protested, and SOPA's sponsors backed away from their own bill. Even Microsoft, known for its aggressive views on expanding copyright law, got cold feet a year ago.SOPA said that Google and other search engines must, when receiving a legal order, "prevent the foreign infringing site that is subject to the order, or a portion of such site specified in the order, from being served as a direct hypertext link."That would be broader than what the DMCA allows, which is page-by-page takedowns, rather than yanking entire Web sites or domain names. That's more free-speech protective, because a Web site with some infringing portions can also be home to public domain or other non-infringing music or video files.For its part, Google says it receives 1.2 million requests per month to remove links to pages, with Microsoft being the most frequent complainant, followed by the RIAA and movie studios.It says it complies with 97 percent of the requests, which are submitted under a process created by the DMCA for the benefit of copyright holders -- a turbocharged takedown process not available to people who believe their privacy is violated by a YouTube video, for instance, or think a blog post is libelous or defamatory.In August, Google went beyond what the DMCA requires by announcing a new policy that penalizes sites that generate too many complaints from copyright owners. For YouTube, it's introduced an automatic infringement-identification system called Video ID, which also is not required by the DMCA.SAN FRANCISCO â€” I.B.M. scientists are reporting progress in a chip-making technology that is likely to ensure that the basic digital switch at the heart of modern microchips will continue to shrink for more than a decade.The advance, first described in the journal Nature Nanotechnology on Sunday, is based on carbon nanotubes â€” exotic molecules that have long held out promise as an alternative to silicon from which to create the tiny logic gates now used by the billions to create microprocessors and memory chips.The I.B.M. scientists at the T.J. Watson Research Center in Yorktown Heights, N.Y., have been able to pattern an array of carbon nanotubes on the surface of a silicon wafer and use them to build hybrid chips with more than 10,000 working transistors.Against all expectations, silicon-based chips have continued to improve in speed and capacity for the last five decades. In recent years, however, there has been growing uncertainty about whether the technology would continue to improve.A failure to increase performance would inevitably stall a growing array of industries that have fed off the falling cost of computer chips.Chip makers have routinely doubled the number of transistors that can be etched on the surface of silicon wafers by shrinking the size of the tiny switches that store and route the ones and zeros that are processed by digital computers.The switches are rapidly approaching dimensions that can be measured in terms of the widths of just a few atoms.The process known as Mooreâ€™s Law was named after Gordon Moore, a co-founder of Intel, who in 1965 noted that the industry was doubling the number of transistors it could build on a single chip at routine intervals of about two years.To maintain that rate of progress, semiconductor engineers have had to consistently perfect a range of related manufacturing systems and materials that continue to perform at evermore Lilliputian scale.The I.B.M. advance is significant, scientists said, because the chip-making industry has not yet found a way forward beyond the next two or three generations of silicon.â€œThis is terrific. Iâ€™m really excited about this,â€? said Subhasish Mitra, an electrical engineering professor at Stanford who specializes in carbon nanotube materials.The promise of the new materials is twofold, he said: carbon nanotubes will allow chip makers to build smaller transistors while also probably increasing the speed at which they can be turned on and off.In recent years, while chip makers have continued to double the number of transistors on chips, their performance, measured as â€œclock speed,â€? has largely stalled.This has required the computer industry to change its designs and begin building more so-called parallel computers. Today, even smartphone microprocessors come with as many as four processors, or â€œcores,â€? which are used to break up tasks so they can be processed simultaneously.I.B.M. scientists say they believe that once they have perfected the use of carbon nanotubes â€” sometime after the end of this decade â€” it will be possible to sharply increase the speed of chips while continuing to sharply increase the number of transistors.This year, I.B.M. researchers published a separate paper describing the speedup made possible by carbon nanotubes.â€œThese devices outperformed any other switches made from any other material,â€? said Supratik Guha, director of physical sciences at I.B.M.â€™s Yorktown Heights research center. â€œWe had suspected this all along, and our device physicists had simulated this, and they showed that we would see a factor of five or more performance improvement over conventional silicon devices.â€?Carbon nanotubes are one of three promising technologies engineers hope will be perfected in time to keep the industry on its Mooreâ€™s Law pace. Graphene is another promising material that is being explored, as well as a variant of the standard silicon transistor known as a tunneling field-effect transistor.Dr. Guha, however, said carbon nanotube materials had more promising performance characteristics and that I.B.M. physicists and chemists had perfected a range of â€œtricksâ€? to ease the manufacturing process.Carbon nanotubes are essentially single sheets of carbon rolled into tubes. In the Nature Nanotechnology paper, the I.B.M. researchers described how they were able to place ultrasmall rectangles of the material in regular arrays by placing them in a soapy mixture to make them soluble in water. They used a process they described as â€œchemical self-assemblyâ€? to create patterned arrays in which nanotubes stick in some areas of the surface while leaving other areas untouched.Perfecting the process will require a more highly purified form of the carbon nanotube material, Dr. Guha said, explaining that less pure forms are metallic and are not good semiconductors.Dr. Guha said that in the 1940s scientists at Bell Labs had discovered ways to purify germanium, a metal in the carbon group that is chemically similar to silicon, to make the first transistors. He said he was confident that I.B.M. scientists would be able to make 99.99 percent pure carbon nanotubes in the future.This post has been revised to reflect the following correction:Because of an editing error, an article on Monday about an I.B.M. breakthrough on chip design defined incorrectly Mooreâ€™s Law, an observation on technology advances named for Gordon Moore, a co-founder of Intel. Mooreâ€™s Law holds that the chip industry doubles the number of transistors it can build on a single chip at routine intervals of about two years â€” not intervals of about 12 to 18 months.Picture an eerily human-like tangle of metal, wiring and lights, cables dangling from somewhere above like puppet strings. Imagine it springing to life, lifting a long, lanky leg that bends 180 degrees at the hips like the eerie biomechanical GekkoÂ inÂ Metal Gear Solid 4, then placing one foot on a high bench and flexing its ankle, probing, testing, as it leans its thick cage of a torso forward, its arms splayed against plastic and wood walls on either side.And then itâ€™s up, hoisting its bulk into the air, its arms swinging forward just as yours or mine would, finding its feet, gently quaking, balancing.Now picture it leaping back down, landing first one foot, then the other, making a thunderous sound like someone swinging a sledgehammer at sheet metal (or the noise youâ€™d imagine a hulking robot might generate as it falls from above, like a BattleTech mech).Next â€” and you can see all this and more in the video above â€” itâ€™ll straddle a shallow pit teeming with deadly lizards and snakes (okay, just rubber ones, but still scary!) using both legs, edging past the gap fluidlyâ€¦Meet Pet-Proto, a Boston Dynamics-designed bipedal robot, related to the companyâ€™s anthropomorphic PETMAN project.Â Itâ€™s capable of analyzing and navigating complex obstacle courses, making decisions autonomously, and with, if not the actual dexterity of a human being, at least the functional semblance of one.Itâ€™s all part of DARPAâ€˜s (Defense Advance Research Projects Agency) work to promote its ambitious DARPA Robotics Challenge (DRC), which initiated its second phase on Wednesday, Oct. 24 since launching back in April. The contest will test the sort of capabilities illustrated above and others â€œinÂ a series of tasks that will simulate conditions in a dangerous, degraded, human-engineered environment.â€?â€œRobot enthusiasts, the time has come,â€? says DARPA on its website. â€œThe DARPA Robotics Challenge (DRC) begins today. Will you be part of it?â€?Itâ€™s just the start of whatâ€™ll amount to a two-year ordeal for teams competing to design, tweak and test rescue either humanoid or non-humanoid robots: ultra-agile, durable mechanical servants capable of going where most humans wouldnâ€™t dare, say exploring collapsed mines and helping to rescue trapped miners, defusing improvised explosive devices, or working around nuclear meltdown incidents like Fukushima, Chernobyl or Three Mile Island.The prize? A cool $2 million. All teams have to do is create robots that can perform tasks like: drive a utility vehicle, climb a wobbly industrial ladder, shatter a concrete wall using a power tool, cross a debris-littered field, isolate and close a valve in a leaking pipe and replace industrial equipment. Simple, right?If youâ€™re from the future, maybe, but todayâ€™s robots do almost none of these things â€” ergo DARPAâ€™s two-year challenge, designed to make some or all of the above a reality, and which as of Wednesday just got even more interesting.Take the newly announced Track C, which allows participants to compete without touching actual machine parts. Itâ€™ll involve using something DARPA calls its â€œDRC Simulator,â€? an open-source, cloud-based robotics design tool, and all you need to work it is a little software development know-how and an appetite for robotic simulation.â€œThe DRC Simulator is going to be one of DARPAâ€™s legacies to the robotics community,â€? says DRC program managerÂ Gill Pratt. â€œOne of DARPAâ€™s goals for the Challenge is to catalyze robotics development across all fields so that we as a community end up with more capable, more affordable robots that are easier to operate. The value of a cloud-based simulator is that it gives talent from any location a common space to train, design, test and collaborate on ideas without the need for expensive hardware and prototyping. That opens the door to innovation.â€?The DRC Simulator has only been in development for a month, according to DARPA, and its future already sounds bright, with a melange of improvements in the offing, including new â€œmodels of robots, perception sensors and field environmentsâ€? that should ultimately allow the simulator to â€œfunction as a cloud-based, real-time, operator-interactive virtual test bed that uses physics-based models of inertia, actuation, contact and environment dynamics.â€?What about Pet-Proto? As its name suggests, itâ€™s just a prototype â€” part of how DARPAâ€™s promoting the contest. Pet-Proto is really a predecessor to something theoretically more sophisticated that Boston Dynamics is working on, dubbed â€œAtlas.â€?DARPA says challenge participants selected to advance will receive Government Funded Equipment (GFE) â€œin the form of a modified robot platform based on the Atlas robot.â€? In other words, if you make it through the initial hurdles, you get to play with (and work on) something likeÂ that.This video is unlisted. Only those with the link can see it. Learn moreCompetition in the low-cost tablet space has been heating up for a while now thanks to strong new hardware from the likes of Asus, Google, and Barnes & Noble, but it seems the time has come for the Kindle Fire hucksters at Amazon to go on the offensive against a very prominent rival: Appleâ€™siPad mini.The company has recently given its homepage a facelift with a very prominent comparison between the 7-inch Kindle Fire HD and the iPad mini sitting right at the top. Most of it is pretty tame and points out the disparity in features between the two tablets (ex. the Fire HD sports a higher resolution display and smarter speaker layout than the mini), but the kicker here is the quote Amazon used to drive its point home. Itâ€™s a brief snippet culled from a Gizmodo post by Brent Rose on Appleâ€™s perceived hypocrisy when it came to crafting a smaller tablet:For better or worse Amazon lopped off the beginning of that paragraph, which began with â€œAre. You. Fucking. Kidding. Me.â€? Sort of a shame, methinks â€” it wouldâ€™ve made Amazonâ€™s point that much stronger, though Iâ€™m pleased as punch to see Amazon allow such a prominent reference to balls on its front page.Itâ€™s hardly the first time that Amazon has sought to position its tablets as a strong competitor to the iPad â€” Amazon CEO Jeff Bezos noted in an interview with AllThingsD that he felt the 8.9-inch Kindle Fire HD was â€œthe best tablet at any priceâ€? â€” but this move represents a considerable change in tone for Amazon. Then again, this sort of trash-talking seems to be quickly becoming par for the course in the industry â€” when Apple officially revealed the iPad mini earlier this month, SVP of Worldwide Marketing Phil Schiller jabbed at smaller tablets (and Google and Asusâ€™s own Nexus 7 in particular) by basically crapping on the sorts of experiences that theyâ€™re capable of delivering.â€œOthers have tried to make tablets smaller than the iPad, and theyâ€™ve failed miserably,â€? Schiller noted on-stage.One has to wonder what exactly has prompted Amazon to go on the offensive, and it may be that surging sales momentum may have given the company a shot in the proverbial arm. According to a statement Amazon released on Friday, the 7-inch Kindle Fire HD enjoyed its biggest day of sales since launch on the same day that Appleâ€™s iPad mini announcement took place. It went on to note that sales for the Seattle companyâ€™s tablet lifted â€œ3x week over weekâ€? on the day of Appleâ€™s event, though exactly what that works out to in numbers is unclear since Amazon tends to be infuriatingly vague when it comes to concrete Kindle sales figures.With a season of unabashed consumerism nearly upon us, weâ€™ll soon see if Amazonâ€™s new approach to appealing to would-be tablet purchasers pans out. In the meantime, hereâ€™s a tip for anyone from Amazon who may be reading this â€” next time you need an feisty anti-iPad quote or five, you should spend some time checking out our comments section. Pure gold, Iâ€™m telling you.This video is unlisted. Only those with the link can see it. Learn moreThe Verge has learned that Google's Android event scheduled for Monday in New York Cityhas been canceled due to Hurricane Sandy. On Friday, New York Governor Andrew Cuomo declared a state of emergency in response to the incoming storm, and Google's event was set to take place on a waterfront pier, which is now in an evacuation zone. Monday won't be a total loss, though: we'll be in San Francisco to cover Microsoft's Windows Phone 8 launch,which should be able to evade Sandy's wrath. It's the second time Google has postponed a launch event in recent memory â€” last year it moved its Ice Cream Sandwich event after the death of Steve Jobs. We'll keep you updated on Google's plans to reschedule, but in the meantime, grab your jackets and head somewhere dry.Update: Google provided the following statement about the event tomorrow:We are canceling our Monday morning event in New York due to Hurricane Sandy. We will let you know our plans as soon as we know more.Preface:Â  We hope and expect that the severity of the hurricane is being overblown, and that the nuclear plants in the Northeast will ride out the storm without any incident.We noted Friday thatÂ more than a dozen nuclear plants are near Hurricane Sandyâ€™s path.Nuclear expert Arnie GundersenÂ says that there are actuallyÂ 26 nuclear plants in the path of the hurricane, and that the spent fuel pools in the plants donâ€™t have backup pumps (summary viaÂ EneNews):EneNews alsoÂ reports that the hurricane is forecast to directly hit the Oyster Creek nuclear plant and that â€“ while the plant is currently shut down for refueling â€“ it still might very well have new, very hot fuel in the fuel pools:WithÂ Oyster Creek shut down for refueling starting last week, hot fuel may have been placed in the fuel pool quite recently. The unit at Oyster Creek is the same as Fukushima Daiichi No. 1: â€œOyster Creek is one of the oldest US nuclear plants and is the same design as Fukushima unit 1.â€?-SimplyInfoRemember, Fukushima reactor number 4 wasÂ shut down for maintenance when the Japanese earthquake hit.Â  And yet the fuel pools at reactor 4 are in such precarious condition that theyÂ pose aÂ giantthreat to humanity.(Ad) Depopulation is Not Left or Right, it Effects us All â€”Â LEARN MOREHurricane Sandy is not very intense in terms of wind speed.Â  But the storm is so large, that storm surges could beÂ 11 feet high.Obviously, the path of the hurricane could veer substantially, and may not hit Oyster Creek after all â€¦ weather forecasting is not an exact science.Â  But Gundersen argues that nuclear plants in Pennsylvania and New Jersey are in the most danger given current projections.As weÂ noted Friday, the Salem and Hope Creek plants in New Jersey are also near the path of the hurricane, as are the following plants in Pennsylvania:Another concern is the Millstone plant in Connecticut:EneNews summarizes the situation in a post entitled â€œOfficials in Connecticut warn of giant 16-foot storm surge, with 15-foot waveson top of that â€” Stateâ€™s nuclear plant directly exposed on oceanâ€œ:In a message sent to residents Sunday afternoon, [Norwalk, Connecticut] Mayor Richard A. Moccia warned of a 16-foot storm surge brought to land by Hurricane Sandy. [...] â€œI have declared a state of emergency in the City,â€? he said. â€œCoastal flooding from this event will peak at midnight on Monday night and will be worse than any flooding Norwalk has experienced in recent history. If you have ever experienced flooding before it is likely you will be flooded in this storm.â€? Moccia said that the storm will be equal to a Category 4 hurricane and will produce 16 foot storm surges. â€œThe mood during the meeting was tense as federal officials estimated a 13-foot storm surge for WestportÂ  [Connecticut] -â€“ 3 or 4 feet higher that the inundation from Storm Irene last year,â€? a news release said. â€œThis is an unprecedented storm,â€? said [First Selectman Gordon Joseloff], following his teamâ€™s briefing with federal and state disaster preparedness officials. â€œThis will be a storm of long duration, high winds and record-setting flooding. Take Storm Irene from last year and double it.â€? he said. [...] The town is bracing for at least three waves of flooding, beginning with the high tide at midnight Sunday, the announcement said. [... An] estimated 15-foot wind-driven waves [...] are expected on top of the storm surge. According to the Weather Channelâ€™s latest map, a 6 to 11 foot water level rise is forecast for the Connecticut coastline. This is theÂ highest increase of any area in the US. The stateâ€™s only nuclear power plant is located directly on the ocean, see marker â€˜Aâ€™ below:Millstone Power Station, Connecticutâ€™s sole nuclear plant, is focusing onÂ how best to guard against flooding and earthquakes to comply with tougher federal standards following the nuclear plant meltdown in Japan last year, the new chief of the power station said in an interview. Millstone isÂ assessing its ability to withstand flooding and â€œseismic events,â€? Stephen E. Scace, who took over as site vice president at Millstone in January, told The Associated Press on Thursday. He expects upgrades and installation of new equipment in the next three to four years.Join theintelhub.com FORUMS to Talk About Articles Like This One - ENTER NOWIn the last five weeks, Apple has revamped its entire product lineup with new iPods, iPhones and computers. But on Thursday it said those products would be more expensive to make, nibbling into its ample profits.That forecast for the holiday quarter was the main blemish on an otherwise solid financial report. Apple said its fiscal fourth-quarter profit jumped 24 percent, largely because of a surge in sales of the iPhone, a product that now accounts for nearly half of the companyâ€™s sales.The quarter ended Sept. 29 was the first to reflect sales of the iPhone 5, which was introduced Sept. 21. Apple has struggled to deliver enough of the devices to meet customer demand, making them tough to find in many retail stores. The companyâ€™s shares have fallen 9 percent since the product hit the market, in part because of investor concerns about short supply.In a conference call with analysts, Timothy D. Cook, Appleâ€™s chief executive, said that demand for the new iPhone was â€œextremely robustâ€? and that the company had a significant number of back orders for it. He said production had picked up substantially since earlier this month.The profit report was slightly below analystsâ€™ expectations, and Appleâ€™s stock was largely unchanged in after-hours trading. It fell 1.2 percent to $609.54 in regular trading.Underscoring how drastically Appleâ€™s business has been transformed by mobile products, revenue from the iPhone rose 56 percent to $17.13 billion, making up 48 percent of the companyâ€™s total revenue. It sold 26.9 million iPhones, 58 percent more than a year earlier.Apple said its net income was $8.22 billion, or $8.67 a share, compared with $6.62 billion, or $7.05 a share, a year ago. Revenue for the period rose 27 percent to $35.97 billion, and revenue for the full fiscal year was $156.5 billion. To put that in perspective, Appleâ€™s revenue for the year exceeded that of Microsoft, Google and Facebook combined.Analysts surveyed by Thomson Reuters had expected Apple to report earnings of $8.75 a share and revenue of $35.8 billion. The results were well ahead of Appleâ€™s own forecast of $7.65 a share in earnings and $34 billion in revenue for the period.It was the companyâ€™s projections for its current holiday quarter that raised eyebrows among investors. The company forecast earnings of $11.75 a share and revenue of $52 billion for the period, typically its biggest of the year. That implied a gross profit margin of 36 percent, lower than the 40 percent margin Apple reported in the fourth quarter, said Rob Cihra, an analyst at Evercore Partners.Apple executives attributed the decline to higher costs associated with building its new products, which tend to get less expensive over time as Apple gets better at manufacturing them. While this pattern is familiar, the company said the sheer magnitude of its product-line overhaul made the decline in gross margin more severe. In addition to the new iPhone and iPods, Apple has announced new Macs and a smaller version of the iPad, called the iPad Mini.Mr. Cihra said the company might be lowballing its estimates. â€œThey have a history of beating their guidance,â€? he said.Apple said its revenue from the iPad rose 9 percent to $7.51 billion.As with most Apple products, the iPad Miniâ€™s arrival was widely anticipated after months of rumors and leaks about the product in the news media. Mr. Cook said the rumors led people to postpone tablet purchases.At the iPad Mini event, Apple hinted that sales of the iPad had been slower than expected when it revealed that the company had sold 100 million of the devices since their introduction two years ago, causing some analysts to trim their forecasts for the quarter.â€œI think on balance it was pretty in line with reduced expectations,â€? said Toni Sacconaghi, an analyst at Bernstein Research.At a starting price of $329, the iPad Mini is more expensive than many people were hoping, and well above the sub-$200 bar for smaller tablets set by Amazon and Google. But the device could still open the iPad to a new swath of customers who were put off by the larger size of the original.The wind map is a personal art project, not associated with any company. We've done our best to make this as accurate as possible, but can't make any guarantees about the correctness of the data or our software. Please do not use the map or its data to fly a plane, sail a boat, or fight wildfires :-) If the map is missing or seems slow, we recommend the latest Chrome browser. Surface wind data comes from the National Digital Forecast Database . These are near-term forecasts, revised once per hour. So what you're seeing is a living portrait. (See the NDFD site for precise details; our timestamp shows time of download.) And for those of you chasing top wind speed, note that maximum speed may occur over lakes or just offshore. If you're looking for a weather map, or just want more detail on the weather today, see these more traditional maps of temperature and windThis was aired in either 1991 (according to trash0) or 1987-8 (according to Barry VK2FP). Regardless, Julie (also famously known as "The Batman" on Sydney Australia CB radio in the early 1970s) passed away in 2006, but this was him at his best and most typical. He's gone but will never be forgotten by anyone who knew him!18/8/12: I've uploaded 14 photos of Julius taken in the early 1970s, to my Picasa web album. See them at http://tinyurl.com/vk2xbrThe Android news keeps coming in spite of Google's cancelled Android eventâ€”the company has just taken the wraps off of the Nexus 10 tablet, the 10-inch follow-up to the well-reviewed Nexus 7 tablet introduced in June. Unlike its ASUS-made cousin, the new Nexus 10 was manufactured by Samsung with Google's input, and will be available for $399 (16GB) and $499 (32GB) when it goes up for sale on November 13.The tech in the new tablet is definitely top-shelf material: it features one of Samsung's new Cortex A15-based Exynos 5 chips clocked at 1.7 GHz, and its quad-core Mali-T604 GPU helps to drive a 10.055-inch PLS display with a resolution of 2560x1600. This 300 pixel-per-inch screen has four times the number of pixels in a 1280x800 screen and edges out the Retina iPad's 264 pixels per inch. The tablet's CPU should compare favorably to the Apple-designed CPU cores in its A6 and A6X processors, and the GPU should at least be playing in the same field as the A5X and A6Xâ€”we won't know for sure how they all shake out until we actually have hardware in-hand to test with.Other specs common to high-end Android tablets are also present: 2GB of RAM, storage capacities starting at 16GB, NFC, 802.11n, and Bluetooth 4.0. There are front and rear-facing cameras (at 1.9 and 5 megapixels, respectively). It also has a 9,000mAh battery that Google says is good for nine hours of use. Like the Nexus 7, it lacks a microSD card slot, so the amount of storage you buy with it is the amount that it's stuck withâ€”it does have micro USB and micro HDMI ports, however. It's also running the enhanced version of Jelly Bean, Android 4.2, and as part of the Nexus program should get prompt operating system updates for the foreseeable future.This tablet is the first-ever 10-inch tablet to bear the Nexus branding, but it's not the first 10-inch tablet to run stock Android and get prompt updates: the honor belongs to the Motorola Xoom, which Google and Motorola released to showcase Honeycomb in early 2011. We had mixed feelings about the Xoom in our original review, but we were more impressed when we re-reviewed it after its Jelly Bean update rolled outâ€”we called it "the right software in search of the right hardware," and as long as it doesn't inherit the chintzy, flexible plastic of Samsung's Galaxy Note 10.1, the Nexus 10 might just be that hardware.Update: the original version of this article said that the Nexus 10 had a Super AMOLED display; it actually uses a plane-to-line switching (PLS) display.This was aired in either 1991 (according to trash0) or 1987-8 (according to Barry VK2FP). Regardless, Julie (also famously known as "The Batman" on Sydney Australia CB radio in the early 1970s) passed away in 2006, but this was him at his best and most typical. He's gone but will never be forgotten by anyone who knew him!18/8/12: I've uploaded 14 photos of Julius taken in the early 1970s, to my Picasa web album. See them at http://tinyurl.com/vk2xbrPhysicists at New York University have demonstrated a micro-tractor beam capable of pushing and pulling molecules.The system by David B. Ruffner and David G. Grier consists of a set of superimposed Bessel beamsâ€”beams which do not spread and are capable of self healing after partial obstructionâ€”which is able to push and pull tiny objects along its length.According to the project's abstract: "These optical conveyors have periodic intensity variations along their axes that act as highly effective optical traps for micrometer-scale objects."The duo's tractor beam is closer to the traditional science fiction concept of light-based transportation as it emits from a single source rather than relying on light from opposing points of origin to move the matter up and downstream. It is also reportedly more stable than other options:"Optical conveyors thus have the potential to out-perform optical tweezers, which cannot always achieve stable axial trapping," state Ruffner and Grier.While the current offering is only suited for moving microscopic particles, the team are already making suggestions to improve the mini tractor beam including improving speed of transportation by using a brighter conveyor and using higher order conveyors to transport oddly shaped objects.Right on schedule (ahem), Valve has begun requesting applications for the first Steam for Linux beta test. There are only 1,000 spots available, but the company is looking for "experienced Linux users" only -- presumably, ones that will be better at debugging than spilling zombie brains. So, if you've got a rig running Ubuntu 12.04 or above and decent Linux knowledge, head to the source link to register your interest.The French government has been causing a lot of headaches in Mountain View, California recently. The government believes it is unfair that Google (GOOG) receives advertising revenue from searches for news and may force the Internet giant to pay for the privilege of linking to its news sites. Google has threatened to remove all French news sites from its index, however, potentially eliminating 4 billion views per year. Eric Schmidt, the companyâ€™s chairman, is now reportedly planning on traveling to Paris next week to discuss the issue, according to Quartz. Fleur Pellerin, Franceâ€™s minister of technology, said that if Google can reach an agreement with French newspaper publishers, legislation would not be necessary.â€œWe donâ€™t want to appear as a country that is anti-Google,â€? Pellerin told Quartz. â€œObviously Google is a wonderful tool and Google is a major actor of the digital ecosystem. What I would suggest â€” and what Iâ€™m going to suggest to Google and to the press â€” is to start negotiating, to start discussions for maybe three months, and try to find an agreement on a negotiated basis. And if they donâ€™t, well weâ€™ll see.â€?LG Electronics bounced back to a profit in the third quarter on stronger-than-expected results from its handset division, which may be showing signs of turning around after several bumpy quarters.Overall the South Korean electronics conglomerate posted a net profit of around $142 million in the quarter, a major improvement over the loss of around $375 million the company posted in the year-ago period and beating analysts' estimates, according to Dow Jones Newswires. Total sales, however, fell 4 percent to $11.2 billion.It was the strong performance in LG's mobile division that stood out. The company's handset unit reported an operating profit of $19.02 million, up from an operating loss of $127 million in the year-ago period and $53.4 million in the second quarter. The handset unit posted sales of $2.07 billion, up 6 percent from the second quarter but down 9 percent year-over-year.Â LG shipped 14 million handsets in the quarter, better than the 13.1 million it had in the second quarter but down from the 21.1 million handsets it shipped in the third quarter of 2011. Still, LG said it is benefiting from higher sales of its LTE smartphones in South Korea, Japan and the United States. The company said that, despite increased expenses for marketing and R&D, the unit turned profitable "as a result of improved product mix and cost structure.""The biggest factor was their handset business returning to profit," Park Kang Ho, a Seoul-based analyst at Daishin Securities Co., told Bloomberg. "We thought their mobile business would at best break even. The overall product mix has improved and margins got better."LG, once the world's No. 3 handset maker, slipped to No. 5 in the second quarter. However, the company has been trying to shift to smartphones to increase its profitability and catch up to rivals like Apple(NASDAQ:AAPL)and Samsung Electronics.Â LG sold 7 million smartphones in the third quarter and expects smartphone shipments to grow in the fourth quarter, exceeding shipments of feature phones for the first time, LG CFO David Jung said, according to Bloomberg. "We're trying to step up our marketing efforts to make sure our product competitiveness will lead to revenue growth," he said.Looking ahead to the fourth quarter, LG said it expects both increased consumer demand and competition as OEMs push out their flagship products for the holiday shopping season. LG said it will focus heavily on its high-end Optimus G and Optimus Vu 2 products. LG is also widely rumored to be building a Nexus-branded smartphone for Google (NASDAQ:GOOG), called the Nexus 4, which reports have suggested Google will announce Oct. 29.By making a Nexus device, LG could be able to raise its profile at a time when it is trying to gain more support from U.S. carriers and bolster its brand. Verizon Wireless (NYSE:VZ) recently launched the $200 LTE-powered LG Intuition "phablet," LG's first device in the larger-than-a -smartphone-but-smaller-than-a-tablet category in the United States. Both AT&T Mobility (NYSE:T) and Sprint NextelÂ (NYSE:S) will launch the Optimus G, LG's 4.7-inch screenÂ smartphone that sports Qualcomm's (NASDAQ:QCOM) 1.5 GHz Snapdragon S4 Pro quad-core processor. Further, T-Mobile USA said it will launch the Optimus L9 for $80, which is part of LG's "L-Series" of phonesÂ that run on Android 4.0 and sport a dual-core 1 GHz processor and 4.5-inch display."Today's results show that it doesn't have to be Appleor Samsung to make profits in smartphones," Hong Sung-ho, an analyst at I'm Investment & Securities, told Reuters."LG won't be able to earn double digit profit margin in handsets as Apple and Samsung do. Still, LG proved it has the potential to stand out among its second-tier peers of Huawei, ZTE, Motorola etc., with its manufacturing competitiveness."For more: - see this release - see this presentation (PDF) - see this Bloomberg article - see this Reuters article - see this WSJ article (sub. req.)Special Report:Â Wireless in the third quarter of 2012 Related Articles: Report: LG is working with Google on a Nexus smartphone Report: Google to expand Nexus device program to multiple OEMs LG to push high-end Optimus G to the U.S. in November LG unwraps quad-core, LTE Optimus G 'superphone' Verizon unveils LG Intuition phablet in challenge to Samsung's Galaxy Note LG posts Q2 loss in handset unit as sales drop LG struggles in Q3, pins hopes on LTE smartphonesCOLUMBIA, S.C. -- By the time the computer crimes office of the U.S. Secret Service discovered a problem Oct. 10, a foreign hacker had taken a database from the Department of Revenue's computers exposing 3.6 million Social Security numbers and 387,000 credit and debit card numbers, one of the largest computer breaches in the state or nation.The breathtaking breach has launched a high-stakes international criminal investigation and prompted South Carolina Gov. Nikki Haley, whose administration had another massive theft of confidential information at another cabinet agency earlier this year, to order an assessment of all the state's computer systems.Many questions remain unanswered. Officials are still unsure the state's system is entirely buttoned up. And investigators and the governor declined to answer any substantive questions about the investigation -- including whether the database may have been copied and whether taxpayers paid a ransom to the hacker to retrieve it.Haley administration officials, the State Law Enforcement Division and the Secret Service disclosed the breach publicly Friday, raising questions about why officials kept it shrouded in secrecy while the records of millions of the state's residents were nakedly exposed, and whether the system was now secure and whether taxpayers remain at risk.The breach, officials said, potentially affects anyone who has filed a South Carolina tax return since 1998. Even weeks into the investigation and during Friday's public unveiling of it, law enforcement investigators and Haley administration officials couldn't say who, or precisely how many, are at risk of having their identities stolen.All but 16,000 of the credit and debit cards, officials said, were encrypted -- meaning they were coded against being used by outside groups. But they said they don't know whether hackers could break the encryption. The remaining credit cards are so old, investigators said, that they don't believe they are at risk of being used.None of the Social Security numbers were encrypted and officials said they are studying whether they can do that -- raising other questions about whether safeguards exist that weren't used.Residents shocked"South Carolina has come under attack but South Carolina is going to fight back in every way possible to make sure every taxpayer is taken care of," said Haley.Taxpayers will bear the cost of fighting back. The state government is paying for the cost of the credit-protection service for millions of residents and the burden to taxpayers couldn't be determined by GreenvilleOnline.com on Friday.Reactions from taxpayers ranged from shock and concern to resigned eye-rolling about their government in Columbia. Some residents expressed doubt about whether state government is taking enough steps to safeguard sensitive personal information."It makes me question the state and how it was securing that kind of information," said Misha Morris, a recent Clemson graduate and Seneca, S.C., resident. "It's scary."Officials refused to go into details of what they have so far discovered about how the breach occurred and who was behind it, but said the August intrusion was basically a scouting mission by the hacker."To the best of our knowledge, it was kind of a look-see, what's here," said James Etter, director of the Department of Revenue. "They were not doing anything with the data in August. They got in, 'Now, let's see what we've got.' "Three more breaches followed -- the first, another "browse" on Sept. 3, Etter said, and then two more, concluding with the data theft on Sept. 13, Etter said.Authorities somehow discovered the intrusions on Oct. 10. A Secret Service agent, Mike Williams, said the agency's computer crimes office first uncovered the intrusion and notified state authorities.The Department of Revenue contacted a computer security firm recommended by the Secret Service -- Mandiant -- to "find and fix the leak."Outside expertsMandiant continues to work to determine what exactly was taken and whether numbers were stolen or just exposed."We're making great progress," said Marshall Heilman, director of the firm. "Those investigations are measured in weeks and months, not hours and days."State Law Enforcement Division Chief Mark Keel and the Secret Service's Williams refused to answer questions about the investigation in an exclusive interview with Gannett Co. Inc.'s GreenvilleOnline.com and WLTX in Columbia, which first received a tip about the breach, including the country where they believe the hacker resides."It would be inappropriate for me to comment," Keel said. "We have a very sensitive investigation. Obviously, we are making every effort that we can to bring someone to justice for this breach. And it would be inappropriate for me to comment any further."Public kept in the darkAsked why they didn't notify the public, Keel and Williams said they decided to notify the public after the investigation reached a series of "benchmarks." They said it was in the public's best interest that the investigation proceed further before public notification."We believed that during the course of the investigation that there were these benchmarks that if we could reach, we would do a better job of trying to protect the public," Keel said, declining to explain what the benchmarks were.South Carolina, like many states, doesn't operate a centrally controlled system. Instead, most of the 100 boards, agencies, universities and commissions operate their own systems that officials say complicates security measures.Taxpayers are being asked to call 1-866-578-5422 to determine whether their information is affected. The state will provide those affected with one year of credit monitoring and identify-theft protection, officials said.Greenville, S.C., resident Ashley Reynolds said she was relieved to hear about the credit monitoring and identity-theft protection being offered."It makes you sick. You just hear nightmares of people trying to recover from identity theft," she said. "It can be years of trying to reclaim your good status."But names can never hurt meMy bf is working in Abu DhabiI hope you get your wish. If you have any more wishes, could you wish that this fucking war ends immediately?* Droog4 kicked by KillaZ (do you use that mouth to kiss your mom?){arrow} this is the first amarican i see like to stop the war{Droog4} hmmmm i guess for the last 5 years of the Vietnam War lots of people were saying: Well, you're right, this really is a sucky terrible war, but we can't back out now.{Droog4} okay i am gonna find some other Commie Pinko Lefty Peaceniks to talk to about ending this fu**ing war like by tomorrow at 9:30 amgot disconnected but managed to get back on Undernet]here a big Lag (delay) tsunami hit Undernet. I could tell I was still connected, but it was taking a long time -- minutes or longer -- for anyone to get my messages or reply to them. But before I left ...and I never saw his nick on Undernet again, but that doesn't mean anything, there are typically 50,000 people on Undernet at any given moment. But I never saw Ygor again.What hurts the most are the vile threats and insults hurling back and forth through the Chat-o-Sphere in times of war. It's still much better than the actual warbut there is a huge volume of particularly ugly hatred especially reserved for Peace Assholes like me. A Hezbollah guy would rather French-kiss an Israeli soldier than read Peace Crap from anybody, and ditto the feelings of an IDF soldier.Once war starts, it's like when sex starts -- nobody wants it interrupted or stopped. It just feels so good, you want it to just go on and on and on and on and on. Peace doesn't offer any emotions that feel nearly as good.Peace is complicated and confusing. Israeli Jews will have to learn how to be day-to-day neighbors with Palestinian and Arab Muslims. Hezbollah will have to learn how to be day-to-day neighbors with Lebanese Christians and Druse. Shia and Sunni will have to go shopping for groceries at the same market, without firearms. I'm not joking when I say that's going to be incredibly hard.War is simple and easy. It's so easy that the United Nations is trying to make every country and combatant on Earth stop using Child Soldiers younger than 16. Without much success. The government of Sri Lanka was just accused of using Child Soldiers, a nasty rap previously reserved for the Tamil Tigers. In Africa, the Lord's Resistance Army usually wins the prize for accusations of abducting children to be soldiers and sex slaves. The Lord's Resistance Army is a religious movement, and teaches the child soldiers that if they believe, enemy bullets cannot harm them.But war is so easy that little boys make excellent soldiers, and little boys and girls make excellent sex partners for older soldiers. You don't need to be mature to be an effective soldier; in fact maturity usually just gets in the way.Tonight's Relapse ... well, I really didn't want any war or any politics or any anger or any flame wars. I didn't want to read KILL THE JEWS or KILL THE FUCKING SAND NIGGERS. I just wanted some easy, fun, innocent chat, so I didn't click on any of the Hot Button chatrooms. seemed safe. I'd been there before, and it's usually all and and and We somehow began singing musical theater songs from "My Fair Lady," and it was all very pleasant, but then I lost the first half of my chat because we were chatting about doors, and said she wished that someday she'd have a house with a purple front door, so I saidand the Bot instantly kicked me off the channel for using the F-word, and that means I lost the first 20 minutes of my #worldchat. But I was just kicked in the teeth, not banned forever, so I was able to re-join immediately.Meanwhile a boy from Jordan named was struggling along with some pretty bad English, but as it turned out, he reads and understands English a lot better than he types it.Jordan is almost entirely Arab and Muslim.Its next-door neighbors are . There's no war in Jordan. It even has a peace treaty with Israel. War in Iraq, war in Lebanon, but Jordan itself has stayed pretty peaceful, or at least pretty Lo-Violence. Not an easy trick. Uneasy lies the head that wears that crown.But please note so many interesting things more than my bad manners and vulgar mouth.See all these people from all over the , from every Time Zone, just chatting (or trying to chat) with each other.Here I am in Northampton Massachusetts USA, and in this little college town I could get on the phone and have 50 Lefty Peacenik Quaker Commies in my living room in a half-hour.The Congressional election a few weeks ago made it abundantly and noisily clear that all over the United States of America there are people who are very pissed off about the War in Iraq.But read on down to what the Jordanian kid typed.He has a computer. He has a television. He has a radio. He has a phone. His English is pretty competent.But read on down to what typed.******** Now talking in #worldchat* Topic is 'Welcome to #Worldchat (http://www.worldchat.org) enjoy your stay.'* Set by KillaZ on Sun Nov 19 11:29:35{Droog4} whoops sorry{girlscout} hehe{gumnaam} salaam* catty_29 has quit IRC (Quit){girlscout} people need to believe in it again for it to stop{Droog4} salaam gumnaam* ieza80 has joined #worldchat{gumnaam} h r u{Droog4} pretty good gumnaam how r u, did you have good Ramadan and Eid?* SwEeTy_InDiG has left #worldchat* Fevil has left #worldchat{gumnaam} yup{Droog4} excellent{gumnaam} where u from* ieza80 has quit IRC (Quit)* X sets mode: +l 68{Droog4} USA, sorta near Boston{Droog4} u in PK?* neat40 has joined #worldchat{gumnaam} yup{gumnaam} in karachi{girlscout} what's boston like?* neat40 has left #worldchat{Droog4} oh actually it's a real interesting and entertaining city{girlscout} I have never been there* Fevil has joined #worldchat{gumnaam} yaaaaaaa{Droog4} lot of Big Brain Places there, MIT, Harvard{gumnaam} u r rite{girlscout} *nod** Fevil has left #worldchat{Droog4} aha gumnaam has been to Boston* SwEeTy_InDiG has joined #worldchat{gumnaam} ok{gumnaam} friend{gumnaam} i have to go{ashley} hi{Droog4} arrow i can fill a very big stadium with americans who want to stop the war{gumnaam} ALLAH HAFIZ to all{Droog4} salaam gumnaam{girlscout} they want to stop it for the wrong reasons though{arrow} droog4{Droog4} there is no wrong reason to stop any war* pink_24 has joined #worldchat{girlscout} I don't condone war in general* X sets mode: +l 70{girlscout} but what's done is done{girlscout} it seems even worse to back out now* Droog4 confesses he is a bit of a peacenik refusenik commie pinko lefty* Bojan_ww has joined #worldchat{gumnaam} droog ALLAH HAFIZ answer is ALLAH HAFIZ* pink_24 has left #worldchat{gumnaam} not salaam{Droog4} gumnaam thank you for the free lesson, i really need it, my Urdu really sux{gumnaam} okz{girlscout} lol{gumnaam} ALLAH HAFIZ{briar} hi{Droog4} Allah Hafiz to you also{gumnaam} girlscout y u laghing{girlscout} just because{Droog4} girlscout is guessing i know zero words of Urdu{gumnaam} dont laugh* girlscout chuckles{girlscout} why not?{girlscout} don't tell me what I can and cannot do{girlscout} I happen to like to laugh* isloo has joined #worldchat{girlscout} heh* zeek has joined #worldchat* X sets mode: +l 72* KFEPKFEW has joined #worldchat{GrimLurkin} Group hug my ass. Die.* SwEeTy_InDiG has quit IRC (Quit)* solitario_77 has joined #worldchat* zeek has left #worldchat* Crazy_Devil_ has quit IRC (Quit){KFEPKFEW} DFDDDD{GrimLurkin} Droog4 I'd appreciate if you kept such political matters under wraps.* briar has left #worldchat* X sets mode: +l 70{GrimLurkin} Or I will escort you out.{KFEPKFEW} HI* natashe has quit IRC (Ping timeout){gumnaam} Droog4 i thnk she dont have sense to talk any person* jane has left #worldchat* durb1 has quit IRC (Ping timeout){Droog4} gumnaam i have just been warned not to talk politics here or i will be kicked, banned, sodomized and made to wear polka-dot clothes.* Tommy} has quit IRC (Read error: EOF from client)* kaYaL_viLLi has joined #worldchat{gumnaam} okz* kaYaL_viLLi has left #worldchat{GrimLurkin} Humerous as that was, don't test my patience.* ComicS_GirL has joined #worldchat* KFEPKFEW has left #worldchat* X sets mode: +l 66* ishi^_^ has joined #worldchat{gumnaam} tum kabhi aye ho khi ya pk Droog4{GrimLurkin} You've gotten a lot more warning than others woul dhave gotten.{Droog4} okay chill our grim{Droog4} our = out{GrimLurkin} Thank you.{GrimLurkin} =)* FayRa has joined #worldchat{Droog4} gumnaam, speaking Urdu is a good way to get around the censorship, but there is just one tiny little problem with that ..........* X sets mode: +l 68* co_cr_cw_ml has left #worldchat* SweetieDoll has joined #worldchat* ComicS_GirL has quit IRC (Quit)* Chastity_Sun has quit IRC (Quit)* gumnaam has quit IRC (Quit)* layla92 has joined #worldchat* ruthie has joined #worldchat{layla92} who from malaysia in here{ruthie} halleeerr* vdvdv is now known as erie^* chiquilla has joined #worldchat* Droog4 leaps off the roof of Petronas Tower{layla92} ...{layla92} lalalalalala{chiquilla} hola!{Droog4} hola chiquilla* MrLuvr has left #worldchat* MATET has joined #worldchat* ComicS_GirLy has joined #worldchat* arrow has left #worldchat{MATET} hello{chiquilla} hace mucho tiempo que no entraba a este lugar* IR-45m has joined #worldchat* layla92 has left #worldchat* ishi^_^ is now known as he_she* he_she has quit IRC (Quit)* MATET has quit IRC (Quit)* X sets mode: +l 66* ruthie has quit IRC (Read error: Connection reset by peer)* melissa27fph has quit IRC (Quit)* X sets mode: +l 64* ComicS_GirLy has quit IRC (Quit)* kerei_f has left #worldchat* X sets mode: +l 62* cute_bi has quit IRC (Quit)* big__dck has joined #worldchat* X sets mode: +l 54* KillaZ sets mode: +b *!*@*.satgate.net* M_M was kicked by KillaZ (Blacklisted- Pervertistan){arrow} sory man are you english{Droog4} nope, worse{Droog4} USA{Droog4} u?{arrow} im frome jordan{Droog4} salaam how you doin?{Droog4} i wanna see Amman and i wanna see Petra{arrow} itry in this chat to speak english{Droog4} you're doing a lot better than my Arabic{arrow} patra very baetiful{Droog4} alf layla iwa layla{arrow} romans city{Droog4} did the Romans build Petra? thanks{arrow} no iam not mean roman{Droog4} they show Petra in lots of Hollywood movies{arrow} tray to visy patra and jarash om qes* Droog4 tries to find jarash om qes on a Map{Droog4} I found Jerash!!!No such nick{arrow} plz your email{Droog4} oh{Droog4} hmmmmm{Droog4} hey -- I found Jerash on the map!{Droog4} it's in the North!{Droog4} (you know that){arrow} thank{Droog4} bobmerk@earthlink.net{Droog4} yeah i respect your No Politics rule{Droog4} i'm an Army vet from the Vietnam War{Droog4} wasted young american lives is a very real thing for me{Droog4} i want it to stop instantly{Droog4} here is what Staying The Course does: http://www.thememoryhole.org/war/coffin_photos/dover/{Droog4} their families and sweethearts will never see them again{Droog4} i lost friends and still miss them bitterly{Droog4} the kid arrow from jordan said he'd never seen an american on irc who wanted to end the war{Droog4} i wanted him to know there are lots like me{Droog4} this is where i speak about these things: http://vleeptronz.blogspot.comAMD Changes Compute Landscape: First to Deliver both x86 and ARM Processors for the Data CenterOn October 29, 2012, AMD announced it will design 64-bit ARMÂ® technology-based processors in addition to its x86 processors for multiple markets, starting with cloud and data center servers.Just as AMD introduced the industryâ€™s first mainstream 64-bit x86 server solution with the AMD Opteronâ„¢ processor in 2003, AMD will be the only processor provider bridging the x86 and 64-bit ARM ecosystems to enable new levels of flexibility and drive optimal performance and power efficiency.AMD is uniquely positioned to offer the most flexible and complete processing solutions for the modern data center based on the companyâ€™s deep 64-bit processor knowledge, years of server development experience, and industry-leading AMD SeaMicro Freedomâ„¢ supercompute fabric.AMDâ€™s first ARM-based server CPU is targeted for production in 2014.SAN FRANCISCO â€” I.B.M. scientists are reporting progress in a chip-making technology that is likely to ensure that the basic digital switch at the heart of modern microchips will continue to shrink for more than a decade.The advance, first described in the journal Nature Nanotechnology on Sunday, is based on carbon nanotubes â€” exotic molecules that have long held out promise as an alternative to silicon from which to create the tiny logic gates now used by the billions to create microprocessors and memory chips.The I.B.M. scientists at the T.J. Watson Research Center in Yorktown Heights, N.Y., have been able to pattern an array of carbon nanotubes on the surface of a silicon wafer and use them to build hybrid chips with more than 10,000 working transistors.Against all expectations, silicon-based chips have continued to improve in speed and capacity for the last five decades. In recent years, however, there has been growing uncertainty about whether the technology would continue to improve.A failure to increase performance would inevitably stall a growing array of industries that have fed off the falling cost of computer chips.Chip makers have routinely doubled the number of transistors that can be etched on the surface of silicon wafers by shrinking the size of the tiny switches that store and route the ones and zeros that are processed by digital computers.The switches are rapidly approaching dimensions that can be measured in terms of the widths of just a few atoms.The process known as Mooreâ€™s Law was named after Gordon Moore, a co-founder of Intel, who in 1965 noted that the industry was doubling the number of transistors it could build on a single chip at routine intervals of about two years.To maintain that rate of progress, semiconductor engineers have had to consistently perfect a range of related manufacturing systems and materials that continue to perform at evermore Lilliputian scale.The I.B.M. advance is significant, scientists said, because the chip-making industry has not yet found a way forward beyond the next two or three generations of silicon.â€œThis is terrific. Iâ€™m really excited about this,â€? said Subhasish Mitra, an electrical engineering professor at Stanford who specializes in carbon nanotube materials.The promise of the new materials is twofold, he said: carbon nanotubes will allow chip makers to build smaller transistors while also probably increasing the speed at which they can be turned on and off.In recent years, while chip makers have continued to double the number of transistors on chips, their performance, measured as â€œclock speed,â€? has largely stalled.This has required the computer industry to change its designs and begin building more so-called parallel computers. Today, even smartphone microprocessors come with as many as four processors, or â€œcores,â€? which are used to break up tasks so they can be processed simultaneously.I.B.M. scientists say they believe that once they have perfected the use of carbon nanotubes â€” sometime after the end of this decade â€” it will be possible to sharply increase the speed of chips while continuing to sharply increase the number of transistors.This year, I.B.M. researchers published a separate paper describing the speedup made possible by carbon nanotubes.â€œThese devices outperformed any other switches made from any other material,â€? said Supratik Guha, director of physical sciences at I.B.M.â€™s Yorktown Heights research center. â€œWe had suspected this all along, and our device physicists had simulated this, and they showed that we would see a factor of five or more performance improvement over conventional silicon devices.â€?Carbon nanotubes are one of three promising technologies engineers hope will be perfected in time to keep the industry on its Mooreâ€™s Law pace. Graphene is another promising material that is being explored, as well as a variant of the standard silicon transistor known as a tunneling field-effect transistor.Dr. Guha, however, said carbon nanotube materials had more promising performance characteristics and that I.B.M. physicists and chemists had perfected a range of â€œtricksâ€? to ease the manufacturing process.Carbon nanotubes are essentially single sheets of carbon rolled into tubes. In the Nature Nanotechnology paper, the I.B.M. researchers described how they were able to place ultrasmall rectangles of the material in regular arrays by placing them in a soapy mixture to make them soluble in water. They used a process they described as â€œchemical self-assemblyâ€? to create patterned arrays in which nanotubes stick in some areas of the surface while leaving other areas untouched.Perfecting the process will require a more highly purified form of the carbon nanotube material, Dr. Guha said, explaining that less pure forms are metallic and are not good semiconductors.Dr. Guha said that in the 1940s scientists at Bell Labs had discovered ways to purify germanium, a metal in the carbon group that is chemically similar to silicon, to make the first transistors. He said he was confident that I.B.M. scientists would be able to make 99.99 percent pure carbon nanotubes in the future.This post has been revised to reflect the following correction:Because of an editing error, an article on Monday about an I.B.M. breakthrough on chip design defined incorrectly Mooreâ€™s Law, an observation on technology advances named for Gordon Moore, a co-founder of Intel. Mooreâ€™s Law holds that the chip industry doubles the number of transistors it can build on a single chip at routine intervals of about two years â€” not intervals of about 12 to 18 months.Google is now in the same-day delivery business. In San Francisco, some people affiliated with Google can buy a product, using their phones or computers, and have it delivered to their homes in a matter of hours.Plans for the new service have been under way for more than a year. But it recently went live for some Google employees and their friends, according to two people briefed on the service who were not authorized to discuss it because Google has not yet publicly introduced it. At least one national apparel chain is involved, one of these people said. A Google spokesman, Nate Tyler, declined to comment.Google is just one company tackling same-day delivery. So are Wal-Mart Stores, Amazon.com, eBay and the United States Postal Service.Though the service propels Google into commerce, the company does not intend to operate warehouses or a shipping service but to team up with retailers and delivery companies. Several San Francisco retailers, including national chains, are participating in the program already.For shoppers, the service means they can avoid the trouble of driving to the store and some of the wait for items ordered online.Same-day delivery could help physical retailers, which have been under siege from e-commerce companies that offer the convenience of shopping without leaving home. But online retailers offering same-day delivery could make life even harder for physical retailers, because letting people own something the same day has become physical retailersâ€™ biggest remaining advantage.The reasons that Google is interested in same-day delivery are less obvious.Retail ads are a huge portion of Googleâ€™s business, but they are under threat from companies like Amazon, where shoppers increasingly go to search for products, bypassing Google. Also responding to the threat from Amazon, Google recently tried to improve its comparison shopping service by charging retailers to list their products there. It says retailers are more likely to list accurate and up-to-date items if they are paying.Additionally, Google has been trying to bridge the gap between the digital and physical worlds to better understand and profit from mobile ads. On computers, Google and advertisers know if a user clicks on an ad and visits or buys on another Web site. But they lose track of customers who look up a business or product on their phone and then put their phone away, walk into the store and buy something. Online ordering and delivery could help solve that problem.Scan this on your phone to join in with MMO BATTLE TANKS!MinecraftÂ isÂ the breakout indie game that combined simple game mechanics with an immersive, 3D sandbox experience. A WebGLÂ demoÂ shows that such an experience can be made possible in the browser.In what isÂ 850 lines of JavaScript combined with three.js, a leading WebGL library, visualization hacker AlteredQualiaÂ has recreated the basic MinecraftÂ experience in the browser. Thereâ€™s no interaction â€” no mining, monsters, or cute pigs or sheep â€” but youâ€™re able to fly around using the W, A, S and D keys and by left- and right-clicking the mouse.Even though WebGL might not achieve the same performance and beauty of games such as Halo or StarCraft, focusing on game mechanics can make even the simplest demo fun.We hope you weren't basing your calendar around Google's big Android event on October 29th. The company has confirmed to us that it's postponing the event to an as yet undetermined point in the future due to Hurricane Sandy, whose East coast arrival will follow so closely before the New York City gathering that Google isn't willing to take the chance on its big day. If you're experiencing a sense of dÃ©ja vu, you're not alone -- Google delayed last year's event revealing the Galaxy Nexus out of respect for the late Steve Jobs. While it's not what we'd call an auspicious start to Google's holiday launches, we can at least hope for an abundance of riches when the company is ready once again. The full statement waits below."We are canceling our Monday morning event in New York due to Hurricane Sandy. We will let you know our plans as soon as we know more."Maybe youâ€™ve already heard this, but I recently got a Kindle Paperwhite, my first e-reader. This was a big deal for me, and a decision which involved a lot of hand-wringing. Iâ€™m a lifelong avid reader, book lover, and collector, so for me, reading isnâ€™t just about inhaling information. I like the way books smell and feel, and I like physically turning pages. But when Amazon announced the Kindle Paperwhite, it seemed the right moment to me: e-readers had finally progressed far enough that I could feel something other than dread about owning one, and, at least for traveling, I thought Iâ€™d find it to be useful. Of course, I was still worried.Iâ€™m happy to report that most of the things I was worried about arenâ€™t as serious as Iâ€™d thought they might be. Sure, sometimes I miss holding a book, but mostly Iâ€™ve adjusted just fine, and have found that the conveniences of the Kindle far outweigh the relatively tiny (but nagging) preferences Iâ€™ve built up over many, many years of reading. In fact, my experience over the last three weeks has been far better than expected. Except for one thing: ebooks are apparently lousy with typos. This is not a minor issue, and it doesn't seem to be an isolated one, either.Though Iâ€™ve only had the Kindle for three weeks, Iâ€™ve noticed that the book Iâ€™ve been reading, Foucaultâ€™s Pendulum, has many typos. This isnâ€™t an out-of-copyright, cheaply made book from a fly-by-night press. This is marketed and published as a 2007 edition of the 1988 book by Mariner, an imprint of Houghton Mifflin. Its list price is $15.95, and it costs $8.77 on Amazon. Many of the typos â€” the letter "c" in place of what should be an "e" â€” appear to be the casualties of a hasty OCRing of some actual text of the work. OCR (Optical Character Recognition) is a process of scanning a book and using software which recognizes the scanned words as words, rather than merely as images, converting the images into text files. Anyone who has ever used OCR software knows that the process is far from perfect and always demands a serious attention to detail in the copy editing phase, once scanning is done, because the software doesnâ€™t "read" the text perfectly. This seems to be at least partially what is happening in my Kindle edition of Foucaultâ€™s Pendulum, and itâ€™s unacceptable.Iâ€™ve found other typos in other books too, but statistics on this are hard to come by, and since Iâ€™ve only been using an e-reader for a few weeks, I donâ€™t have much history to go on. But Iâ€™ve asked around a lot and everyone Iâ€™ve talked to since noticing this shocking fact has basically said the same thing: in their experience, theyâ€™ve seen more typos in ebooks than in their printed counterparts.Now, I can tell you that typos in most mainstream printed books are fairly rare. Occasionally, Iâ€™ll see one, but rarely two: itâ€™s just not that common. Iâ€™ve got a good number of old pulp fiction paperbacks at my house, original Philip K. Dicks published by Ace, and typos are sometimes more common in those, with good reason: they were produced on a smaller budget than the bigger, literary publishing houses were working with. In general, typos betray a hasty and cheap You enter and arc stunned by a conspiracy...editing process, and have historically been found in the less reputable, or less well-financed, companies. It has nothing in common with the quality of the work, but typos make the reader feel like the writer or publisher doesnâ€™t care â€” which is pretty much rarely true, as far as I can tell. It also pulls you out of the story, drawing your attention to the typo, rather than the words: "You enter and arc stunned by a conspiracy..." But Foucaultâ€™s Pendulum is a major work by a living author, released by a major publisher. The publisher also undertook the lengthy and expensive process of having the book translated from Italian. And yet the ebook is riddled with issues: in the 90 or so pages since I started marking typos with notes, Iâ€™ve found 16; a cursory search for the word "arc" (instead of "are") turns up 18 examples, and as far as I can tell only three of them should actually be the word "arc."To be clear, this isnâ€™t exactly an Amazon problem: I bought the same book from iBooks and it reproduces most of the same errors (though not quite all of them, someone appears to have caught some). But, as the biggest player in the ebook game, it would be great to see Amazon be a leader here, and give publishers and readers alike better options for reporting and fixing issues with ebooks. Because Iâ€™ll be honest: this could be a dealbreaker for me. Oh, I know that Foucaultâ€™s Pendulum seems to be a worse case than most ebooks, but it is completely intolerable.Now, I donâ€™t have an insiderâ€™s perspective on ebook publishing, but my understanding (Iâ€™ve contacted both Amazon and Apple for comment) is that while Apple does allow publishers to push updates to their ebooks, Amazon does not, meaning that if there are typos in a work, theyâ€™ll always be there until a fully new edition is published. An Amazon spokesperson told me that readers can report typos in the "Feedback" section of a bookâ€™s details, but the only option is literally to report that a book "has typos." The Kindle app for desktop, the Paperwhite, and the Kindle Touch have the additional functionality of being able to highlight the word and specify the type of error, but it's unclear how those reported errors are dealt with. It seems that pushing updates to ebooks isn't a simple or quick process. Believe me, Iâ€™m dying to report specific typos, and I think this is one scenario where Believe me, I'm dying to report typoscrowdsourcing could be helpful, but so far, itâ€™s just not happening. Amazon in particular, with its shared notes features, seems to have all the pieces in place which would allow some type of real reporting and correction system to work. This seems completely insane to me â€” the technology should allow us to move fairly quickly on pushing updates of minor typos for new purchasers of a book. This should be one of the great advances of ebooks: that if the printer makes a mistake, everyone doesnâ€™t have to live with it until they sell through a million copies or whatever. Instead, Iâ€™m needlessly looking at typos that surely thousands of other people have seen in the past few years, and which Mariner is certainly aware of at this point (Iâ€™ve emailed them for comment). Appleâ€™s recent announcement of a new version of iBooks seems to include better options for publishers to push updates to their ebooks, and this is a start.The reality is, however, that publishing is changing very fast, and to keep up with that pace, publishers are moving quickly to get their books into stores like Amazon and iBooks. Thatâ€™s great, I want as much content available as possible. But I also demand, and believe that all readers should demand, the high quality that book publishers have always offered to their customers. We can assume that this won't be a problem with most new books, because printed and digital versions will be created simultaneously from the same master text... unless publishers actually get lazy. But most books aren't brand new, and if the convenience of an e-reader must bring with it an acceptance of shoddily produced and edited versions of books, then count me out.This article has been updated to clarify the typo reporting process based on a conversation with Amazon.(Don't worry, folks! The SDK is included in the Early Bird perk!)Â Introducing Muse, our brainwave-sensing headband.It's a comfortable, sleek, four-sensor headband that allows you to control applications, games, reduce stress, improve memory and concentration, and eventually control devices directly with your mind. Â Muse measures your brainwaves in real-time. It sends those brainwaves to your smart phone or tablet showing you how well your brain is performing and also translates your brainwaves into instructions to interact with content on your iOS or Android device.The neat thing is every time you use your brain with Muse and one of our applications, youâ€™re strengthening it. Â And that will let you do more with your mind than you ever thought possible.The Muses were ancient Greek goddesses of Art and Science who inspired genius and creativity in mortalsYour brain creates brainwave activity every moment of your life, day and night, awake or asleep. Each state is accompanied by specific brain wave patterns. For example, brains of people in relaxed states create gentle, slow-moving alpha waves, while those engaged in intense concentration generate quick, jaggedÂ beta waves.This brainwave data may look like itâ€™s just couple of squiggly lines, but our algorithms (and our developers) see a wealth of informationMuse uses sensors to pick up the tiny electrical outputs generated by your brainâ€™s activity. Â As you shift Â between states like concentration and relaxation, Museâ€™s algorithms detect the subtle changes in your brain and show you those changes in real time, just like a heart rate monitor can provide information about your physical activity.Â These signals can be used in a number of ways. Right now, you can see your brainwaves in action and use that information to improve and strengthen your mind. Â In the future, InteraXon is looking to use these brainwaves to interact with devices in the real world--devices that respond to your thoughts like turning off your smart phone when you are asleep or turning off the TV.Muse sits across your forehead like a headband, and rests behind your ears like a pair of glasses. When properly worn, the EEG (electroencephalography) sensors on the front of the band make contact on your forehead, and the reference sensors on the arms rest on the backs of your ears. Muse connects wirelessly to your devices via Bluetooth. Once Muse is on, youâ€™ll hardly notice it at all.Weâ€™re including our first in-house application with Muse: Â our Integrated Brain Health system. Â It will guide you through a series of lessons delivered in beautiful virtual environments on your phone or tablet. Â Run through some exercises to sharpen your mind before delivering a speech. De-stress and detox your mind on the train ride home. Flood your brain with alpha waves and embark on a five-minute mental vacation.Itâ€™s filled with fun, interesting and challenging exercises to help you build health brain habits such as: better attention skills, improving your memory, reducing anxiety, building a more positive attitude and staying motivated. Â Our brain training integrates cognitive and emotional exercises because we believe a healthy brain needs both to perform at its best.Â This illustration of a focus training app shows howÂ brainwave data can help you track your progress over timeWe decided to introduce this application with Muse because of discussions we had with people about their attempts to improve their mood and build a more positive outlook and the growing number of stress-related illnesses. Â  The problem most people had was a lack of helpful, real-time feedback to know whether what they were doing was working. People simply didnâ€™t know whether they were doing the exercises right. Lacking direction and guidance, itâ€™s no wonder most gave up.Â Despite best efforts, most people run into numerous stumbling blocks and eventually give up on trying to change the negative ways they think. Â The problem most had - developing practices to sustain concentration, relaxation, increase motivation, and maintain composure in stressful situations, among other things - was a lack of helpful, real-time feedback to know whether what they were doing was working. People simply didnâ€™t know, whether they were getting closer to their goals or if they were performing the techniques right at all! Lacking direction and guidance, itâ€™s no wonder most gave up.This was the â€œA-ha!â€? moment for our first application.With our background in brain-computer interfaces, we saw how EEG could provide meaningful and timely feedback to help people get past the usual stumbling blocks. Â So weâ€™ve been working with experts who teach mental practices fusing their methods and our technology into gorgeous, compelling digital experiences for your iPad, iPhone, or Android device.Â A personal tracking app, like the one in this concept illustration could let you track your brainstate throughout the dayInteraXon is an interdisciplinary team of artists & engineers, neuroscientists & designers. Our founders have been working with this technology for almost a decade. The team started to come together in 2007, and since then weâ€™ve been working to make brain-computer interfaces an accessible, affordable reality.One of our first projects was a recreation of a game from Star Trek: The Next GenerationÂ  (click image for video)Weâ€™re best known for the installation we created for Ontario at the 2010 Vancouver Winter Olympics. It allowed people in Vancouver to control the lights on Niagara Falls, the CN Tower, and the Canadian Parliament buildings from more than 3000k (over 2000 miles!) away, using only their brainwaves!At the Vancouver Olympics, InteraXon let visitors use their brainwaves to control theÂ lights onÂ Niagara Falls,the CN Tower and the Canadian Parliament Buildings (click image for video!)Â Since then weâ€™ve been building the coolest things we can think of for ourselves and for others. For Wrigleyâ€™s we created a chewing game competition. Â Every chew pumped up the size of one of their fruit flavors until it exploded with juice. Â The first to get the fruit-flavored explosion was the winner. Â We also built a game where TEDxToronto after partygoers raced to fill virtual martini glasses using their brainwaves; the winners got drink tickets to make their martinis a reality. Â Of course, we should also give mention to our thought-controlled beer tap. Â Concentrate hard and the tap unleashed a frothy cold one right into your glass.Ariel showing off the â€œlevitatingâ€? chair which rose into the air as the user relaxed. (click image for video)Â From thought-controlled slot cars to brainwave-powered toasters. From levitating chairs to remote-controlled blimps. Weâ€™ve been playing and experimenting, pushing the boundaries of whatâ€™s possible with this technology. Itâ€™s given us a profound understanding of what makes this technology work, what makes it fun, and what makes it meaningful. And all of that knowledge is built into Muse.Â Our first ever tin-foil hat day was a big success.Other people working on EEG spend most of their time thinking about the technology. At InteraXon, weâ€™re constantly thinking about ground breaking solutions that make sense in everyday life for people just like you. Itâ€™s this focus that we think is going to make all the difference to you.In 2010, we partnered with Secret Exit to make a brainwave- powered version of the award-winning ZenBound 2 (click image for video!)We want Muse to be an everyday part of your life so we crafted it to be as attractive, comfortable, light and intuitive as possible. We develop applications that address real life scenarios providing real life benefits, while also developing applications that inspire, educate and entertain.Muse is here to be the guide to the wonders of brainwave-enabled technology for people all over the world. Beyond the initial app included with Muse will be apps created by ourselves and others â€“ maybe including you! Weâ€™re releasing an SDK (Software Development Kit) for Muse, and with the developers & developers deluxe pledges youâ€™ll get a set of tools for analyzing and visualizing brain waves that we use in our lab.Â And please, please, keep us in the loop about what youâ€™re up to with your Muse on Facebook and Twitter. We canâ€™t wait to see the sort of things people do with Muse, and, of course, weâ€™ll eagerly pump up your projects to all of our friends and followers.Weâ€™ve spent the last four years designing Muse and developing the algorithms that make brainwaves meaningful, and weâ€™re ready to take the next step. But taking Muse from a prototype to a finished product means we need to purchase tooling (the parts that make the parts), order components, and build test equipment to make sure everything runs smoothly. And that stuff ainâ€™t cheap.Get a sweet InteraXon T-Shirt with a contribution of $45!Â Thatâ€™s why weâ€™re asking you to help us fund our first production run. Muse canâ€™t start changing the world until itâ€™s in your hands, and thatâ€™s what this project is about. Weâ€™ve been playing, experimenting and building with this technology for years now, and we want to give the rest of the world access to amazing experiences and interactions as soon as we can. Your contributions will make that possible.Thanks for your support!1.Â  Are the Developer's Perks compatible with Linux?2. I just pledged to the Muse IndieGoGo campaign, and would like to request a headband colour. Where can I do this?You can email InteraXon, stating the headband colour of your choice, to 'community at interaxon dot ca' (community@interaxon.ca). Please make sure to provide the full name that you used to place your order.Microsoft bills Windows 8 as a "reimagining" of the personal computer market's dominant operating system, but still has a lot to do before the makeover captures the imagination of most consumers, a poll has shown.The phone survey of nearly 1,200 adults in the US by The Associated Press and GfK found 52% had not even heard of Windows 8, leading up to Friday's release of the redesigned software.Among the people who knew something about the new operating system, 61% had little or no interest in buying a new laptop or desktop computer running on Windows 8, according to the poll. And only about a third - 35% - of the people who had heard about the new system believed it would be an improvement.Engineer Chris Dionne, 43, of Waterbury, Connecticut, had already seen Windows 8 and it did not persuade him to abandon or upgrade his laptop running on Windows 7, the previous version of the operating system released in 2009."I am not real thrilled they are changing things around," he said. "Windows 7 does everything I want it to. Where is the return on my investment to learn a new OS (operating system)?"Microsoft usually releases a new version of Windows every two or three years, but it is different this time around.Windows 8 is the most radical redesign of the operating system since 1995 and some analysts consider the software to be Microsoft's most important product since co-founder Bill Gates won the contract to build an operating system for IBM's first personal computer in 1981.Microsoft is hoping the way Windows 8 looks and operates will appeal to the growing number of people embracing the convenience of smartphones and tablets.The consumer ambivalence, however, was even more pronounced when it came to Microsoft's new tablet computer, Surface, which was built to show off Windows 8's versatility.Sixty-nine per cent of the poll's respondents expressed little or no interest in buying a Surface, which Microsoft is hoping will siphon sales from Apple's pioneering iPad and other popular tablets such as Amazon's Kindle Fire and Google's Nexus 7.The Foreign Intelligence Surveillance Act (FISA), enacted by Congress after the abuses of the 1960s and 70s, regulates the governmentâ€™s conduct of intelligence surveillance inside the United States. It generally requires the government to seek warrants before monitoring Americansâ€™ communications. In 2001, however, President Bush authorized the National Security Agency to launch a warrantless wiretapping program, and in 2008 Congress ratified and expanded that program, giving the NSA almost unchecked power to monitor Americansâ€™ international phone calls and emails.On October 29, the Supreme Court will hear arguments on whether plaintiffs represented by the ACLU have the right to challenge the constitutionality of the law.Less than an hour after President Bush signed the 2008 amendments, the ACLU filed a lawsuit challenging the lawâ€™s constitutionality. The case, Amnesty v. Clapper, was filed on behalf of a broad coalition of attorneys and human rights, labor, legal and media organizations whose work requires them to engage in sensitive and sometimes privileged telephone and e-mail communications with individuals located outside the United States.In 2009, a judge in New York dismissed the suit on the grounds that the ACLUâ€™s clients couldnâ€™t prove that their communications would be monitored under the new law. A federal appeals court reversed that ruling in 2011 and the Obama administration has now asked the Supreme Court to hear the case.You can view the court filings here.Learn more about the plaintiffs in the ACLUâ€™s challenge to the 2008 FISA Amendments Act>>July 2008: The FISA Amendments Act of 2008 is signed into law by President Bush. The ACLU files a lawsuit in the U.S. District Court for the Southern District of New York challenging the constitutionality of the new law.August 2009: The district court dismisses the lawsuit on "standing" grounds because plaintiffs could not prove with certainty that they had been spied on. The court's legal analysis would have the effect of placing the FAA â€“ and other broad surveillance laws â€“ permanently beyond the scope of judicial review.October 2009: The ACLU appeals the district court's dismissal of the lawsuit.December 2009: The ACLU files its principal brief on appeal. Â "Friend-of-the-court" briefs in support of the ACLU are filed by the Brennan Center and other civil liberties and privacy groups,Â Reporters Committee for Freedom of the Press, the Association of the Bar of the City of New York and a coalition of law professors.March 2011: A federal appeals court reinstates the ACLUâ€™s lawsuit challenging the FAA, ruling that the plaintiffs in the case could indeed challenge the FAA without first showing with certainty that they had been spied on under the statute.September 2011: The Second Circuit Court of Appeals denies the government's request for rehearingÂ en banc,Â allowing the ACLU's challenge to theÂ FAA to proceed.February 17, 2012: The Obama administration appeals the standing issue to the Supreme Court.May 21, 2012: The Supreme Court agrees to consider whether ACLU plaintiffs have standing in the case.Â Itâ€™s the fast, free browser thatâ€™s built for the modern web.The Canadian Association of Police Chiefs is calling on the federal government to pass its controversial internet surveillance bill so police can fight cybercrime more effectively.Association president and Vancouver police Chief Jim Chu says he is concerned Bill C-30 will die on the order paper, meaning officers investigating criminal activity on cellphones and the internet will still have to get a warrant every time they want to intercept communications by cybercriminals."Law enforcement continues to be handcuffed by legislation introduced in 1975, the days of the rotary telephone," said Chu on Friday morning in Vancouver.Bill C-30 was introduced by Public Safety Minister Vic Toews last winter and was immediately criticized by many groups concerned about the sweeping powers it would give the government to track the ordinary activities of citizens online without judicial oversight.Bill C-30 stalled in the HouseThe legislation was tabled in the House but has not been debated since a massive public backlash when it was released.But Chu insists it's not about spying â€” it's about getting timely information from telecommunications providers."If we don't take a strong stance on this issue Canadians won't appreciate the limitations that constrain law enforcement in the cyberworld," said Chu on Friday in Vancouver.Chu said that if Bill C-30 passes internet and cellphone providers will have to release the name, address, phone number, email and IP information of suspects to police.That's essential in this era of gangsters and cyberbullies, he said.Deputy police chief Warren Lemcke agrees."Like the chief said, I can tell you right now there are gangsters out there communicating about killing someone and we can't intercept that," said Lemcke.Critics question unchecked powersSection 34 of the bill essentially would give any government appointed agents, who may or may not be a police or intelligence officer, the right to access and copy any information and documentation collected by internet providers and telecommunications companies, without the need for a warrant, judicial oversight or even a criminal investigation.It would also require those communications companies to install the surveillance technology and software necessary to enable them to monitor and gather phone and internet traffic for the government.Critics say the information will be more vulnerable to hackers and consumers will end up paying for the cost of the equipment needed for companies to implement the legislation.Chu said he agrees that Section 34 is problematic."While the CACP endorses Bill C-30, we would like to make it clear there is one part of the bill that has posed concerns to some and we share that concern," Chu said in a release."It is easy to understand why some might conclude from that wording that inspectors would have unfettered access to Canadians' personal records when doing these inspections. While we realize that's not the intention of this section, this must be clarified."You may remember that, a year ago, Pakistan announced they were banning encryption online. Not that any such ban would likely to be effective, but it seems to fit in with the claim that the government has told PTCL, the Pakistani telco, that within 90 days it must monitor basically all communications that go across the Pakistani border:Yeah, sure, just to "curb blasphemous and obscene websites." I'm sure all that monitoring won't be abused otherwise at all... right? Somehow, despite that earlier ban, I'm guessing that encryption technologies just became a lot more popular in Pakistan.January this year the U.S. Government destroyed Megaupload, but founder Kim Dotcom is a not done with the file-hosting business yet and is preparing a comeback with something bigger and better. Over the past months a group of coders have been working hard on the new â€œMegaâ€? venture and Dotcom announced today that the raid-proof service will launch exactly one year after Megaupload was shut down.With 50 million visitors per day at its peak, Megaupload was one of the largest websites on the Internet.This abruptly ended January this year when the U.S. Government took down the file-hosting service and had several key employees arrested including founder Kim Dotcom.Despite ongoing criminal proceedings Dotcom and his team are determined to launch a new Megaupload, which will simply be called â€œMegaâ€?.Initially the new Mega was expected to launch in 2012, but according to the latest information the launch is now scheduled for January 19 2013, exactly one year after Megaupload was shut down.â€œThe new Mega will launch exactly 1 year after the raid,â€? Dotcom announced a few hours ago, adding that thereâ€™s a Doomsday launch button in place, a reference to the device U.S. authorities claimed could have been in place to self-destruct the old Megaupload in the event of a raid.Previously Dotcom said that the coding work for the new Megaupload was nearly finished and that the servers had been ordered. Investors are lining up to join the new venture that Dotcom has described as a â€œmassive global network.â€?â€œAll non-US hosters will be able to connect servers & bandwidth,â€? he explained.According to Dotcom we can expect a Mega with an even greater range of applications than just file-sharing. Developers of file managers are being encouraged to get in touch for early API access, and Dotcom is also calling out to those involved in email and fax tools, VOIP and video apps.For users the new Mega will also mean more security. Uploaded files will be encrypted using the AES algorithm. Users will then be provided with a unique decryption key giving them sole responsibility for who can have future use of their files.Former Megaupload users who expect â€œMegaâ€? to give them access to their old files will be disappointed. While Megaupload is trying to convince the court to help users retrieve their old files, the new Mega is going to start from scratch.One detail that still remains a secret is the domain name the new Mega will be operating on. Megaupload.com remains seized and is therefore unavailable.Dotcom told TorrentFreak that he hasnâ€™t made a definite choice for a domain yet. He did register a few options this summer that would be fitting for the new service, and his other upcoming project Megabox.Whatever the choice turns out to be, January 19 is going to be an eventful date once again.The BBC and Deutschlandradio have joined forces to support the rollout of a single, universal chip to enable radios to receive multiple broadcasting standards across Europe.The move aims to tackle uncertainty in the market and create a 'future proof' design with enough volume to bring costs down dramatically. The 'Euro-Chip' is an existing set of minimum features and functions, originally created by WorldDMB, for all new digital radio receivers. It ensures the interoperability of all new digital radio receivers in European countries where broadcasters are using DAB, DAB+ or DMB, and/or analogue AM and FM. "Digital radio across Europe has been plagued by uncertainty," said Tim Davie, Director of Audio and Music at the BBC. "We may be reaching a tipping point, but first we have to bank what is certain about radio's digital hybrid future and join forces to promote a common vision across Europe." "Digital radio is a technology invented in Europe and we as broadcasters in Europe can show that we are able to work together to assure the future of radio," said Willi Steu, Director-General of Deutschlandradio (left) "This is of critical importance for broadcasters, manufacturers and the public," said Nyberg Frankenhaeuser, Media Director of the European Broadcasting Union. "We must ensure that European consumers are able to buy future-proofed receivers that will provide them with radio services across Europe." Chip makers for DAB and DMB include Frontier Silicon (now part of Toumaz Technologies) using designs from Imagination Technologies, and Panasonic. www.ebu.chChipmaker AMD is looking for a partner to help revive its flagging fortunes and help build some kick-ass server chips. And we think that partner is going to be ARM, the U.K. design shop thatâ€™s best known for coming up with the brains of the iPhone.Next Monday, the day before ARMâ€™s annual developer conference kicks off in Santa Clara, California, AMD is gathering CEO Rory Read and an unnamed â€œspecial guestâ€? together to talk about something it calls its â€œambidextrous strategy.â€?AMD first floated this ambidextrous strategy idea at its financial analyst meeting back in February. Essentially, it means that the company wants to license other companiesâ€™ intellectual property and work that into its chip designs. The problem is that AMD hasnâ€™t said a lot about exactly whose designs itâ€™s considering. Back in February, we asked AMD CTO Mark Papermaster flat out if he was going to do an ARM-based chip. His response? â€œThe answer is not no.â€?Since that meeting AMD has indeed taken out an ARM license â€” for a very basic chip design called the Cortex-A5. Itâ€™s using this to develop some new security capabilities for its future client chips, but we guess that next weekâ€™s announcement is going to be about servers, and about a different, server-friendly ARM design called ARMv8.ARM is starting to look like like a pretty neat fit with the server room. ARMâ€™s chips are so power efficient, theyâ€™ve already bested Intel in the mobile phone market. So maybe the companies that license ARMS designs could make a go of it in the server space, where Intelâ€™s high-wattage Xeon chips are now king?To date, ARM has been missing some key features that server-room geeks really need. Most importantly, ARMâ€™s chips donâ€™t work well in computers that have more than 4 gigabytes of memory. Servers are memory hogs, so AMD and Intel moved their most popular server microprocessors to 64-bit designs about a decade ago, but ARM is now catching up. And next year, the first ARM licensees will start shipping 64-bit chips based on the V8 design.Last spring, ARMâ€™s Simon Segars told us that he sees the V8 being ideal for a certain class of very popular web applications â€” serving video or search results, for example â€” that would work fine with the low-power ARM designs. There â€œis a potential for 90 percent power saving by adopting this type of approach,â€? said Segars, the general manager of ARMâ€™s Processor and Physical IP Divisions. â€œSo the prize is potentially very big.â€?If AMD joins companies like Calxeda and Applied Micro and starts building 64-bit ARM processors for servers, it could give AMD a low-power alternative to Intelâ€™s Xeon, says Kevin Krewell, an analyst with chip-watching firm The Linley Group. â€œThereâ€™s definitely an ongoing battle right now thatâ€™s really just staring to heat up between the ARM architecture and Intel.â€?AMD is desperate for an edge. Intel has drubbed it on servers and AMD has been badly hurt by the downturn in PC sales. Last week, as he was walking financial analysts through AMDâ€™s dreary quarterly results and plans to chop 15 percent of his companyâ€™s staff, CEO Rory Read said that the company was looking for â€œthird-party processor cores,â€? to help it build more power-efficient servers.Will those â€œthird-partyâ€? cores include ARMâ€™s? We canâ€™t say for sure, Krewell thinks that thereâ€™s a pretty good chance, especially given the fact that AMD is promising an announcement with a surprise guest the day before ARM kicks off its developer conference.â€œThe timing is interesting,â€? he says. â€œIâ€™d have to admit that Iâ€™d fall into the â€˜one plus one equals twoâ€™ camp on this one.â€?Cade Metz contributed to this story. This story has been updated to include the correct name for ARMâ€™s next-generation processor design. It is ARMv8.Bug that just keeps popping up Live authentication and won't stop. UPDATE: Had lots of questions about the password - I changed my password for these videos, then changed it to something else. It wasn't the password I was used to typing.The iPad has been a true tech phenomenon. Apple has sold 100 million of the tablets in just 2Â½ years, even though many people doubted they needed a $500 device that's in between a smartphone and a laptop. No competing model has gained significant traction in the market.Still, there's been a problem with the iPad. Though it's much smaller than a laptop, at just 1.44 pounds, and 0.37 inch thick, it can be too heavy to hold for long periods of time, such as when you're using it to read an e-book. It typically takes two hands to hold. Its 9.7-inch screen, while a pleasure to use, makes it too large to carry without a thought in many purses.So, on Friday, Apple is introducing a much smaller variant, the iPad Mini, which works exactly like the original and runs all the same appsâ€”the 275,000 tablet-optimized programs plus the rest of the over 700,000 apps available for the iOS operating system the iPad shares with Apple's iPhone.The iPad Mini weighs just less than 11 ounces, and is only 0.28 inch thick. That's 53% lighter and 23% thinner than the standard iPad. It's 5.3 inches wide versus 7.3 inches for its larger sibling.In shrinking the iconic iPad, Apple has pulled off an impressive feat. It has managed to create a tablet that's notably thinner and lighter than the leading small competitors with 7-inch screens, while squeezing in a significantly roomier 7.9-inch display. And it has shunned the plastic construction used in its smaller rivals to retain the iPad's sturdier aluminum and glass body.Unlike its two top small tablet competitors, the Mini has a rear camera. And unlike the Kindle Fire HD, it offers optional cellular data connectivity to supplement Wi-Fi. It has very good battery life.However, there are two downsides compared with the leading 7-inch competitors, the Google Nexus 7 and the Amazon Kindle Fire HD. First, the iPad mini starts at $329, versus $199 for its two main rivals (though the Fire HD costs $214 without annoying ads). Second, it has a lower screen resolutionâ€”1024x768, versus 1280x800 for the other two.I've been testing the iPad Mini for several days and found it does exactly what it promises: It brings the iPad experience to a smaller device. Every app that ran on my larger iPad ran perfectly on the Mini. I was able to use it one-handed and hold it for long periods of time without tiring. My only complaints were that it's a tad too wide to fit in most of my pockets, and the screen resolution is a big step backwards from the Retina display on the current large iPad.But it's about 30% thinner than the leading 7-inch competitors, the Google Nexus 7 and the Amazon Kindle Fire 7. And it's about 9% lighter than the Nexus and about 22% lighter than the Fire HD. It's very slightly narrower across than the Fire HD, but about 11% wider than the Nexus. I found it easy to hold with one hand, though the width might be a bit too much for some people with smaller hands.Even though the Mini is thinner and lighter than the leading 7-inch tablets, its larger screen provides about 35% more room for viewing content like books and Web pages. I found it easy to see and read material on the screen and to tap and swipe. My only complaint was that the keyboard, in portrait mode, felt a bit cramped, though it was fine in landscape mode. (I found that, unlike with the big iPad, it was more common for me to hold the Mini in portrait mode.)In my harsh battery test, where I play videos back to back with the screen set at 75% and the Wi-Fi on to collect email, the iPad mini exceeded Apple's battery life claim of 10 hours and lasted 10 hours and 27 minutes. That was about an hour better than the Kindle Fire HD, but about 17 minutes less than the Nexus 7.I found the cameras did a very good job. I conducted several clear video chats using the 1.2 megapixel front camera, and the 5-megapixel rear camera produced very good photos and videos. The stereo speakers sounded good to my ears.So why did Apple, whose large iPad and new Macs boast extremely high screen resolution, choose a lower resolution for the Mini? The company did so because it says there are only two resolutions that allow its tablet apps to run unmodified. One is the extremely high resolution on the current large iPad, which would have boosted the cost and lowered the battery life of the Mini. The other, the one Apple chose for the Mini, is the same resolution on iPad models consumers have snapped up: the original iPad and the iPad 2, which is still on the market at $399.This makes sense, but it means that, unlike its closest competitors, the Mini can't play video in high definition. Apple insists the device does better than standard definition, if you are obtaining the video from its iTunes service, since iTunes scales the video for the device, so it will render somewhere between standard definition and HD. It says some other services will do the same. But the lack of true HD gives the Nexus and Fire HD an advantage for video fans. In my tests, video looked just fine, but not as good as on the regular iPad.The cellular models, which will start at $459, will be available in a couple of weeks.The $329 price may well tempt some budget-conscious buyers who have lusted for an iPad. But Apple believes the lower size and weight, not the price, are the key attractions.If you love the iPad, or want one, but just found it too large or heavy, the iPad Mini is the perfect solution.Bug that just keeps popping up Live authentication and won't stop. UPDATE: Had lots of questions about the password - I changed my password for these videos, then changed it to something else. It wasn't the password I was used to typing.The number of apps available for Android now totals about 700,000, a Google spokesman confirmed to CNET. That's up from the 675,000the company said it had a month ago.And it equals the figure Apple most recently touted. The Cupertino, Calif., company first revealed it had about 700,000 apps available in its store last month, and Apple reiterated that amount during the iPad Mini launch last week.Hurricane Sandy did its work over the night, and Twitter has been more busy than usual, with users reporting power outages, flooding, and other weather-related damage in their area. Some of those users are actual websites and even entire website networks. Gawker, Buzzfeed, and the Huffington Post have reported outages of their respective websites due to Hurricane Sandy.The Gawker Media network consists of eight websites, such as Gizmodo, Lifehacker, and Kotaku, and all eight of them were taken down last night, and as of this writing, theyâ€™re still down. Buzzfeed also reported on Twitter last night that the website was experiencing some technical difficulties, but it seems to be back up and running as of this morning. The Huffington Post is partially back up, but the main website still seems to be down. The company has been tweeting the news, as well as posting on a temporary blog.Both New York City and New Jersey have been experiencing flooding, and approximately 6.5 million people across the northeast US are without power. There have been no reports of any major flooding, but New York City major Michael Bloomberg is urging residents to stop evacuating and stay inside until the storm passes.Appleâ€˜s 5th Avenue flagship store ended up preparing for potential flooding, and GameStop cancelled all of its midnight releases of Assassinâ€™s Creed III because of the hurricane. And while Google still announced all of their new products and features, they had to end up canceling their Android event in New York City due to the storm.Data center sites and colocation centers in and around New York City are struggling to stay online with varying degrees of success. And there are reports of intermittent issues with undersea cables crossing the Atlantic Ocean.Updated: Hurricane Sandy continued to take a toll on internet infrastructure in New York City and beyond on Tuesday.The specter of trouble with the undersea cables could be a huge deal, although experts said that there is so much redundancy that much of the risk is mitigated. Â There were some reports attributed to cable operators who said they had experienced power issues but back-up generators prevented service disruption.Update: (5:30 p.m. EDT)Â Level 3 Communications, just emailed a statement about the status of the AC-2 cable:â€œWe made extensive preparations in advance of the storm and have experienced no major service disruptions. All of our subsea cable systems are operating normally. We have experienced a minor fiber cut to one of our diversely routed, secondary backhaul lines which provides connectivity to our AC2 Cable Landing Station, and our technicians are currently working to repair it as quickly as possible. Few customers were affected because most traffic was rerouted through redundant lines. And again, the AC2 subsea cable itself is operating normally.â€?Carriers and ISPs use the cables to pump data across the Atlantic. Two of the major gateways are in Brookhaven, N.Y., (on Long Island) and in northern New Jersey, where the cables come ashore. â€œGiven the duration and strength of this storm, you have to worry about the cables getting disrupted,â€? said an executive with a data center company who did not want to be named. He said problems with the cables is â€œ the kind of thing companies will keep close to the vest. If Â either AC-1 or AC-2 were to go out there would be major, major issues.â€?As already reported, data center facilities in lower ManhattanÂ suffered a string of outagesÂ after flooding and Con Ed cut electrical power. Datagram, the web hosting company that serves the Huffington Post,Â Gawker, Gizmodo and BuzzFeed,Â went down Monday evening after floodingÂ caused those sites to go dark. DataÂ centers at Google-owned Carrier Hotel on 8th Avenue, includingÂ Equinix, XO Communications and others wereÂ also reportedly affectedÂ by power outages, though itÂ appears some are back up and running.Â And Atlantic Metro Communications alsoÂ reportedÂ disruptionsÂ due to flooding at a New York data center.Researchers with the Computer Emergency Response Team in the country of Georgia say they turned the tables on a hacker who planted advanced espionage malware on Georgian and American computers to collect sensitive security documents.Researchers had been following perpetrators behind the "Georbot Botnet" they said used advanced methods to infiltrate the computers of government ministries and parliament, banks, and non-governmental organizations. The Botnet's targets spanned Georgia, the US, Canada, Ukraine, France, and other countries. Besides exploiting unpublished software vulnerabilities to install malware, the attackers also planted malicious links on specific webpages that would interest the kinds of people being targeted.The campaign searched victim machines for documents with certain terms and also used embedded webcams and microphones to eavesdrop on targeted individuals. It began as early as March 2011 and lasted as long as 12 months. The CERT members tracking the hacking said they linked it to "Russian Security agencies."Part of their research, outlined in a 27-page report, included infecting one of the perpetrators with the same malware used in the campaign. The researchers then recorded a man as he used one of the computers the researchers had compromised.We have infected our PC from Lab, then gave Cyber Attacker Fake ZIP Archive with his own virus inside and the name "Georgian-Nato Agreement". As we had access to BOT Panel, we had maintained control over his PC. Then captured got video of him, personally. We have captured process of creating new malicious modules. We have obtained Russian Document, from e-mail, where he was giving someone instructions how to use this malicious software and how to infect targets. We have linked him with some of German and Russian hackers. Then we have obtained information about his destination city, Internet service provider, e-mail, and etc.Attributionâ€”that is, the task of determining what group or country is behind a physical or network attackâ€”has long been a complicated and imprecise undertaking. That makes it hard for disinterested third parties to state with certainty who is behind an attack and easy for the accused party or country to provide facts that seem to rebut the claims. In 2008, crippling denial-of-service attacks on Georgian banks and government websites preceded Russia's military campaign in that country. Many Georgians claim the attacks were carried out by Russians. The photographs and other data allegedly taken by the hacker's own computer may be of particular value as this latest dispute plays out.As much as Gmail shines when it's on the web, some of its most avid users stay in native apps for the multitasking; having to check a past message in the web client has usually meant putting the current draft on hold, or at least maintaining a near-photographic memory. Google wants to translate some of that desktop experience to the web through a new composition interface it's testing as of today. New messages start off in a shrinkable pop-up that lets us find old threads without having to put the new conversation on ice, even we're indecisive enough to leave multiple unfinished e-mail messages open. Other upgrades lurk in the background for the more focused among us, such as a pared-back composition interface, in-line photos and a reply box that dynamically adapts to the space it needs. Only those in the preview will see the Gmail update for now; Google is promising a wider launch in the months ahead that could save us all a few precious minutes each day.By Emma Thomasson VEVEY, Switzerland (Reuters) - It looks like mission control: in a Swiss market town, an array of screens in Nestle's headquarters tracks online sentiment. Executives watch intently as California wakes up, smells the coffee - and...1 of 9.Staff of the Nestle Digital Acceleration Team (DAT) monitor social networks at the company headquarters in Vevey September 24, 2012. This is the nerve centre of the company's Digital Acceleration Team. By monitoring conversation about its products on social media - right down to ''realtime recipe tweets'' across the United States - they aim to win over a sometimes hostile world.This is the nerve centre of the company's Digital Acceleration Team. By monitoring conversation about its products on social media - right down to "realtime recipe tweets" across the United States - they aim to win over a sometimes hostile world.Other companies, such as PepsiCo, Danone and Unilever, have exploited the opportunities to promote themselves online. But Nestle is also concentrating on using social media for damage limitation.Vilified for years for its sales of baby milk formula in developing countries, Nestle today is confronting its critics online as protesters find newer targets, such as the company's $7 billion a year bottled water business. The $200 billion food and beverage group set up its digital team a year ago, and says it has doubled spending on social media advertising in the last couple of years."People have been complaining about companies forever, but before they did it at the water cooler or at the bar," said Bernhard Warner, co-founder of London-based consultancy Social Media Influence. "Now they are doing it online and spreading their complaints to disparate communities."Nestle is not the only bottled water producer under fire. Others including Coca-Cola are also accused of undermining public water systems. Groups such as Boston-based Corporate Accountability International, a non-profit which originated in the protests against Nestle's infant formula, have alleged for almost a decade that bottled water makers damage the environment when they extract the water, waste resources on bottles and shipping, and take what should be a common good.The fight matters a lot to Nestle, as it's the world's largest producer of bottled water. Its brands include Poland Spring, Perrier and San Pellegrino and accounted for almost 8 percent of its sales of 83.6 billion Swiss francs ($85.31 billion) in 2011.In 2008 it ran an advertisement in Canada claiming that "bottled water is the most environmentally responsible consumer product in the world." Campaigners in North America have nonetheless persuaded tens of thousands of people to sign a "Think outside the bottle" pledge to drink water from the tap, and pushed some U.S. campuses and municipal buildings to ban the bottled variety.At HQ, Nestle's team of Digital Accelerators is tasked with "listening, engaging, transforming and inspiring." Each member spends eight-month stints working in the space with a mini TV studio, rather like a busy newsroom or trading floor.Pete Blackshaw, 47-year old head of digital marketing and global media, is in charge. On a recent weekday, the American and his staff of 30 to 40-year-olds were monitoring the online action on such topics as the latest cute dog photo on the Purina pet food website, or who was drinking Nescafe.Blackshaw pointed to a map of the world showing California's Twitter action. He also highlighted how the centre's screens are set up to spot trouble."If there is a negative issue emerging, it turns red," says Blackshaw, indicating a screen powered by software from Salesforce.com Inc., which is also used by such brands as Dell computers and delivery company UPS. It captures millions of posts each day on topics of interest to Nestle."When there is a high number of comments," Blackshaw adds, "it alerts you that you need to engage."That can mean a real-time online response from a team member - each has a small flag indicating their country of origin above their desk - or the team might pass an issue on.Nestle says it has strict 'do's and don'ts' for how staff should respond online, including disclosing their relationship to the company if they discuss a product. At the same time, the team is inevitably making up some rules as it goes along.The company does not pay bloggers for pro-Nestle posts and follows industry ethics codes, disclosing any "consideration" it gives, such as providing product samples to online reviewers. Common tricks used by some public figures include faking - or purchasing - social network followers: California-based web security research firm Barracuda Labs estimates the average price for 1,000 'robot' Twitter followers at $18.32 (Facebook fans are a pricier $35.59 for 1,000).When it recently thanked its "fans" for reaching 600,000 "Likes" on its main corporate Facebook page, a user identified as Andrew Wood from Britain retorted: "We are not all fans however - some have joined so that they can protest about your ethics and spread word of the long standing boycott of your products."Nestle replied on Facebook: "That's a fair point, and the terms â€˜fans' and â€˜likes' may not be the ideal descriptors for everyone. That said, we value the input and feedback from all 600,000+. Thanks for the feedback."Such responses result from a lesson learnt two years ago, when Greenpeace posted a spoof ad, watched by nearly 1.5 million people on YouTube, for Nestle's KitKat snacks.The ad showed a bored office worker take "a break" from shredding documents, to munch on a chocolate wafer finger that - unnoticed by him - had mutated into an ape-like claw. As he chewed, it spurted blood. "Give the orang-utan a break," the slogan urged. "Stop Nestle buying palm oil from companies that destroy the rainforests."Nestle initially made the problem worse, earning an entry in a book by the consultant Bernhard Warner about "the 50 greatest social media screw-ups". It tried to get the video pulled and threatened to delete hostile messages on its Facebook page.No matter what your views on palm oil, that reaction was "absolutely â€˜verboten' for digital natives," said Warner. "All corporates looked at this and thought â€˜oh my goodness, how vulnerable are we?'"Eventually, after more than 200,000 protest emails, Nestle sat its officials down with Greenpeace to plan a policy against deforestation."One of the most significant things that has happened in the corporate world in the last 10 years is this idea of being respectful of and monitoring not just what your fans have to say but also your critics," said Warner. "It has completely changed the world of crisis management and reputation management and all the training that goes into it."Nestle has climbed to 12th spot from 16th in 2011 in the Reputation Institute's index of the world's most reputable companies."They have a very strong reputation among the general public," said Nicolas Trad of the New York-based consultancy firm, which surveys 100,000 consumers for an annual reputation survey. "However, looking a little bit deeper, we find that perceptions of key opinion leaders - such as academics, regulators, nutritionists, NGOs and the like - are much weaker than those of consumers," he said. "This is risky as this group is often ahead of the curve."On the day Nestle's Digital Accelerators were monitoring online responses to cute dog photos, they were also on the lookout for word on its water business.Chairman Peter Brabeck had posted a blog in response to "Bottled Life," a documentary criticising Nestle that was released earlier this year. The documentary, shown in cinemas in Switzerland as well as at film festivals and on European TV channel Arte, alleges Nestle is "intent on amassing resource rights worldwide with the aim of dominating the water market of the future."In his blog, Nestle chairman Brabeck sought to put such criticism into the context of a broader global crisis of water scarcity. "This is the most vital issue of our time, and in this big picture, bottled water is rather irrelevant," he wrote.Among the film's targets is Pure Life, the world's top-selling bottled water brand, which is produced by Nestle and uses purified groundwater - the same water as comes out of the tap - with added minerals. Pure Life is a budget brand largely aimed at emerging markets, where demand is growing.The movie alleges a bottling plant for Pure Life in Pakistan may be contributing to a falling water table there. Nestle denies this, saying the amount used by its plant at Sheikhupura near Lahore is too small.In Pakistan, there's no conclusive evidence on either side. Data from the province of Punjab show no significant variation in the water table at testing stations in the region, but local water authorities do not maintain data on how much groundwater individual companies or industries pump.History shows the power of such objections.Around a decade ago, a California-based NGO publicised locals' worries that a Coke bottling plant in Kerala in India was damaging their water supply. The claims were rejected by Coke but eventually resulted in officials closing the plant. A government-appointed committee proposed that Coca-Cola pay damages for causing "environmental degradation by over-extraction of ground water."More than 1 million people have so far watched "Bottled Life" - not a huge audience by global standards. But social media is "the amplifier", as Blackshaw, who previously worked as a digital brand manager at Proctor & Gamble, says.Nestle's global critics have already picked up the documentary. "We are calling on Nestle to come clean about where the water is coming from and stop undermining local control of water," said Kristin Urquiza of Corporate Accountability International. "Nestle should be concerned about how this is hurting its brand image."The company has not engaged directly with the film makers: it says it responded to their questions on paper, but declined to make executives available on camera as it knew the documentary would be "polemical."In his blog, Brabeck wrote that the film "illustrated a whole spectrum of perceptions, misperceptions and allegations concerning this part of our business."A woman named Deirdre Mistarz asked on the blog about a suggestion in the film that Nestle is not willing to provide drinking water for people near the Pakistan plant: "Are the poor to be treated as lepers, to be deprived of the basic human need of clean water; are they to be extinguished because they are so poor they cannot help to fill the coffers of Nestle?"Two hours later, Brabeck responded: "This is not true. We have installed two water filtration facilities in the region which can be accessed by more than 10,000 people and we are in the process of building a third."Of course, Nestle's Digital Accelerators also use social media for traditional publicity. A French team member has developed an app that plays a cookery video when a package code is scanned. And Nestle said sales of Perrier water had a strong start to the year, helped by a video which was popular on YouTube. Its story: to save a melting world, a glamorous woman drinks Perrier.(Additional reporting by Qasim Naumann in Islamabad and Ben Beavan and Himanshu Ojha in London; Edited by Sara Ledwith, Simon Robinson and Richard Woods)It might seem that the Internet doesnâ€™t lose track of anything that has been published online. The alleged permanence of tweets, blogs, snapshots, and instant messages worries many privacy activists and policymakers such as Viviane Reding, justice commissioner of the European Union and vice president of the European Commission. She has proposed that Europe adopt a â€œright to be forgottenâ€?â€”a proposal that is now working its way through the EU legal process and could be law within two years.Redingâ€™s proposal would grant EU citizens the right to withdraw their consent from online information services after the factâ€”allowing people to redact embarrassing things from the global information commons, even after the data had been copied to other websites. Itâ€™s a controversial proposal: George Washington University law professor Jeffrey Rosen wrote in the Stanford Law Review that such a right could have deeply negative implications for both free speech and journalism and could ultimately fragment the Internet. Rosen pointed out that companies like Google would need to suppress from European search queries information that had been deemed â€œforgottenâ€? on the continent, even as such information would still be perfectly allowable in the United States.The proposal might also be unnecessary. Even without a right to be forgotten, there are still many ways that information can be removed from the Web. Such methods could be made more widespread.Somewhat surprisingly, the easiest information to remove from the Internet may be data stored in Facebook, and to a lesser extent in other social networks. Facebookâ€™s â€œStatement of Rights and Responsibilitiesâ€? says that any information a Facebook user uploads to the social network remains that userâ€™s propertyâ€”posting, liking, and otherwise interacting with Facebook merely gives the service a revocable license to the data. That license ends when the data are deleted.Wiping away those embarrassing self-portraits you took and posted when you were drunk wonâ€™t delete the copies that your friends have saved on their own hard drives. But who makes copies of photos anymore? Hereâ€™s a way that the convenience of cloud-based services works in favor of privacy controls: they give you one-stop-shopping for information oblivion, a single place to go and get something deleted.Facebook was created to make it easy for people to share their personal dataâ€”and as a result, people often share information without even realizing it. But Facebook also makes it easy to clean up after yourself. If you put your phone number in your profile, that number might get copied to your friendâ€™s cell phones through Facebookâ€™s application programming interface (API). But if you delete your phone number from your Facebook profile, that same API should go through your friendsâ€™ phones and remove your information as well. Thatâ€™s because Facebookâ€™s developer guidelines prohibit programs that access Facebook from making permanent copies of your personal information: software is only allowed to make a â€œcacheâ€? copy in order to improve performance, but that copy must be linked back so that it can be kept up to date. Such license terms, designed to keep developers dependent on Facebook, have the side effect of enforcing a privacy policy thatâ€™s surprisingly pro-consumer.Itâ€™s not necessarily difficult to have information removed from Twitter, either. Even though the companyâ€™s privacy policy warns â€œwhat you say on Twitter may be viewed all around the world instantly,â€? Twitter lets users delete their own tweets. You can delete other peopleâ€™s tweets if you are willing to swear out a complaint that the tweets violate the Digital Millennium Copyright Actâ€”thatâ€™s how big media companies get Twitter to take down links pointed at copyrighted material. (In a nod to transparency, Twitter makes those requests public on the Chilling Effects website at http://chillingeffects.org/twitter.) Most of us donâ€™t have copyright claims to make, but Twitter will also take down tweets that contain harassing or private information, including credit card numbers, Social Security numbers, addresses, phone numbers, and e-mail addresses. Although itâ€™s possible that someone has made a copy, in many cases removing information effectively sends it down the memory hole.Yahoo and other websites have similar forms for requesting that information be taken down. They do this even though they generally are not required to by U.S. law. Advertising-funded websites make so little money off any individual piece of data that itâ€™s much easier to take information down than to spend time fighting for the rights of the person who posted the data.Back in 2005, I met a person who had been the victim of horrible harassment a few years earlier, in high school.  Even years later, this colleague of mine was still haunted by a series of harassing websites that her tormentors had put up on free Web-hosting services. My colleague was too traumatized to deal with the issue, so I sent a few e-mails to the Web-hosting companies, and within a few days the offending material had been taken down. Today a search for the personâ€™s name yields only professional results, not those teenage pranks.Unfortunately, wiping data away from every cranny of the Internet can be challenging. Consider my colleague. If you know where to look, itâ€™s still possible to find those harassing pages. They donâ€™t show up in Google or Bing, but there are copies hidden away at the Internet Archive, a website that seeks to preserve most of the Internetâ€™s content for posterity. There are procedures for removing data from the Internet Archive, but those procedures generally require the active participation of the current holder of the Web domain. Fortunately for my colleague, the Internet Archiveâ€™s pages arenâ€™t indexed by Google or Bing, so except for those people who know specifically where to look, the information is invisible.In fact, itâ€™s hard to imagine a system that could index all of the worldâ€™s information thoroughly enough to allow someone exercising the â€œright to be forgottenâ€? to track down and eradicate every regrettable message or photo. More likely, the mechanisms to find that data would cause more privacy violations than they would prevent.A better solution could be a set of standards for labeling the provenance of information on the Internet. It would be somewhat like the way Facebook requires application developers to keep checking back to see whether personal information is still acceptable to use. It would also take advantage of the privacy-protecting steps that other sites like Twitter and Yahoo sometimes are willing to take for their users.This could be done using the HTML microdata standard being developed. It is still evolving, but this standard will expand the ways that information in Web pages can be represented in their underlying HTML code. For example, the microdata could include tags designed to facilitate privacy tracking and the retraction of privacy-sensitive information. So if you persuaded a website to take down information because it violates the siteâ€™s terms of service, that website could automatically notify others that have made copies of your information, informing them that the license to use the data has been revoked.Such voluntary technical measures would go a long way toward improving the situation that policymakers hope to fix with a legal right to be forgotten.The Department of Energy has flipped the switch on what is now the world's most powerful supercomputer.The DOE's Oak Ridge National Laboratory facility announced on Monday that its new Titan system is now live. The supercomputer can handle 20,000 trillion calculations a second, which in computing language is referred to as 20 petaflops. ORNL says that makes Titan 10 times more powerful than the laboratory's Jaguar supercomputer, once the fastest machine in the world and now the sixth.Titan will likely unseat the DOE's Sequoia supercomputer, based on an IBM design, that is currently the world record holder.Titan gets its speed from a family of processors called graphic processing units, which were first developed for computer gaming, combined with traditional central processing units. An ORNL press release describes the computer, based on the Cray XK7 system:The supercomputer will support research in energy, climate change, efficient engines and materials science.James Hack, direction of ORNL's computational sciences center, said Titan will let scientists simulate physical systems more realistically and in greater detail.Please turn on JavaScript. Media requires JavaScript to play. Machines can already drive trains, beat humans at chess and conduct countless other tasks. But what happens if technology starts getting more creative - can a machine ever win the Booker Prize for fiction? In George Orwell's fiction, by 1984 the "proles" were entertained by books produced by a machine. In real life, robots have been capable of writing a version of love letters for over 60 years. One xenia epigram - a poem originally found in Latin literature with a formal structure - has been written by poet Luke Wright for the BBC. The other is written by a computer after being given instructions about the poetic form. Can you tell which is which? To truth I offer this thanks, when needing something like realityWhen I'm writing and drawing blanks, I almost settle using actualityI am in search of more, trying to sing your praise!It's you I very much adore, lacking in so many ways. Felicity, my dear, my thanks the cheque you sent was great.Tomorrow I'll go to the bankmy rent's already late.And sorry for the shoddy rhymeI'm tired, I'm not on it,perhaps if you send more next time I'll scribble you a sonnet. But how far away are books written by robots? Well they have already happened, in their hundreds of thousands. Professor Philip Parker, of Insead business school, created software that has generated over 200,000 books, on as varied topics as the 60 milligrams of fat in fromage frais to a Romanian crossword guide. Amazon currently lists over 100,000 titles under his name. While not expecting to top the bestsellers list or win any literary awards, they take under an hour to "write" because of how they are produced and are printed when requested rather than in bulk. The books compile existing information and offer new predictions using forumulas, like estimating the future size of markets for example. But Professor Parker has experimented with a piece of software that is capable of creating automated fiction. Fiction is often criticised for being a factory process of using formula and "write by numbers" approaches. Creative writing programmes have been likened to working "from a pattern book" by Booker-nominated author Will Self. Certain pieces of writing software provide templates that will automatically create the structure of a novel and once written, can tell you how easy the novel is to read. "No novel writing package will write your book for you," says software firm NewNovelist. "They certainly can help you complete your novel and make sure it is composed correctly." I couldn't think of anything more pointless than reading a piece of fiction written by a robot But if there is a formula, can the novelist really be replaced by an algorithm? Russian Alexander Prokopovich is said to be responsible for the first successful book to be created by robots. It was published in 2008 and was written in the style of Japanese author Haruki Murakami in a variation on Leo Tolstoy's Anna Karenina. "The program can never become an author, like Photoshop can never be Raphael," Prokopovich told the St Petersburg Times. Whether this is actually an original work of fiction is up for debate. Though this could be compared to the literary argument about whether any work of fiction is truly original. On a more simple level, the people experimenting with the technology believe that it is not as difficult to create fiction as critics believe. "Any genre of fiction that has a 'dummy's guide' to it could be created with an algorithm," says Prof Parker. "The more a genre subscribes to a formula, the more straightforward it is. "In romantic fiction, instructions for authors can be as specific as down to the page. If you feed that information into a computer, the formula is followed. Each genre has some sort of formula, just some more than others." Despite the failure of machines to deceive us into believing they are human, Turing would be excited by the remarkable progress of AI More on how Turing influenced AI Prof Parker's software, still in prototype, would allow characters to be decided, locations to be set, genre fixed and plot mechanisms chosen. It then creates anything from 3,000-word flash fiction to a 300,000-word novel. He has even done public experiments with poetry. "A computer works very well with rules and the most obvious way is poetry," he says. "We did a blind test between a Shakespearean sonnet and one that the computer had written. A majority of people surveyed preferred ours. "That's not to say it was better, Shakespeare is a genius, but it was what people preferred." With so many authors around - Mills and Boon publishes around 100 books a month - Prof Parker is keen to stress that his aim is not to produce fiction that is already created in abundance. Instead, it could be used to write in languages or on topics that are not widely covered. But computers are not just seen as a threat to creative work but to other writing as well. Startup company Narrative Science has started creating articles, without a human doing the writing. With 30 clients for its articles already, written automatically by a machine collating data and writing "rich narrative content" from it, the death of the journalist has been mentioned in more than one speculative column. Business news site Forbes is using the service for a number of pieces each weekday. But if neither Beryl Bainbridge nor Martin Amis can win the Booker Prize, what chance does a machine really have? And if creative writing really is creative, what new ideas could a computer offer? "I couldn't think of anything more pointless than reading a piece of fiction written by a robot," says science fiction author Alastair Reynolds. Computers are already useful in developing new mathematical theories "Even if it was indistinguishable from your average Booker Prize winning novel. "You might find a lot of regurgitated platitudes but I can't imagine a piece of software being capable of producing something that would stop you in your tracks. Not until we get truly intelligent computers." The Loebner Prize of $100,000 was set up as an offer to the first computer program to convince testers that it was human through two-way communication. No-one has won that prize yet but it could be that the written word, without interaction, could provide a more immediate way to confuse the reader as to who or what is writing. And then a different sort of prize could only be a step away. "I don't think the computer will win the Booker but no-one ever expected a computer to beat a chess grandmaster," says Reynolds. "A normal tool in a mathematician's tool kit is the computer. 100 years ago, it would be considered heresy. "The idea of a computer winning the Nobel Prize for physics is not too unlikely, citing a computer as joint recipient. It's obviously not a huge leap to think of something similar happening in fiction." Note: To Felicity is written by the poet Luke Wright. To Truth is written by computer softwareThe company's Maps application was powered by Google until iOS 6, when Apple took matters into its own hands.Apple has won a patent for built-in mapping applications running on its mobile operating system.Referred to as "Touch screen device, method, and graphical user interface for providing maps, directions, and location-based information," the patent, which was awarded by the U.S. Patent and Trademark Office, describes -- as one might expect from the title -- the way in which maps, directions, and location-based information are displayed on a touch-screen-equipped device.AppleInsider was first to discover the patent.The focus of Apple's patent appears to be improving the experience of actually using a mapping application. Apple's patent describes issues with user interfaces employed by GPS devices, saying that they "include physical push buttons [that] are also inflexible.""Mapping applications are available for mobile phones (e.g., Google maps for mobile, available at www.google.com/gmm). But navigating in such applications using physical push buttons (e.g., the number keys on a hard keyboard) or touch screens in existing mobile phones is cumbersome for most users," Apple wrote in its patent. "Thus, at present, relatively few people use mapping applications in mobile phones and other portable devices."Apple filed its patent in 2008 when companies like Garmin and TomTom were still selling boatloads of portable GPS devices that largely required physical buttons to work.As Apple continues to describe its patent, the company discusses how its interface design, relying mainly on touch screens and a user's fingers, makes navigation more intuitive.What's perhaps most interesting, though, is that Apple won the patent despite using Google's mapping services in its built-in application for the last several years. Only this year did Apple switch to its own built-in mapping offering, called Maps.That changeover has caught the ire of many users who have witnessed Maps' many errors and omissions. Apple has promised improvements, but so far, the application, by most accounts, pales in comparison to Google Maps.Apple's Maps patent is the latest in a string of intellectual property the company has scored in the last several weeks. Just last week, in fact, Apple won 34 patents.Just a reminder: when you think you get past an attempt by certain legacy industries to shove through bad laws with questionable international trade agreements, there's always at least one (and probably more) such agreements lurking. So, from ACTA we went straight into TPP... and following TPP, it looks like the US and the EU are already discussing a new US-EU Free Trade Agreement to be worked out soon. A "working group" to get the process started put out a report about what the agreement would include... and, of course, there will be a section on "intellectual property." The USTR has made it clear over the past few years that it thinks free trade agreements are the perfect vehicle for intellectual property maximalism. This makes little sense, since intellectual property is the exact opposite of "free trade." It's whole purpose is to be a trade barrier and a monopoly. But...So, at the very least, there would be some limits on what such an agreement would get into, given existing "differences," but they still seem to want to include something about "dealing with IPR matters," which can only mean ratcheting things up. It's still early, but you can bet that the legacy industry lobbyists are already well aware of this and involved in the process -- so it needs to be on everyone else's radar as well. Oh, and both Obama and Romney have indicated they support such an agreement, so it's not like either one is better than the other going into next year.MacRumors attracts a broad audience of both consumers and professionals interested in the latest technologies and products. We also boast an active community focused on purchasing decisions and technical aspects of the iPhone, iPod, iPad, and Mac platforms.Looking for a job? We are hiring.China is growing in importance in the tech industry. The Chinese have been dominant for years in regard to manufacturing, and weâ€™ve discussed their monopoly on certain vital elements for electronics production before. Now, they are becoming increasingly more dominant as a purchasing power of technology.Itâ€™s recently come to light that China is now accounting for 15% of Appleâ€™s revenue. That is an increase of 3% in the last fiscal year. More impressively, itâ€™s an increase of 13% since 2009. In this past quarter, China brought in $5.7 billion for Apple. If this trend continues, it wonâ€™t be long at all until China is on par with the US in terms of revenue generated for Apple.In the English-speaking Western world, it is all too easy to think almost exclusively about sales and market share in Europe and North America. Clearly, the Chinese cannot be ignored anymore. They arenâ€™t just some country of little consequence where our computers and phones are made. They are becoming a financial force to be reckoned with, and the Apples and Samsungs of the world arenâ€™t stupid. China is looking more and more dominant by the day.As phone and computer saturation reaches its pinnacle in North America and Europe, those markets just arenâ€™t as interesting to an industry addicted to ever-increasing growth. Countries like China, India, and Brazil are going to be the new golden children of the tech world. Itâ€™s only a matter of time before this becomes the driving force of the majority of tech companies.What does this mean for the industry? Besides the ego-blow to the long-dominant Western countries, it also means that tech companies are going to start prioritizing the needs and desires of the Chinese people. Design, engineering, and business could all be drastically shifted with developing and recently-developed countries in mind. When products are being developed, it would be very short-sighted for companies not to consider heavily how well they will play to Chinese consumers.Most importantly, we need to keep in mind that the current way of doing business just might not scale. If demand grows in size three or four times in a relatively short period of time, supply constraints will become a real issue. The pre-order allotment of iPad Minis sold out in the first twenty-or-so minutes. Think about a world where we have two-to-three billion more consumers of iPads, laptops, and phones. It might be months before everyone who wants a new product can purchase it. Itâ€™s a real problem, and we canâ€™t ignore it any longer.Now read: Rare earth crisis: Innovate, or be crushed by China[Image credit: chinnian]NEW YORK (AP) -- PayPal is cutting 325 full-time jobs to streamline its business and speed up product development amid intense competition from plucky startups and established companies such as Google.The company also is ending jobs with about 120 independent contractors worldwide.The job cuts have been expected and were reported by The Associated Press earlier this month. Its parent company, San Jose, Calif.-based eBay Inc., said it expects to book a restructuring charge of about $15 million in the current quarter, related to the job cuts.Monday's cuts represent about 2.5 percent of PayPal's work force of 13,000. The company said the cuts are primarily in PayPal's product and technology organizations. PayPal said it wants to simplify and speed up how products are developed. The moves come as PayPal faces increasing competition in the world of online and offline payments services such as Square Inc. and Google Inc."If we don't change, we simply won't be able to sustain PayPal's global leadership position over time. And we will not let that happen," PayPal's president, David Marcus, wrote in a memo sent out to employees and obtained by the AP. "To do this we need a simpler, streamlined place to work."The Supreme Court today heard oral arguments in Kirtsaeng v. Wiley & Sons Company, a case that could further undermine the "first sale doctrine." First sale, described in section 109 of the US Copyright Act, gives people the right to resell, lend, or give away the works that theyâ€™ve bought, even if those works contain copyrighted elements.Textbook publisher Wiley claims that this doctrine only applies to goods that are manufactured in the U.S., and that the defendant, Supap Kirtsaeng, was infringing its copyright by purchasing books at a reduced rate in his native Thailand and selling them below list price in the States.The effects of such a dubious interpretation could be far-reaching for American consumers, and it appears several Supreme Court Justices were appropriately concerned about the implications of Wileyâ€™s proposed geographic limit on first sale. Of course, itâ€™s unwise to predict how the Court will decide a case based solely on comments during the oral arguments, but they can provide insight into what factors the Justices are considering. Today the Court mirrored our concerns about the right of Americans to resell the goods that theyâ€™ve legally acquired â€” from books to smartphones to cars â€” just because those goods happen to contain copyrighted materials and were manufactured overseas.Defenders of Wileyâ€™s position are quick to denounce those concerns as overblown. It's curious, then, that Wileyâ€™s own lawyer, former Solicitor General Ted Olson, was hard-pressed to explain why. Justice Breyer asked about specific examples â€” buying a book overseas to give to your wife in the U.S., or reselling a Toyota manufactured in Japan with numerous individually copyrighted components â€” andÂ  did not seem impressed with the answers he got. And when Justices Breyer, Sotomayor, and Roberts questioned Olson about the "parade of horribles," raised by Kirtsaeng and supporting amici (including EFF), he asserted that, yes, indeed, sales of foreign made goods might require approval from the copyright holder, whether the seller is a Toyota distributor or a university library:It goes without saying that a secondary market that exists only with the permission of innumerable copyright holders is a poor substitute for the genuine article. Consumers would be worse off for it, and itâ€™s not what Congress intended.Later, in questioning the Deputy Solicitor General arguing on behalf of the government, Justice Alito was even more explicit about the choice facing the Court:Pressed in this manner, the government conceded:The Court also appropriately persisted in asking questions about the perverse incentive that Wileyâ€™s interpretation would provide to manufacturers in moving their production overseas.Critics of the Second Circuitâ€™s decision in Kirtsaeng have been accused of exaggeration. Perhaps Justice Breyer put it best today:Itâ€™s gratifying that the Court seems to appreciate the ramifications of this case, even if Wileyâ€™s attorneys do not. Weâ€™ll be watching closely as the Court releases an opinion.But thatâ€™s not end of the story. Regardless of the Courtâ€™s decision, we need to be prepared to tell elected lawmakers that we stand up for first sale, whether the threat is through arcane import regulations or onerous EULAs. EFF has joined Demand Progress and the Free Software Foundation in giving you a platform to contact your legislators to urge them to stand up for first sale. Take action today.And please show your support by embedding our graphic into your website. It's easy! Just copy and paste this code into the HTML of your site:Windows 8's most obviousâ€”and most divisiveâ€”new feature is its user interface. However, it would be a mistake to think that the user interface is the only thing that's new in Windows 8: there's a lot that's changed behind the scenes, too.Just as is the case with the user interface, many of the improvements made to the Windows 8 core are motivated by Microsoft's desire to transform Windows into an effective tablet operating system. Even those of us with no interest at all in tablets can stand to take advantage of these changes, however. For example, Windows 8 is more power efficient and uses less memory than Windows 7; while such work is critical to getting the software to run well on low-memory tablets with all-day battery life, it's equally advantageous for laptop users.The biggest single piece of technology that is new to Windows 8 is, however, squarely Metro focused: it's a large set of libraries and components called WinRT. I've already written extensively about what WinRT is, so I won't be getting into that here, but there are system capabilities that WinRT apps can use (or are forced to use) that are interesting in their own right.First up is sandboxing. Metro-style apps are all sandboxed: by default, each app can only read from and write to its own private storage area. If the app needs to do anything more than thisâ€”access the Pictures library, say, or connect to the network as either a client or a serverâ€”it must explicitly indicate that it needs these extra capabilities in something called a manifest. This prevents apps from being able to read each other's files, documents that you haven't explicitly granted them permission to read, and so on. This serves two purposes; it helps safeguard user privacy, instilling greater confidence in apps downloaded from the store, and it also reduces the impact of security flaws in those apps.These sandboxes are enforced by a new Windows 8 feature called AppContainers, which in turn builds on a feature introduced in Windows Vista, called integrity levels. Before integrity levels, access to files and registry keys on Windows was governed solely by the user identity. Every file and registry key has an access control list (ACL) which describes which users and groups can perform what operations to those files and registry keys. For example, an ACL on a file might say that User A can read the file, User B can read and write the file, and Group C can read, write, and delete the file. Every process running with User B's identity would have the same access to that file: read and write.Integrity levels created a system to give processes all running with the same user identity different levels of access to the system. Each process has not just the user identity, but also an integrity level, denoting the trust given to the process. Web browsers, for example, would be given low integrity, because they're not especially trusted (because they are so often attacked and exploited by malicious Web pages). A normal process such as Notepad might be given medium integrity, because it's relatively unlikely to be attacked. An installer or setup program might be given high integrity, because it's trusted to update pieces of system configuration. There is also an untrusted integrity, that's even lower than low, and a system integrity, that's even higher than high.Every file and registry key on the system is tagged with an integrity level, which specifies the minimum level required to write the file. Reads are (almost) always allowed. Temporary directories, for example, might be tagged with low integrity, allowing even Web browsers to use them. System directories will be tagged with high integrity, preventing modification by low and medium integrity processes.This integrity level system was instrumental in User Account Control (UAC), the confirmation prompts also introduced with Windows Vista. With UAC enabled, even an Administrator account normally runs processes with only medium integrity, and hence preventing modification of system files. Clicking on a UAC prompt creates a process with high integrity. This is why you need to perform UAC elevation before you can modify system files.AppContainers introduce an additional integrity level, called simply AppContainer. AppContainer is even more restricted than low integrity. AppContainer blocks both reads as well as writes. Unlike low integrity, it isn't a simple tag. When each Metro app is installed, the system examines the capabilities that the app says it needs in its manifestâ€”network access, library access, and so onâ€”and constructs a unique AppContainer security identifier based on those capabilities. When the app is run, it not only has the AppContainer integrity level applied; it also has this security identifier applied.Windows then uses this information to perform extra validation whenever the process tries to perform a restricted operation, such as opening a file or making a network connection. It uses the information in the security identifier to determine whether to allow the operation. For example, only if the security identifier indicates that the process has "access the Photos library" capability will the system allow the app to open files from the Photos library.This system allows Windows to exercise tight control over Metro applications. It removes access to almost the entire system, letting them see only a tiny selection of files.Although the sandboxing AppContainer mechanism is primarily used by Metro apps, it's not actually restricted to them. There's an API and documentation for it, and regular applications, even on the desktop, can use it. The first application to actually do so is Internet Explorer 10. Internet Explorer has two guises in Windows 8; a desktop guise, and a Metro guise. The Metro guise puts all of its tabs in AppContainers, so if a malicious attack is made, it will be quite a bit harder for the attacker to break out and damage the system.Desktop Internet Explorer doesn't put its tabs in AppContainers by default, because most plugins and extensions can't cope with such a limited environmentâ€”they need to at least be able to read the hard disk, so need at least low integrity. However, you can opt in to a new mode called Enhanced Protected Mode that will put each tab of the desktop browser into a sandbox. If you come across a page that needs an extension, Internet Explorer will offer to reload the page without the sandbox.Mozilla has investigated the AppContainer mechanism for its own Metro browser so Internet Explorer is unlikely to be the sole browser to offer this security. Other software such as Adobe Reader also uses sandboxing, and over time could take advantage of this Windows 8 feature.Preserving battery life is one of the key goals for Metro applications. Unlike desktop applications, Metro applications aren't in general allowed to run in the background; unless you're actively looking at a Metro application, Windows suspends it after a few seconds. If memory becomes low, Windows will quietly terminate the app. Switching back to the app, whether it was suspended or terminated, resumes it.To ensure that apps don't lose their state when terminated, they're given an opportunity to save any necessarily information just before they get suspended. They can then reload this information when resumed, allowing the user to continue using the app without any interruption.Apps that need to do work in the background without that work being interrupted by suspension and resumption can register background tasks. These background tasks are subject to tight CPU and network usage constraints to ensure they don't interfere with the machine's performance.In and of itself, that's not too special. It's just suspending and resuming some processes. However, Windows 8 takes this to another level with a feature called Connected Standby.Connected Standby allows Windows to take process suspension to the next level, pausing not just apps but the entire machine, while still allowing these background tasks to run.With Connected Standby, the operating system can put itself in an extremely low-power suspended state, but without losing network connectivity. Whenever some network activity occurs, it will wake up just enough to handle that activity, before going back to sleep. With Connected Standby, a system can receive all the power savings and long lifetime of standby mode, but still fetch new e-mail as it arrives, respond to VoIP calls, or whatever else it might take to keep up-to-date.Connected Standby isn't a pure software feature. It requires network adaptors to support a special suspend mode, whereby they remain connected to the network, but do not need the CPU to poll them periodically (this is particularly an issue for USB network adaptors). It also requires a processor that can operate without a fan, a solid state disk, and the system firmware to advertise support of a very-low-power idle mode.These capabilities, especially the ability to operate without a fan, are rare, and presently restricted to certain system-on-chip (SoC) machines, such as Microsoft's Surface. The passive cooling requirement makes it unlikely that we'd ever see, for example, Connected Standby support on an Ivy Bridge machine, but none of the requirements actually require the use of SoCs.When a system supports Connected Standby, those Metro background tasks can fire up if necessary even when the system is suspended. Programs such as Skype listen out for network activity in a background task. The system goes to sleep, but if the Skype connection should start receiving data due to an incoming call or instant message, the network adaptor wakes the CPU and lets the Skype task start handling the data. Skype might then update its indicator on the lock screen to show that you've got a new IM or missed a call, or it could sound the speaker to alert you to the call.Connected Standby allows machines to sleep for days at a time while still remaining up-to-date. The only wrinkle is that at the moment, only Metro apps can register background tasks to run during Connected Standby. Desktop applications get completely suspended. So while the Metro Mail app might be able to keep itself up-to-date even with the machine almost "turned off," Outlook cannot.NEW YORK (CNNMoney) -- As Hurricane Sandy battered the Northeast on Monday, a different kind of storm was brewing in Cupertino, Calif.Apple (AAPL, Fortune 500) shook up its management team, announcing that two of its top executives had been shown the door.Scott Forstall -- responsible for the iOS software running iPhones and iPads, and often considered an heir-in-waiting to CEO Tim Cook -- is the most prominent executive departing. He'll stick around as an advisor for the rest of this year, then leave the company, Apple said in a press release.The move is a surprise: Forstall was one of the top executives at Apple over the past decade, and his team's software fuels Apple's premiere devices.Yet Forstall was also behind Apple's Maps software, a debacle that was widely mocked on social media. The debut of Maps was so disastrous that Cook issued a public apology for the app and recommended rival applications while Apple worked on improvements-- including the Google Maps software that it replaced.Siri, the iPhone and iPad's electronic personal assistant, is also an incomplete product. The service is frequently down and remains very hit-or-miss when delivering answers.A group of Apple executives will replace Forstall, each sharing some of his responsibilities.Eddy Cue, head of Apple's iTunes and iCloud services, will take over Siri and Maps. Mac OS chief Craig Federighi will take control of iOS, uniting Apple's two operating systems into one product group. And Jony Ive, Apple's head of hardware design, will be in charge of Apple's software look and feel going forward as well.Cook said the management changes will "encourage even more collaboration" between the company's hardware and software teams."We are in one of the most prolific periods of innovation and new products in Apple's history," Cook said in a written statement.Apple made a few other executive changes as well.Apple's widely criticized retail store chief, John Browett, is leaving after just nine months of the job. Since coming over from British electronic store giant Dixons, Browett has had one stumble after another, including slashing the number of workers in stores -- for which Cook also had to apologize.As the company searches for an executive to replace Browett, Cook will personally oversee the retail unit.Apple also announce that Mac hardware guru Bob Mansfield -- who planned last year to retire, but backtracked two months later -- will head a new group called "Technologies."The unit will focus on mobile devices, putting all of Apple's wireless products under one roof. Mansfield will also head the semiconductor teams, "who have ambitious plans for the future," Apple said.Upgrade to the latest Flash Player for improved playback performance. Upgrade now or more infoMIAMI -- While complaints can be heard far and wide that it's hard to find the right IT security experts to defend the nation's cyberspace, the real problem in hiring security professionals is the roadblocks put up by lawyers and human resources personnel and a complete lack of understanding of geek culture, says security consultant Winn Schwartau.Take Janet Napolitano, U.S. secretary of the Department of Homeland Security, who has said the country can't find the right people for network defense. The real problem is a misunderstanding of computer geeks, their personalities, habits and their backgrounds, said Schwartau today during his talk at the Hacker Halted information security conference here.MIAMI -- While complaints can be heard far and wide that it's hard to find the right IT security experts to defend the nation's cyberspace, the real problem in hiring security professionals is the roadblocks put up by lawyers and human resources personnel and a complete lack of understanding of geek culture, says security consultant Winn Schwartau.Take Janet Napolitano, U.S. secretary of the Department of Homeland Security, who has said the country can't find the right people for network defense. The real problem is a misunderstanding of computer geeks, their personalities, habits and their backgrounds, said Schwartau today during his talk at the Hacker Halted information security conference here.NEWS: Gartner: 10 critical IT trends for the next five yearsÂ MORE: Ernst & Young's IT Security survey shows struggle to secure mobile, social media, cloudComputer geeks are discriminated against under hiring rules and legal niceties that often categorize them as undesirables. "We do not fit the mold. We at the outer limits of normal," Schwartau said.According to Schwartau, there's a gauntlet of hiring obstacles today that actually work to discriminate against computer geeks who have the expertise to do the job of protecting government networks. Demands for college degrees and IT certifications and the ability to get IT security clearances should not be a priority in hiring, said Schwartau. "Forget education," he said, adding, "We need to re-design clearances -- they're a Cold War relic designed for nuclear secrets and 1950s crypto." The era of 9-to-5 is also over, he added.He said what's holding up hiring IT security professionals can be found in the thinking of human resources departments that frown on conditions such as attention deficit disorder and autism, or obsessive-compulsive personalities which are typical of computer geeks willing to focus on an issue through the night. And although hiring rules in place tend to go the extra mile to accept alcoholism, the slightest type of illegal drug infraction makes it tough for job applicants. "We've got to start getting politically incorrect if we want to get the job done," said Schwartau.If there are tests that need to be done to probe the basic trustworthiness of job applicants for sensitive network security jobs in government or industry, said Schwartau, it would be better to try industrial psychological profiling, making it clear that anyone that passed it and got hired would be subject to it over and over again during the time they were in their job.Computer geeks could be asked something like, "If your wife and daughter were kidnapped, will you turn against my company?" he suggested. The answer would likely need to be "yes," because "anything else is deceptive.""Do you need a secret clearance to defend a network? They say you do," said Schwartau, alluding to government rules. But the government is competing against private industry and, yes, the criminal world, for the kind of talent held by those who really know about network weaknesses.I sat staring at the screen, my emotions lodged somewhere between dumbfounded and despondent. From what I was seeing, I knew I'd made a horrific mistake, and restitution must be made immediately. I'd been told time and time again there was no going back; what's done is done, you have to accept it, there's no living in the past. But a violation this total demanded only one response from me.I had to uninstall Windows 8, and I had to do it immediately.What possessed me to put the latest version of Microsoft's flagship operating system on my home computer this past fateful weekend, I'll never know. To some extent, I'm sure, it was the persistent ministrations of my colleagues Michael Muchmore and Samara Lynn, who had been trying to sell me on Windows 8 for months. I'd dabbled in every major version since the Developer Preview, and never warmed to it, but I'd somehow succeeded in convincing myself that this time things would be different.Yet the instant I saw my entire 1,920 x 1,200 monitor consumed with only the Windows 8 update notifications â€“ the rest of the screen a field of white vast enough to drive Alaska to fits of murderous envy â€“ it was clear I'd been drastically mistaken. Windows 8 is not, by any stretch of the imagination, for me. And it's time I stopped pretending otherwise.Don't get me wrong: My feelings about it have evolved, and even softened, over the past year. At first I saw nothing of worth in this radical new spin on the tried-and-true Windows formula. But as I explored it on touch systems, rather than on my beloved (and â€“ pardon me if I brag â€“ insanely powerful) desktop PC, I began to discover some virtues in it. To my eye (and fingers), it's at least as good at driving such devices as iOS, and perhaps even better: It's slicker, livelier, and treats the user as more innately capable of making intelligent decisions.More power still revealed itself when I did additional research. Being a big traditional computer guy, I live by the keyboard â€“ and discovering and mastering Windows 8's myriad Windows key shortcuts increased and improved the level of my accomplishments. It was partially this experience, I think, that led me to believe that maybe I could deal with this on a 24/7 basis away from work.Unfortunately, the disjointed time I'd spent with Windows 8 before did not prepare me for what using it at home would entail. After (an admittedly painless) installation, I was faced with the garish Start screen, loaded with apps that didn't interest me at all. I clicked on a couple to see how I'd respond to them. The Weather and Stock apps were pretty, no doubt â€“ but did each one need to occupy upwards of two million pixels on my screen? Because all the Start apps open full-screen, too little information was looking much too big â€“ and there's no way to change this.Frustrated, I decided to check my Hotmail account (also the source of the Microsoft ID I entered while configuring Windows 8). I clicked on one new message, then another. The first wasn't marked read. Clicking on a third did mark the second one read, for some reason. I decided I wanted to file these, so I held down the mouse button and dragged the message just as on Outlook.com, but that didn't work as it had for some 17 years of Windows history. To move the message now, you have to click an icon on the bottom right of the screen to start the process; this is an unintuitive change whether you're using your finger or a mouse.I was certain that Internet Explorer must be better. Launching it revealed the ITProPortal home page, centred on my enormous display, with gaping chasms of white on each side. Naturally, I couldn't resize the window. So I went to open a new tab. Except I couldn't do that, either: One browser window per screen.I then fled to my safe haven, the Desktop â€“ now treated just as any other app. No Start button, right. But I could launch Internet Explorer here. Finally! Separate windows! Tabs! Except... things didn't look very good. The smoothly elegant rounded glass of Aero has been replaced by sharp, unfriendly two-dimensional corners I was sure had gone the way of Microsoft Bob. I moved to use Windows key-D to show my bare desktop, but my finger slipped half a second too early and I was thrown back to Start.From there, I decided maybe I should see the Control Panel. That shunted me back to the Desktop. Ditto Task Manager. Ditto any of several other deep-dive settings functions I use on a daily basis. But changing the image on the Start or Lock screens, or powering off the computer, could only be done through the new Windows 8 interface.I gritted my teeth and endured it for as long as I could, the constant schizophrenic flipping between Start and Desktop environments propelling me ever nearer to total mental breakdown. When I decided to update a few apps from the Microsoft Store, and received the indication that wasted more 90 per cent of the screen, I knew it was time for this experiment to end. I wiped the hard drive, reinstalled Windows 7, and have not looked back since.As I struggled to try to make sense of what was where, and more importantly why things were where they were, it became clearer than ever to me that Microsoft had never actually intended the Start screen and the Desktop to work together. So haphazard, so clunky, so confusing was everything, one could only conclude that all the company cared about was the touch market, and it was doing everything it could to discourage Desktop (and desktop) use once and for all.Microsoft is not necessarily wrong for doing this. With tablets and other mobile systems increasing in popularity, any tech company should be courting them. And, as far as Windows 8 and its kid cousin, Windows RT, are concerned, ruling over the kingdom of touch is a real possibility. Although I'm not sure I can really say I've liked using Windows 8 on touch devices, I can absolutely say I haven't hated it.Using it on anything else is another story. It makes everything I do more difficult. Michael and Samara have expounded at great length on what Windows 8 has to offer (see Michaelâ€™s review here), and I don't dispute much of what they have to say. But for people who want or need to use non-touch desktop or laptop computers in anything resembling the classic way, the learning curve isn't just steep â€“ it's vertical. Windows 8 was not designed to be used that way, but I was shocked at just how unfriendly it was towards me and my way of working, and how unwelcome it made me feel for wanting to do things with minimal convolution.I realise I'm not part of Microsoft's target audience anymore, but I still think power users like myself â€“ I've been using Windows for 22 years â€“ deserve better. If I've been using GUI-based operating systems for nearly three decades and this one regularly for over a year, and it still fails to suffice for basic tasks, there's something seriously wrong.The danger Microsoft faces is also the danger it's scrupulously trying to avoid: The industry isn't the same as it once was. Phones and tablets may be taking over, but Microsoft's dominance is also threatened as it's never been before. Real alternatives are getting real attention, and they've never had a better opportunity to gobble up the people Microsoft is casting aside.The latest versions of Mac OS X are far more usable and appealing than Windows 8. Many Linux distributions, starting with the well-known Ubuntu, have made rapid-fire about-faces in recent months to get themselves in shape to fill the vacuum Windows 8 has been creating. Both operating systems make multi-window multitasking a clean, smooth reality, acknowledging, as Microsoft will not, that most people still work that way.Hope for us Windows lovers, however, is not necessarily lost. Microsoft has demonstrated some ability to learn from its mistakes and come back stronger. Nearly six years ago, Windows Vista fizzled upon its release, but was redeemed by a comprehensive service pack and then, within two and a half years or so, Windows 7. There's no reason it can't weave similar magic on 2012's deeply flawed OS.But Microsoft must have the will to do so. If the future is touch, why should it waste time and resources considering how Windows 8 works with creaky keyboards and mice? What Microsoft has forgotten is that you can't get to the future without moving through the present. In trying to skip over today, the folks in Redmond have angered a lot of people â€“ and wasted their time and monitor real estate just like they've wasted mine.I've been forgiving of Microsoft's foibles and idiosyncrasies for a long time, but my patience has about run out. If Microsoft wants me to use Windows 8 or a touch system, it has to give me a concrete reason â€“ and one boring app per screen ain't gonna cut it. Otherwise, I'll stick with Windows 7 â€“ and maybe even dual-boot Linux with it at the same time. Those two operating systems together give me everything I need. Windows 8 doesn't come close. Worse still, it doesn't even try.Published under license from Ziff Davis, Inc., New York, All rights reserved.Copyright Â© 2012 Ziff Davis, IncDow Jones Reprints: This copy is for your personal, non-commercial use only. To order presentation-ready copies for distribution to your colleagues, clients or customers, use the Order Reprints tool at the bottom of any article or visit www.djreprints.comMicrosoft Corp. officially released an overhaul for its nascent Windows Phone software, in its latest attempt to catch up to Apple Inc. and devices running software from Google Inc.The new software, dubbed Windows Phone 8, will include a bevy of new features, including the ability for apps, such as those from Facebook Inc. or Groupon Inc., to display recently posted photos or the latest daily deal on the device's home screen.But Microsoft said some of the new Windows 8 phones won't launch until mid-November or later. The timing means that Microsoft could lose out on some sales in ...Ok, so this app made me feel really dirty when I downloaded it. Itâ€™s called Badabing! and it basically goes through your friendsâ€™ photos on Facebook to pull out the ones of them at the pool or beach. In other words, weâ€™re talking about scantily clad photos here.I of course, for the sake of technology journalism, had to download the app and give it a whirl. It actually kind of works and itâ€™s really creepy. To protect the innocent, Iâ€™m not going to post any actual screenshots of my Facebook friends. Theyâ€™d kill me. And probably the folks who made this app.The app is $1.99 and all you have to do is log in with your Facebook account and then choose a few friends to dig up some dirt on. The company has some sort of image recognition technology that looks forâ€¦skin?After your search is complete you can bookmark your favorite photos. Now letâ€™s get to the heart of the matter, is this wrong to do? I mean, technically, your friends have uploaded these photos and shared them with you anyway. All this app does is do a search, albeit a search with icky intent.Moral of the story, donâ€™t upload photos to Facebook and share them with friends unless you want them looking at them. Especially if youâ€™re in a bikini or tight swim trunks.Creep you out? Cool use of tech? Tell us in the comments.Visit our directory for more information about Google blogs.Federal authorities said they uncovered an advanced bank heist that defrauded Citigroup of more than $1 million by exploiting a security loophole in the way it handles electronic payments.The scam worked by simultaneously withdrawing funds from cash advance kiosks maintained in at least 11 casinos located in California and Nevada, according to an indictment unsealed late last week in federal court in San Diego. Alleged ringleader Ara Keshishyan recruited at least 13 people to make transactions from different kiosks in each location. To exploit the weakness, the multiple advance requests had to be near identical and had to be made in the same 60-second window, FBI officials said in a press release."In order to obtain the case, the conspirators exploited a loophole in Citi's account security protocols, which caused Citi's account reconciliation systems to treat identical, near-simultaneous withdrawals as duplicates of a single withdrawal from an individual Citi Checking account," prosecutors alleged in the indictment. "In exploiting this loophole, the conspirators withdrew identical sums of money in succession from a single Citi checking account all within a specific time window. This allowed the conspirators to fraudulently withdraw several times the amount of money deposited into each account."The defendants obtained more than $1 million from Citigroup, prosecutors said. To conceal the scam, they kept withdrawal below $10,000 to avoid federal transaction reporting requirements. The kiosks were operated by Global Cash Access, a Las Vegas-based financial transaction services company. They allow casino patrons to get cash that's held in personal banking accounts. The Citigroup loophole has been closed, The Press-Enterprise reported.Prosecutors said Keshishyan caused sums of $10,000 or less to be deposited into various Citi checking accounts. The conspirators he allegedly hired would then use Citi ATM cards to obtain cash amounts from the kiosks that collectively exceeded the account balances. The defendants allegedly used the stolen funds to gamble at the casinos, allowing them to receive free rooms and other perks in return for high-roller status.All 14 defendants were charged with conspiracy to commit bank fraud and conspiracy to illegally structure financial transactions to avoid reporting requirements. The maximum penalty if convicted on those charges is five years in prison and a $250,000 fine. Keshishyan has also been charged with 14 counts of bank fraud, each of which is punishable by up to 30 years in prison and a $1 million fine. Prosecutors are also seeking forfeiture of money and property belonging to the defendants.It's unknown if any of the defendants have issued a plea in the case.Hurricane Sandy may have stopped Google's Android event, but it couldn't stop the Google website. There will be no swanky event in downtown New York City, but Google's Android team has taken to a blog post to announce the latest Android devices, including the long-rumored Nexus 4 phone made by LG and Nexus 10 tablet made by Samsung.Google is also refreshing its 7-inch Nexus 7 tablet, bringing the total number of Nexus devices on the market to three.Nexus devices, unlike all the other hundreds of Android phone and tablets out there, are built in close partnership between Google and other phone or tablet makers. They are also the first devices to run the new version of Android. In this case, all the devices being announced today run Android 4.2, the next version of Jelly Bean. Android 4.2 isn't a complete overhaul of the software, but adds such features as a new keyboard, wireless video streaming services, a 360-degree photo feature, and a new Google Now service."People increasingly have more than one device, and they switch between them many times a day. Nexus â€” Google's hardware line for Android devices â€” gets rid of the hassle," Google's Senior Vice President of Android, Andy Rubin, said in the post. "Just sign in with your Google Account and everything is there ready to go, whatever device you're using: photos, emails, contacts, bookmarks, even your entertainment on Google Play."Below are details on all of the new devices:Nexus 4 (Starts at $299) The new Nexus 4 phone, which is made by LG, will replace the Samsung Galaxy Nexus phone that came out about a year ago. The phone has a large 4.7-inch screen with a high-resolution 1280 x 768 display, and a fast quad-core S4 Pro processor. The camera on the phone has also been updated (it was one of the major pain points of the last version) -- it now has an 8-megapixel camera on the back and a 1.3-megapixel camera on the front for video chatting.The $299 base version has 8GB of storage and a $349 version will have 16GB of space. For now, Google will only offer the phone unlocked through T-Mobile, meaning it won't be available through Verizon, Sprint or AT&T. That also means it will not have LTE service in the U.S.The new Android 4.2 software brings new gesture typing, "which lets you glide your finger over the letters you want to type on the keyboard," Google says. It also supports wireless video and new photo features. The phone will be available to order through Google's Play store starting today and in select T-Mobile retail stores and online on Nov. 14.Nexus 7 (Starts at $199) Moving up to the 7-inch screen, Google has slightly refreshed its Nexus 7 tablet, which it announced back in June in collaboration with Asus. The new version will run Android 4.2, but there is also a 32GB version now that will cost $249. There will be a 32GB version with HSPA+ cellular connectivity for $299. That version will work with AT&T SIM cards and service. The 16GB version with WiFi only costs $199.Apple's iPad Mini, which has a larger 7.9-inch screen, goes on sale this Friday for $329, while Amazon's Kindle Fire HD, which has 16GB of storage, starts at $199.Nexus 10 ($399) Of course, there's one more! The Nexus 10, as you might guess, has a 10-inch screen and the latest Android 4.2 software. Built by Samsung, the tablet has a high-resolution 2560 x 1600 resolution screen, similar to the Retina display on the new iPad. Internally, the tablet has a dual-core processor and 2GB of RAM. The 16GB version will start at $399.ABC News has been promised a hands-on look at the new devices. Stay tuned for more information.Icrontic has been around for twelve years. With thousands of people coming and going, variously circling in and out of the group as lives and times and interests change, old online communities like ours become a magnifying glass into the ebb and flow of the human experience.Of course, death is a natural part of that experience, and weâ€™ve had our fair share over the years. From natural causes to tragic accidents, our community has been through a lot of down moments. Thankfully, weâ€™ve also experienced the joyous news of families, new children, marriages, and career successes that far outnumber the sad times.This past week, however, hit us harder than weâ€™ve ever been hit. One of our core community members lost his father suddenly and unexpectedly, right before our annual Oktoberfest gathering. The community reeled; we didnâ€™t know how to help our dear friend cope with his shocking loss. For a man who has done so much for Icrontic over the years, we wanted to turn the tables and be there for him, but we didnâ€™t know how. All we could do is take up a collection for his family to help with the funeral costs, and to make a small donation to a local charity in his fatherâ€™s name. People sitting behind keyboards thousands of miles away, some in other countries, some on other continents, had only this one mechanism by which to extend their condolences. They canâ€™t hug their friend while he weeps, so they do the only thing they can do. They write some words, maybe they call, maybe they email, maybe they open up Paypal. What can they do? None of it seems sufficient, especially when you cannot get there. This is the only true downside of online communityâ€”when your friends need you, physically, distance can be an insurmountable obstacle.Soon after, those who could began gathering together for Oktoberfest, here in Detroit. This is an event thatâ€™s been going on for five years, and is our second largest annual community gathering. We anticipated over 50 people coming in from all over the country for this event. This was going to be an especially poignant gathering because itâ€™s the first in our new headquarters.The Icrontic gatherings have been going on since 2004. From small and humble beginnings, we have blossomed into a full-blown convention organization, culminating in Expo Icrontic every summer. Many community members save up their vacation days and travel accounts to come up, over, or down to Detroit to be with their online family. This event was going to be incredible.On the first day, tragedy struckâ€”again. What was supposed to be a fantastic party and community gathering has turned into a memorial service and an extended wake. For days now, a group of Icrontians has been together in a large house in Detroit coming to terms with the sudden loss of our friend.Itâ€™s still abstract for me to type those words out. They happened just days ago. Spencer was in my living room, fifteen feet from where Iâ€™m sitting. I hugged him hello, told him I was glad he was here, and we struck up a normal nerdy conversation. He looked around the house, proud of the work he had done to help the progress of ICHQ Detroit (he did a ton of work sanding our front entrance ceiling, helping with wall repairs, and helping scrub grout stains off our new tile in the bathroom), and marveled at how far it had come in such a short time. He was just here.I am extremely fortunate. I was here. I have extremely recent memories of Spence. I was part of the small group that last saw him alive. I feel guilty that people who were closer to him did not get that same treasure. I saw him moments before he died, and he was laughing. I have that memory and so many others donâ€™t. I feel terrible about that.I returned from the hospital after a long and horrible night, and came up to the front door. There was a group of people standing on the porch, crying. I grabbed the first person I saw and didnâ€™t let go. We wept.People milling around. From every corner of the house, you could hear either laughter or tears. Spencer was a tremendously comical person. He laughed loud and hard and often. When we tell stories of him, itâ€™s almost impossible not to laugh. You can only cry so much.Should the party go on? Should I cancel my trip? Should we do the beer tasting? What should we do?The group came to the consensus that the costume party and gaming would carry on. Spencer would definitely not have wanted us to cancel the event on his behalf, and he most certainly wouldnâ€™t want us to not game. Gaming was his greatest joy.Fuck it, we said, weâ€™re carrying on. For Spencer.I had guilt about this new sudden tragedy overshadowing the other recent tragedy, the loss of one of my best friendsâ€™ dad. I sent him a text message. â€œIâ€™m thinking about you.â€? Here is a person who is suffering alone, hundreds of miles from his Icrontic family, who has just lost his father, and now he has to deal with finding out one of his good friends died in a senseless car accident, before his fatherâ€™s memorial service is even complete. Why can I not have a magic wand? I am the community manager for this group, and more than ever I felt completely and utterly powerless. I wanted to be able to get everybody into a room together for a group hug.Being thousands of miles away when your friend dies, without enough money to get an emergency plane ticket. What can you do? You need information, you want to talk to people. The group is thereâ€”awayâ€”inaccessible. They are healing, talking, laughing, hugging, crying. You need to be a part of that, yet you cannot.The Icrontic community is the most generous online community in the worldâ€”I am convinced of that. In this past week, thousands of dollars have been raised to help with funeral expenses and plane tickets. People made discreet arrangements. People flew in. Friends arrived, and got the laughter, tears, screams, and hugs out that they so desperately needed. If only it could have been everyone. If only.There is a lot of survivorâ€™s guilt going on. Two cars left for the restaurant that night. My son was in one, and I am so, so glad he wasnâ€™t in the other. My other son decided not to come that night because he was having a party with his friends. If he had come, he almost certainly would have been in that car. I am so, so glad he wasnâ€™t. I feel terrible about that, and I am struggling with my guilt for thinking those thoughts, while at the same time understanding that itâ€™s completely rational and normal for me to have them. Group therapy has been helpful. Weâ€™re all starting to share our feelings and dark thoughts. If I had chosen a different restaurant, Spencer would be alive. If Spencer had gotten in the other side, it may have been Nick instead. If Spencer came with me. If I hadnâ€™t stopped to pee on the way out of the house. If we had left ten seconds later or sooner. If, if, if.There was a lot of speculation about the driver of the other vehicle. Violent, angry rants about revenge. Calm, rational discourse. Drunk, not drunk. Male, female. We were looking for a focus. We needed a bad guy to pin this on. We needed to make sense of this. Of courseÂ it was a loud, obnoxious, easy-to-hate drunk driver. What else could it be? Or a mother. Or a grandfather. Or a brother or cherished son with a promising career ahead of him. Maybe a teacher. Maybe a volunteer. Maybe a social worker. Maybe a drug addict or a thug. Maybe a dealer or a criminal. We donâ€™t know, so we create characters.Today we say goodbye. Today is the funeral, and today is the end of the gathering. After people grieve again, they will scatter and disperse back to their homes around the country.Icrontic is forever changed by this. We have had a unique opportunity to really come to terms with the death of a dear friend, in a group setting full of open communication, no barriers, and true companionship. We are very, very lucky for that. This is not the first tragedy in our community, nor will it be the lastâ€¦ It was, however, one of the most educational.Icrontic will carry on. For Bart, for Keith, for Angel Heather, for Ericâ€™s dad, for all the others who we have lost along the way. For Spencer.The U.S. Supreme Court on Monday considers whether to allow a challenge to a federal law that provides for large-scale electronic surveillance of international phone calls and emails. The case is not a direct test of the Foreign Intelligence Surveillance Act. Rather, it is a test of whether the law can even be challenged in court at all.How FISA Came To BeCongress first passed the law in 1978 to prevent the kind of warrantless surveillance of Americans that had been uncovered by congressional investigators. Known by the acronym FISA, it required the government to obtain a warrant from a special intelligence court when conducting electronic surveillance of individuals abroad â€” surveillance that could pick up communications to and from people in the United States.After Sept. 11, 2001, the Bush administration secretly circumvented the law. When its warrantless wiretapping was disclosed, the administration proposed legislation to quell the resulting furor. In 2008, Congress passed a new version of the law, loosening the reins considerably. It limited the FISA court's supervision, did away with the previous requirement for individual targeting, and instead allowed the government to monitor large swaths of people. Critics called it the "vacuum cleaner" approach to electronic surveillance.Groups and individuals with frequent international contacts challenged the law in court, contending that FISA, by authorizing "dragnet surveillance," violates the Constitution's ban on unreasonable searches. But Monday's Supreme Court arguments do not get to that issue. Instead, the court is focusing on a threshold question: whether the case can be brought at all because the challengers cannot prove with certainty that their communications were intercepted.Among those suing to invalidate FISA are human rights groups such as Amnesty International, journalists and lawyers for detainees. The lawyers, for instance, routinely have telephone conversations with the families of detainees, with witnesses and with investigators. The government, however, contends that without proof positive, the claims to have been spied upon are speculative, and the challengers have no legal standing to bring a case to court.The challengers counter that the government's position amounts to a Catch-22 because in a secret program, there is no way to prove you've been monitored."Their argument is you can't challenge the statute if you can't show your own communications have been acquired under it," says Jameel Jaffer, deputy legal director of the ACLU, who is representing the groups. But the government, he adds, refuses to "tell you if your own communications have been acquired under it."A federal appeals court in New York agreed with the challengers that they have suffered a concrete injury that justifies allowing the case to go forward. That court said that based on the challengers' reasonable fear of being monitored, they have largely abandoned international phone and email communications, and have spent time and money to travel overseas to meet with people in person in order to be free from government surveillance.Todd Hinnen, who served as acting assistant attorney general for National Security in the Obama administration, concedes that because of the secret nature of the surveillance, "it's very difficult for a plaintiff to make specific and concrete allegations."But, he adds, in an age of terrorism, the intelligence community needs greater latitude, and therefore Congress "consciously limited the circumstances" under which FISA can be challenged.Basically, the government argues that the civil liberties protections in the law are internal. For example, the statute requires the attorney general and National Intelligence director to periodically assess the steps taken to minimize the effect of the surveillance on U.S. citizens.But at the same time, the law does not contemplate a direct challenge in the courts. As Hinnen puts it: "It is a statute that governs foreign intelligence practices, targeting foreign citizens overseas, subjects that traditionally have been viewed as the core of Congress and the executive branch's prerogative."Jaffer, of the ACLU, replies that if the Supreme Court accepts the government's position, the justices "will be accepting that this statute is immune to the kind of judicial review that we generally think federal statutes ought to be subject to."After all, the issue being argued on Monday is not whether the law is constitutional, he observes, but "whether we have the right to challenge the constitutionality of the law."It may seem like a technicality, but it is â€” at this point â€” the whole ball of wax.The shrinking size of features on modern processors is slowly approaching a limit where the wiring on chips will only be a few atoms across. As this point approaches, both making these features and controlling the flow of current through them becomes a serious challenge, one that bumps up against basic limits of materials.During my visit to IBM's Watson Research Center, it was clear that people in the company are already thinking about what to do when they run into these limits. For at least some of them, the answer would involve a radical departure from traditional chipmaking approaches, switching from traditional semiconductors to carbon nanotubes. And, while I was there, the team was preparing a paper (now released by Nature Nanotechnology) that would report some significant progress: a chip with 10,000 working transistors made from nanotubes, formed at a density that's two orders of magnitude higher than any previously reported effort.During my visit to Watson, I spoke with George Tulevski, who is working on the nanotube project, and is one of the authors of the recent paper. Tulevski described nanotubes as a radical rethinking of how you build a chip. "Silicon is a solid you carve down," he told Ars, "while nanotubes are something you have to build up." In other words, you can't start with a sheet of nanotubes and etch them until you're left with the wiring you want.One possible alternative is to use graphene, a sheet of carbon a bit like an unrolled nanotube, which can potentially be etched into distinct features. The problem, according to Tulevski, is that graphene doesn't naturally have a bandgap, the feature of semiconductors that makes them useful for circuitry. It's possible to manipulate graphene so that it develops a bandgap, but that adds to the complexity of manufacturing devices. Some carbon nanotubes, in contrast, are semiconductors without the need for any manipulation (others are metals).This still left IBM with a choice, Tulevski said. You could potentially attempt to grow a pure population of carbon nanotubes in place, on your chip. We've gotten much better at controlling the growth of nanotubes, and IBM has equipment in house that be been used to produce them. The problem there is that, if anything goes wrong with just one of the tubes, the whole chip would be lost. We may have gotten much better, but we've not gotten that good.So, Tulevski's group is taking a different approach: buy off-the-shelf nanotubes, isolate the ones they want, and then assemble them on a chip.The first couple of steps of this is easier than it sounds. Tulevski showed off a large jar, obtained from a chemical manufacturer, that contained a mixture of carbon nanotubes. As it turns out, the two types of nanotubes, metals and semiconductors, interact differently with a standard column of the type commonly used in chemistry and biochemistry labs. Simply run a mixture down the column, and it's possible to separate out a relatively pure population of one type. To make matters even more convenient, the two populations are slightly different colors.Once you have a collection of semiconducting nanotubes, you have to build circuits out of these. If we're ever going to make processors out of them, this has to be done quickly, cheaply, and consistently. As Tulevsky described it in referring to purifying the right nanotubes, a one part-per-billion error rate just isn't good enough when you consider the number of transistors on a modern chip.The team at Watson is working on solution processing, which is where the new paper comes in. The idea is to pre-pattern the needed circuitry onto a chip using IBM's existing foundry experience. Once that's in place, a solution containing carbon nanotubes can be washed across the chip, at which point they'll drop out of solution and attach to the chip based on the pattern.In the paper, the pattern was set up by etching away silicon dioxide to reveal an underlying layer of hafnium dioxide. The HfO layer could interact with a charged organic molecule (4-(N-hydroxycarboxamido)-1-methylpyridinium iodide), creating a charged surface. The carbon nanotubes could then be floated across this surface while encased in a coating of an organic molecule with the opposite charge. A simple ion exchange reaction locks the nanotube in place above the hafnium layer.With the hafnium features at 70nm wide, this process was used to create field-effect transistors (FETs), and it worked with an efficiency of over 90 percent. The density of these FETs was 10 per square centimeter, 100 times higher than the previous reported best. And these devices could be made en masse: the researchers were able to test over 10,000 of the FETs on a single chip, and found over 7,000 functional ones (most of the rest ended up with a metallic nanotube instead of a semiconductor).This still isn't ready for chip manufacture. But it's a lot closer than most previous efforts, and gives IBM's team some obvious things to troubleshoot if they want to boost the efficiency further.The two have been benefiting from losses at rivals like Nokia and Motorola, Canaccord Genuity says, and that trend should continue.Controlling all of the mobile market's profits doesn't appear to be enough for Apple and Samsung anymore. Now they're actually generating more than 100 percent of the industry's earnings -- 106 percent, to be precise -- according to a report from Canaccord Genuity.That may seem impossible, but it's largely because rivals -- like Research In Motion, Nokia, and Motorola -- posted operating losses during the September quarter, the firm said."With Samsung extending its overall smartphone and Android market share combined with Apple's strength in high-end smartphones, competing smartphone [original equipment manufacturers] continued to struggle to compete with these dominant smartphone OEMs," Canaccord analyst T. Michael Walkley noted today.It's actually the second quarter in a row that the two companies captured greater than 100 percent of the industry's profits, Walkley added. In the second quarter, Apple and Samsung held 108 percent shareWalkley estimates that Apple captured 59 percent of the industry's operating profits in the calendar third quarter, with only 6.3 percent of global handset unit sales and 15.4 percent of smartphone unit sales.Samsung, meanwhile, controlled 47 percent of the profits, up from 37 percent in the second quarter. It held 25.6 percent of the global handset unit market share in the third quarter, up from 25.3 percent in the second quarter, in part because of strong Galaxy S3 sales. Walkley expects Samsung to maintain its leading unit market share position during the fourth quarter and beyond, continuing to supplant longtime leader Nokia.The two companies' dominance should continue in the current quarter, Walkley said, with Apple likely to take some share from Samsung during the period because of strong global demand for the iPhone 5.The numbers continue to paint a dismal picture for the handset industry at large, with barely anyone being able to make money aside from Apple and Samsung. The giants continue to dominate and squeeze rivals like Motorola while low-cost handset makers like ZTE are applying pressure on the low end.The Internet is experiencing severe outages across North American and AsiaTake in the sights from the torch balcony at the Statue of Liberty, where the public has not been permitted to visit in person since 1916, and see unique, one-of-a-kind perspectives of the torch, crown, face and tablet, in addition to ultra widescreen panoramic images and live HD streaming video. Enjoy unmatched streaming video of Lady Liberty from Brooklyn, as well. Click on the links below to learn more about the TorchCams: The Associated Press Â Â Â Â |Â Â Â Â One of the notable features announced with the release of Android 4.2 yesterday was support for multiple users on a single Android device. Google's list of 4.2 features, though, makes it very clear that multiple users is supported only on Android 4.2 tablets, not phones.TechCrunch speculates that the limitation is due to a patentâ€”US 2005/0107114 A1, "Multi-user mobile telephone," to be specific. The patent was filed in late 2004, granted in 2005, and was penned by then-current Symbian employee Tim O'Cock. The abstract makes it pretty clear that it envisions several different people, each with their own personalizations, using a single device:A mobile telephone is designed to be used by several different end-users at different times. A first end-user can alter the mobile telephone so that it operates in a manner specific to that first end-user and a subsequent end-user can alter the mobile telephone so that it operates in a manner specific to that subsequent end-user; each end-user has only to respond to prompts displayed on a screen in order to alter the mobile telephone so that it operates in a manner specific to that end-user.The USPTO lists the patent's current assignment with both Tim O'Cock and Symbian Limited, with both pointed back to Nokia. TechCrunch guesses that the original intent behind the patent was to take revenue from emerging markets by providing an easy method for lots of different folks to share a single phone; in areas of the world where cellular phones are expensive, a feature which lets several people use the same phone gives that phone a competitive advantage.It's easy to see how this patent might be a potential stumbling block to any company wanting to implement a similar feature. The patent language is broad enough to cover just about any possible implementation of multiple user accounts, and even though no Nokia phone has shown up with anything like "multiple users" on the feature list, anyone with something similar in mind would have to deal with licensing from Nokia.The loophole which Google is using to bring the feature to tablets is that the patent language very clearly states "mobile telephone" over and over again. In 2004 when the application was filed, consumer-grade tablet devices were but a twinkle in technologists' eyes (stylus-driven "tablet" notebook computers notwithstanding). The patent narrowly applies to phones, not "mobile communications devices" or anything else.However, the "freedom to tinker" mindset which pervades the Android ecosystem might win out here. If the feature is available in tablets, it is likely only a matter of time before enterprising Android 4.2 hackers (and I mean hackers in the good sense of the word) find a way to enable the functionality on their handsets.BERLIN â€” Angry Birds, the top-selling paid mobile app for the iPhone in the United States and Europe, has been downloaded more than a billion times by devoted game players around the world, who often spend hours slinging squawking fowl at groups of egg-stealing pigs.While regular players are familiar with the particular destructive qualities of certain of these birds, many are unaware of one facet: The game possesses a ravenous ability to collect personal information on its users.When Jason Hong, an associate professor at the Human-Computer Interaction Institute at Carnegie Mellon University, surveyed 40 users, all but two were unaware that the game was storing their locations so that they could later be the targets of ads.â€œWhen I am giving a talk about this, some people will pull out their smartphones while I am still speaking and erase the game,â€? Mr. Hong, an expert in mobile application privacy, said during an interview. â€œGenerally, most people are simply unaware of what is going on.â€?What is going on, according to experts, is that applications like Angry Birds and even more innocuous-seeming software, like that which turns your phone into a flashlight, defines words or delivers Bible quotes, are also collecting personal information, usually the userâ€™s location and sex and the unique identification number of a smartphone. But in some cases, they cull information from contact lists and pictures from photo libraries.As the Internet goes mobile, privacy issues surrounding phone apps have moved to the front lines of the debate over what information can be collected, when and by whom. Next year, more people around the world will gain access to the Internet through mobile phones or tablet computers than from desktop PCs, according to Gartner, the research group.The shift has brought consumers into a gray legal area, where existing privacy protections have failed to keep up with technology. The move to mobile has set off a debate between privacy advocates and online businesses, which consider the accumulation of personal information the backbone of an ad-driven Internet.In the United States, the data collection practices of app makers are loosely regulated, if at all; some do not even disclose what kind of data they are collecting and why. Last February, the California attorney general, Kamala D. Harris, reached an agreement with six leading operators of mobile application platforms that they would sell or distribute only mobile apps with privacy policies that consumers could review before downloading.In announcing the voluntary pact with Amazon, Apple, Google, Hewlett-Packard, Microsoft and Research in Motion, whose distribution platforms make up the bulk of the American mobile app market, Ms. Harris noted that most mobile apps came without privacy policies.â€œYour personal privacy should not be the cost of using mobile apps, but all too often it is,â€? Ms. Harris said at the time.But simple disclosure, in itself, is often insufficient.The makers of Angry Birds, Rovio Entertainment of Finland, discloses its information collection practices in a 3,358-word policy posted on its Web site. But as with most application makers around the world, the terms of Rovioâ€™s warnings are more of a disclaimer than a choice.The company advises consumers who do not want their data collected or ads directed at them to visit the Web site of its analytics firm, Flurry, and to list their details on two industry-sponsored Web sites. But Rovio notes that some companies do not honor the voluntary lists.As a last resort, Rovio cautions those who want to avoid data collection or ads simply to move on: â€œIf you want to be certain that no behaviorally targeted advertisements are not displayed to you, please do not use or access the services.â€?Despite multiple requests by phone and Internet over five days, Rovio did not respond to questions.Policy practices like Rovioâ€™s often do little to inform consumers. Most people simply click through privacy permissions without reading them, said Mr. Hong, the Carnegie Mellon professor. His institute is developing a software tool called App Scanner that aims to help consumers identify what types of information an application is collecting and for what likely purpose.In Europe, lawmakers in Brussels are planning to bring Web businesses for the first time under stringent data protection rules and to give consumers new legal powers, the better to control the information that is being collected on them.Proposed revisions to the European Unionâ€™s General Data Protection regulation now before the Civil Liberties, Justice and Home Affairs Committee of the European Parliament would require Web businesses to get explicit consent from consumers to collect data. A proposal would also give consumers the ability to choose what information an app can store on them without losing the ability to use the software.But the drafting of the revisions, which are not expected until late 2013 at the earliest, has set off a concerted lobbying battle by global technology companies, most of which are based in the United States, to weaken the consent requirements, which could undermine the advertising-financed business models that drive many free applications.Everything you need to know to make the right choice.Our selection of recommended PCs for WindowsÂ 8 and WindowsÂ RT.Discover new ways to personalize your PC with WindowsÂ 8 and WindowsÂ RT.See what you can do with the world of apps at the Windows Store.1 of 6.An automated train dumps ore in a sorting area after transporting it from thousands of meters underground at Vale's Copper Cliff mine near Sudbury, Ontario October 16, 2012.Once filled, the automated train will snake through a series of narrow tunnels, emerge from a rocky outcropping, then loop past St-Jean's window and dump its payload for sorting.Vale SA, the Brazilian company that owns the mine near this nickel-rich Canadian town, has spent nearly $50 million in two years to install and test the "rail-veyor." The company believes the transport system will revolutionize how it builds and extracts new mineral deposits.The equipment is made locally by Rail-Veyor Technologies Global Inc. It is one of many mining technologies that developers hope will allow future production to be run almost entirely by people safely above ground.Such advances may prove crucial as easy-to-exploit deposits run dry and miners drill deeper in more remote places to supply China, India and other emerging economies. The technology could make mining cheaper and safer, avoiding the need to dig wide tunnels and hire large numbers of expensive, skilled workers."As we go deeper, if we continue to apply existing thinking and existing technologies, it's a death spiral" for company profits, said Alex Henderson, who heads Vale's technology team in Sudbury."We need to begin to look at a step-change in mining rather than just incrementally improving our existing processes."The rail-veyor is one such step-change. At the test site, it has halved the time to build a mine, and Vale expects a 150 percent boost in production rates before year end.In Australia, Rio Tinto Ltd, one of the world's largest miners and an automation pioneer, is rolling out a fleet of self-driving trucks and trains at its iron ore operations. Vale, BHP Billiton and Chile's Codelco are in hot pursuit.Gold miner AngloGold Ashanti is eyeing automation in South Africa, where miners spend hours each shift traveling up and down shafts and ounces of gold are left behind in support pillars each year.Organized labor has made its peace with the automation drive, although there were some concerns that robots would displace humans."We're ok with automation, it's part of the changing times and it's a good thing for productivity," said Myles Sullivan of the United Steelworkers Canada, whose workers ended a year-long strike at Vale over bonuses and wages in 2010.New challenges in mining are driving technological changes. Large, accessible deposits have all but disappeared. Resources of tomorrow are in far-flung corners of the globe or hundreds of meters beneath the surface.Add a shortage of skilled labor - expected to worsen as the baby-boom generation retires - and mining costs have surged.While soaring demand means higher metal prices, rising costs are crimping profits. Canada's S&P/TSX Mining share index has fallen more than 38 percent since the beginning of 2011.Experts say mining companies must change how they operate.Making that shift is not easy for an industry steeped in tradition, especially when change doesn't come cheap. Rio Tinto is spending more than $500 million on train automation alone."This is a very conservative industry that has been very productive over the last 30 years doing it the way they're doing it now," said Douglas Morrison, chief executive of the Centre for Excellence in Mining Innovation (CEMI), an industry-funded research center in Sudbury."But is the old way going to work for us into the future? I think probably not, so we need to make some changes."After decades of production, the nickel mines around Sudbury are getting deeper and deeper. At Vale's Creighton mine, the No. 8 shaft drops nearly 8,000 feet into the ground - equivalent of a 700-story condo tower.At that depth it is very hot, around 50 degrees Celsius (120 Fahrenheit), so tunnels must be pumped full of cooled air to make temperatures manageable for people and heavy machinery."The bigger issue is when we get much deeper we start to generate our own earthquakes - very small earthquakes - these are called 'rock bursts,'" said Morrison.Smaller tunnels and new ways of digging can hopefully reduce the danger of these rock bursts, which create a safety concern and slow development.Rio Tinto is working with CEMI on automated tunnel borers, currently used to build subway and sewer tunnels. By cutting through the rock instead of blasting, Rio aims to quadruple its underground advance rates to 20 meters a day.But while automated tunnel borers will build shafts and tunnels more quickly, massive mining equipment still handicaps the industry, which is where Vale's rail-veyor comes in.A train hauling 50 tonnes of ore uses a far smaller tunnel than a truck with the same load. By taking the massive trucks and scooptrams - large vehicles with shovels on the front - out of the equation, Vale can build more compact and stable tunnels.The rail-veyor, built on tracks that zig-zag down to the deposit, actually eliminates the need for expensive shafts and may eventually move people and equipment, along with ore.Vale's Henderson believes the technology - which the company plans to roll out in five upcoming projects - is a game-changer that will help usher in a new era of mining."Just as the scooptram was the key enabler for the mechanized era, is the rail-veyor a key enabler for the next?" he said.What that "next era" will look like is still up for debate. Some innovators believe robots will do most of the labor in mines of the future, as in automobile assembly plants. This would ease likely shortages in skilled labor in many countries.Over the next decade Canada's mining sector will need more than 100,000 skilled new hires to sustain even modest growth, according to the Mining Industry Human Resources Council.In Australia, the labor crunch is already so intense that truck drivers can make upwards of $100,000 a year, with turnover rates at some mines still near 40 percent."One of the biggest problems that the mining industry faces worldwide is trained personnel. We can't get them," said John Meech, director of CERM3, a mining research center at the University of British Columbia in Vancouver."One of the ways we are going to have to deal with that is to automate the systems so that the human becomes the supervisor, rather than the direct means of control."It is a concept already used at remote open-pit mines in Australia, where Rio's new fleet of driverless trucks can be run from a control room hundreds of miles away.Canada's Nautilus Minerals Inc is using automated rovers to explore the ocean bed for mineral deposits that underwater robots will eventually mine.In addition to boosting productivity, the advances will enhance safety. As labor leader Sullivan says, "so long as there's underground mining, there will be women and men working underground."Safety is the focus at a converted schoolyard just outside Sudbury, where a duo of mine rescue robots roll through a makeshift obstacle course. Their thick tires grind over logs and through mud pits.Designed by Canada's Penguin Automated Systems Inc, the equipment is being tested by Codelco at its Andina copper mine in Chile, doing dangerous jobs like checking stability after blasting and surveying tunnels at risk of flooding."Our mining industry is not quite there yet in Canada and it needs to get there to be competitive with the rest of the world," said Penguin Chief Executive Greg Baiden. "It comes back to the culture. Who wants to do it? Who wants to be first?"(Additional reporting by Bhaswati Mukhopadhyay in Bangalore; Editing by Frank McGurty, Janet Guttsman and David Gregorio)Symantec provide overview and analysis of the year in global threat activity via its Internet Security Threat Report (ISTR) , with aÂ exclusiveÂ details that 400 million new variants of malware were created in 2011, which is an average of 33 million new variants of malware a month, or an average of one million new variants a day.."Â Symantec said in a blog post. Political activism and hacking were two big themes in 2011 themes that are continuing into 2012. There were many attacks last year that received lots of media attention. Hacking can undermine institutional confidence in a company, and loss of personal data can result in damage to an organizationâ€™s reputation.Also,Â Many companies are keen to adopt cloud computing. It can reduce costs by outsourcing routine services.Â The first risk is unmanaged employee use of cloud services. The proportion of phishing emails varied considerably by company size with the smallest and largest companies attracting the most, but the proportion of spam was almost identical for all sizes of business. The United States was the number one source of all activities, except for malicious code and spam zombies, where India took first place. Around 12.6% of bot activity originated in the USA as did 33.5% of web-based attacks, 16.7 % of network attacks and 48.5% of phishing websites.A new class of electronics that are biocompatible and can dissolve completely in liquid mean that implantable medical treatments are closer to reality for on-the-go warfighters.DARPA researchers have created electronic systems and components using ultrathin sheets of silicon and magnesium encapsulated in silk, a biocompatible material. The thickness and crystallinity of the silk determines how long the electronics take to dissolve: days, hours, or even minutes. Silicon and magnesium are naturally occurring at low levels in the human body, and since the amount of material used in these devices is below physiological levels these electronics are biocompatible and eco-friendly.A paper appearing in the September 28, 2012 issue of Science explains how DARPA researchers were able to use this technology to create an implantable device that acts as a non-antibiotic, programmable bactericide that can dissolve harmlessly into the body to prevent surgical site infection. This is one driving example of biodegradable medical treatments for remote patient care that does not require extraction surgery while warfighters are deployed.â€œTransient electronics applied to localized antimicrobial therapy would be a major advance,â€? said Alicia Jackson, DARPA program manager for this effort. â€œA limitation of current implanted devices such as pacemakers and artificial joints is localized infection. Applying thin film appliquÃ©s to implant devices for localized surface heating and sterilization may help counter these infections, even when antibiotic resistant bacteria are present. Having means of eradicating infections could enhance the efficacy of many implant devices and ultimately reduce patient morbidity and mortality.â€?This work was funded by a study in the DARPA Microsystems Technology Office (MTO).If you are running an open network, it is NOT the case that anyone can break into your computer, and you are still, by and large, in a safe situation. If you are running a separate â€œguestâ€? network apart from your primary network, you have no reason to worry. If you are running an open wireless network as your primary home network, it is important that you understand whether or not your network is set up to allow sharing, or if you can enable wireless isolation to create a firewall between users on the network so that sharing is not possible. If your network is set up to allow sharing, then you should be aware that users of your open network might be able to use devices that are attached to the network, e.g. printers, smart TVs, etc. Moreover, if your computer is set to share files over the network, those files will be accessible to anyone on your network. So if you are running an open network, and don't want strangers printing things or reading your network files, it is important to research whether you can disable sharing on your network, or to carefully check the sharing settings for each computer or device attached to the network.Understanding why open networks are generally safe for users requires a little more background. Websites and services that take security seriously use transport layer encryptionâ€”most notably Transport Layer Security (TLS), which underlies HTTPS. Using transport layer encryption is the gold standard for security. Since it encrypts data between your computer and the web service you are using, TLS provides a strong level of communication security whether or not you are on an open wireless network. It protects against snooping and attacks from anyone who can read the traffic passing between your computer and the website you are visiting, such as ISPs and governments as well as people on your local wireless network. The security gain from using HTTPS as much as possible is quite significant. This is why we encourage everyone to use our HTTPS Everywhere browser extension. On the other hand, WPA2 and other Wi-Fi security schemes protect only against an attacker on your local network, and provide only nominal protection. Very often, "securing" your wireless network will not be enough to thwart a determined attacker on your local network from being able to read and manipulate your data. Therefore, the security loss from moving to an open wireless network is less significant than you might realize, especially if you set up your network to firewall users from each otherâ€”as we recommend in our tutorialswhenever possible.Four years after discovering that militants were tapping into drone video feeds, the U.S. military still hasnâ€™t secured the transmissions of more than half of its fleet of Predator and Reaper drones, Danger Room has learned.Â The majority of the aircraft still broadcast their classified video streams â€œin the clearâ€? â€” without encryption. With a minimal amount of equipment and know-how, militants can see what Americaâ€™s drones see.Unmanned aerial vehicles, or UAVs, have become the single most important weapon in Americaâ€™s far-flung pursuit of violent extremists. Hundreds of American Predators and Reapers fly above Libya, Yemen, Somalia, Pakistan, and Afghanistan â€” watching suspected enemies, and striking them when necessary.Â Nearly 3,000 people have been killedÂ in the decade-long drone campaign.â€œIf somebody could obtain reliable access to real-time Predator or Reaper video â€” without attribution or alerting U.S. military â€” that would Â a tremendous intel coup,â€? says Micah Zenko, a fellow at the Council on Foreign Relations. â€œThere is an insatiable demand from Predator and Reaper imagery in Afghanistan and elsewhere. Any reluctance to use those for spying or missile strikes places operations in Afghanistan, Pakistan, Yemen, and Somalia at some risk.â€?Military officials have known about â€” and mostly shrugged off â€” the vulnerability since the development of the Predator in the 1990s. But the problem drew increased attentionÂ in 2008, when drone video footage was found on the laptops of Shiâ€™ite militants in Iraq, who were able to intercept the feed using a piece of $26 software. The Pentagon and the defense industry assured the public that theyâ€™d close the hole by retrofitting the robotic aircraft with new communications protocols and encrypted transceivers that would keep the video from being intercepted again.Four years into the effort, however, only â€œ30 to 50 percentâ€? of Americaâ€™s Predators and Reapers are using fully encrypted transmissions, a source familiar with the retrofitting effort tells Danger Room. The total fleet wonâ€™t see its communications secured until 2014. This source and others who work closely with drone operations say that drones flying overseas are among the first to get the newly secured equipment. They also noted that they are unaware of any incidents of militants using Americaâ€™s unmanned eyes in the sky to their advantage. â€œBut Iâ€™m surprised I havenâ€™t,â€? the source adds. â€œAnd that doesnâ€™t mean itâ€™s not happening.â€?This isnâ€™t the only vulnerability in the drone fleet. In March of 2011, an unknown software glitch caused a PredatorÂ stationed at a U.S. base inÂ Africa toÂ start its engine without human direction.Â Last October, as Danger Room first reported, Air Force technicians discovered aÂ virus infecting the dronesâ€™ remote cockpitsÂ in Las Vegas. It tookÂ weeks of sustained effortÂ to clean up the machines. The aircraft, which rely on GPS to guide them through the air, can run into problems if GPS signals are jammed in a particular area â€” something that can be done with cheap, commercially available hardware.Â Iranian officials claimed they hacked the GPS control signal of an advanced drone, though itâ€™sÂ impossible to verify that lofty claim.No one who works with UAVs is questioning the fundamental integrity of the drone fleet at the moment; it would take an incredibly sophisticated hacker toÂ commandeerÂ a Predator, for example. Nor is anyone pretending that this premiere tool of the U.S.global Â counterterror campaign is flawless.Predators and the larger, better-armed Reapers transmit video and accept instructions in one of two ways. The first is via satellite, to remote pilots and sensor operators who are often on the other side of the planet; these satellite communications are encrypted, and are generally considered secure.The second is through a radio frequency signal called the Common Data Link, which is used to share the droneâ€™s video feed with troops on the ground. The CDLâ€™s carrier signal â€” its specific pattern of frequencies, in a given order and for a given length of time â€” tells both transmitter and receiver on how to function. The problem is that the Predatorsâ€™ version of the CDL carrier signal (also known as a â€œwaveformâ€?) didnâ€™t include an order to encrypt the signal. So neither the transmitter on the drone nor the receivers that troops used on the ground employed encryption, either.There were reasons for this.Â The original Predator, just 27 feet long, was little more than a scaled-up model plane with an 85-horsepower engine. It had a payload of just half a ton for all its fuel, cameras and radios. And encryption systems can be heavy. (Big crypto boxesÂ are a major reasonÂ the Armyâ€™s futuristic universal radio ended up being too bulky for combat, for example.) With the early Predator models, the Air Force made the conscious decision to leave off the crypto.The flying branch was well aware of the risk. â€œDepending on the theater of operation and hostile electronic combat systems present, the threat to the UAVs could range from negligible with only a potential of signal intercept for detection purpose, to an active jamming effort made against an operating, unencrypted UAV,â€?Â the Air Force reported in 1996.Â â€?The link characteristics of the baseline Predator system could be vulnerable to corruption of down links data or hostile data insertions.â€?The Predator models steadily grew in power and payload, and took a big leap in dimensions and capability with the 36-foot-long Reaper version introduced in 2007. The Reaper has a 950-horsepower engine and a nearly 4,000-pound payload â€” more than enough capacity for crypto-enabled systems which, like all electronics, had shrunk in size and weight.The problem was that, by then, the military had rushed to the battlefield hundreds ofÂ Remotely Operated Video Enhanced Receivers, orÂ RoversÂ â€“ rugged, laptop-sized receivers with screens for watching drone footage. And those early version of the Rovers were developed and distributed so fast, the military once again left the crypto off. â€œIt could be both intercepted (e.g., hacked into) and jammed,â€? e-mails an Air Force officer with knowledge of the program.Which mean the Pentagon was stuck, for a time. The military couldnâ€™t replace the old CDL waveform with something encryptable until the Rovers â€” and the radio transmitters aboard the Predators â€” could handle such a signal.Eventually, the Rovers began to be swapped out for newer models. The latest version, the â€œTactical Rover,â€? (.pdf) is about the size of an old-school mobile phone. It can use both the Advanced Encryption Standard an the triple-Data Encryption Standard to secure video feeds. There are now about a thousand of the units in the militaryâ€™s hands.And now, the Predators and Reapers are starting to get enhanced radios, too. â€œThe fleet-wide upgrade begins later this year and carries on for several years,â€? says Maj. Mary Danner-Jones, an Air Force spokesperson. The service is spending $12 million on crypto-enabled Vortex transceivers (.pdf).Thatâ€™s allowing a new, hardened waveform to be introduced throughout the Predator and Reaper fleet. The Air Force recently gave Predator-maker General Atomics Aeronautical SystemsÂ a $26 million contract to retrofit its drone cockpits to accept the carrier signal, among other enhancements.The question is why hasnâ€™t this happened sooner. After all,Â the Navy installed multiple layers of encryption inÂ theirÂ â€™bots some time ago. Navy spokesman Jamie Cosgrove tells Danger Room that â€œthe vast majorityâ€? of naval drones are encrypted â€“Â  â€œand have been since development.â€?One source who works on developing Navy UAVs, but is not authorized the speak on the record, explains why:Â â€?Standard unencrypted video is basically a broadcast to whoever can figure out the right carrier frequency, so essentially, we are simulcasting to battlefield commanders and the opposing force. If that opposing force knows we can see them and from where, they can take better evasive maneuvers.â€?Itâ€™s possible that none of the militants America is trying today are as sophisticated as the ones who intercepted that drone video in 2008. Itâ€™s possible that the value of such footage-from-above is so fleeting that extremists have never again bothered to grab it. But itâ€™s worth noting that Predator and Reaper video is considered by the U.S. military to be classified information. And when U.S. commanders on the ground get into a firefight, the first call they usually make is for a drone, so they can take a look at the battlefield through the eyes of a drone.You can see more of what Linus Torvalds shares on his profileThe Department of Energy's Oak Ridge National Laboratory has today unveiled its new supercomputer Titan, claimed to be the world's most powerful system.The Cray XK7 system's 20 petaflops of power will be put to use researching climate change and other data-intensive tasks.It contains 18,688 nodes, each based around a 16-core AMD Opteron 6274 processor and an NVIDIA Tesla K20 graphics processing unit (GPU) accelerator, and has more than 700 terabytes of memory.The combination of traditional central processing units and more recent GPUs means Titan occupies the same amount of space as its Jaguar predecessor and uses only marginally more electricity."One challenge in supercomputers today is power consumption," says Jeff Nichols, associate laboratory director for computing and computational sciences."Combining GPUs and CPUs in a single system requires less power than CPUs alone and is a responsible move toward lowering our carbon footprint. Titan will provide unprecedented computing power for research in energy, climate change, materials and other disciplines to enable scientific leadership."Because they handle hundreds of calculations simultaneously, GPUs can get through a lot more work than CPUs in a given time. While the 299,008 CPU cores guide simulations, the new NVIDIA GPUs do the 'heavy lifting',Â  allowing scientific calculations to be run with greater speed and accuracy."Titan will allow scientists to simulate physical systems more realistically and in far greater detail," says James Hack, director of ORNL's National Center for Computational Sciences."The improvements in simulation fidelity will accelerate progress in a wide range of research areas such as alternative energy and energy efficiency, the identification and development of novel and useful materials and the opportunity for more advanced climate projections."The system will be used for several different applications, including a nanoscale analysis of important materials such as steels, iron-nickel alloys and advanced permanent magnets that will help drive future electric motors and generators.Titan will also allow researchers to model large-molecule hydrocarbon fuels such as the gasoline surrogate isooctane; commercially important oxygenated alcohols such as ethanol and butanol; and biofuel surrogates that blend methyl butanoate, methyl decanoate and n-heptane.|Meanwhile, the Denovo application will model the behavior of neutrons in a nuclear power reactor, simulating a fuel rod through one round of use in a reactor core in 13 hours - a job that took 60 hours on the Jaguar system.Its most important task, though, is to simulate long-term global climate, enabling researchers to better understand future air quality as well as the effect of particles suspended in the air."As scientists are asked to answer not only whether the climate is changing but where and how, the workload for global climate models must grow dramatically," says Kate Evans of ORNL. "Titan will help us address the complexity that will be required in such models." Â Huge news out of Apple today, as its senior vice president of iOS software, Scott Forstall, will leave the company next year after putting in some 15 years. Furthermore, John Browett -- head of Apple retail -- is also on his way out. The memo was delivered late today, on a day that is littered with other news that the company may hope will bury the bulk of it -- and, on a day where trading on the New York Stock Exchange is halted due to Hurricane Sandy. It's practically a given that Forstall is taking the brunt of the impact from its decision to forge ahead with an obviously subpar Maps application, all while trumpeting it as one of the pillars of iOS 6 during his keynote speech at WWDC 2012. The introduction of Siri as a beta product is also on Forstall, and we all know what happens to executives who flub something related to iPhone....As the shakeup unfolds, Jony Ive, Bob Mansfield, Eddy Cue and Craig Federighi will add more responsibilities to their roles. In other words, Tim Cook isn't about to usher in new help who may thwart the company's efforts to continue at its breakneck pace. Curiously, Mansfield will be heaping more on his own plate just months after he had originally planned to retire. As for Ive? He'll be responsible for providing "leadership and direction for Human Interface (HI) across the company in addition to his role as the leader of Industrial Design." Eddy Cue will be burdened with Siri and Maps, while also keeping an eye on the iTunes Store, the App Store, the iBookstore and iCloud. Needless to say, he probably won't be seeing too many walls outside of Cupertino for the foreseeable future. Federighi is being tasked to lead both iOS and OS X, while Mansfield chairs a new Technologies group that bundles Apple's wireless teams across the company. (Of note, Dan Riccio -- who was scheduled to take over for Mansfield prior to his retirement retraction -- isn't among those who are gaining duties.)Just months after Browett was brought in from Dixons in order to lead up Apple's retail efforts, he's on the outs as well. Of course, he's also responsible for the branch having to tell stores that it "messed up" when he fiddled with staffing levels back in August. A search for a new head of Retail is underway and in the interim, the Retail team will report directly to CEO Tim Cook.Update: The Wall Street Journal is reporting that Forstall was asked to resign after refusing to sign his own name to Apple's Maps apology, leaving Tim Cook to sign his name instead. Yikes.Apple Announces Changes to Increase Collaboration Across Hardware, Software & Services Jony Ive, Bob Mansfield, Eddy Cue and Craig Federighi Add Responsibilities to Their Roles CUPERTINO, California-October 29, 2012-AppleÂ® today announced executive management changes that will encourage even more collaboration between the Company's world-class hardware, software and services teams. As part of these changes, Jony Ive, Bob Mansfield, Eddy Cue and Craig Federighi will add more responsibilities to their roles. Apple also announced that Scott Forstall will be leaving Apple next year and will serve as an advisor to CEO Tim Cook in the interim. "We are in one of the most prolific periods of innovation and new products in Apple's history," said Tim Cook, Apple's CEO. "The amazing products that we've introduced in September and October, iPhone 5, iOS 6, iPad mini, iPad, iMac, MacBook Pro, iPod touch, iPod nano and many of our applications, could only have been created at Apple and are the direct result of our relentless focus on tightly integrating world-class hardware, software and services." Jony Ive will provide leadership and direction for Human Interface (HI) across the company in addition to his role as the leader of Industrial Design. His incredible design aesthetic has been the driving force behind the look and feel of Apple's products for more than a decade. Eddy Cue will take on the additional responsibility of SiriÂ® and Maps, placing all of our online services in one group. This organization has overseen major successes such as the iTunes StoreÂ®, the App Storeâ„ , the iBookstoreâ„  and iCloudÂ®. This group has an excellent track record of building and strengthening Apple's online services to meet and exceed the high expectations of our customers. Craig Federighi will lead both iOS and OS XÂ®. Apple has the most advanced mobile and desktop operating systems, and this move brings together the OS teams to make it even easier to deliver the best technology and user experience innovations to both platforms. Bob Mansfield will lead a new group, Technologies, which combines all of Apple's wireless teams across the company in one organization, fostering innovation in this area at an even higher level. This organization will also include the semiconductor teams, who have ambitious plans for the future. Additionally, John Browett is leaving Apple. A search for a new head of Retail is underway and in the interim, the Retail team will report directly to Tim Cook. Apple's Retail organization has an incredibly strong network of leaders at the store and regional level who will continue the excellent work that has been done over the past decade to revolutionize retailing with unique, innovative services for customers. Apple designs Macs, the best personal computers in the world, along with OS X, iLife, iWork and professional software. Apple leads the digital music revolution with its iPods and iTunes online store. Apple has reinvented the mobile phone with its revolutionary iPhone and App Store, and is defining the future of mobile media and computing devices with iPad.Want to play old school Nintendo games on your iPad? Download Google Play apps from foreign countries to your Galaxy Tab? If so, you'll have to break the law. That's because under new rules issued by the U.S. government, jailbreaking (or in the case of Android, rooting) tablets becomes a violation of the Digital Millennium Copyright Act on Sunday, October 28. On Thursday, the Librarian of Congress issued its latest set of exemptions to the DMCA. By default, digital rights management (DRM) mechanisms cannot legally be flouted by consumers, but the DMCA allows the government to periodically define exemptions to this rule. In 2010, tinker-happy iPhone owners breathed a sigh of relief (and Steve Jobs likely just sighed) when it was ruled that jailbreaking smartphones was perfectly legal under the DMCA. This remains the case, but the updated list of exemptions explicitly excludes tablets, a category of devices that the government found to be too "broad and ill-defined" to allow their owners free reign when using them. So as of now, it is illegal to jailbreak an iPad or root a tablet running Android or any tablet-focused flavor of Windows. This Makes No SenseThe tablet exemption is a bit of a head scratcher. I'm free to jailbreak my iPhone and do as I please with it, but if I want to run the same jailbreak tool on a larger device running the same exact operating system, it's against the law?Accessing Cydia on my iPhone 4 is cool, but doing it on a screen a few inches bigger? That's illegal. Other than its size, the only significant difference between these two devices is that the iPhone makes and receives calls. The new rules also forbid personal copying of DVDs. And starting in January 2013, it will be illegal to unlock new smartphones for the purpose of switching carriers. Unlocking older handsets will continue to be fine. The whole thing illustrates what Ars Technica's Timothy B. Lee calls "the fundamentally arbitrary nature of the DMCA's exemption process."Explains Lee: In order to convince the Librarian to allow DVD ripping in order to watch it on an iPad, a court would first need to rule that doing so falls under copyright's fair use defense. To get such a ruling, someone would have to rip a DVD (or sell a DVD-ripping tool), get sued in court, and then convince a judge that DVD ripping is fair use. But in such a case, the courts would probably never reach the fair use question, because - absent an exemption from the Librarian of Congress- circumvention is illegal whether or not the underlying use of the work would be a fair use.Lee goes on to make the case that new rules surrounding DVD copying and eBook DRM don't make sense either and suggests that perhaps DRM schemes should not be legally protected from tampering by default. His take is well worth a read. How Will This Impact iOS Jailbreaking? When the news broke, iOS jailbreak developer MuscleNerd expressed concern about it on Twitter. When I asked him for his perspective, he declined to comment because of potential legal repercussions.SAN FRANCISCO â€” I.B.M. scientists are reporting progress in a chip-making technology that is likely to ensure that the basic digital switch at the heart of modern microchips will continue to shrink for more than a decade.The advance, first described in the journal Nature Nanotechnology on Sunday, is based on carbon nanotubes â€” exotic molecules that have long held out promise as an alternative to silicon from which to create the tiny logic gates now used by the billions to create microprocessors and memory chips.The I.B.M. scientists at the T.J. Watson Research Center in Yorktown Heights, N.Y., have been able to pattern an array of carbon nanotubes on the surface of a silicon wafer and use them to build hybrid chips with more than 10,000 working transistors.Against all expectations, silicon-based chips have continued to improve in speed and capacity for the last five decades. In recent years, however, there has been growing uncertainty about whether the technology would continue to improve.A failure to increase performance would inevitably stall a growing array of industries that have fed off the falling cost of computer chips.Chip makers have routinely doubled the number of transistors that can be etched on the surface of silicon wafers by shrinking the size of the tiny switches that store and route the ones and zeros that are processed by digital computers.The switches are rapidly approaching dimensions that can be measured in terms of the widths of just a few atoms.The process known as Mooreâ€™s Law was named after Gordon Moore, a co-founder of Intel, who in 1965 noted that the industry was doubling the number of transistors it could build on a single chip at routine intervals of about two years.To maintain that rate of progress, semiconductor engineers have had to consistently perfect a range of related manufacturing systems and materials that continue to perform at evermore Lilliputian scale.The I.B.M. advance is significant, scientists said, because the chip-making industry has not yet found a way forward beyond the next two or three generations of silicon.â€œThis is terrific. Iâ€™m really excited about this,â€? said Subhasish Mitra, an electrical engineering professor at Stanford who specializes in carbon nanotube materials.The promise of the new materials is twofold, he said: carbon nanotubes will allow chip makers to build smaller transistors while also probably increasing the speed at which they can be turned on and off.In recent years, while chip makers have continued to double the number of transistors on chips, their performance, measured as â€œclock speed,â€? has largely stalled.This has required the computer industry to change its designs and begin building more so-called parallel computers. Today, even smartphone microprocessors come with as many as four processors, or â€œcores,â€? which are used to break up tasks so they can be processed simultaneously.I.B.M. scientists say they believe that once they have perfected the use of carbon nanotubes â€” sometime after the end of this decade â€” it will be possible to sharply increase the speed of chips while continuing to sharply increase the number of transistors.This year, I.B.M. researchers published a separate paper describing the speedup made possible by carbon nanotubes.â€œThese devices outperformed any other switches made from any other material,â€? said Supratik Guha, director of physical sciences at I.B.M.â€™s Yorktown Heights research center. â€œWe had suspected this all along, and our device physicists had simulated this, and they showed that we would see a factor of five or more performance improvement over conventional silicon devices.â€?Carbon nanotubes are one of three promising technologies engineers hope will be perfected in time to keep the industry on its Mooreâ€™s Law pace. Graphene is another promising material that is being explored, as well as a variant of the standard silicon transistor known as a tunneling field-effect transistor.Dr. Guha, however, said carbon nanotube materials had more promising performance characteristics and that I.B.M. physicists and chemists had perfected a range of â€œtricksâ€? to ease the manufacturing process.Carbon nanotubes are essentially single sheets of carbon rolled into tubes. In the Nature Nanotechnology paper, the I.B.M. researchers described how they were able to place ultrasmall rectangles of the material in regular arrays by placing them in a soapy mixture to make them soluble in water. They used a process they described as â€œchemical self-assemblyâ€? to create patterned arrays in which nanotubes stick in some areas of the surface while leaving other areas untouched.Perfecting the process will require a more highly purified form of the carbon nanotube material, Dr. Guha said, explaining that less pure forms are metallic and are not good semiconductors.Dr. Guha said that in the 1940s scientists at Bell Labs had discovered ways to purify germanium, a metal in the carbon group that is chemically similar to silicon, to make the first transistors. He said he was confident that I.B.M. scientists would be able to make 99.99 percent pure carbon nanotubes in the future.This post has been revised to reflect the following correction:Because of an editing error, an article on Monday about an I.B.M. breakthrough on chip design defined incorrectly Mooreâ€™s Law, an observation on technology advances named for Gordon Moore, a co-founder of Intel. Mooreâ€™s Law holds that the chip industry doubles the number of transistors it can build on a single chip at routine intervals of about two years â€” not intervals of about 12 to 18 months.Picture an eerily human-like tangle of metal, wiring and lights, cables dangling from somewhere above like puppet strings. Imagine it springing to life, lifting a long, lanky leg that bends 180 degrees at the hips like the eerie biomechanical GekkoÂ inÂ Metal Gear Solid 4, then placing one foot on a high bench and flexing its ankle, probing, testing, as it leans its thick cage of a torso forward, its arms splayed against plastic and wood walls on either side.And then itâ€™s up, hoisting its bulk into the air, its arms swinging forward just as yours or mine would, finding its feet, gently quaking, balancing.Now picture it leaping back down, landing first one foot, then the other, making a thunderous sound like someone swinging a sledgehammer at sheet metal (or the noise youâ€™d imagine a hulking robot might generate as it falls from above, like a BattleTech mech).Next â€” and you can see all this and more in the video above â€” itâ€™ll straddle a shallow pit teeming with deadly lizards and snakes (okay, just rubber ones, but still scary!) using both legs, edging past the gap fluidlyâ€¦Meet Pet-Proto, a Boston Dynamics-designed bipedal robot, related to the companyâ€™s anthropomorphic PETMAN project.Â Itâ€™s capable of analyzing and navigating complex obstacle courses, making decisions autonomously, and with, if not the actual dexterity of a human being, at least the functional semblance of one.Itâ€™s all part of DARPAâ€˜s (Defense Advance Research Projects Agency) work to promote its ambitious DARPA Robotics Challenge (DRC), which initiated its second phase on Wednesday, Oct. 24 since launching back in April. The contest will test the sort of capabilities illustrated above and others â€œinÂ a series of tasks that will simulate conditions in a dangerous, degraded, human-engineered environment.â€?â€œRobot enthusiasts, the time has come,â€? says DARPA on its website. â€œThe DARPA Robotics Challenge (DRC) begins today. Will you be part of it?â€?Itâ€™s just the start of whatâ€™ll amount to a two-year ordeal for teams competing to design, tweak and test rescue either humanoid or non-humanoid robots: ultra-agile, durable mechanical servants capable of going where most humans wouldnâ€™t dare, say exploring collapsed mines and helping to rescue trapped miners, defusing improvised explosive devices, or working around nuclear meltdown incidents like Fukushima, Chernobyl or Three Mile Island.The prize? A cool $2 million. All teams have to do is create robots that can perform tasks like: drive a utility vehicle, climb a wobbly industrial ladder, shatter a concrete wall using a power tool, cross a debris-littered field, isolate and close a valve in a leaking pipe and replace industrial equipment. Simple, right?If youâ€™re from the future, maybe, but todayâ€™s robots do almost none of these things â€” ergo DARPAâ€™s two-year challenge, designed to make some or all of the above a reality, and which as of Wednesday just got even more interesting.Take the newly announced Track C, which allows participants to compete without touching actual machine parts. Itâ€™ll involve using something DARPA calls its â€œDRC Simulator,â€? an open-source, cloud-based robotics design tool, and all you need to work it is a little software development know-how and an appetite for robotic simulation.â€œThe DRC Simulator is going to be one of DARPAâ€™s legacies to the robotics community,â€? says DRC program managerÂ Gill Pratt. â€œOne of DARPAâ€™s goals for the Challenge is to catalyze robotics development across all fields so that we as a community end up with more capable, more affordable robots that are easier to operate. The value of a cloud-based simulator is that it gives talent from any location a common space to train, design, test and collaborate on ideas without the need for expensive hardware and prototyping. That opens the door to innovation.â€?The DRC Simulator has only been in development for a month, according to DARPA, and its future already sounds bright, with a melange of improvements in the offing, including new â€œmodels of robots, perception sensors and field environmentsâ€? that should ultimately allow the simulator to â€œfunction as a cloud-based, real-time, operator-interactive virtual test bed that uses physics-based models of inertia, actuation, contact and environment dynamics.â€?What about Pet-Proto? As its name suggests, itâ€™s just a prototype â€” part of how DARPAâ€™s promoting the contest. Pet-Proto is really a predecessor to something theoretically more sophisticated that Boston Dynamics is working on, dubbed â€œAtlas.â€?DARPA says challenge participants selected to advance will receive Government Funded Equipment (GFE) â€œin the form of a modified robot platform based on the Atlas robot.â€? In other words, if you make it through the initial hurdles, you get to play with (and work on) something likeÂ that.New technology has allowed researchers to come closer than ever to cracking the worldâ€™s oldest undeciphered writing system.Researchers from the University of Oxford and the University of Southampton have developed a Reflectance Transformation Imaging (RTI) System for Ancient Documentary Artefacts (funded by the UK Arts and Humanities Research Council and the Andrew W. Mellon Foundation) to capture images of some of the worldâ€™s most important historical documents. Recently this system was used on objects held in the vaults of the Louvre Museum in Paris.These images have now been made available online for free public access on the Cuneiform Digital Library Initiative website.Among the documents are manuscripts written in the so-called proto-Elamite writing system used in ancient Iran from 3,200 to 3,000 BC and which is the oldest undeciphered writing system currently known. By viewing extremely high quality images of these documents, and by sharing them with a community of scholars worldwide, the Oxford University team hope to crack the code once and for all.Dr Jacob Dahl, a co-leader of the Cuneiform Digital Library Initiative and a member of Oxford Universityâ€™s Faculty of Oriental Studies, said: 'I have spent the last ten years trying to decipher the proto-Elamite writing system and, with this new technology, I think we are finally on the point of making a breakthrough.'The quality of the images captured is incredible. And it is important to remember that you cannot decipher a writing system without having reliable images because you will, for example, overlook differences barely visible to the naked eye which may have meaning. Consider for example not being able to distinguish the letter i from the letter t.'The reflectance transformation imaging technology system designed by staff in the Archaeological Computing Research Group and Electronics and Computer Science at the University of Southampton comprises a dome with 76 lights and a camera positioned at the top of the dome. The manuscript is placed in the centre of the dome, whereafter 76 photos are taken each with one of the 76 lights individually lit. In post-processing the 76 images are joined so that the researcher can move the light across the surface of the digital image and use the difference between light and shadow to highlight never-before-seen details.'We have never been able to view documents in this quality before,' Dr Dahl explained.Dr Dahl believes this writing system might be even more interesting than previously thought. He said: 'Looking at contemporary and later writing systems, we would expect to see proto-Elamite use only symbols to represent things, but we think they also used a syllabary â€“ for example 'cat' would not be represented by a symbol depicting the animal but by symbols for the otherwise unrelated words 'ca' and 'at'.'Half of the signs used in this way seem to have been invented ex novo for the sounds they represent â€“ if this turns out to be the case, it would transform fundamentally how we understand early writing where phonetecism is believed to have been developed through the so-called rebus principle (a modern example would be for example "I see you", written with the three signs 'eye', the 'sea', and a 'ewe').'Some features of the writing system are already known. The scribes had loaned - or potentially shared - some signs from/with Mesopotamia, such asÂ  the numerical signs and their systemsÂ  and signs for objects like sheep, goats, cereals and some others. Nevertheless, 80-90% of the signs remain undeciphered.The writing system died out after only a couple centuries. Dr Dahl said: 'It was used in administration and for agricultural records but it was not used in schools â€“ the lack of a scholarly tradition meant that a lot of mistakes were made and the writing system may eventually have become useless as an administrative system. Eventually, the system was abandoned after some two hundred years.'Dr Dahl joked: 'This is probably the worldâ€™s first case of a collapse of knowledge because of the under-funding of education!'The Louvre gave the researchers access to the c. 1100 proto-Elamite tablets in its collections, half of which can now be viewed on the Cuneiform Digital Library Initiative website.Dr Dahl said: 'The Louvre collection of early writing from Mesopotamia and Iran is incredibly important â€“ it contains the first substantial law code, the first record of a battle between kings, the first propaganda, and the first literature. Being able to put these documents online would be a great achievement.'Dr Dahl said making important documents from early human history publicly accessible is becoming increasingly important, both as a consequence of the ever-expanding influence of cyberscholarship in academic research, but also in many cases more pressingly as a matter of cultural heritage preservation in areas of the world threatened by armed conflict and collapse of security.'Iraqâ€™s cultural heritage has been pillaged in the last 20 years, and the situation in neighbouring Syria is looking dire as well,' he said.has headed the FT's San Francisco bureau since 2002 and covers Google and Microsoft, among other things. A former New York bureau chief for the FT, he is intrigued by Silicon Valley's unique financial and business culture, and is looking forward to covering his second Tech Bust. has been online and messing around with computers for more than 20 years and since 2004 has reported from the FT's San Francisco bureau on semiconductors, video games, consumer electronics and all things interwebby. has been writing about technology for the FT since 1999 and is facinated by cybercrime, privacy and all the other issues of the information society. Based in London, she covers European tech companies and hopes that they won't all get acquired by American rivals. is the FT's technology, media and telecoms page editor in London. Formerly he was the Taipei correspondent and wrote about the companies that manufacture the vast majority of the world's computers and gadgets. He is interested in the intricacies of the technology supply chain and how China is increasingly changing the tech landscape. is the FT's digital media correspondent, and has just moved from London to join our team in San Francisco. He has covered start-ups such as Twitter and Spotify, as well as the online ambitions of more established media companies, such as the BBC iPlayer. He also covers the advertising, marketing and video-game industries. Tim has been writing about technology, business and finance since 2003.Nuclear reactors in the mid-Atlantic and Northeast are being monitored for potential impacts by Hurricane Sandy, a Category 1 storm that may strike anywhere from Delaware to southern New England.â€œBecause of the size of it, we could see an impact to coastal and inland plants,â€? Neil Sheehan, a spokesman based in Philadelphia for the U.S. Nuclear Regulatory Commission, said by phone today. â€œWe will station inspectors at the sites if we know they could be directly impacted.â€?The NRC met earlier today to discuss the necessary precautions to take for the storm, Sheehan said. Plants must begin to shut if wind speeds exceed certain limits, he said.As of 2 p.m. New York time, Sandy had winds of 75 miles (121 kilometers) per hour, according to the National Hurricane Center in Miami. It was about 430 miles south-southeast of Charleston, South Carolina, moving north at 7 mph.The current Hurricane Center track calls for the system to come ashore just south of Delaware Bay on Oct. 30.Contingency Plans Nuclear plants in the projected path of the hurricane include North Anna and Surry in Virginia, Calvert Cliffs in Maryland, Hope Creek and Salem in New Jersey, Indian Point in New York and Millstone in Connecticut. The NRC is considering enhancing inspector coverage of these reactors, Sheehan said in an e-mail today.Public Service Enterprise Group must shut all units at the Salem and Hope Creek plants two hours before the onset of hurricane-force winds greater than 74 mph, according to Sheehan. An â€œunusual eventâ€? would be declared if the winds are sustained for greater than 15 minutes or if the water level reaches 99.5 feet or higher, he said. Such an event is the lowest of four level of emergency used by the commission.Salem Unit 2 is currently shut for refueling, while Unit 1 was operating at 83 percent of capacity today during maintenance on the circulating water system. Hope Creek ran at full power. The three units have a combined capacity of 3,365 megawatts.â€œWe are in phase one of our severe-weather plan,â€? Joe Delmar, a company spokesman, said in an e-mail responding to questions. â€œThis includes inspecting, removing and securing outside areas for potential missiles, objects that could go airborne, and staging of emergency equipment and supplies.â€?Millstone Reactor Nuclear generation in the Northeastern region dropped 1.1 percent to 18,016 megawatts, with seven plants shut, an NRC report today showed.Dominion Resourcesâ€™s Millstone plant is monitoring Sandyâ€™s progress and preparing to adjust staff as it comes closer, according to Ken Holt, a plant spokesman based in Richmond, Virginia. The plant must shut if winds reach 90 mph.â€œWe would shut down in advance of the storm if they were expected to be 90 miles per hour at the site,â€? Holt said by phone today. â€œFloods and high winds are a threat because they can knock off off-site power and weâ€™d then need to activate emergency generators for power to put the plant to safe conditions.â€?A recent update to the Xbox 360 dashboard made Internet Explorer available as a free download. This is exciting news for an HTML5 game company like us, as it means that our games are now playable on Xbox 360 consoles.In an interview with ImpactJS creator Dominic Szablewski, we talked about some of the developer frustrations revolving around Microsoft and HTML5. Dominic has his game Biolab Disaster running natively on an Xbox 360, but at a completely unplayable 3 frames per second. Itâ€™s so close to working but thereâ€™s no apparent interest from Microsoft to seal the deal, despite their repeated pushes into the HTML5 game space.Microsoft has financed or otherwise produced a handful of HTML5 game projects in the past few years, including Pirates Love Daisies, Agent 008 Ball, Cut the Rope, and most recently the apparent game platform Atari Arcade.These projects are beneficial to the HTML5 game development scene and weâ€™re glad Microsoft has sponsored them, but it does contrast the decidedly lackluster support for HTML5 on its Xbox 360 consoles.The release of Internet Explorer on Xbox 360 is a step in the right direction. Hopefully someday youâ€™ll see our HTML5 games running natively via XBIG, but in the meantime, why not fire up Internet Explorer?First, download Internet Explorer onto your console. Then, open Internet Explorer and navigate it to arcade.lostdecadegames.com. Once there, it should look like this:First, I recommend a quick game of Onslaught! Defense. I played a game and happily got my highest score ever! Fair warning, there is some awkwardness with the controls: youâ€™ll need to move Internet Explorerâ€™s cursor to the directional slider at the bottom of the screen. Hold down the A button and you should be able to control the character.Onslaught! Defense isnâ€™t a terribly deep game, so next up how about some Lunch Bug? It feels best with a touch or click interface, but Internet Explorerâ€™s cursor is good enough. Of course, like in many other browsers, the sound playback is buggy and unreliable, but the game runs pretty smoothly and the graphics look great on a big TV.I think youâ€™ll agree that the games show a lot of potential, but there are plenty of issues that would be largely solved by a native wrapper. For example, the audio in Lunch Bug is pretty bad in desktop and mobile browsers, but sounds great in the native Android version.So this is really exciting and awesome, but our question is: will we get native HTML5 games on Xbox 360, or will we have to wait for the next generation of consoles? If someone at Microsoft happens to read this, please do get in touch.All of the Tor Browser Bundles have been updated with the latest Firefox 10.0.10esr release and all of the alpha packages, including the alpha Tor Browser Bundles, have been updated with the latest release of Tor 0.2.3.24-rc.We've been following the core media appsâ€”Music and Videoâ€”since the Windows 8 Consumer Preview. That development hinted Microsoft wanted to become a viable competitor to Apple and Amazon in the multimedia content realm. We found the first glimpse compelling, a signal that perhaps there was a true stake for Redmond to claim.Now with Windows 8 live, the Preview groundwork has been built upon. As you'll see here, things have changed, but not always as expected. The evolution of Music and Video begins up front, where the apps have shed their Zune branding. Instead, Microsoft choseÂ to reuse the Xbox brand, as the company moves to expand the scope of the Xbox name from gaming to allÂ media and entertainment.The Music and Video applications are close siblings. Aside from the obvious difference implied by their names, their structure and organization are essentially identical.In both apps, the first/main screen is dominated by Microsoft's attempts to sell to you. Users are greeted by a mix of promotional areas that highlight "hot" artists or movies, and entryways into the music, movie, and TV stores. Your own media are hidden out of view to the left.Drill into your media, and you get simple browsing. For videos you get a bunch of thumbnails, and the ability to filter the visible videos according to whether they're films, TV shows, or other. (I don't know what it uses to make this distinction because all my videos appear as "other." There doesn't appear to be a way within the application to change that.)The layout is also terribly unscalable. The only option is to see some moderately large thumbnails in a list that scrolls left to right. That's OK if you have a few dozen videos; it's practically worthless if you have any more. It's just too hard to find what you want.In music, you get a spreadsheet-type view with the option to group by song, artist, or album. The most notable bit about this spreadsheet view is just how extraordinarily slow it is. Scroll too fast and you'll just see a blank great space where songs should be listed. A few seconds later it'll manage to populate itself. This slowness, combined with the lack of any apparent "fast scroll" mechanism (such as iOS's ability to scroll down the right edge) makes browsing and selecting files a tedious experience.Songs and albums can be selected by right clicking them or nudging them sideways, allowing group operations such as adding them to a playlist, to the Now Playing pseudo-playlist, or deleting them. Adding to playlists is a little glitchy. There are actually two buttons to add to playlists; one that adds to a new playlist, and one that adds to the last playlist you modified. This is a good idea, but I found the Music app was slow to notice when I'd changed to modifying a different playlist. For example, if I first edit playlist A and then edit playlist B, the "add" button would still show playlist A's name... and then a few seconds later change to playlist B.Like Windows Media Player, Music's Now Playing pseudo-playlist is maintained independently of your current view of the song spreadsheet. This is in contrast to iOS, where changing the sort order of the song list while browsing is also prone to changing the playback order. I prefer this approach, but its implementation in Music seems to leave a lot to be desired. Although it is easy to see what the Now Playing list is, I can't find any facility for actually changing it. Decide that you want to get rid of one of the songs you've cued up? Want to swap them around? For the life of me, I couldn't tell you how (if it's even possible to do at all). This feels like such a glaring oversight that I'm sure I must be missing something.Overall, I feel there's nothing fundamentally wrong with the basic presentation. With a bit of care and attention it could work well, but it's just not there yet.One smart feature: when Music is playing, the volume popup that appears when you use the hardware volume keys also includes playback controls and album art. It's a nice touch.One not at all smart feature: the play/pause key on keyboards with media keys doesn't control playback of the Music app. Want to quickly pause playback to take a phone call? You'll have to go into the app to do it.The main way for people to begin downloading content from BitTorrent is to visit one of the Internetâ€™s many hundreds of torrent sites. There they can download either .torrent files or, in the case of The Pirate Bay, magnet links. This week it became possible to go on a YouTube-like â€œrelated videoâ€? journey through BitTorrentâ€™s Distributed Hash Table to find similar content to that being already downloaded, all without visiting a torrent site.Visiting a torrent site to access content is a fairly simple affair. Select the URL, go to the site and type whatever youâ€™re looking for into the search box.However, if a BitTorrent user doesnâ€™t really know what he or she is looking for and needs some ideas, a torrent siteâ€™s category view comes in useful to allow browsing of specific content such as videos, music or games.But what if there was another mechanism through which to find new content, one that doesnâ€™t involve visiting a torrent site? One that would find content to download based on the activities of other BitTorrent users that have downloaded, to some extent, the same or similar content as you?Now all of that is possible with â€œSwarm Discoveriesâ€?, a new and intriguing feature added to the open source Vuze client this week. The feature uses the Vuze Distributed Hash Table (DHT) to anonymously relate one piece of downloaded content with another.â€œFor a long time users have been asking for a means to find more content that they might like, stuff similar to the kind of things they already download,â€? Paul Gardner from Vuze tells TorrentFreak.â€œExisting sites tend not to offer anything beyond simple categorization (e.g. by format or genre), and only cover their own domain of content â€“ users are looking for something that works â€˜horizontallyâ€™, across sites, while at the same time zooming in on things that may be of interest.â€?Striving towards solving this problem the Vuze team came up with Swarm Discoveries, a behavior-based torrent content discovery system. So what makes it tick?â€œGiven the lack of any standardized metadata for torrents, and the huge diversity of naming conventions, languages etc., any approach based on matching between static torrent data is difficult. So what we decided to concentrate on was the behavioral aspects of torrent selection,â€? Gardner reveals.â€œUsers are already way smarter than us at finding content they like, so why not use their expertise to raise everybodyâ€™s game?â€?And this is where it gets both slightly more complex and much more interesting.â€œSwarm Discoveries is based on the fact that if Alice downloads torrents A, B and C then, in some (unspecified) way there is a link between A, B and C. At the most abstract the link is that Alice likes A, B and C,â€? Gardner explains.â€œNow if Bob downloads B, C and D this re-enforces the fact that B and C are somehow related, but between them we know nothing regarding A and D.â€?Of course, when looking at the habits of just Alice and Bob the dataset is very small. However, millions of people are using the Distributed Hash Table which results in a much larger sample and the creation of ever more interesting links between content.As a side note, Vuze (or Azureus as it was then) debuted the first ever BitTorrent DHT.TorrentFreak gave the feature a test drive, and this is what happened when we tested it on a Fuduntu Linux distro we planned to test in a VirtualBox virtual machine.1. First we loaded up the Fuduntu torrent using Vuzeâ€™s inbuilt torrent search feature. Once underway a right-click revealed the Swarm Discovery option.2. Once selected this short list of related content appeared.Item 1 is for a Knoppix torrent. Knoppix is another Linux distro so the connection to our Fuduntu download is obvious.Item 2 turns out to be Hirenâ€™s Boot CD, a collection of fairly geeky system management tools which is (coincidentally or not) based on Knoppix.3. At this point the discovery can continue simply by right clicking on any result and selecting â€œDiscover Relatedâ€?. If you want to do some research on the torrents already found, the same menu gives access to some research tools.4. Digging down another level produced further related results.Of course, the system doesnâ€™t work only for Linux distros. In our tests popular video and music content hashes produced the richest and most complex results.I donâ€™t want to do anything, just make it work!For those of you too busy (or lazy) to right-click on downloads to find explicit results you can sit back and let Vuze do the work for you. Over time Vuze builds up results in the main Swarm Discoveries tab (youâ€™ll find it under â€˜Plugins & Extrasâ€™) and ranks them â€“ the more ways a torrent is related to your downloads the higher the rank it will be assigned (up to a max of 100).If youâ€™re bored with the current results then right-click on sidebar entry and select â€˜delete all resultsâ€™, Vuze will start generating a new set to inspire you.Although the Swarm Discoveries system might at first appear to be a privacy nightmare, concerned users can rest easy. There are no external databases and relationship data is anonymous. (Not to be confused with anonymous downloads of course, that would require a VPN or similar)â€œSwarm Discoveries is entirely implemented using the Distributed Hash Table (DHT) and results are automatically generated by Vuze clients â€“ there are no centralized components,â€? Gardner explains.â€œIn the same way that the DHT is used to relate content to peers during decentralized tracking it is also used to related one piece of content to another â€“ this relationship is stored anonymously, so when a Vuze client reads a relationship the originator of the relationship is unknown.â€?While Swarm Discoveries often produced fairly predictable results, such as supplying torrents to similar genres of music and movies, it also throws in the occasional curve ball â€“ perfect for those who browse YouTube for pop videos and end up two hours later viewing the mating rituals of a rare breed of mountain goat.Download the latest version of Vuze with Swarm Discoveries here.SUDBURY, Ontario (Reuters) - In an office trailer parked outside a mine shaft in northern Ontario, operator Carolyn St-Jean leans back in her chair and monitors a machine loading nickel-rich ore into rail cars deep underground.Once filled, the automated train will snake through a series of narrow tunnels, emerge from a rocky outcropping, then loop past St-Jean's window and dump its payload for sorting.Vale SA, the Brazilian company that owns the mine near this nickel-rich Canadian town, has spent nearly $50 million in two years to install and test the "rail-veyor." The company believes the transport system will revolutionize how it builds and extracts new mineral deposits.The equipment is made locally by Rail-Veyor Technologies Global Inc. It is one of many mining technologies that developers hope will allow future production to be run almost entirely by people safely above ground.Such advances may prove crucial as easy-to-exploit deposits run dry and miners drill deeper in more remote places to supply China, India and other emerging economies. The technology could make mining cheaper and safer, avoiding the need to dig wide tunnels and hire large numbers of expensive, skilled workers."As we go deeper, if we continue to apply existing thinking and existing technologies, it's a death spiral" for company profits, said Alex Henderson, who heads Vale's technology team in Sudbury."We need to begin to look at a step-change in mining rather than just incrementally improving our existing processes."The rail-veyor is one such step-change. At the test site, it has halved the time to build a mine, and Vale expects a 150 percent boost in production rates before year end. Â  Continued...Quantum entanglement stands as one of the strangest and hardest concepts to understand in physics. Two or more particles can interact in a specific ways that leave them entangled, such that a later measurement on one system identifies what the outcome of a similar measurement on the second systemâ€”no matter how far they are separated in space.Repeated experiments have verified that this works even when the measurements are performed more quickly than light could travel between the sites of measurement: there's no slower-than-light influence that can pass between the entangled particles. However, one possible explanation for entanglement would allow for a faster-than-light exchange from one particle to the other. Odd as it might seem, this still doesn't violate relativity, since the only thing exchanged is the internal quantum stateâ€”no external information is passed.But a new analysis by J-D. Bancal, S. Pironio, A. AcÃ­n, Y-C. Liang, V. Scarani, and N. Gisin shows that any such explanation would inevitably open the door to faster-than-light communication. In other words, quantum entanglement cannot involve the passage of informationâ€”even hidden, internal information, inaccessible to experimentâ€”at any velocity, without also allowing for other types of interactions that violate relativity.Experiments have definitively demonstrated entanglement, and ruled out any kind of slower-than-light communication between two separated objects.Â The standard explanation for this behavior involves what's called nonlocality: the idea that the two objects are actually still a single quantum system, even though they may be far apart. That idea is uncomfortable to many people (including most famously Albert Einstein), but it preserves the principle of relativity, which states in part that no information can travel faster than light.To get around nonlocality, several ideas have been proposed over the decades. Many of these fall into the category of hidden variables, wherein quantum systems have physical properties (beyond the standard quantities like position, momentum, and spin) that are not directly accessible to experiment. In entangled systems, the hidden variables could be responsible for transferring state information from one particle to the other, producing measurements that appear coordinated. Since these hidden variables are not accessible to experimenters, they can't be used for communication. Relativity is preserved.Hidden variable theories involving slower-than-light transfer of state information are already ruled out by the experiments that exclude more ordinary communication. Some modern variations combine hidden variables with full nonlocality, allowing for instantaneous transfer of internal state information. But could non-instantaneous, faster-than-light hidden variables theories still work?To investigate this possibility, the authors of the new study considered the possible experimental consequences. Obviously, one way to test it would be to increase the separation between the parts of the entangled system to see if we can detect a delay in apparently instantaneous correlation we currently observe. Sufficiently fast rates of transfer, however, would still be indistinguishable from nonlocality, given that real lab measurements take finite time to perform (this assumes that both experiments happen on Earth).The researchers took a theoretical approach instead, using something known as the no-signalling conditions. They considered an entangled system with a set of independent physical attributes, some observable, some hidden variables. Next, they allowed the state of the hidden variables to propagate faster than the speed of light, which let them influence the measurements on the separated pieces of the experiment.However, because of the nature of quantum mechanical systems, there was a symmetry between the hidden and measurable attributes of the systemâ€”meaning if the hidden variables could transfer information faster than light, then the properties we can measure would do so as well. This is a violation of the no-signalling condition, and causes serious problems for the ordinary interpretations of quantum physics.Of course, one conceivable conclusion would be that faster-than-light communication is possible; this result provided a possible avenue for testing that possibility. By restricting the bounds on the speed of interaction between entangled systems, future experiments could show whether any actual information is traveling or not.However, the far more likely option is that relativity is correct. In that case, the strong ban on faster-than-light communication would rule out the possibility of faster-than-light transfer of information encoded in hidden variables, and force us to deal with nonlocality. Once again, it would seem that local realism and relativity are incompatible notions in the quantum world.Hurricane Sandy swelled into a major threat to much of the U.S. East Coast on Thursday, U.S. forecasters said, as the storm swirled through the Bahamas after killing 21 people across the Caribbean.HAVANA (Reuters) - Hurricane Sandy swelled into a major threat to much of the U.S. East Coast on Thursday, U.S. forecasters said, as the storm swirled through the Bahamas after killing 21 people across the Caribbean.Strengthening rapidly after tearing into Jamaica and crossing the warm Caribbean Sea, Sandy hit southeastern Cuba early on Thursday with top sustained winds up to 110 miles per hour (177 km per hour) that left a trail of destruction, especially in the historic city of Santiago de Cuba.The Cuban government said on Thursday night that 11 people died in the storm, most killed by falling trees or in building collapses, including nine in Santiago de Cuba province and two in neighboring Guantanamo province.Haiti's civil protection office said nine people had died despite not getting a direct hit from Sandy, and one person was killed by falling rocks in Jamaica when the storm struck there on Wednesday.The Cuban deaths were an unusually high number for the communist island that prides itself on protecting its people from storms by ordering mass evacuations.Images on Cuban television showed downed trees, damaged buildings and debris-clogged streets in the country's second-largest city of Santiago de Cuba, which suffered a direct hit when the storm came ashore in the early morning hours."Everything's destroyed in Santiago. People are going to have to work very hard to recover," Alexis Manduley, a resident of the 498-year-old city, told Reuters by telephone.Santiago de Cuba, with a population of about 500,000, is 470 miles southeast of Havana.U.S. government forecasters warned that much of the U.S. East Coast could get swiped by Sandy, with flooding, heavy rains and high winds beginning late Thursday in Florida. By early next week - amid final preparations for the crucial November 6 presidential election - the storm could hit an area of New England where Hurricane Irene caused severe damage last year.White House spokesman Jay Carney declined to speculate about whether there would be any change in President Barack Obama's campaign travel schedule because of Sandy, as he makes a last-minute blitz to win an edge over Republican Mitt Romney in a close race."The president's concern about this storm is to make sure that citizens in potentially affected areas are aware of this and taking necessary precaution," Carney said.He spoke aboard Air Force One as Obama headed from Florida to Virginia, saying the president had asked his team to hold regular briefings with federal disaster officials as the storm progresses.Sandy is forecast to make landfall as a Category 1 hurricane and the hardest-hit areas could span anywhere from the coastal Carolinas up to Maine, with New York City and the Boston area potentially in harm's way."Regardless of the exact track of Sandy, it is likely that significant impacts will be felt over portions of the U.S. East Coast through the weekend and into early next week," the Miami-based U.S. National Hurricane Center said."It's going to be a high-impact event," said Bob Oravec, a lead forecaster with the National Oceanic and Atmospheric Administration's HydroMeteorological Prediction Center in College Park, Maryland."It has the potential to be a very significant storm with respect to coastal flooding, depending on exactly where it comes in. Power outages are definitely a big threat," he said.In a subsequent report, NOAA's storm-prediction center suggested that Sandy could invite the ghoulish nickname "Frankenstorm," due to upcoming celebrations of Halloween and some of the freakish characteristics of the storm.The late-season cyclone is widely expected to undergo an unusual merger with a polar air mass over the Mid-Atlantic and Northeast on Tuesday, essentially bringing two sources of energy together and giving Sandy the potential to punch above its weight as it sloshes across the U.S. coast.At 11 p.m. EDT), the NHC said Sandy was about 15 miles north-northeast of Eleuthera Island in the Bahamas and packing maximum sustained winds of 90 mph.High winds, rains and pounding surf are expected across parts of Florida's Atlantic coast, with the biggest impact lasting through Friday.Orange juice prices rose in U.S. trading on Thursday on speculative buying as investors bet that Sandy could damage crops in the citrus-rich Sunshine State.Unlike Irene, which caused billions of dollars in damage as it battered the Northeast in August last year, Sandy is forecast to be a weaker storm but will be moving slower than Irene, likely bringing more rain and increasing its potential for damage, weather forecasters said.At $4.3 billion in losses, Irene ranks as one of the 10 costliest hurricanes, adjusted for inflation and excluding federally insured damage, according to the Insurance Information Institute, an industry group.Jeff Masters, a hurricane specialist and blogger with private forecaster Weather Underground (www.wunderground.com), said a landfall by Sandy on Monday along the Mid-Atlantic Coast could trigger "a billion-dollar disaster.""In this scenario, Sandy would be able to bring sustained winds near hurricane force over a wide stretch of heavily populated coast," he said.Alternately, Masters said, some computer forecast models indicated Sandy had the potential to unleash "the heaviest October rains ever reported in the northeast U.S., Nova Scotia and New Brunswick."NOAA's Oravec said there could be tropical-storm to hurricane-force winds on the coast and added: "Coastal flooding will be a big concern."Sandy is expected to hit the United States during a full moon, increasing the flood potential since tides will be at or near their highest."There's a big potential for huge effects from the storm," said Oravec."We can't rule out the potential for snow eventually as we go into the week and the storm moves inland," he said.(Reporting by Jeff Franks and Nelson Acosta in Havana, Neil Hartnell in the Bahamas, Kevin Gray in Miami, Ben Berkowitz and Josephine Mason in New York; Writing by Tom Brown; Editing by David Brunnstrom, Philip Barbara and Lisa Shumaker)At its Windows Phone 8 launch event on Monday in San Francisco, Microsoft (MSFT) announced its Windows Phone Store is now filled with 120,000 apps. The Redmond, Washington-based company also unveiled that Windows Phone is now available in 50 languages. Comparatively, Appleâ€™s (AAPL) iOS App Store has over 700,000 apps and Android has 675,000 apps.Microsoftâ€™s corporate vice president Joe Belfiore didnâ€™t stop there, though. Belfiore said that Windows Phone 8 will have 46 of the top 50 apps on other smartphone platforms including Temple Run, Words With Friends,Â Angry Birds Star Wars and Pandora. To entice user to Windows Phone 8, Microsoft is tossing one year of ad-free Pandora with every device.If you keep all of your contacts in Google you might be interested in seeing a map showing their locations. Tech weblog Digital Inspiration shows how you can use their script to connect to your Google account and display a map of your contacts in Google Maps or Google Earth.You'll need to copy this spreadsheet to your Google Drive account. Inside the spreadsheet will be a custom menu labelled as Google Contacts. Click on that, choose Initialize, and authorize the script to run. When that is done click again on the Google Contacts menu and choose Generate KML file. The file will be generated and automatically emailed to your Gmail address.If you have Google Earth installed you can just open the file on your computer to view the map but if you'd prefer to use online Google Maps you'll just need to upload the file and then copy the link into Google Maps. I used Dropbox.You'll see a standard Google map with all of your contacts that have an address listed on their contact entry. For most of us this may be more gimmick than tool but if you have a list of customers you need to visit having such a list already in Google Maps may cut down on your travel preparations.See All Your Google Contacts on a Google Map | Digital InspirationIn the event that a giant asteroid is headed toward Earth, youâ€™d better hope that itâ€™s blindingly white. A pale asteroid would reflect sunlight â€” and over time, this bouncing of photons off its surface could create enough of a force to push the asteroid off its course. How might one encourage such a deflection? The answer, according to an MIT graduate student: with a volley or two of space-launched paintballs. Sung Wook Paek, a graduate student in MITâ€™s Department of Aeronautics and Astronautics, says if timed just right, pellets full of paint powder, launched in two rounds from a spacecraft at relatively close distance, would cover the front and back of an asteroid, more than doubling its reflectivity, or albedo. The initial force from the pellets would bump an asteroid off course; over time, the sunâ€™s photons would deflect the asteroid even more. Paekâ€™s paper detailing this unconventional strategy won the 2012 Move an Asteroid Technical Paper Competition , sponsored by the United Nationsâ€™ Space Generation Advisory Council, which solicits creative solutions to space-related problems from students and young professionals. Paek presented his paper this month at the International Astronautical Congress in Naples, Italy. The challenge put forth by this yearâ€™s U.N. competition was to identify novel solutions for safely deflecting a near-Earth object , such as an asteroid. Scientists have proposed a wide variety of methods to avoid an asteroid collision. Some proposals launch a projectile or spacecraft to collide with an incoming asteroid; the European Space Agency is currently investigating such a mission. Other methods have included detonating a nuclear bomb near an asteroid or equipping spacecraft as â€œgravity tractors,â€? using a craftâ€™s gravitational field to pull an asteroid off its path. Paekâ€™s paintball strategy builds on a solution submitted by last yearâ€™s competition winner, who proposed deflecting an asteroid with a cloud of solid pellets. Paek came up with a similar proposal, adding paint to the pellets to take advantage of solar radiation pressure â€” the force exerted on objects by the sunâ€™s photons. Researchers have observed that pressure from sunlight can alter the orbits of geosynchronous satellites, while others have proposed equipping spacecraft with sails to catch solar radiation, much like a sailboat catches wind. In his proposal, Paek used the asteroid Apophis as a theoretical test case. According to astronomical observations, this 27-gigaton rock may come close to Earth in 2029, and then again in 2036. Paek determined that five tons of paint would be required to cover the massive asteroid, which has a diameter of 1,480 feet. He used the asteroidâ€™s period of rotation to determine the timing of pellets, launching a first round to cover the front of the asteroid, and firing a second round once the asteroidâ€™s backside is exposed. As the pellets hit the asteroidâ€™s surface, they would burst apart, splattering the space rock with a fine, five-micrometer-layer of paint. From his calculations, Paek estimates that it would take up to 20 years for the cumulative effect of solar radiation pressure to successfully pull the asteroid off its Earthbound trajectory. He says launching pellets with traditional rockets may not be an ideal option, as the violent takeoff may rupture the payload. Instead, he envisions paintballs may be made in space, in ports such as the International Space Station, where a spacecraft could then pick up a couple of rounds of pellets to deliver to the asteroid. Paek adds that paint isnâ€™t the only substance that such pellets might hold. For instance, the capsules could be filled with aerosols that, when fired at an asteroid, â€œimpart air drag on the incoming asteroid to slow it down,â€? Paek says. â€œOr you could just paint the asteroid so you can track it more easily with telescopes on Earth. So there are other uses for this method.â€? Lindley Johnson, program manager for NASAâ€™s Near Earth Objects Observation Program, says Paekâ€™s proposal is â€œan innovative variationâ€? on a method used by others to capitalize on solar radiation pressure. For example, MESSENGER, a spacecraft orbiting Mercury, is equipped with solar sails that propel the craft with solar radiation pressure, reducing the fuel needed to power it. â€œIt is very important that we develop and test a few deflection techniques sufficiently so that we know we have a viable â€˜toolboxâ€™ of deflection capabilities to implement when we inevitably discover an asteroid on an impact trajectory,â€? Johnson says.William Ailor, principal engineer for Aerospace Corp. in El Segundo, Calif., adds that the potential for an asteroid collision is a long-term challenge for scientists and engineers. â€œThese types of analyses are really timely because this is a problem weâ€™ll have basically forever,â€? Ailor says. â€œItâ€™s nice that weâ€™re getting young people thinking about it in detail, and I really applaud that.â€?If you are like us and love R/C, this is the place for you. Every possible type of R/C model can be127 of my files in Dropbox are now gone forever, due to a bug where files were "updated" to be 0 bytes, and Dropbox lost its previous copy of the file.2 other files (precious family photos) were also affected, but it happened recently enough to be recovered manually by Dropbox engineers. 23 other files were also turned to 0 byte dust, but Dropbox kept its version history of these and I could revert them to their original version.Check whether you've been affected (on Mac or Linux) by running this command in a Terminal, it'll spit out a list of 0-byte files to a text file on your desktop.Important: Make sure you sanity check the list. Some systems have hidden 0-byte files, such as Macs' "Icon\r", that are expected and normal.If you find any that look unexpected, let Dropbox know, and reference this blog post to them so they can connect it with the issue I reported.I've included my correspondence with Dropbox on the issue below. They've been very nice about it, and are looking into it, but this is a very serious bug. Because they don't know what the bug is, potentially anyone could be affected. I'll update this post if they find a fix.Update: Some folks on Hacker News, and Matt Holden of Dropbox in the comments, have raised the possibility of filesystem corruption, particularly because of a recently reported ext4 bug. I do use ext4, so this can plausibly explain why my files were 0-byte'd in the first place, and why others have reported finding 0-byte'd files.I also do not use Packrat, a premium Dropbox feature that stores version history for longer than 30 days, so this could plausibly explain why my 127 files that had been 0-byte'd months ago no longer have a version history of before then. I wasn't aware of the 30-day window.However, these do not plausibly explain why the 2 manually recovered files that had recently been 0-byte'd, well within the 30-day window, showed no pre-0-byte version history, and required the assistance of Dropbox engineers.It could be that the bug here has nothing to do with their desktop client - it could be a version history bug in the web frontend that affects some recently edited files. If that's the case, then that still needs to be fixed, so that people in my position can recover files their disk corrupted before they pass out of the 30-day window. It's only by finding and fixing that website bug that Dropbox can say with confidence that there's no desktop client bug.Update 2: A report by someone who is on OS X, uses Packrat, but has lost 70 files they can't recover.If you are like us and love R/C, this is the place for you. Every possible type of R/C model can beFlooding and power outages caused by Hurricane Sandy have forced several New York data centers to switch to generator power. But those generators are quickly running out of fuel, so data center companies are telling their customers to shut down their servers and move workloads elsewhere.One of the worst situations is at 75 Broad Street in Manhattan, where both Internap and Peer1 Hosting are shutting down operations "after basement-level flooding disabled critical diesel fuel pumps," Data Center Knowledge reports. 75 Broad Street is part of the "Zone A" portion of the city that is under emergency evacuation orders, as is another data center operated by Datagram at 33 Whitehall Street. The Datagram outage led to downtime for popular websites Gawker, Huffington Post, and BuzzFeed.Peer1's official network status page reported last night that it was running on emergency generator power. This morning, the company said "we have an estimate of 4 hours for the fuel left on our generators. Our techs and facility are continuously working to get emergency fuel delivery on time and was looking to set-up a temporary tank and pump since the basement is still flooded. In the event of not receiving the fuel on time, worst case scenario is we will have to gracefully shutdown the facility."The worst case scenario has apparently occurred, as the latest update says, "We are going to implement a controlled shutdown of NY Data Center at 10:45 ET." (UPDATE: Peer1 reported good news just before 12:30pm ET. "The New York facility is still on generator power, sustaining longer than initially estimated," Peer1 said. "We will have the latest update on the remaining fuel available, along with the arrival of fuel replacement shortly.")Internap is reporting much the same scenario. In a note to customers made public on Pastebin, Internap said, "The flooding has submerged and destroyed the site's diesel pumps and is preventing fuel from being pumped to the generators on the mezzanine level. The available fuel reserves on the mezzanine level are estimated to support customer loads for approximately 5-7 hours. Once this fuel supply has been exhausted the generator will no longer be able to sustain operation and critical customer power loads will be lost. The building itself is being evacuated and no remote hands support will be available to assist in any equipment shutdown."Internap advised its self-service customers to shut down their servers immediately and is having its customer support team execute a "graceful" shutdown of servers for managed customers. Internap's cloud services are also being shut down, the company said. We've asked Internap for an update and will report back if we get one. But according to iT News, Internap sent customers a follow-up e-mail this morning that said, "Available fuel reserves on the mezzanine level are estimated to be nearly depleted and able to support customer loads for less than 2 hours. Once this fuel supply has been exhausted the generator will no longer be able to sustain operation and critical customer power loads will be lost."UPDATE: Internap is reportedlyÂ out of fuel and offline, but it is trying to get more fuel to the building. As of 12:55pm ET, the Internap network operations center hotline was playing a recorded message that says the facility is "currently without power due to flooding" and that co-location and IP customers can expect "widespread outages." Later in the day, the company posted a blogÂ saying the 75 Broad Street facility was still without power, but that Internap isÂ trying to get its generator farm back up and running. "It is unclear how long it will take ConEd to restore utility power to the site, but we are preparing for the possibility of remaining on generator power for many days," Internap said.Â In addition to running out of fuel in secondary tanks, Internap said the flooding damaged "both our redundant fuel pumps and our generator fuel tank." Internap is coordinating fuel deliveries and pumps, and said it will have engineers "fabricate pipe to bring the fuel directly to the generators on the mezzanine level."In addition to damage caused by flooding, New York power company Con Edison said it preemptively shut off electricity in part of Lower Manhattan last night, and reported today that substation damage and downed wires cut off power to many customers. Con Edison called it "the largest storm-related outage in our history."As mentioned, Gawker, Huffington Post, and BuzzFeed have suffered downtime as a result of flooding at Datagram's data center at 33 Whitehall Street. As of this writing, the main Gawker sites are still offline (stripped-down versions are reachable at live.gawker.com), while the Huffington Post andÂ Buzzfeed have gotten themselves back online.Further outages includedÂ Steadfast hosting at 121 Varick Street in New York City due to "an auxiliary electrical failure," and Init7 at 111 8th Avenue, due to a data center power outage. Init7 operates IP backbone services. As a result of the outage, the company said to expect "possible routing issues from/to the United States." As it turns out, Internap also has servers at the 8th Avenue address, but they are operating under generator power and have enough fuel for several days.It's not as if data centers didn't take any precautions. In advance of the storm, Data Center Knowledge reported that "data center providers in New York, Philadelphia and the Washington, DC area said they are testing and fueling up their emergency backup generators, preparing to maintain services during any utility power outages caused by the hurricane." The cloud storage provider Nirvanix allowed customers to move data out of its data center in New Jersey for free. And cloud service providers such as Amazon are closely monitoring data centers on the East Coast, stocking up on generator fuel, and having extra staff on hand.As various non-storm-related outages at Amazon have shown, customers relying on hosting providers and cloud services may want to build systems that can fail over across multiple regions. Ultimately, when a data center is in the wrong spot at the wrong time, even the most extensive preparations may not be enough to stay online in the face of a storm like Hurricane Sandy.The Internet has evolved quite a bit since I first logged on to CompuServe in 1994. Iâ€™d spent a few years tooling around on BBS (Bulletin Board Systems) connections throughout the country at that point and the most visible portions of a forming World Wide Web were quite innocent in appearance. But as I ramped up my fatherâ€™s 4600 baud modem and looked around at the fringes of online existence, I unknowingly caught a glimpse at the Webâ€™s early underbelly. From there, pornography, craziness and illegal activities were easily accessible. There werenâ€™t many people logging on so, naturally, there werenâ€™t many people to police this new digital space. Eventually, as AOL, Prodigy and other ISPs became more mainstream, the more nefarious outlets vanished into the shadows. But where did it all go? I recently took a plunge into the â€˜Deep Web,â€™ a sub-surface area of the Internet not indexed by search engines and only available to those on the forefront of technology, namely people connected to the Tor Network. This network of hidden websites is the new underbelly of the Web, the New Underground, if you will, chock full of all sorts of illicit activities. Child porn peddlers, drug dealers, hitmen and other criminal groups thrive on the Deep Web and anonymity reigns supreme. The following post outlines my findings and hopefully sheds some light on the true Wild Wild West of the World Wide Web.What is the Deep Web?: Wikipedia has an excellent overview on the Deep Web.The Deep Web (also called Deepnet, the invisible Web, DarkNet, Undernet or the hidden Web) refers to World Wide Web content that is not part of the Surface Web, which is indexed by standard search engines. Mike Bergman, credited with coining the phrase,[1] has said that searching on the Internet today can be compared to dragging a net across the surface of the ocean: a great deal may be caught in the net, but there is a wealth of information that is deep and therefore missed. Most of the Webâ€™s information is buried far down on dynamically generated sites, and standard search engines do not find it. Traditional search engines cannot â€œseeâ€? or retrieve content in the deep Web â€“ those pages do not exist until they are created dynamically as the result of a specific search. The deep Web is several orders of magnitude larger than the surface Web.So if the Internet as you know it is an iceberg, the smallest part of that iceberg, the visible portion, is where you have been surfing your entire life. You visit websites, click links, use search engines to research topics of interest and generally just make your way around the visible Web. But below that visible portion, there is a much larger compilation of destinations beyond the reach of most Internet users. This portion, the Deep Web, is much harder for the average person to access and even harder to navigate. Much of the criminal activity that happens on the Deep Web is cloaked in anonymity, shrouded in secrecy or somehow hidden from the prying eyes that would love to put an end to this virtual land of OZ. Essentially what Iâ€™m saying is this: You may be familiar with the Internet, maybe even the darker side of the Internet. You may know how to find pornography for free, download music illegally, use a torrent program to download pirated movies and other media or purchase prescription pills from some online pharmacy. But if you havenâ€™t visited the Deep Web, you ainâ€™t seen nothing yet. Sure, there are research papers and legitimate and interesting pieces of content to view on The Other Side but thereâ€™s also some pretty nefarious happenings there.How do you connect to the Deep Web?: Though the Deep Web may be beyond those of you with little in the way of technical and Web savvy, itâ€™s not impossible, nor even extremely difficult to visit. First, youâ€™ll need to download Tor, the software that allows you to access the Deep Web. Tor is designed to provide Internet users with as close to complete anonymity as possible. The Tor website describes their software and their mission as follows.You can use Tor on virtually any PC, Mac or even mobile devices like the iPhone and Android-operated smartphones. But, if, like me, youâ€™re using Firefox, you next need to install the Torbutton. With the Tor software up and running and the Torbutton installed, youâ€™ll see a small onion logo near the address bar of your browser. If youâ€™re correctly logged in to the Tor network, you can click this button and begin to explore the Deep Web. This collection of Deep Web links should get you started. But, keep in mind, you wonâ€™t be able to maneuver in this new land quite as easily as you did back on the visible Web. There is no Google-like search engine of these sites that Iâ€™m aware of at the moment. Instead, itâ€™s a collection of Wikis and BBS-like sites that aggregate links to other locations on the Deep Web. These sites generally have bizarre, unmemorable domain names like SdddEEDOHIIDdddgmomionw.onion. Thatâ€™s right, instead of .com, these domains generally end in the .onion suffix. And because youâ€™ll never remember how you got to where you are if you spend any significant time here, itâ€™s best to save URLs or bookmark your way through this journey.What can you find on the Deep Web?: The Silk Road is the most popular place to buy drugs on the Deep Web. From ecstasy, pure MDMA, marijuana, psychedelics and seeds to opiates, they have basically any drug with a userbase. They also have categories for â€˜servicesâ€™ like hacking, â€˜lab suppliesâ€™ like sulfuric acid and liquid mercury, â€˜moneyâ€™ for stolen credit cards, travelers checks and forged bills and coins, â€˜jewelryâ€™ like uncut stones, stolen gold and other precious metals obtained via devious means and finally â€˜weaponsâ€™ where they currently list a Glock 17 for sale out of Canada that â€œincludes 1 clip with 9 live rounds.â€? Another Deep Web drug outlet, the General Store, focuses on Ketamine, MDMA, MDPV and DMT (you may need to Google some of those).Additional items in the â€˜marijuanaâ€™ category on The Silk Road:Forum posts like this are common (and often answered) and even include requests for murders:(Note: This is not from The Silk Road, but a popular message board on the Deep Web)Most transactions on the Deep Web are conducted via Bitcoins. You can purchase virtually anything with this digital currency, ranging from the legit to the oh-so-far-away from legit. You can buy all the items outlined above and you can even hire a prostitute. There is, however, some debate over whether or not these transactions are anonymous (more on that below). 1 Bitcoin = $9 US.You can find literally ANYTHING illegal on the Deep Web. Speaking of illegalâ€¦Let me issue a STRONG WARNING at this point. Be extremely careful what sites you visit and links you click. You could find yourself on a child pornography website or just all-around grotesque sexual deviance-focused site that will ruin your experience (and in the case of child pornography, your life). The wiki page linked to above contains mostly safe sites to search but stay away from anything labeled as a â€˜chanâ€™ or â€˜bulletin boardâ€™ as they probably traffic heavily in child pornography. Anything labeled CP is to be AVOIDED AT ALL COSTS. It will lead you to child porn.There are sites on the Deep Web that offer the services of hitmen, advice to gang members, directions on how to build explosives, how to cheat at virtually anything and pretty much any other illegal activity or service that you can dream of â€“ itâ€™s all there, some of it is frightening, some of it is interesting, all of it is anonymous. Wait, is it really anonymous?Is this all truly anonymous?: Probably not. To the horseâ€™s mouth, we go.Though he may be saying that because Bitcoin hopes to be viewed as a legitimate business.My journey though The New Underground, the Deep Dark Web, was interesting, to say the least. Thereâ€™s a lot of potential for trouble down near the bottom of this iceberg, so always be aware of what youâ€™re doing and the legality of your actions. Still, I have an unquenchable thirst for the unknown so by carefully maneuvering in a way that kept several meters and a snake pit between myself and the most vile content on the Deep Web, I was able to learn a bit about a facet of the Internet I had yet to discover. Iâ€™d encourage you to poke around a bit as well. But, remember, do so at your own risk. Be safe, watch what you click and refrain from purchasing anything along the way.Be careful, itâ€™s a whole new world down there.Last year AMD officially became an ARM licensee, although the deal wasn't publicized at the time. Fast forward to June 2012 and we saw the first fruits of that deal: AMD announced it would integrate ARM's Cortex A5 core into its 2013 APUs to enable TrustZone support.Today comes a much bigger announcement: AMD will be building Opteron processors based on a 64-bit ARM architecture. There are no product announcements today, but the 64-bit ARM Opterons will go into production in 2014. Today's announcement is about a processor license, not an ARM architecture license - in other words, AMD will integrate an ARM designed 64-bit core for this new Opteron. Update: AMD will integrate ARM's new Cortex-A50 series of 64-bit ARMv8 CPU cores.The only other detail we know is that these ARM based Opterons will embed SeaMicro's Freedom Fabric, presumably on-die.AMD offering ARM based Opterons is really to target the microserver market. As for why AMD isn't using Jaguar for these parts, it's likely that by going with ARM it can lower the development time and cost to get into this market. The danger here is the total microserver market is expected to be around 10% of the overall server market, but that includes x86 + ARM. With x86 as the default incumbent, it's going to be an uphill battle for AMD/ARM to carve out a significant portion of that market.AMD was quick to mention that despite today's announcement, it will continue to build x86 CPUs and APUs for client and server markets.Overall the move sounds a lot like AMD trying to move quickly to capitalize on a new market. It's unclear just how big the ARM based server market will be, but AMD seems to hope that it'll be on the forefront of that revolution - should it happen. Embracing ARM also further aligns AMD with one of Intel's most threatening sources of competition at this point. The question is whether or not AMD is doing itself more harm than good by working to devalue x86 in the server space. I suspect it'll be years before we know the real impact of AMD's move here.The other major takeaway is that AMD is looking to find lower cost ways of bringing competitive platforms to market. I do think that a Jaguar based Opteron would likely be the best route for AMD, but it would also likely require a bit more effort than integrating an ARM core.Obviously competition will be more prevalent in the ARM server space, but here is where AMD hopes its brand and position in the market will be able to give it an advantage. AMD will also be relying heavily on the SeaMicro Freedom Fabric for giving its ARM based Opterons a leg up on the competition. This is one time where I really wish AMD hadn't spun off its fabs.Yesterday morning, the Free Software Foundation crashed the Windows 8 launch event in New York City. A cheerful GNU and her team handed out DVDs loaded with Trisquel, FSF stickers, and information about our new pledge, which asks Windows users to upgrade not to Windows 8, but to GNU/Linux.Drag and drop file or link here to translate the document or web page.Drag and drop link here to translate the web page.We do not support the type of file you drop. Please try other file types.We do not support the type of link you drop. Please try link of other types.The U.S. Supreme Court will hear arguments on Monday in one of the most important copyright cases in a decade, over whether works manufactured outside the United States can be resold here without the permission of the copyright owner.The decision could have a huge impact on the $63 billion "gray market" for goods purchased abroad and sold for a higher price in the United States.Both parties to the case believe a loss for their side will result in a doomsday scenario of sorts. One side says that a ruling in their favor is the only way to free American consumers from the potential of copyright holders to exert never ending control over their material. The other side insists that a decision for them is the only way U.S. companies will be able to successfully participate in the global marketplace. A down-the-line victory for one side or the other is likely to result in the loser lobbying Congress for an update to the Copyright Act.At issue in the case, Kirtsaeng v. John Wiley & Sons, are provisions of the Copyright Act that appear contradictory. One section says that the importation into the United States, without the authority of the copyright owner, of works acquired abroad is an infringement of the copyright owner's exclusive right to distribute copies. However, another part of the act limits the copyright holder's distribution rights by saying that the owner of a copy "lawfully made under this title" can sell or otherwise get rid of it. That resell right is known as the "first-sale doctrine."Supap Kirtsaeng, a Thai man who attended college and graduate school in the United States, had his family at home buy textbooks manufactured internationally and ship them to him. He then resold the books on eBay. John Wiley & Sons, a prominent textbook publisher, has the exclusive rights to distribute its textbooks in the United States, and some of the books Kirtsaeng sold were Wiley textbooks that were manufactured abroad. Wiley sued and was awarded several hundred thousand dollars in damages. The student, who maintained that he had the right to resell books he owned, appealed. In August 2011, the 2nd U.S.Circuit Court of Appeals sided with Wiley and held that the first-sale doctrine was inapplicable because the "lawfully made under this title" language referred only to copies manufactured in the United States.In its decision, authored by Judge Jose Cabranes, the 2nd Circuit acknowledged the "particularly difficult question of statutory construction" and said that "if our decision leads to policy consequences ... which Congress now find unpalatable, Congress is of course able to correct our judgment."Those "unpalatable" consequences have been highlighted, in amicus briefs and other public statements by companies like eBay and Costco, whose businesses rely on resales, as well as by libraries and museums who acquire works from around the world.(We wrote about the library group's amicus brief in July.)Kirtsaeng's brief, submitted by a team including Joshua Rosenkranz of Orrick, Herrington & Sutcliffe, also walks through examples of what could happen if the court upholds the 2nd Circuit's decision. The resale or lease of cars imported into the United States, which almost always have copyrighted software, would violate copyright laws, and movie producers could begin manufacturing DVDs abroad and "enjoy a permanent veto over any further rental of the foreign-made DVD," the brief said.Though "anyone who makes a product would love to control what happens to it downstream," the longstanding U.S. law is that if you bought it, you own it, no matter where that purchase was made, Rosenkranz said. That is a point he will put "front and center" to the court, he said.While it sounds like an odd outcome that goods manufactured abroad could receive more far-reaching copyright protection than goods manufactured domestically, John Wiley's team, led by Theodore Olson of Gibson, Dunn & Crutcher, argued in its brief that those fears were much ado about nothing. Kirtsaeng's examples, it argued, focus on scenarios where the copyright owner authorized the original import. The court does not need to address what happens to the first-sale doctrine in the event of an "authorized" importation, the Wiley brief said, and can instead just focus on Kirtsaeng's unauthorized import and sale.Evan Finkel, an intellectual property partner at Pillsbury Winthrop Shaw Pittman, said because of the facts of the case and the section's wording, it's unlikely the Supreme Court will enact such a specific exception in this case. Instead, should the court rule for Wiley, he said, they could note some exception for individual consumers reselling a book or two, or at least note that it is a question for another day.Monday will be like the second time around for this copyright question. In 2010, the Supreme Court upheld a 9th Circuit decision involving Costco's sale of gray-market Omega brand watches. The circuit court had ruled that the first sale doctrine does not apply to works manufactured outside the United States. The Supreme Court's holding came with no opinion, however. It was a result of a 4-4 tie, with Justice Elena Kagan not participating. This time around, Kagan will be on the bench.While both parties argue that history and statutory interpretation are on their side, they recognize to some extent that an increasingly shrinking world might not fit within the confines of the current law. Wiley's brief acknowledges that many of the scenarios, like one involving Netflix and DVD rentals, could not have been considered by Congress because they didn't exist when the first sale-related section was drafted nearly 40 years ago.Follow us on TwitterÂ @AlisonFrankel,Â @erin_gs,Â @ReutersLegalÂ Â |Â Like us onÂ FacebookÂ Â Â Computerworld - The FBI has arrested Paul Ceglia for attempting to defraud Facebook and its co-founder Mark Zuckerberg in a scheme to grab a large stake in the company and billions of dollars.Federal agents picked up 39-year-old Ceglia at his home in Wellsville, N.Y. this morning, according to a report in Forbes.Ceglia first filed a lawsuit in June 2010, claiming he signed a contract with Zuckerberg that entitles him to 84% ownership of what is easily the world's largest social network. In an amended filing last year, though, Ceglia modified his claim, alleging he was owed 50% of Zuckerberg's stake in the social networking company.According to a criminal complaint filed with the Southern District of New York, Ceglia is accused of using the U.S. Postal Service as part of a fraudulent scam against Facebook and Zuckerberg.Ceglia is being charged with mail fraud and wire fraud."Ceglia filed a federal lawsuit falsely claiming that he was entitled to at least a 50% interest in Facebook," the complaint contends. "Ceglia has deliberately engaged in a systematic effort to defraud Facebook and Zuckerberg and to corrupt the federal judicial process."Not surprisingly, today's arrest was met with excitement at Facebook."We commend the United States Attorney for charging Ceglia with federal crimes in connection with his fraudulent lawsuit against Facebook," Orin Snyder, a partner with Gibson Dunn, attorneys for Facebook and Zuckerberg, said in an email to Computerworld. "Ceglia used the federal court system to perpetuate his fraud and will now be held accountable for his criminal scheme."The complaint also contends that Ceglia and Zuckerberg had signed a contract between them, but it had nothing to do with Facebook, did not reference Facebook and did not give Ceglia any interest in the social network.And federal investigators allege that as part of his scheme, Ceglia manufactured and destroyed evidence, for instance replacing a page of the original contract with a fraudulent one that made it look like Zuckerberg had offered Ceglia interest in the company.The complaint even has a section titled: The Founding of Facebook Did Not Involve Ceglia.In 2011, Facebook attorneys filed court documents saying they had found evidence that Ceglia had concealed or destroyed relevant documents, including six missing USB drives.The social network's lawyers said they had uncovered an "authentic" contract that showed that Ceglia wasn't owed any interest in Facebook.Sharon Gaudin covers the Internet and Web 2.0, emerging technologies, and desktop and laptop chips for Computerworld. Follow Sharon on Twitter at Â @sgaudin, on Google+ or subscribe to Sharon's RSS feedÂ . Her email address is sgaudin@computerworld.com.See more by Sharon Gaudin on Computerworld.com.Read more about Social Media in Computerworld's Social Media Topic Center.BASF has been researching into metal-organic frameworks (MOFs), and the processes that can be used to manufacture these highly efficient storage materials for gases on an industrial scale, for more than ten years. In September, BASF was awarded the Pierre Potier Prize in the field of process innovation for its successful research. This prize is awarded for outstanding examples of sustainable innovations in the field of chemistry by the two French chemical associations FÃ©dÃ©ration FranÃ§aise pour les sciences de la Chimie (FFC) and lâ€™Union des Industries Chimiques (UIC) in honour of the chemist and pharmacist Pierre Potier.We spoke with Dr. Manuela Gaab, one of the chemists in the MOF research team at BASF, in order to learn more about the potential of MOFs, their applications and the innovative new manufacturing process.Why is this new manufacturing process so innovative and sustainable? This novel process enables us to produce aluminium MOFs on an industrial scale for the first time. We can now produce batches of several tons, and they can be used commercially in applications such as storage tanks for natural gas. Another important advantage is that this innovative process no longer employs any organic solvents, only water. This makes it safe and environmentally friendly. These MOFs are very easy to produce, so easy that advanced school students can make them in our school laboratory.Why are MOFs so special? The special feature of MOFs is that their crystalline nanostructures enable them to be used to store natural gas and other fuel gases such as hydrogen. MOFs consist of a three-dimensional metal-organic framework with pore sizes in the nanometer range. Their high porosity and their large internal surface area allow them to be used to store large quantities of gas.The huge surface area of these crystals is illustrated very well by MOF-210, which was developed by Professor Yaghi (University of California, Berkeley). These zinc carboxylate crystals have a surface area of more than 10 000 m2 per gram. This corresponds to three football pitches within a material quantity that correlates to a sugar cube! Their enormous surface area enables metal-organic frameworks to be used to store large quantities of gas, just like water in a sponge.What are the applications for MOFs? Mobility is an interesting area of application for MOFs. At BASF, we are researching into alternative power concepts for the future that are environmentally friendly and conserve resources as well as being comfortable. We are investigating several different concepts aimed at improving the performance of vehicles powered by electricity and natural gas. MOFs can make a decisive contribution to the performance of vehicles powered by natural gas. Up until now, very few vehicles powered by natural gas have been approved for use on the roads, even though they represent an environmentally friendly alternative mode of transport. One of the main reasons for this is their low fuel storage capacity, which causes the bulky gas tanks and bottles to take up lots of room, and their limited range. They have to be fitted with an extra tank, and some of the luggage space is used to accommodate large gas bottles. MOFs can play an important role here, because their special properties can be used to obtain a large increase in fuel storage capacity.How can MOFs be used to increase the storage capacity of tanks for natural gas? Gas molecules can be stored at a higher density on the surfaces of MOFs than in conventional tanks. This enables more gas to be stored in tanks with the same volume at the same pressure. Larger quantities of gas in the tank increase the range of vehicles and, in future, cars powered by natural gas will be able to travel twice as far on one tank of gas.What other possible applications are there for MOFs? Separating and purifying gases are examples of industrial applications for MOFs. These applications make use of the different pore sizes of MOFs and differences in the affinity of gases for different materials. Another industrial application is catalysis, and we are also currently exploring other applications such as fuel cells for automobiles. MOFs could be used to store hydrogen fuel in the same way as the natural gas that is used to power vehicles. These are only a few examples of the versatile range of applications for MOFs and their future potential. We are in a position to supply customized MOFs in order to meet the specific demands of different customers, and new classes of MOF will also gradually find their way onto the market.In the space of one hour, my entire digital life was destroyed. First my Google account was taken over, then deleted. Next my Twitter account was compromised, and used as a platform to broadcast racist and homophobic messages. And worst of all, my AppleID account was broken into, and my hackers used it to remotely erase all of the data on my iPhone, iPad, and MacBook.In many ways, this was all my fault. My accounts were daisy-chained together. Getting into Amazon let my hackers get into my Apple ID account, which helped them get into Gmail, which gave them access to Twitter. Had I used two-factor authentication for my Google account, itâ€™s possible that none of this would have happened, because their ultimate goal was always to take over my Twitter account and wreak havoc. Lulz.Had I been regularly backing up the data on my MacBook, I wouldnâ€™t have had to worry about losing more than a yearâ€™s worth of photos, covering the entire lifespan of my daughter, or documents and e-mails that I had stored in no other location.Those security lapses are my fault, and I deeply, deeply regret them.But what happened to me exposes vital security flaws in several customer service systems, most notably Appleâ€™s and Amazonâ€™s. Apple tech support gave the hackers access to my iCloud account. Amazon tech support gave them the ability to see a piece of information â€” a partial credit card number â€” that Apple used to release information. In short, the very four digits that Amazon considers unimportant enough to display in the clear on the web are precisely the same ones that Apple considers secure enough to perform identity verification. The disconnect exposes flaws in data management policies endemic to the entire technology industry, and points to a looming nightmare as we enter the era of cloud computing and connected devices.This isnâ€™t just my problem. Since Friday, Aug. 3, when hackers broke into my accounts, Iâ€™ve heard from other users who were compromised in the same way, at least one of whom was targeted by the same group.â€¬Moreover, if your computers arenâ€™t already cloud-connected devices, they will be soon. Apple is working hard to get all of its customers to use iCloud. Googleâ€™s entire operating system is cloud-based. And Windows 8, the most cloud-centric operating system yet, will hit desktops by the tens of millions in the coming year. My experience leads me to believe that cloud-based systems need fundamentally different security measures. Password-based security mechanisms â€” which can be cracked, reset, and socially engineered â€” no longer suffice in the era of cloud computing.I realized something was wrong at about 5 p.m. on Friday. I was playing with my daughter when my iPhone suddenly powered down. I was expecting a call, so I went to plug it back in.It then rebooted to the setup screen. This was irritating, but I wasnâ€™t concerned. I assumed it was a software glitch. And, my phone automatically backs up every night. I just assumed it would be a pain in the ass, and nothing more. I entered my iCloud login to restore, and it wasnâ€™t accepted. Again, I was irritated, but not alarmed.Â I went to connect the iPhone to my computer and restore from that backup â€” which I had just happened to do the other day. When I opened my laptop, an iCal message popped up telling me that my Gmail account information was wrong. Then the screen went gray, and asked for a four-digit PIN.By now, I knew something was very, very wrong. For the first time it occurred to me that I was being hacked. Unsure of exactly what was happening, I unplugged my router and cable modem, turned off the Mac Mini we use as an entertainment center, grabbed my wifeâ€™s phone, and called AppleCare, the companyâ€™s tech support service, and spoke with a rep for the next hour and a half.It wasnâ€™t the first call they had had that day about my account. In fact, I later found out that a call had been placed just a little more than a half an hour before my own. But the Apple rep didnâ€™t bother to tell me about the first call concerning my account, despite the 90 minutes I spent on the phone with tech support. Nor would Apple tech support ever tell me about the first call voluntarily â€” it only shared this information after I asked about it. And I only knew about the first call because a hacker told me he had made the call himself.At 4:33 p.m., according to Appleâ€™s tech support records, someone called AppleCare claiming to be me. Apple says the caller reported that he couldnâ€™t get into his Me.com e-mail â€” which, of course was my Me.com e-mail.In response, Apple issued a temporary password. It did this despite the callerâ€™s inability to answer security questions I had set up. And it did this after the hacker supplied only two pieces of information that anyone with an internet connection and a phone can discover.At 4:50 p.m., a password reset confirmation arrived in my inbox. I donâ€™t really use my me.com e-mail, and rarely check it. But even if I did, I might not have noticed the message because the hackers immediately sent it to the trash. They then were able to follow the link in that e-mail to permanently reset my AppleID password.At 4:52 p.m., a Gmail password recovery e-mail arrived in my me.com mailbox. Two minutes later, another e-mail arrived notifying me that my Google account password had changed.Â At 5:02 p.m., they reset my Twitter password. At 5:00 they used iCloudâ€™s â€œFind Myâ€? tool to remotely wipe my iPhone. At 5:01 they remotely wiped my iPad. At 5:05 they remotely wiped my MacBook. Around this same time, they deleted my Google account. At 5:10, I placed the call to AppleCare. At 5:12 the attackers posted a message to my account on Twitter taking credit for the hack.By wiping my MacBook and deleting my Google account, they now not only had the ability to control my account, but were able to prevent me from regaining access. And crazily, in ways that I donâ€™t and never will understand, those deletions were just collateral damage. My MacBook data â€” including those irreplaceable pictures of my family, of my childâ€™s first year and relatives who have now passed from this life â€” werenâ€™t the target. Nor were the eight years of messages in my Gmail account. The target was always Twitter. My MacBook data was torched simply to prevent me from getting back in.I spent an hour and a half talking to AppleCare. One of the reasons it took me so long to get anything resolved with Apple during my initial phone call was because I couldnâ€™t answer the security questions it had on file for me. It turned out thereâ€™s a good reason for that. Perhaps an hour or so into the call, the Apple representative on the line said â€œMr. Herman, Iâ€¦.â€?â€œWait. What did you call me?â€?â€œMy name is Honan.â€?Apple had been looking at the wrong account all along. Because of that, I couldnâ€™t answer my security questions. And because of that, it asked me an alternate set of questions that it said would let tech support let me into my me.com account: a billing address and the last four digits of my credit card. (Of course, when I gave them those, it was no use, because tech support had misheard my last name.)It turns out, a billing address and the last four digits of a credit card number are the only two pieces of information anyone needs to get into your iCloud account. Once supplied, Apple will issue a temporary password, and that password grants access to iCloud.Apple tech support confirmed to me twice over the weekend that all you need to access someoneâ€™s AppleID is the associated e-mail address, a credit card number, the billing address, and the last four digits of a credit card on file. I was very clear about this. During my second tech support call to AppleCare, the representative confirmed this to me. â€œThatâ€™s really all you have to have to verify something with us,â€? he said.We talked to Apple directly about its security policy, and company spokesperson Natalie Kerris told Wired, â€œApple takes customer privacy seriously and requires multiple forms of verification before resetting an Apple ID password. In this particular case, the customerâ€™s data was compromised by a person who had acquired personal information about the customer. In addition, we found that our own internal policies were not followed completely. We are reviewing all of our processes for resetting account passwords to ensure our customersâ€™ data is protected.â€?On Monday, Wired tried to verify the hackersâ€™ access technique by performing it on a different account. We were successful. This means, ultimately, all you need in addition to someoneâ€™s e-mail address are those two easily acquired pieces of information: a billing address and the last four digits of a credit card on file. Hereâ€™s the story of how the hackers got them.On the night of the hack, I tried to make sense of the ruin that was my digital life. My Google account was nuked, my Twitter account was suspended, my phone was in a useless state of restore, and (for obvious reasons) I was highly paranoid about using my Apple email account for communication.I decided to set up a new Twitter account until my old one could be restored, just to let people know what was happening. I logged into Tumblr and posted an account of how I thought the takedown occurred. At this point, I was assuming that my seven-digit alphanumeric AppleID password had been hacked by brute force. In the comments (and, oh, the comments) others guessed that hackers had used some sort of keystroke logger. At the end of the post, I linked to my new Twitter account.And then, one of my hackers @ messaged me. He would later identify himself as Phobia. I followed him. He followed me back.We started a dialogue via Twitter direct messaging that later continued via e-mail and AIM. Phobia was able to reveal enough detail about the hack and my compromised accounts that it became clear he was, at the very least, a party to how it went down. I agreed not to press charges, and in return he laid out exactly how the hack worked. But first, he wanted to clear something up:â€œdidnt guess ur password or use bruteforce. i have my own guide on how to secure emails.â€?I asked him why. Was I targeted specifically? Was this just to get to Gizmodoâ€™s Twitter account? No, Phobia said they hadnâ€™t even been aware that my account was linked to Gizmodoâ€™s, that the Gizmodo linkage was just gravy. He said the hack was simply a grab for my three-character Twitter handle. Thatâ€™s all they wanted. They just wanted to take it, and fuck shit up, and watch it burn. It wasnâ€™t personal.â€œI honestly didnâ€™t have any heat towards you before this. i just liked your username like I said beforeâ€? he told me via Twitter Direct Message.After coming across my account, the hackers did some background research. My Twitter account linked to my personal website, where they found my Gmail address. Guessing that this was also the e-mail address I used for Twitter, Phobia went to Googleâ€™s account recovery page. He didnâ€™t even have to actually attempt a recovery. This was just a recon mission.Because I didnâ€™t have Googleâ€™s two-factor authentication turned on, when Phobia entered my Gmail address, he could view the alternate e-mail I had set up for account recovery. Google partially obscures that information, starring out many characters, but there were enough characters available, mâ€¢â€¢â€¢â€¢n@me.com. Jackpot.This was how the hack progressed. If I had some other account aside from an Apple e-mail address, or had used two-factor authentication for Gmail, everything would have stopped here. But using that Apple-run me.com e-mail account as a backup meant told the hacker I had an AppleID account, which meant I was vulnerable to being hacked.â€œYou honestly can get into any email associated with apple,â€? Phobia claimed in an e-mail. And while itâ€™s work, that seems to be largely true.Since he already had the e-mail, all he needed was my billing address and the last four digits of my credit card number to have Appleâ€™s tech support issue him the keys to my account.So how did he get this vital information? He began with the easy one. He got the billing address by doing a whois search on my personal web domain. If someone doesnâ€™t have a domain, you can also look up his or her information on Spokeo, WhitePages, and PeopleSmart.Getting a credit card number is tricker, but it also relies on taking advantage of a companyâ€™s back-end systems. Phobia says that a partner performed this part of the hack, but described the technique to us, which we were able to verify via our own tech support phone calls. Itâ€™s remarkably easy â€” so easy that Wired was able to duplicate the exploit twice in minutes.First you call Amazon and tell them you are the account holder, and want to add a credit card number to the account. All you need is the name on the account, an associated e-mail address, and the billing address. Amazon then allows you to input a new credit card. (Wired used a bogus credit card number from a website that generates fake card numbers that conform with the industryâ€™s published self-check algorithm.) Then you hang up.Next you call back, and tell Amazon that youâ€™ve lost access to your account. Upon providing a name, billing address, and the new credit card number you gave the company on the prior call, Amazon will allow you to add a new e-mail address to the account. From here, you go to the Amazon website, and send a password reset to the new e-mail account. This allows you to see all the credit cards on file for the account â€” not the complete numbers, just the last four digits. But, as we know, Apple only needs those last four digits. We asked Amazon to comment on its security policy, but didnâ€™t have anything to share by press time.And itâ€™s also worth noting that one wouldnâ€™t have to call Amazon to pull this off. Your pizza guy could do the same thing, for example. If you have an AppleID, every time you call Pizza Hut, youâ€™ve giving the 16-year-old on the other end of the line all he needs to take over your entire digital life.And so, with my name, address, and the last four digits of my credit card number in hand, Phobia called AppleCare, and my digital life was laid waste. Yet still I was actually quite fortunate.They could have used my e-mail accounts to gain access to my online banking, or financial services. They could have used them to contact other people, and socially engineer them as well. As Ed Bott pointed out on TWiT.tv, my years as a technology journalist have put some very influential people in my address book. They could have been victimized too.Instead, the hackers just wanted to embarrass me, have some fun at my expense, and enrage my followers on Twitter by trolling.I had done some pretty stupid things. Things you shouldnâ€™t do.I should have been regularly backing up my MacBook. Because I wasnâ€™t doing that, if all the photos from the first year and a half of my daughterâ€™s life are ultimately lost, I will have only myself to blame. I shouldnâ€™t have daisy-chained two such vital accounts â€” my Google and my iCloud account â€” together. I shouldnâ€™t have used the same e-mail prefix across multiple accounts â€” mhonan@gmail.com, mhonan@me.com, and mhonan@wired.com. And I should have had a recovery address thatâ€™s only used for recovery without being tied to core services.But, mostly, I shouldnâ€™t have used Find My Mac. Find My iPhone has been a brilliant Apple service. If you lose your iPhone, or have it stolen, the service lets you see where it is on a map. The New York Timesâ€™ David Pogue recovered his lost iPhone just last week thanks to the service. And so, when Apple introduced Find My Mac in the update to its Lion operating system last year, I added that to my iCloud options too.After all, as a reporter, often on the go, my laptop is my most important tool.But as a friend pointed out to me, while that service makes sense for phones (which are quite likely to be lost) it makes less sense for computers. You are almost certainly more likely to have your computer accessed remotely than physically. And even worse is the way Find My Mac is implemented.When you perform a remote hard drive wipe on Find my Mac, the system asks you to create a four-digit PIN so that the process can be reversed. But hereâ€™s the thing: If someone else performs that wipe â€” someone who gained access to your iCloud account through malicious means â€” thereâ€™s no way for you to enter that PIN.A better way to have this set up would be to require a second method of authentication when Find My Mac is initially set up. If this were the case, someone who was able to get into an iCloud account wouldnâ€™t be able to remotely wipe devices with malicious intent. It would also mean that you could potentially have a way to stop a remote wipe in progress.But thatâ€™s not how it works. And Apple would not comment as to whether stronger authentification is being considered.As of Monday, both of these exploits used by the hackers were still functioning. Wired was able to duplicate them. Apple says its internal tech support processes werenâ€™t followed, and this is how my account was compromised. However, this contradicts what AppleCare told me twice that weekend. If that is, in fact, the case â€” that I was the victim of Apple not following its own internal processes â€” then the problem is widespread.I asked Phobia why he did this to me. His answer wasnâ€™t satisfying. He says he likes to publicize security exploits, so companies will fix them. He says itâ€™s the same reason he told me how it was done. He claims his partner in the attack was the person who wiped my MacBook. Phobia expressed remorse for this, and says he would have stopped it had he known.â€œyea i really am a nice guy idk why i do some of the things i do,â€? he told me via AIM. â€œidk my goal is to get it out there to other people so eventually every1 can over come hackersâ€?I asked specifically about the photos of my little girl, which are, to me, the greatest tragedy in all this. Unless I can recover those photos via data recovery services, they are gone forever. On AIM, I asked him if he was sorry for doing that. Phobia replied, â€œeven though i wasnt the one that did it i feel sorry about that. Thats alot of memories im only 19 but if my parents lost and the footage of me and pics i would be beyond sad and im sure they would be too.â€?But letâ€™s say he did know, and failed to stop it. Hell, for the sake of argument, letâ€™s say he did it. Letâ€™s say he pulled the trigger. The weird thing is, Iâ€™m not even especially angry at Phobia, or his partner in the attack. Iâ€™m mostly mad at myself. Iâ€™m mad as hell for not backing up my data. Iâ€™m sad, and shocked, and feel that I am ultimately to blame for that loss.But Iâ€™m also upset that this ecosystem that Iâ€™ve placed so much of my trust in has let me down so thoroughly. Iâ€™m angry that Amazon makes it so remarkably easy to allow someone into your account, which has obvious financial consequences. And then thereâ€™s Apple. I bought into the Apple account system originally to buy songs at 99 cents a pop, and over the years that same ID has evolved into a single point of entry that controls my phones, tablets, computers and data-driven life. With this AppleID, someone can make thousands of dollars of purchases in an instant, or do damage at a cost that you canâ€™t put a price on.Additional reporting by Roberto Baldwin and Christina Bonnington. Portions of this story originally appeared on Mat Honanâ€™s Tumblr.Continued: How I Resurrected My Digital Life After an Epic Hacking.Subscribe to an NBR ONLINE Business Subscription today and get business news your staff can use.We now offer a flat rate for companies, unlimited access for all staff. Signup now for just $249 +GST per company, per quarter. With an NBR ONLINE Business Subscription all articles can easily be forwarded to anyone within your company or organisation. Free access is guaranteed, no login required. Register below or contact Todd Scott for more information tscott@nbr.co.nzEnvision this: you're at a Halloween party, a little drunk, a little bored. You don't recognize anyone's costumes around you except the third, fourth, and fifth Psy you've seen that night, all doing the Gangnam style dance together. Your eyes pass over a seemingly innocuous pumpkin decoration. But waitâ€”is that a Tetris matrix carved into its face? Is the stem a joystick? Are you in discreet gaming heaven?Nathan Pryor of Hahabird initially aspired to grow several pumpkins into the shape of Tetris blocks (Tetrominos). But when that didn't pan out, he simply used an Arduino to turn a carved pumpkin into a compact gaming cabinet. Behold: a Pumpktris.Initially Pryor planned to use a LoLShield LED matrix as the pumpkin's display, but each LED needed two wires to run to the Arduino board powering the game. The bundle would have been enormousâ€”and a mess. So to make the display, Pryor built and wired his own (appropriately orange) 8Ã—16 LED matrix and carved out 128 holes for each light on the face of an appropriately-shaped pumpkin. He also programmed the Arduino board true to the game's rules, with pieces that fall with increasing speed as the level goes up, as well as a scorekeeping element.Pryor told Ars the entire project cost about $100 altogether (including Arduino, LEDs, LED controllers, joystick assembly, and four pumpkinsâ€”three of which he had to reject due to suboptimal shape). In all it took twelve hours to build. That means there's still time before your Halloween celebration tomorrow to make a Pumpktris. Use it to impress your friends, or ignore themâ€”the Pumpktris does not judge.A key part of any cybersecurity plan is â€œcontinuous monitoringâ€?, or enabling auditing and monitoring throughout a network environment and configuring automated analysis of the resulting logs to identify anomalous behaviors that merit investigation. This is part of the new â€œassumed breachâ€? mentality that recognizes no system is 100% secure. Unfortunately, the company at the heart of this case didnâ€™t have a comprehensive monitoring system, so had been breached for some time before updated antimalware signatures cleaned their infection and brought the breach to their attention. Besides highlighting just how weak cybersecurity is at many companies, this case highlights the use of several Sysinternals Process Monitor features, including the Process Tree dialog and one feature many people arenâ€™t aware of, Process Monitorâ€™s ability to monitor network activity.The case opened when a network administrator at a South African company contacted Microsoft Services Premier Support and reported that their corporate Exchange server, running on Windows Server 2008 R2, appeared to be making outbound FTP connections. They noticed this only because the companyâ€™s installation of Microsoft Forefront Endpoint Protection (FEP) alerted them that it had cleaned a piece of malware it found on the server. Concerned that their network might still be compromised despite the fact that FEP claimed the system was malware-free, he examined the companyâ€™s perimeter firewall logs. To his horror, he discovered FTP connections that numbered in the hundreds per day and dated back several weeks. Instead of attempting a forensic examination on his own, he called on Microsoftâ€™s security consulting team, which specializes in helping customers clean up after an attack.The Microsoft support engineer assigned the case began by capturing a five-minute Process Monitor trace of the Exchange server. After stopping the trace he opened the Process Tree dialog (under the Tools menu), which shows the parent-child relationships of all the processes that existed at any point in the current trace. He quickly found that around 20 FTP processes had been launched during the collection, each of them short-lived, except for one, which was still active (process 7324 below):The engineer looked at the command lines for the FTP processes by selecting them in the tree so that their details appeared at the bottom of the Process Tree dialog. The command lines for the half of them bizarrely included just the â€œ-?â€? argument, which simply brings up FTP help:The other half were more interesting, including â€œ-iâ€? and â€œ-sâ€? switches:The â€“i switch has FTP turn off prompting for multiple file transfers, and â€“s directs FTP to execute the FTP commands listed in a file, in this case a file named â€œjâ€?.Â  Setting out to find out what file 'â€?jâ€? contained, he clicked on the â€œInclude Processâ€? button at the bottom of the Process Tree dialog so that he could find the processâ€™s file events:He searched the resulting filtered trace for â€œjâ€? and found the fileâ€™s location in several of the events:He navigated to the C:\Windows\System32\i4333 directory, but the â€œjâ€? file was gone. That being a dead end, he turned his attention to the FTP processâ€™s parent, Cmd.exe, and looked at its command line. The line was too long and convoluted to easily understand:He selected it, typed Ctrl+C to copy it to the clipboard, pasted it into Notepad, and decomposed it into its constituent components, each of which was separated by a â€œ&â€?. The result looked like this:The first instruction has the command prompt create a directory named i4333 and then start creating the contents of the â€œjâ€? file. The commands it writes into â€œjâ€? instruct FTP to connect to NUXZb.in.into4.info, login with the user name â€œNewâ€? and the password â€œ123â€?, then download all the files on the FTP server that end with â€œ.exeâ€?. After FTP has processed the file, the command prompt deletes â€œjâ€? and then creates a batch file that executes the downloaded files, first using the Shell to launch them (â€œstartâ€?) and then the Command Prompt.A quick detour to Whois showed the engineer that the NUXZb hostname was issued by Protected Name Services and didnâ€™t reveal any useful information. The engineer toggled off Process Monitorâ€™s network name resolution and found the outbound FTP connection in the trace to see the IP address the name had resolved to:An IP address location lookup on the Web pinpointed the IP address at an ISP in Chicago (the name now resolves to a different IP address), so he concluded the connection was to a server that was also compromised or one the attacker had hosted at the ISP. Finished analyzing the command line, he looked at the contents of the resulting script, D.bat, which was still in the directory and contained this single command:Not coincidentally, 134.exe was the executable Forefront had flagged as a remote access Trojan (RAT) in the alerts that the administrator first responded to. The script could therefore not find it, making it seem that the attack â€“ or at least this part of it - had been neutralized by FEP. It also implied that the attack was automated and stuck in a loop trying to activate.The engineer next set out to determine how the command-prompt processes were being launched. Looking at their parent processes in the process tree, he learned they were all launched from Sqlserver.exe:This obviously wasnâ€™t a good sign, but it wasnâ€™t the worst of it: examining SQL Serverâ€™s network activity in the trace, he saw many incoming connections:Lookups of the IP address locations placed them in China, Tunisia, Taiwan, and Morocco:The SQL Server was being used by an attacker or multiple attackers from around the world in countries known for being cybercriminal safe havens. It was clearly time to flatten the server, but before calling the administrator to give him the bad news and advise him to immediately disconnect the server from the network, he thought heâ€™d spend a few minutes examining the security of the SQL Server. Understanding what had led to the compromise could help the company avoid being compromised the same way again.He launched a Microsoft support batch file that checks various SQL Server security settings. The tool ran for a few seconds and then printed its discouraging results: the server had an administrator account with a blank password, was configured for mixed-mode authentication, and allowed stored procedures to launch command prompts via the enablement of the â€œxp_cmdshellâ€? feature:That meant that anyone on the Internet could logon to the server without a password and execute executables â€“ like FTP â€“ to infect the system with their own tools.With the help of Process Monitor and some discussion with the companyâ€™s administrator, the support engineer had a solid theory for what had happened: an administrator at the company had installed SQL Server on the companyâ€™s Exchange server several weeks prior to the incident. Not realizing the server was on the perimeter, they had opened the SQL Serverâ€™s port in the local firewall, left it with a blank admin account, and enabled xp_cmdshell. It goes without saying that even if the server wasnâ€™t on the Internet, that configuration leaves a server without any network security. Not long after, automated malware scanning the Internet for exposed targets had stumbled across the open SQL port, infected the server with malware, and likely enlisted it in a Botnet. FEP signatures for the new malware variant were delivered to the server some time later and removed the infection. The Botnet-enlisting malware was still trying to reintegrate the server when the case with Microsoft support was opened. While the company canâ€™t know how much â€“ if any â€“ of its corporate data was pilfered during the infection, this was a very loud and clear wakeup call.You can test your own cybersecurity knowledge by taking my Operation Desolation cybersecurity quiz.NEW YORK (CNNMoney) -- A number of popular websites went down late Monday after Superstorm Sandy took out a major Internet service provider.The Huffington Post, Gawker and many other sites were unreachable after Datagram, a New York-based provider of corporate Internet connections and servers, said it was battling flooding in its offices. The floods caused Datagram's fiber network to lose power, and the company said its backup generators were rendered useless because the diesel fuel pumps used to refuel generators were offline.Datagram is located on 33 Whitehall Street in Battery Park -- a large area of reclaimed land at the southern tip of Manhattan that was in an evacuation zone. It was among the worst-hit areas in the city.BuzzFeed, another Datagram customer, was able to get its site back up online and running Tuesday afternoon.On its Tumblr page, the company said Datagram told its staff that its basement was flooded with five feet of water. A Datagram representative was unreachable for comment.Many sites were updating their status on Twitter and publishing news stories on Tumblr accounts.Gawker was completely unreachable Tuesday morning."Gawker is temporarily down because the 57th Street Crane just flooded our servers with sea foam, or something," the company posted on Twitter. "Back with you shortly."The Huffington Post's site was down Tuesday morning, but it automatically redirected to a company blog. "We are working around the clock to get the site back to normal," the news organization, owned by AOL (AOL), noted. AOL's site was unaffected by the storm. The site came back online around noon ET.Cloud storage company Internap, located just four blocks away from Datagram, also flooded and was unable to refuel its generators. The company issued an emergency notification to customers suggesting they back up their data and make contingency plans.What do you get when you combine a pumpkin with the classic video game Tetris? Pumpktris! Fully playable, embedded in a pumpkin, and with the stem serving as a controller. Watch the video below to see it in action, then read on for the development story.One of my habits is to write down all the crazy, fleeting ideas I have, then go back to review later rather than judging right off the bat, or even worse, forgetting them. Â Earlier in the month I was looking through that idea notepad and found â€œMake Tetris Pumpkinsâ€? from sometime last year. My original plan had been to make forms to shape pumpkins into Tetris pieces as they grew, then stack them together for Halloween. Since Halloween was only a few weeks away and it was too late to start growing pumpkins, I thought â€œWhy not make a pumpkin you can play Tetris on instead?â€?I had a LOLShield I hadnâ€™t assembled yet, and I knew that someone had already written Tetris for it, so I figured it would be a simple matter to poke some holes in the pumpkin to match the LEDs, make a controller, and be done. But oh no, that would be too simple, and would look kind of lame. Little tiny LEDs, all stuck together on a 2Ã—3â€³ area? Nahhhh.Plan B: Still use the LOLshield, but instead of mounting LEDs in the shield I would wire them up externally so I could space them out more on the pumpkin. Luckily, I didnâ€™t get too far down that route before I realized that the bundle of wires between the LEDs and the shield would be as thick as my wrist and a nightmare to solder and organize.I was going to have to make my own LED matrix and program my own Tetris. With the decision made, I ordered 140 amber LEDs from Mouser and a pair of LED Matrix I2C â€œbackpacksâ€? from Adafruit. These little circuits come with a mini (.8â€³ square) LED matrix that I could use for programming instead of having to wire up my own LED matrix right from the start..The first step was to make the LED matrix, and for that Iâ€™m grateful to have found this guide on hackaday.com to making a 70 LED matrix. My construction steps were essentially the same (plus 58 more LEDs), but Iâ€™ll go through them here anyway. For more theory, check out their post. Mine leans toward â€œwhat I didâ€? rather than â€œwhy you should do it this way.â€?It started with cutting 112 pieces of 2.5â€³ wire and 16 pieces of 8â€³ wire. The short ones would go between each LED, and the long ones would run to the controller. A cutting mat made it easy to quickly and accurately measure out the lengths.Next I soldered seven short wires and one long one into a daisy chain. Then again 15 more timesâ€”one for each row and one for each column in the matrix.A jig was needed for assembly, and here I differed from Hackaday. Instead of drilling hardboard, I opted to poke holes into 1/4â€³ foam-core board with an awl. It was a lot quicker than a drill would be, and the foam-core board had a little bit of give so that I could make the holes small and theyâ€™d stretch out to hold the LED securely while I soldered.With a row of LEDS poked into holes, I tinned the base of each anode and clipped it short, then soldered the wire daisy-chain down the line. At each joint I slipped on a half-inch of heat-shrink tubing before soldering. Iâ€™m proud to say there were only a couple of times I forgot the heat-shrink and had to go back. What caused more trouble was being in a hurry and sliding the tubing down to the joint while it was still hot. It would start to shrink up and wouldnâ€™t fit over the connection on the LEDs.When eight rows of LEDs were finally strung together, it was time to mount them all into the jig and solder on the cathode columns. The procedure with the heat-shrink was the same. As each column was finished I would pull it out of the jig and fold it out of the way in order to reach the next column.But guess what? Thatâ€™s only one, and 8Ã—8 isnâ€™t enough room for a game of Tetris, so it all got done again! Iâ€™ll spare you a rerun on the pictures and description, but if you want to you can go back up and read it again to get the full experience.TheÂ Adafruit LED Matrix BackpackÂ is meant to have its LED matrix soldered right to the board, but instead I soldered on female headers that would permit me to plug in either the mini LED matrix for code testing or the large matrix for deployment. Someone will probably be along to tell me I need a resistor here or there or Iâ€™m going to blow some chip upâ€”and theyâ€™re likely rightâ€”but it seems to have worked so far as-is.To connect my own matrix to the I2C Backpack, I cut down a piece of prototyping board and soldered in the male headers, then connected the 8â€³ wires from the last row and last column of the matrix to the board.Would it work, though? I needed some code in order to find out.I did all coding with the hardware mounted on my bamboo prototyping board. The mini matrices in the I2C backpack sockets fit on the desk much better than the big, floppy matrices I built would have.There are seven Tetrominosâ€”yes, thatâ€™s what theyâ€™re calledâ€”in the game. Each has four points, as implied by the â€œtetraâ€? prefix. A three-dimensional array stores the location of every pixel of every shape, in each of four possible rotations. Storing each rotation is a lot easier (for my brain at least) than calculating it on the fly. As an example, hereâ€™s the T shape:To draw the active piece the program keeps an activePiece variable (the index of the shape in the array) and a rotation variable (the index of the rotation description of that shape), then offsets each pixel pair that it pulls out by a yOffset and xOffset of how far down the screen itâ€™s moved and how far left or right.It also keeps an array describing the status of each â€œfixedâ€? piece. With every move of the active piece, whether by gravity or by user control, it checks against that fixed-piece array to see if the requested move can be made without a collision. If the forbidden movement is left, right, or a rotation, it simply doesnâ€™t make the move. If the forbidden movement is vertical it considers the piece to have landed and writes the piece to the array of fixed pieces, then launches a new active piece. Along the way it keeps score, tracks the level, speeds up the drop of the active piece as the game goes on, etc.This project required the perfect arcade cabinetâ€”errr, I mean pumpkin. It had to be tall enough that the eight-inch tall matrix wouldnâ€™t wrap too far around the bottom or top, and it needed a nice straight stem. I bought 3 pumpkins in a row, thinking each was perfect until I got it home and realized one thing or another wouldnâ€™t work. Finally I found what I needed and the other pumpkins were relegated to prototyping duty for practice drilling holes and cutting.To get inside the pumpkin I cut a large opening on the back. It wouldnâ€™t work to cut from the top because I wanted the controller up there, and it would be easier to put the LEDs straight in from the back rather than the top.With a paper template taped on to the pumpkin, I poked guide holes through the orange flesh.Once the holes were marked I drilled through with a 13/64â€³ bit.And since round pixels just would not do for a proper Tetris game, I cut a square around each hole with an X-Acto blade. The ends of the holes on the inside of the pumpkin were left round.To turn the stem into a joystick I carefully sawed the it off at its base and drilled a 1-1/8â€³ hole right where the shaft would pass through.I squared off the inside of the pumpkin below the stem, cut down some drywall anchors so they wouldnâ€™t poke through the pumpkin, and screwed them in. Later I would attach the joystick with short screws into the drywall anchors.For a controller I used short handle joystick from SparkFun, with the red ball unscrewed and replaced with the stem of the pumpkin. I think Iâ€™m going to call this the Â â€?joystemâ€? from now on, as disgusting as that may sound.Â I drilled a hole in the detached stem and epoxied in a 6mm bolt, then screwed that into a coupling nut on the joystick shaft.One at a time, I started to poke each LED into its slimy place. It wasnâ€™t long before a problem became apparent: there were 16 rows of holes on the outside, but only 15 on the inside. The angle that the holes were drilled toward the top of the pumpkin had the two rows coming together into a single row. I was eventually able to squeeze the LEDs past each other and direct them into their appropriate shafts. Once the LEDs were in, IÂ attached the joystem.I plugged each matrix into the I2C backpack and then that into the Arduino. Usually Iâ€™ll build a standalone bare-bones controller board, but since this was definitely not a permanent piece I used the Arduino board. Power was provided by eight rechargeable AA batteries.It was time to play Pumpktris!Everything worked great, except for some occasional glitches in the top matrix as the night went on. Maybe a power supply issue, but itâ€™s also possible there might be some intermittent shorts that happen when you bury that many electrical connections inside a pumpkin. Itâ€™s also weird playing with the controller on the top and the display underneath, so if I were to do it again I would wire the joystem into a separate pumpkin, either wireless or with the wire made to look like a vine.Next up? Porting Halo to a watermelon.** No, not really.